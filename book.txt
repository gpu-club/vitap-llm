Praise for earlier editions of
Software Engineering: A Practitioner’s Approach
“Roger Pressman has written a solid comprehensive guidebook for the /f#5fi  eld of software 
engineering for both students of the discipline and software developers and managers 
practicing it—or needing to practice it.” IEEE Software
“This is a classic modern textbook, clear and authoritative, with lots of pictures, examples, 
questions and references ... . I recommend it to anyone who asks, ‘What is software 
engineering and where is it now?’ ACM Computing Reviews
“An up-to-the minute, in-depth treatment of the software engineering process.”
Byte Book Club (main selection)
“... had the best explanations of what I want to cover ...”
“... The de/f#5fi  nitive book on the subject as far as I’m concerned ...”
“... A good textbook as well as reference ...” from comp.software-eng FAQ
“As a practicing Software Engineer, I /f#5fi  nd this book to be invaluable. It has served as 
a great reference for all the projects that I have worked on.”
“This book is a framework on how to develop high quality software.”
reviews from Amazon.com
For almost three decades, Software Engineering: A Practitioner’s Approach has been the best selling guide to software 
engineering for students and industry professionals alike.
In its seventh edition, the book has been restructured and redesigned, undergoing a substantial content update 
that addresses every important topic in what many have called “the engineering discipline of the 21st century.” 
Unique sidebars and marginal content have been expanded and enhanced, o/f#5ff  ering the reader an entertaining 
and informative complement to chapter topics. New chapters and a new organization make the book still easier 
to use in the classroom and as a self-study guide.
  Part 1, The Software Process, presents both prescriptive and agile process models.
  Part 2, Modeling, presents modern analysis and design methods with a new emphasis on UML-based modeling. 
   Part 3, Quality Management, is new for the seventh edition and address all aspects of software testing, quality 
assurance, formal veri/f#5fi  cation techniques, and change management.
   Part 4, Managing Software Projects, presents topics that are relevant to those who plan, manage, and control 
a software project. 
   Part 5, Advanced Topics, presents dedicated chapters that address software process improvement and 
future software engineering trends.
Roger Pressman, continuing in the tradition of his earlier editions, has written a book that will serve as an excellent 
guide to software engineering for everyone who must understand, build, or manage computer-based systems.
Visit the book’s On-Line Learning Center at www.mhhe.com/pressman.
The site, visited by thousands of readers each month, has been signi/f#5fi  cantly expanded and updated to provide 
comprehensive software engineering resources for students, instructors, and industry professionals.Software Engineering
A Practitioner’s Approach
Seventh Edition
Roger S. PressmanSeventh 
EditionSoftware EngineeringA Practitioner’s Approach
Pressman
Roger S. Pressman, Ph.D
MD DALIM #1001702 12/23/08 CYAN MAG YELO BLKSoftware Engineering
A PRACTITIONER ’S APPROACHpre75977_FM.qxd  11/27/08  6:38 PM  Page ipre75977_FM.qxd  11/27/08  6:38 PM  Page iiSoftware Engineering
A PRACTITIONER ’S APPROACH
SEVENTH EDITION
Roger S. Pressman, Ph.D.pre75977_FM.qxd  11/27/08  6:38 PM  Page iiiSOFTWARE ENGINEERING: A PRACTITIONER’S APPROACH, SEVENTH EDITIONPublished by McGraw-Hill, a business unit of The McGraw-Hill Companies, Inc., 1221 Avenue of the Americas, NewYork, NY 10020. Copyright © 2010 by The McGraw-Hill Companies, Inc. All rights reserved. Previous editions © 2005,2001, and 1997. No part of this publication may be reproduced or distributed in any form or by any means, or storedin a database or retrieval system, without the prior written consent of The McGraw-Hill Companies, Inc., including,but not limited to, in any network or other electronic storage or transmission, or broadcast for distance learning.Some ancillaries, including electronic and print components, may not be available to customers outsidethe United States.This book is printed on acid-free paper. 1 2 3 4 5 6 7 8 9 0 DOC/DOC 0 9ISBN 978–0–07–337597–7MHID 0–07–337597–7Global Publisher: Raghothaman SrinivasanDirector of Development: Kristine Tibbetts Senior Marketing Manager: Curt Reynolds Senior Managing Editor: Faye M. SchillingLead Production Supervisor: Sandy LudovissySenior Media Project Manager: Sandra M. SchneeAssociate Design Coordinator: Brenda A. RolwesCover Designer: Studio Montage, St. Louis, Missouri(USE) Cover Image: © The Studio Dog/Getty ImagesCompositor: Macmillan Publishing SolutionsTypeface: 8.5/13.5 LeawoodPrinter: R. R. Donnelley Crawfordsville, INLibrary of Congress Cataloging-in-Publication DataPressman, Roger S.Software engineering : a practitioner’s approach / Roger S. Pressman. — 7th ed.p. cm.Includes index.ISBN 978–0–07–337597–7 — ISBN  0–07–337597–7 (hard copy : alk. paper)1. Software engineering. I. Title.QA76.758.P75 2010005.1—dc22 2008048802
www.mhhe.compre75977_FM.qxd  11/27/08  6:38 PM  Page ivIn loving memory of myfather who lived 94 yearsand taught me, above all,that honesty and integritywere the best guides formy journey through life.pre75977_FM.qxd  11/27/08  6:38 PM  Page vRoger S. Pressman is an internationally recognized authority in software processimprovement and software engineering technologies. For almost four decades,he has worked as a software engineer, a manager, a professor, an author, and a con-sultant, focusing on software engineering issues.As an industry practitioner and manager, Dr. Pressman worked on the developmentof CAD/CAM systems for advanced engineering and manufacturing applications. Hehas also held positions with responsibility for scientific and systems programming.After receiving a Ph.D. in engineering from the University of Connecticut,Dr. Pressman moved to academia where he became Bullard Associate Professor ofComputer Engineering at the University of Bridgeport and director of the university’sComputer-Aided Design and Manufacturing Center.Dr. Pressman is currently president of R.S. Pressman & Associates, Inc., a consultingfirm specializing in software engineering methods and training. He serves as principalconsultant and has designed and developed Essential Software Engineering,a complete video curriculum in software engineering, and Process Advisor,a self-directed system for software process improvement. Both products are used by thousands of companiesworldwide. More recently, he has worked in collaboration with EdistaLearningin India to develop comprehensive Internet-based training in software engineering.Dr. Pressman has written many technical papers, is a regular contributor toindustry periodicals, and is author of seven technical books. In addition to SoftwareEngineering: A Practitioner’s Approach, he has co-authored Web Engineering (McGraw-Hill), one of the first books to apply a tailored set of software engineeringprinciples and practices to the development of Web-based systems and applications.He has also written the award-winning A Manager’s Guide to Software Engineering(McGraw-Hill); Making Software Engineering Happen(Prentice Hall), the first book to address the critical management problems associated with software processimprovement; and Software Shock(Dorset House), a treatment that focuses on soft-ware and its impact on business and society. Dr. Pressman has been on the editorialboards of a number of industry journals, and for many years, was editor of the“Manager” column in IEEE Software.Dr. Pressman is a well-known speaker, keynoting a number of major industryconferences. He is a member of the IEEE, and Tau Beta Pi, Phi Kappa Phi, Eta KappaNu, and Pi Tau Sigma.On the personal side, Dr. Pressman lives in South Florida with his wife, Barbara.An athlete for most of his life, he remains a serious tennis player (NTRP 4.5) and asingle-digit handicap golfer. In his spare time, he has written two novels, The Aymara Bridgeand The Puppeteer,and plans to begin work on another.ABOUT THE AUTHOR
vipre75977_FM.qxd  11/27/08  6:38 PM  Page viCONTENTS AT A GLANCE
CHAPTER 1Software and Software Engineering 1
PART ONE THE SOFTWARE PROCESS 29
CHAPTER 2Process Models 30CHAPTER 3Agile Development 65
PART TWO MODELING 95
CHAPTER 4Principles that Guide Practice 96CHAPTER 5Understanding Requirements 119CHAPTER 6Requirements Modeling: Scenarios, Information, and Analysis Classes 148CHAPTER 7Requirements Modeling: Flow, Behavior, Patterns, and WebApps 186CHAPTER 8Design Concepts 215CHAPTER 9Architectural Design 242CHAPTER 10Component-Level Design 276CHAPTER 11User Interface Design 312CHAPTER 12Pattern-Based Design 347CHAPTER 13WebApp Design 373
PART THREE QUALITY MANAGEMENT 397
CHAPTER 14Quality Concepts 398CHAPTER 15Review Techniques 416CHAPTER 16Software Quality Assurance 432CHAPTER 17Software Testing Strategies 449CHAPTER 18Testing Conventional Applications 481CHAPTER 19Testing Object-Oriented Applications 511CHAPTER 20Testing Web Applications 529CHAPTER 21Formal Modeling and Verification 557CHAPTER 22Software Configuration Management 584CHAPTER 23Product Metrics 613
PART FOUR MANAGING SOFTWARE PROJECTS 645
CHAPTER 24Project Management Concepts 646CHAPTER 25Process and Project Metrics 666 viipre75977_FM.qxd  11/27/08  6:38 PM  Page viiCHAPTER 26Estimation for Software Projects 691CHAPTER 27Project Scheduling 721CHAPTER 28Risk Management 744CHAPTER 29Maintenance and Reengineering 761
PART FIVE ADVANCED TOPICS 785
CHAPTER 30Software Process Improvement 786CHAPTER 31Emerging Trends in Software Engineering 808CHAPTER 32Concluding Comments 833APPENDIX 1An Introduction to UML 841APPENDIX 2Object-Oriented Concepts 863REFERENCES871INDEX889viiiPART TWOCONTENTS AT A GLANCEpre75977_FM.qxd  11/27/08  6:38 PM  Page viiiTABLE OF CONTENTS
Preface xxv
CHAPTER 1 SOFTWARE AND SOFTWARE ENGINEERING 11.1 The Nature of Software 31.1.1 Defining Software 41.1.2 Software Application Domains 71.1.3 Legacy Software 91.2 The Unique Nature of WebApps 101.3 Software Engineering 121.4 The Software Process 141.5 Software Engineering Practice 171.5.1 The Essence of Practice 171.5.2 General Principles 191.6 Software Myths 211.7 How It All Starts 241.8 Summary 25
PROBLEMS AND POINTS TO PONDER 25
FURTHER READINGS AND INFORMATION SOURCES 26
PART ONE THE SOFTWARE PROCESS 29
CHAPTER 2 PROCESS MODELS 302.1 A Generic Process Model 312.1.1 Defining a Framework Activity 322.1.2 Identifying a Task Set 342.1.3 Process Patterns 352.2 Process Assessment and Improvement 372.3 Prescriptive Process Models 382.3.1 The Waterfall Model 392.3.2 Incremental Process Models 412.3.3 Evolutionary Process Models 422.3.4 Concurrent Models 482.3.5 A Final Word on Evolutionary Processes 492.4 Specialized Process Models 502.4.1 Component-Based Development 502.4.2 The Formal Methods Model 512.4.3 Aspect-Oriented Software Development 522.5 The Unified Process 532.5.1 A Brief History 542.5.2 Phases of the Unified Process 542.6 Personal and Team Process Models 562.6.1 Personal Software Process (PSP) 572.6.2 Team Software Process (TSP) 582.7 Process Technology 592.8 Product and Process 60 ixpre75977_FM.qxd  11/27/08  6:38 PM  Page ix2.9 Summary 61
PROBLEMS AND POINTS TO PONDER 62
FURTHER READINGS AND INFORMATION SOURCES 63
CHAPTER 3 AGILE DEVELOPMENT 653.1 What Is Agility? 673.2 Agility and the Cost of Change 673.3 What Is an Agile Process? 683.3.1 Agility Principles 693.3.2 The Politics of Agile Development 703.3.3 Human Factors 713.4 Extreme Programming (XP) 723.4.1 XP Values 723.4.2 The XP Process 733.4.3 Industrial XP 773.4.4 The XP Debate 783.5 Other Agile Process Models 803.5.1 Adaptive Software Development (ASD) 813.5.2 Scrum 823.5.3 Dynamic Systems Development Method (DSDM) 843.5.4 Crystal 853.5.5 Feature Driven Development (FDD) 863.5.6 Lean Software Development (LSD) 873.5.7 Agile Modeling (AM) 883.5.8 Agile Unified Process (AUP) 893.6 A Tool Set for the Agile Process 913.7 Summary 91
PROBLEMS AND POINTS TO PONDER 92
FURTHER READINGS AND INFORMATION SOURCES 93
PART TWO MODELING 95
CHAPTER 4 PRINCIPLES THAT GUIDE PRACTICE 964.1 Software Engineering Knowledge 974.2 Core Principles 984.2.1 Principles That Guide Process 984.2.2 Principles That Guide Practice 994.3 Principles That Guide Each Framework Activity 1014.3.1 Communication Principles 1014.3.2 Planning Principles 1034.3.3 Modeling Principles 1054.3.4 Construction Principles 1114.3.5 Deployment Principles 1134.4 Summary 115
PROBLEMS AND POINTS TO PONDER 116
FURTHER READINGS AND INFORMATION SOURCES 116
CHAPTER 5 UNDERSTANDING REQUIREMENTS 1195.1 Requirements Engineering 1205.2 Establishing the Groundwork 1255.2.1 Identifying Stakeholders 125xTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page x5.2.2 Recognizing Multiple Viewpoints 1265.2.3 Working toward Collaboration 1265.2.4 Asking the First Questions 1275.3 Eliciting Requirements 1285.3.1 Collaborative Requirements Gathering 1285.3.2 Quality Function Deployment 1315.3.3 Usage Scenarios 1325.3.4 Elicitation Work Products 1335.4 Developing Use Cases 1335.5 Building the Requirements Model 1385.5.1 Elements of the Requirements Model 1395.5.2 Analysis Patterns 1425.6 Negotiating Requirements 1425.7 Validating Requirements 1445.8 Summary 145
PROBLEMS AND POINTS TO PONDER 145
FURTHER READINGS AND INFORMATION SOURCES 146CHAPTER 6 REQUIREMENTS MODELING: SCENARIOS, INFORMATION,
AND ANALYSIS CLASSES 1486.1 Requirements Analysis 1496.1.1 Overall Objectives and Philosophy 1506.1.2 Analysis Rules of Thumb 1516.1.3 Domain Analysis 1516.1.4 Requirements Modeling Approaches 1536.2 Scenario-Based Modeling 1546.2.1 Creating a Preliminary Use Case 1556.2.2 Refining a Preliminary Use Case 1586.2.3 Writing a Formal Use Case 1596.3 UML Models That Supplement the Use Case 1616.3.1 Developing an Activity Diagram 1616.3.2 Swimlane Diagrams 1626.4 Data Modeling Concepts 1646.4.1 Data Objects 1646.4.2 Data Attributes 1646.4.3 Relationships 1656.5 Class-Based Modeling 1676.5.1 Identifying Analysis Classes 1676.5.2 Specifying Attributes 1716.5.3 Defining Operations 1716.5.4 Class-Responsibility-Collaborator (CRC) Modeling 1736.5.5 Associations and Dependencies 1806.5.6 Analysis Packages 1826.6 Summary 183
PROBLEMS AND POINTS TO PONDER 183
FURTHER READINGS AND INFORMATION SOURCES 184CHAPTER 7 REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS,
AND WEBAPPS 1867.1 Requirements Modeling Strategies 1867.2 Flow-Oriented Modeling 187TABLE OF CONTENTS xipre75977_FM.qxd  11/27/08  6:38 PM  Page xi7.2.1 Creating a Data Flow Model 1887.2.2 Creating a Control Flow Model 1917.2.3 The Control Specification 1917.2.4 The Process Specification 1927.3 Creating a Behavioral Model 1957.3.1 Identifying Events with the Use Case 1957.3.2 State Representations 1967.4 Patterns for Requirements Modeling 1997.4.1 Discovering Analysis Patterns 2007.4.2 A Requirements Pattern Example: Actuator-Sensor 2007.5 Requirements Modeling for WebApps 2057.5.1 How Much Analysis Is Enough? 2057.5.2 Requirements Modeling Input 2067.5.3 Requirements Modeling Output 2077.5.4 Content Model for WebApps 2077.5.5 Interaction Model for WebApps 2097.5.6 Functional Model for WebApps 2107.5.7 Configuration Models for WebApps 2117.5.8 Navigation Modeling 2127.6 Summary 213
PROBLEMS AND POINTS TO PONDER 213
FURTHER READINGS AND INFORMATION SOURCES 214
CHAPTER 8 DESIGN CONCEPTS 2158.1 Design within the Context of Software Engineering 2168.2 The Design Process 2198.2.1 Software Quality Guidelines and Attributes 2198.2.2 The Evolution of Software Design 2218.3 Design Concepts 2228.3.1 Abstraction 2238.3.2 Architecture 2238.3.3 Patterns 2248.3.4 Separation of Concerns 2258.3.5 Modularity 2258.3.6 Information Hiding 2268.3.7 Functional Independence 2278.3.8 Refinement 2288.3.9 Aspects 2288.3.10 Refactoring 2298.3.11 Object-Oriented Design Concepts 2308.3.12 Design Classes 2308.4 The Design Model 2338.4.1 Data Design Elements 2348.4.2 Architectural Design Elements 2348.4.3 Interface Design Elements 2358.4.4 Component-Level Design Elements 2378.4.5 Deployment-Level Design Elements 2378.5 Summary 239
PROBLEMS AND POINTS TO PONDER 240
FURTHER READINGS AND INFORMATION SOURCES 240xiiTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xiiCHAPTER 9 ARCHITECTURAL DESIGN 2429.1 Software Architecture 2439.1.1 What Is Architecture? 2439.1.2 Why Is Architecture Important? 2459.1.3 Architectural Descriptions 2459.1.4 Architectural Decisions 2469.2 Architectural Genres 2469.3 Architectural Styles 2499.3.1 A Brief Taxonomy of Architectural Styles 2509.3.2 Architectural Patterns 2539.3.3 Organization and Refinement 2559.4 Architectural Design 2559.4.1 Representing the System in Context 2569.4.2 Defining Archetypes 2579.4.3 Refining the Architecture into Components 2589.4.4 Describing Instantiations of the System 2609.5 Assessing Alternative Architectural Designs 2619.5.1 An Architecture Trade-Off Analysis Method 2629.5.2 Architectural Complexity 2639.5.3 Architectural Description Languages 2649.6 Architectural Mapping Using Data Flow 2659.6.1 Transform Mapping 2659.6.2 Refining the Architectural Design 2729.7 Summary 273
PROBLEMS AND POINTS TO PONDER 274
FURTHER READINGS AND INFORMATION SOURCES 274
CHAPTER 10 COMPONENT-LEVEL DESIGN 27610.1 What Is a Component? 27710.1.1 An Object-Oriented View 27710.1.2 The Traditional View 27910.1.3 A Process-Related View 28110.2 Designing Class-Based Components 28210.2.1 Basic Design Principles 28210.2.2 Component-Level Design Guidelines 28510.2.3 Cohesion 28610.2.4 Coupling 28810.3 Conducting Component-Level Design 29010.4 Component-Level Design for WebApps 29610.4.1 Content Design at the Component Level 29710.4.2 Functional Design at the Component Level 29710.5 Designing Traditional Components 29810.5.1 Graphical Design Notation 29910.5.2 Tabular Design Notation 30010.5.3 Program Design Language 30110.6 Component-Based Development 30310.6.1 Domain Engineering 30310.6.2 Component Qualification, Adaptation, and Composition 30410.6.3 Analysis and Design for Reuse 30610.6.4 Classifying and Retrieving Components 307TABLE OF CONTENTS xiiipre75977_FM.qxd  11/27/08  6:38 PM  Page xiii10.7 Summary 309
PROBLEMS AND POINTS TO PONDER 310
FURTHER READINGS AND INFORMATION SOURCES 311
CHAPTER 11 USER INTERFACE DESIGN 31211.1 The Golden Rules 31311.1.1 Place the User in Control 31311.1.2 Reduce the User’s Memory Load 31411.1.3 Make the Interface Consistent 31611.2 User Interface Analysis and Design 31711.2.1 Interface Analysis and Design Models 31711.2.2 The Process 31911.3 Interface Analysis 32011.3.1 User Analysis 32111.3.2 Task Analysis and Modeling 32211.3.3 Analysis of Display Content 32711.3.4 Analysis of the Work Environment 32811.4 Interface Design Steps 32811.4.1 Applying Interface Design Steps 32911.4.2 User Interface Design Patterns 33011.4.3 Design Issues 33111.5 WebApp Interface Design 33511.5.1 Interface Design Principles and Guidelines 33611.5.2 Interface Design Workflow for WebApps 34011.6 Design Evaluation 34211.7 Summary 344
PROBLEMS AND POINTS TO PONDER 345
FURTHER READINGS AND INFORMATION SOURCES 346
CHAPTER 12 PATTERN-BASED DESIGN 34712.1 Design Patterns 34812.1.1 Kinds of Patterns 34912.1.2 Frameworks 35212.1.3 Describing a Pattern 35212.1.4 Pattern Languages and Repositories 35312.2 Pattern-Based Software Design 35412.2.1 Pattern-Based Design in Context 35412.2.2 Thinking in Patterns 35612.2.3 Design Tasks 35712.2.4 Building a Pattern-Organizing Table 35812.2.5 Common Design Mistakes 35912.3 Architectural Patterns 36012.4 Component-Level Design Patterns 36212.5 User Interface Design Patterns 36412.6 WebApp Design Patterns 36812.6.1 Design Focus 36812.6.2 Design Granularity 36912.7 Summary 370
PROBLEMS AND POINTS TO PONDER 371
FURTHER READING AND INFORMATION SOURCES 372xivTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xivCHAPTER 13 WEBAPP DESIGN 37313.1 WebApp Design Quality 37413.2 Design Goals 37713.3 A Design Pyramid for WebApps 37813.4 WebApp Interface Design 37813.5 Aesthetic Design 38013.5.1 Layout Issues 38013.5.2 Graphic Design Issues 38113.6 Content Design 38213.6.1 Content Objects 38213.6.2 Content Design Issues 38213.7 Architecture Design 38313.7.1 Content Architecture 38413.7.2 WebApp Architecture 38613.8 Navigation Design 38813.8.1 Navigation Semantics 38813.8.2 Navigation Syntax 38913.9 Component-Level Design 39013.10 Object-Oriented Hypermedia Design Method (OOHDM) 39013.10.1 Conceptual Design for OOHDM 39113.10.2 Navigational Design for OOHDM 39113.10.3 Abstract Interface Design and Implementation 39213.11 Summary 393
PROBLEMS AND POINTS TO PONDER 394
FURTHER READINGS AND INFORMATION SOURCES 395
PART THREE QUALITY MANAGEMENT 397
CHAPTER 14 QUALITY CONCEPTS 39814.1 What Is Quality? 39914.2 Software Quality 40014.2.1 Garvin’s Quality Dimensions 40114.2.2 McCall’s Quality Factors 40214.2.3 ISO 9126 Quality Factors 40314.2.4 Targeted Quality Factors 40414.2.5 The Transition to a Quantitative View 40514.3 The Software Quality Dilemma 40614.3.1 “Good Enough” Software 40614.3.2 The Cost of Quality 40714.3.3 Risks 40914.3.4 Negligence and Liability 41014.3.5 Quality and Security 41014.3.6 The Impact of Management Actions 41114.4 Achieving Software Quality 41214.4.1 Software Engineering Methods 41214.4.2 Project Management Techniques 41214.4.3 Quality Control 41214.4.4 Quality Assurance 41314.5 Summary 413
PROBLEMS AND POINTS TO PONDER 414
FURTHER READINGS AND INFORMATION SOURCES 414TABLE OF CONTENTS xvpre75977_FM.qxd  11/27/08  6:38 PM  Page xvCHAPTER 15 REVIEW TECHNIQUES 41615.1 Cost Impact of Software Defects 41715.2 Defect Amplification and Removal 41815.3 Review Metrics and Their Use 42015.3.1 Analyzing Metrics 42015.3.2 Cost Effectiveness of Reviews 42115.4 Reviews: A Formality Spectrum 42315.5 Informal Reviews 42415.6 Formal Technical Reviews 42615.6.1 The Review Meeting 42615.6.2 Review Reporting and Record Keeping 42715.6.3 Review Guidelines 42715.6.4 Sample-Driven Reviews 42915.7 Summary 430
PROBLEMS AND POINTS TO PONDER 431
FURTHER READINGS AND INFORMATION SOURCES 431
CHAPTER 16 SOFTWARE QUALITY ASSURANCE 43216.1 Background Issues 43316.2 Elements of Software Quality Assurance 43416.3 SQA Tasks, Goals, and Metrics 43616.3.1 SQA Tasks 43616.3.2 Goals, Attributes, and Metrics 43716.4 Formal Approaches to SQA 43816.5 Statistical Software Quality Assurance 43916.5.1 A Generic Example 43916.5.2 Six Sigma for Software Engineering 44116.6 Software Reliability 44216.6.1 Measures of Reliability and Availability 44216.6.2 Software Safety 44316.7 The ISO 9000 Quality Standards 44416.8 The SQA Plan 44516.9 Summary 446
PROBLEMS AND POINTS TO PONDER 447
FURTHER READINGS AND INFORMATION SOURCES 447
CHAPTER 17 SOFTWARE TESTING STRATEGIES 44917.1 A Strategic Approach to Software Testing 45017.1.1 Verification and Validation 45017.1.2 Organizing for Software Testing 45117.1.3 Software Testing Strategy—The Big Picture 45217.1.4 Criteria for Completion of Testing 45517.2 Strategic Issues 45517.3 Test Strategies for Conventional Software 45617.3.1 Unit Testing 45617.3.2 Integration Testing 45917.4 Test Strategies for Object-Oriented Software 46517.4.1 Unit Testing in the OO Context 46617.4.2 Integration Testing in the OO Context 46617.5 Test Strategies for WebApps 46717.6 Validation Testing 467xviTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xvi17.6.1 Validation-Test Criteria 46817.6.2 Configuration Review 46817.6.3 Alpha and Beta Testing 46817.7 System Testing 47017.7.1 Recovery Testing 47017.7.2 Security Testing 47017.7.3 Stress Testing 47117.7.4 Performance Testing 47117.7.5 Deployment Testing 47217.8 The Art of Debugging 47317.8.1 The Debugging Process 47317.8.2 Psychological Considerations 47417.8.3 Debugging Strategies 47517.8.4 Correcting the Error 47717.9 Summary 478
PROBLEMS AND POINTS TO PONDER 478
FURTHER READINGS AND INFORMATION SOURCES 479
CHAPTER 18 TESTING CONVENTIONAL APPLICATIONS 48118.1 Software Testing Fundamentals 48218.2 Internal and External Views of Testing 48418.3 White-Box Testing 48518.4 Basis Path Testing 48518.4.1 Flow Graph Notation 48518.4.2 Independent Program Paths 48718.4.3 Deriving Test Cases 48918.4.4 Graph Matrices 49118.5 Control Structure Testing 49218.5.1 Condition Testing 49218.5.2 Data Flow Testing 49318.5.3 Loop Testing 49318.6 Black-Box Testing 49518.6.1 Graph-Based Testing Methods 49518.6.2 Equivalence Partitioning 49718.6.3 Boundary Value Analysis 49818.6.4 Orthogonal Array Testing 49918.7 Model-Based Testing 50218.8 Testing for Specialized Environments, Architectures, and Applications 50318.8.1 Testing GUIs 50318.8.2 Testing of Client-Server Architectures 50318.8.3 Testing Documentation and Help Facilities 50518.8.4 Testing for Real-Time Systems 50618.9 Patterns for Software Testing 50718.10 Summary 508
PROBLEMS AND POINTS TO PONDER 509
FURTHER READINGS AND INFORMATION SOURCES 510
CHAPTER 19 TESTING OBJECT-ORIENTED APPLICATIONS 51119.1 Broadening the View of Testing 51219.2 Testing OOA and OOD Models 513TABLE OF CONTENTS xviipre75977_FM.qxd  12/1/08  3:15 PM  Page xvii19.2.1 Correctness of OOA and OOD Models 51319.2.2 Consistency of Object-Oriented Models 51419.3 Object-Oriented Testing Strategies 51619.3.1 Unit Testing in the OO Context 51619.3.2 Integration Testing in the OO Context 51619.3.3 Validation Testing in an OO Context 51719.4 Object-Oriented Testing Methods 51719.4.1 The Test-Case Design Implications of OO Concepts 51819.4.2 Applicability of Conventional Test-Case Design Methods 51819.4.3 Fault-Based Testing 51919.4.4 Test Cases and the Class Hierarchy 51919.4.5 Scenario-Based Test Design 52019.4.6 Testing Surface Structure and Deep Structure 52219.5 Testing Methods Applicable at the Class Level 52219.5.1 Random Testing for OO Classes 52219.5.2 Partition Testing at the Class Level 52419.6 Interclass Test-Case Design 52419.6.1 Multiple Class Testing 52419.6.2 Tests Derived from Behavior Models 52619.7 Summary 527
PROBLEMS AND POINTS TO PONDER 528
FURTHER READINGS AND INFORMATION SOURCES 528
CHAPTER 20 TESTING WEB APPLICATIONS 52920.1 Testing Concepts for WebApps 53020.1.1 Dimensions of Quality 53020.1.2 Errors within a WebApp Environment 53120.1.3 Testing Strategy 53220.1.4 Test Planning 53220.2 The Testing Process—An Overview 53320.3 Content Testing 53420.3.1 Content Testing Objectives 53420.3.2 Database Testing 53520.4 User Interface Testing 53720.4.1 Interface Testing Strategy 53720.4.2 Testing Interface Mechanisms 53820.4.3 Testing Interface Semantics 54020.4.4 Usability Tests 54020.4.5 Compatibility Tests 54220.5 Component-Level Testing 54320.6 Navigation Testing 54520.6.1 Testing Navigation Syntax 54520.6.2 Testing Navigation Semantics 54620.7 Configuration Testing 54720.7.1 Server-Side Issues 54720.7.2 Client-Side Issues 54820.8 Security Testing 54820.9 Performance Testing 55020.9.1 Performance Testing Objectives 55020.9.2 Load Testing 55120.9.3 Stress Testing 552xviiiTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xviii20.10 Summary 553
PROBLEMS AND POINTS TO PONDER 554
FURTHER READINGS AND INFORMATION SOURCES 555
CHAPTER 21 FORMAL MODELING AND VERIFICATION 55721.1 The Cleanroom Strategy 55821.2 Functional Specification 56021.2.1 Black-Box Specification 56121.2.2 State-Box Specification 56221.2.3 Clear-Box Specification 56221.3 Cleanroom Design 56321.3.1 Design Refinement 56321.3.2 Design Verification 56421.4 Cleanroom Testing 56621.4.1 Statistical Use Testing 56621.4.2 Certification 56721.5 Formal Methods Concepts 56821.6 Applying Mathematical Notation for Formal Specification 57121.7 Formal Specification Languages 57321.7.1 Object Constraint Language (OCL) 57421.7.2 The Z Specification Language 57721.8 Summary 580
PROBLEMS AND POINTS TO PONDER 581
FURTHER READINGS AND INFORMATION SOURCES 582
CHAPTER 22 SOFTWARE CONFIGURATION MANAGEMENT 58422.1 Software Configuration Management 58522.1.1 An SCM Scenario 58622.1.2 Elements of a Configuration Management System 58722.1.3 Baselines 58722.1.4 Software Configuration Items 58922.2 The SCM Repository 59022.2.1 The Role of the Repository 59022.2.2 General Features and Content 59122.2.3 SCM Features 59222.3 The SCM Process 59322.3.1 Identification of Objects in the Software Configuration 59422.3.2 Version Control 59522.3.3 Change Control 59622.3.4 Configuration Audit 59922.3.5 Status Reporting 60022.4 Configuration Management for WebApps 60122.4.1 Dominant Issues 60122.4.2 WebApp Configuration Objects 60322.4.3 Content Management 60322.4.4 Change Management 60622.4.5 Version Control 60822.4.6 Auditing and Reporting 60922.5 Summary 610
PROBLEMS AND POINTS TO PONDER 611
FURTHER READINGS AND INFORMATION SOURCES 612TABLE OF CONTENTS xixpre75977_FM.qxd  11/27/08  6:38 PM  Page xixCHAPTER 23 PRODUCT METRICS 61323.1 A Framework for Product Metrics 61423.1.1 Measures, Metrics, and Indicators 61423.1.2 The Challenge of Product Metrics 61523.1.3 Measurement Principles 61623.1.4 Goal-Oriented Software Measurement 61723.1.5 The Attributes of Effective Software Metrics 61823.2 Metrics for the Requirements Model 61923.2.1 Function-Based Metrics 62023.2.2 Metrics for Specification Quality 62323.3 Metrics for the Design Model 62423.3.1 Architectural Design Metrics 62423.3.2 Metrics for Object-Oriented Design 62723.3.3 Class-Oriented Metrics—The CK Metrics Suite 62823.3.4 Class-Oriented Metrics—The MOOD Metrics Suite 63123.3.5 OO Metrics Proposed by Lorenz and Kidd 63223.3.6 Component-Level Design Metrics 63223.3.7 Operation-Oriented Metrics 63423.3.8 User Interface Design Metrics 63523.4 Design Metrics for WebApps 63623.5 Metrics for Source Code 63823.6 Metrics for Testing 63923.6.1 Halstead Metrics Applied to Testing 63923.6.2 Metrics for Object-Oriented Testing 64023.7 Metrics for Maintenance 64123.8 Summary 642
PROBLEMS AND POINTS TO PONDER 642
FURTHER READINGS AND INFORMATION SOURCES 643
PART FOUR MANAGING SOFTWARE PROJECTS 645
CHAPTER 24 PROJECT MANAGEMENT CONCEPTS 64624.1 The Management Spectrum 64724.1.1 The People 64724.1.2 The Product 64824.1.3 The Process 64824.1.4 The Project 64824.2 People 64924.2.1 The Stakeholders 64924.2.2 Team Leaders 65024.2.3 The Software Team 65124.2.4 Agile Teams 65424.2.5 Coordination and Communication Issues 65524.3 The Product 65624.3.1 Software Scope 65624.3.2 Problem Decomposition 65624.4 The Process 65724.4.1 Melding the Product and the Process 65724.4.2 Process Decomposition 65824.5 The Project 66024.6 The W
5HH Principle 661xxTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xx24.7 Critical Practices 66224.8 Summary 663
PROBLEMS AND POINTS TO PONDER 663
FURTHER READINGS AND INFORMATION SOURCES 664
CHAPTER 25 PROCESS AND PROJECT METRICS 66625.1 Metrics in the Process and Project Domains 66725.1.1 Process Metrics and Software Process Improvement 66725.1.2 Project Metrics 67025.2 Software Measurement 67125.2.1 Size-Oriented Metrics 67225.2.2 Function-Oriented Metrics 67325.2.3 Reconciling LOC and FP Metrics 67325.2.4 Object-Oriented Metrics 67525.2.5 Use-Case–Oriented Metrics 67625.2.6 WebApp Project Metrics 67725.3 Metrics for Software Quality 67925.3.1 Measuring Quality 68025.3.2 Defect Removal Efficiency 68125.4 Integrating Metrics within the Software Process 68225.4.1 Arguments for Software Metrics 68325.4.2 Establishing a Baseline 68325.4.3 Metrics Collection, Computation, and Evaluation 68425.5 Metrics for Small Organizations 68425.6 Establishing a Software Metrics Program 68625.7 Summary 688
PROBLEMS AND POINTS TO PONDER 688
FURTHER READINGS AND INFORMATION SOURCES 689
CHAPTER 26 ESTIMATION FOR SOFTWARE PROJECTS 69126.1 Observations on Estimation 69226.2 The Project Planning Process 69326.3 Software Scope and Feasibility 69426.4 Resources 69526.4.1 Human Resources 69526.4.2 Reusable Software Resources 69626.4.3 Environmental Resources 69626.5 Software Project Estimation 69726.6 Decomposition Techniques 69826.6.1 Software Sizing 69826.6.2 Problem-Based Estimation 69926.6.3 An Example of LOC-Based Estimation 70126.6.4 An Example of FP-Based Estimation 70226.6.5 Process-Based Estimation 70326.6.6 An Example of Process-Based Estimation 70426.6.7 Estimation with Use Cases 70526.6.8 An Example of Use-Case–Based Estimation 70626.6.9 Reconciling Estimates 70726.7 Empirical Estimation Models 70826.7.1 The Structure of Estimation Models 70926.7.2 The COCOMO II Model 70926.7.3 The Software Equation 711TABLE OF CONTENTS xxipre75977_FM.qxd  11/27/08  6:38 PM  Page xxi26.8 Estimation for Object-Oriented Projects 71226.9 Specialized Estimation Techniques 71326.9.1 Estimation for Agile Development 71326.9.2 Estimation for WebApp Projects 71426.10 The Make/Buy Decision 71526.10.1 Creating a Decision Tree 71526.10.2 Outsourcing 71726.11 Summary 718
PROBLEMS AND POINTS TO PONDER 719
FURTHER READINGS AND INFORMATION SOURCES 719
CHAPTER 27 PROJECT SCHEDULING 72127.1 Basic Concepts 72227.2 Project Scheduling 72427.2.1 Basic Principles 72527.2.2 The Relationship Between People and Effort 72527.2.3 Effort Distribution 72727.3 Defining a Task Set for the Software Project 72827.3.1 A Task Set Example 72927.3.2 Refinement of Software Engineering Actions 73027.4 Defining a Task Network 73127.5 Scheduling 73227.5.1 Time-Line Charts 73227.5.2 Tracking the Schedule 73427.5.3 Tracking Progress for an OO Project 73527.5.4 Scheduling for WebApp Projects 73627.6 Earned Value Analysis 73927.7 Summary 741
PROBLEMS AND POINTS TO PONDER 741
FURTHER READINGS AND INFORMATION SOURCES 743
CHAPTER 28 RISK MANAGEMENT 74428.1 Reactive versus Proactive Risk Strategies 74528.2 Software Risks 74528.3 Risk Identification 74728.3.1 Assessing Overall Project Risk 74828.3.2 Risk Components and Drivers 74928.4 Risk Projection 74928.4.1 Developing a Risk Table 75028.4.2 Assessing Risk Impact 75228.5 Risk Refinement 75428.6 Risk Mitigation, Monitoring, and Management 75528.7 The RMMM Plan 75728.8 Summary 759
PROBLEMS AND POINTS TO PONDER 759
FURTHER READINGS AND INFORMATION SOURCES 760
CHAPTER 29 MAINTENANCE AND REENGINEERING 76129.1 Software Maintenance 76229.2 Software Supportability 764xxiiTABLE OF CONTENTSpre75977_FM.qxd  11/27/08  6:38 PM  Page xxii29.3 Reengineering 76429.4 Business Process Reengineering 76529.4.1 Business Processes 76529.4.2 A BPR Model 76629.5 Software Reengineering 76829.5.1 A Software Reengineering Process Model 76829.5.2 Software Reengineering Activities 77029.6 Reverse Engineering 77229.6.1 Reverse Engineering to Understand Data 77329.6.2 Reverse Engineering to Understand Processing 77429.6.3 Reverse Engineering User Interfaces 77529.7 Restructuring 77629.7.1 Code Restructuring 77629.7.2 Data Restructuring 77729.8 Forward Engineering 77829.8.1 Forward Engineering for Client-Server Architectures 77929.8.2 Forward Engineering for Object-Oriented Architectures 78029.9 The Economics of Reengineering 78029.10 Summary 781
PROBLEMS AND POINTS TO PONDER 782
FURTHER READINGS AND INFORMATION SOURCES 783
PART FIVE ADVANCED TOPICS 785
CHAPTER 30 SOFTWARE PROCESS IMPROVEMENT 78630.1 What Is SPI? 78730.1.1 Approaches to SPI 78730.1.2 Maturity Models 78930.1.3 Is SPI for Everyone? 79030.2 The SPI Process 79130.2.1 Assessment and Gap Analysis 79130.2.2 Education and Training 79330.2.3 Selection and Justification 79330.2.4 Installation/Migration 79430.2.5 Evaluation 79530.2.6 Risk Management for SPI 79530.2.7 Critical Success Factors 79630.3 The CMMI 79730.4 The People CMM 80130.5 Other SPI Frameworks 80230.6 SPI Return on Investment 80430.7 SPI Trends 80530.8 Summary 806
PROBLEMS AND POINTS TO PONDER 806
FURTHER READINGS AND INFORMATION SOURCES 807
CHAPTER 31 EMERGING TRENDS IN SOFTWARE ENGINEERING 80831.1 Technology Evolution 80931.2 Observing Software Engineering Trends 811TABLE OF CONTENTS xxiiipre75977_FM.qxd  11/27/08  6:38 PM  Page xxiii31.3 Identifying “Soft Trends” 81231.3.1 Managing Complexity 81431.3.2 Open-World Software 81531.3.3 Emergent Requirements 81631.3.4 The Talent Mix 81631.3.5 Software Building Blocks 81731.3.6 Changing Perceptions of “Value” 81831.3.7 Open Source 81831.4 Technology Directions 81931.4.1 Process Trends 81931.4.2 The Grand Challenge 82131.4.3 Collaborative Development 82231.4.4 Requirements Engineering 82431.4.5 Model-Driven Software Development 82531.4.6 Postmodern Design 82531.4.7 Test-Driven Development 82631.5 Tools-Related Trends 82731.5.1 Tools That Respond to Soft Trends 82831.5.2 Tools That Address Technology Trends 83031.6 Summary 830
PROBLEMS AND POINTS TO PONDER 831
FURTHER READINGS AND INFORMATION SOURCES 831
CHAPTER 32 CONCLUDING COMMENTS 83332.1 The Importance of Software—Revisited 83432.2 People and the Way They Build Systems 83432.3 New Modes for Representing Information 83532.4 The Long View 83732.5 The Software Engineer’s Responsibility 83832.6 A Final Comment 839APPENDIX 1 AN INTRODUCTION TO UML 841APPENDIX 2 OBJECT-ORIENTED CONCEPTS 863REFERENCES 871INDEX 889xxivTABLE OF CONTENTSpre75977_FM.qxd  12/3/08  1:55 PM  Page xxivWhen computer software succeeds—when it meets the needs of the people who useit, when it performs flawlessly over a long period of time, when it is easy to modifyand even easier to use—it can and does change things for the better. But when softwarefails—when its users are dissatisfied, when it is error prone, when it is difficult to changeand even harder to use—bad things can and do happen. We all want to build software thatmakes things better, avoiding the bad things that lurk in the shadow of failed efforts. Tosucceed, we need discipline when software is designed and built. We need an engineer-ing approach.It has been almost three decades since the first edition of this book was written. Duringthat time, software engineering has evolved from an obscure idea practiced by a relativelysmall number of zealots to a legitimate engineering discipline. Today, it is recognized as asubject worthy of serious research, conscientious study, and tumultuous debate. Through-out the industry, software engineer has replaced programmer as the job title of preference.Software process models, software engineering methods, and software tools have beenadopted successfully across a broad spectrum of industry segments.Although managers and practitioners alike recognize the need for a more disciplinedapproach to software, they continue to debate the manner in which discipline is to beapplied. Many individuals and companies still develop software haphazardly, even as theybuild systems to service today’s most advanced technologies. Many professionals andstudents are unaware of modern methods. And as a result, the quality of the software thatwe produce suffers, and bad things happen. In addition, debate and controversy about thetrue nature of the software engineering approach continue. The status of software engi-neering is a study in contrasts. Attitudes have changed, progress has been made, butmuch remains to be done before the discipline reaches full maturity.The seventh edition of Software Engineering: A Practitioner’s Approach is intended to serve as a guide to a maturing engineering discipline. Like the six editions that preceded it,the seventh edition is intended for both students and practitioners, retaining its appeal asa guide to the industry professional and a comprehensive introduction to the student at theupper-level undergraduate or first-year graduate level.The seventh edition is considerably more than a simple update. The book has beenrevised and restructured to improve pedagogical flow and emphasize new and importantsoftware engineering processes and practices. In addition, a revised and updated “supportsystem,” illustrated in the figure, provides a comprehensive set of student, instructor, andprofessional resources to complement the content of the book. These resources are pre-sented as part of a website (www.mhhe.com/ pressman) specifically designed for Software Engineering: A Practitioner’s Approach.The Seventh Edition.The 32 chapters of the seventh edition have been reorganized intofive parts. This organization, which differs considerably from the sixth edition, has beendone to better compartmentalize topics and assist instructors who may not have the timeto complete the entire book in one term.PREFACE
xxvpre75977_FM.qxd  11/27/08  6:38 PM  Page xxvPart 1, The Process,presents a variety of different views of software process, consider-ing all important process models and addressing the debate between prescriptive andagile process philosophies. Part 2, Modeling, presents analysis and design methods with an emphasis on object-oriented techniques and UML modeling. Pattern-based design anddesign for Web applications are also considered. Part 3, Quality Management, presents the concepts, procedures, techniques, and methods that enable a software team to assesssoftware quality, review software engineering work products, conduct SQA procedures,and apply an effective testing strategy and tactics. In addition, formal modeling and veri-fication methods are also considered. Part 4, Managing Software Projects, presents topics that are relevant to those who plan, manage, and control a software development project.Part 5, Advanced Topics,considers software process improvement and software engineer-ing trends. Continuing in the tradition of past editions, a series of sidebars is used through-out the book to present the trials and tribulations of a (fictional) software team and toprovide supplementary materials about methods and tools that are relevant to chaptertopics. Two new appendices provide brief tutorials on UML and object-oriented thinkingfor those who may be unfamiliar with these important topics.xxviPREFACE
Web resources (1,000+ links)Reference library (500+ links)ChecklistsWork product templatesTiny toolsAdaptable process modelUmbrella activities task setComprehensive case studyStudentresources
InstructorresourcesSolvedproblems
Instructormanual
Testbank
IndustrycommentDistancelearningProfessionalresourcesPower-pointslidesPracticequizzesOtherSEtopics
SEPA7/eChapterstudyguidesSupportSystem forSEPA, 7/epre75977_FM.qxd  11/27/08  6:39 PM  Page xxviThe five-part organization of the seventh edition enables an instructor to “cluster”topics based on available time and student need. An entire one-term course can be builtaround one or more of the five parts. A software engineering survey course would selectchapters from all five parts. A software engineering course that emphasizes analysis anddesign would select topics from Parts 1 and 2. A testing-oriented software engineeringcourse would select topics from Parts 1 and 3, with a brief foray into Part 2. A “manage-ment course” would stress Parts 1 and 4. By organizing the seventh edition in this way,I have attempted to provide an instructor with a number of teaching options. In every case,the content of the seventh edition is complemented by the following elements of the SEPA,7/e Support System.Student Resources.A wide variety of student resources includes an extensive onlinelearning center encompassing chapter-by-chapter study guides, practice quizzes, prob-lem solutions, and a variety of Web-based resources including software engineeringchecklists, an evolving collection of “tiny tools,” a comprehensive case study, work prod-uct templates, and many other resources. In addition, over 1000 categorized Web Refer-encesallow a student to explore software engineering in greater detail and a ReferenceLibrarywith links to over 500 downloadable papers provides an in-depth source ofadvanced software engineering information.Instructor Resources.A broad array of instructor resources has been developed tosupplement the seventh edition. These include a complete online Instructor’s Guide(also downloadable) and supplementary teaching materials including a complete set of over700 PowerPoint Slidesthat may be used for lectures, and a test bank. Of course, allresources available for students (e.g., tiny tools, the Web References, the downloadableReference Library) and professionals are also available.The Instructor’s Guide for Software Engineering: A Practitioner’s Approach presents sug- gestions for conducting various types of software engineering courses, recommendationsfor a variety of software projects to be conducted in conjunction with a course, solutionsto selected problems, and a number of useful teaching aids.Professional Resources.A collection of resources available to industry practitioners(as well as students and faculty) includes outlines and samples of software engineeringdocuments and other work products, a useful set of software engineering checklists, acatalog of software engineering (CASE) tools, a comprehensive collection of Web-basedresources, and an “adaptable process model” that provides a detailed task breakdown ofthe software engineering process.When coupled with its online support system, the seventh edition of Software Engi-neering: A Practitioner’s Approach,provides flexibility and depth of content that cannot beachieved by a textbook alone.Acknowledgments.My work on the seven editions of Software Engineering: A Practi-tioner’s Approachhas been the longest continuing technical project of my life. Even whenthe writing stops, information extracted from the technical literature continues to beassimilated and organized, and criticism and suggestions from readers worldwide is eval-uated and cataloged. For this reason, my thanks to the many authors of books, papers,and articles (in both hardcopy and electronic media) who have provided me with addi-tional insight, ideas, and commentary over nearly 30 years.Special thanks go to Tim Lethbridge of the University of Ottawa, who assisted me inthe development of UML and OCL examples and developed the case study that accompa-nies this book, and Dale Skrien of Colby College, who developed the UML tutorial inPREFACE xxviipre75977_FM.qxd  11/27/08  6:39 PM  Page xxviiThe content of the seventh edition of Software Engineering: A Practitioner’s Approachhas been shaped by industry professionals, university professors, and students who haveused earlier editions of the book and have taken the time to communicate their sugges-tions, criticisms, and ideas. My thanks to each of you. In addition, my personal thanks goto our many industry clients worldwide, who certainly have taught me as much or morethan I could ever teach them.As the editions of this book have evolved, my sons, Mathew and Michael, have grownfrom boys to men. Their maturity, character, and success in the real world have been aninspiration to me. Nothing has filled me with more pride. And finally, to Barbara, my loveand thanks for tolerating the many, many hours in the office and encouraging still anotheredition of “the book.”Roger S. PressmanxxviiiPREFACE
Osman Balci,Virginia Tech UniversityMax Fomitchev,Penn State UniversityJerry (Zeyu) Gao,San Jose State UniversityGuillermo Garcia,Universidad Alfonso X MadridPablo Gervas,Universidad Complutense de MadridSK Jain,National Institute of Technology HamirpurSaeed Monemi,Cal Poly PomonaAhmed Salem,California State UniversityVasudeva Varma,IIIT HyderabadAppendix 1. Their assistance and comments were invaluable. Special thanks also go toBruce Maxim of the University of Michigan–Dearborn, who assisted me in developingmuch of the pedagogical website content that accompanies this book. Finally, I wish tothank the reviewers of the seventh edition: Their in-depth comments and thoughtfulcriticism have been invaluable.pre75977_FM.qxd  11/27/08  6:39 PM  Page xxviiiHe had the classic look of a senior executive for a major software company—mid-40s, slightly graying at the temples, trim and athletic, witheyes that penetrated the listener as he spoke. But what he said shocked me.“Software is dead.”I blinked with surprise and then smiled. “You’re joking, right? The world isdriven by software and your company has profited handsomely because of it. Itisn’t dead! It’s alive and growing.”He shook his head emphatically. “No, it’s dead . . . at least as we once knew it.”I leaned forward. “Go on.”He spoke while tapping the table for emphasis. “The old-school view ofsoftware—you buy it, you own it, and it’s your job to manage it—that’s coming toan end. Today, with Web 2.0 and pervasive computing coming on strong, we’regoing to be seeing a completely different generation of software. It’ll be deliveredvia the Internet and will look exactly like it’s residing on each user’s computingdevice . . . but it’ll reside on a far-away server.”
1CHAPTER
1SOFTWARE AND
SOFTWARE ENGINEERING
What is it?Computer software isthe product that software profession-als build and then support over thelong term. It encompasses programsthat execute within a computer of any size andarchitecture, content that is presented as thecomputer programs execute, and descriptiveinformation in both hard copy and virtual formsthat encompass virtually any electronic media.Software engineering encompasses a process, acollection of methods (practice) and an arrayof tools that allow professionals to build high-quality computer software.Who does it?Software engineers build and sup-port software, and virtually everyone in the indus-trialized world uses it either directly or indirectly.Why is it important?Software is importantbecause it affects nearly every aspect of ourlives and has become pervasive in our com-merce, our culture, and our everyday activities.QUICK
LOOKSoftware engineering is important because itenables us to build complex systems in a timelymanner and with high quality.What are the steps?You build computer soft-ware like you build any successful product, byapplying an agile, adaptable process that leadsto a high-quality result that meets the needs ofthe people who will use the product. You applya software engineering approach.What is the work product?From the point ofview of a software engineer, the work product isthe set of programs, content (data), and otherwork products that are computer software. Butfrom the user’s viewpoint, the work product isthe resultant information that somehow makesthe user’s world better.How do I ensure that I’ve done it right?Read the remainder of this book, select thoseideas that are applicable to the software thatyou build, and apply them to your work.KEY
CONCEPTS
application domains  . . . . . . . .7characteristics ofsoftware  . . . . . . .4framework activities  . . . . . .15legacy software  . .9practice  . . . . . . .17principles  . . . . . .19softwareengineering  . . . .12software myths . .21software process . .14umbrella activities  . . . . . .16WebApps  . . . . . .10pre75977_ch01.qxd  11/27/08  3:11 PM  Page 1I had to agree. “So, your life will be much simpler. You guys won’t have to worryabout five different versions of the same App in use across tens of thousands ofusers.”He smiled. “Absolutely. Only the most current version residing on our servers.When we make a change or a correction, we supply updated functionality andcontent to every user. Everyone has it instantly!”I grimaced. “But if you make a mistake, everyone has that instantly as well.”He chuckled. “True, that’s why we’re redoubling our efforts to do even bettersoftware engineering. Problem is, we have to do it ‘fast’ because the market hasaccelerated in every application area.”I leaned back and put my hands behind my head. “You know what they say, . . .you can have it fast, you can have it right, or you can have it cheap. Pick two!”“I’ll take it fast and right,” he said as he began to get up.I stood as well. “Then you really do need software engineering.”“I know that,” he said as he began to move away. “The problem is, we’ve got toconvince still another generation of techies that it’s true!”Is software reallydead?If it was, you wouldn’t be reading this book!Computer software continues to be the single most important technology on theworld stage. And it’s also a prime example of the law of unintended consequences.Fifty years ago no one could have predicted that software would become an indis-pensable technology for business, science, and engineering; that software wouldenable the creation of new technologies (e.g., genetic engineering and nanotech-nology), the extension of existing technologies (e.g., telecommunications), and theradical change in older technologies (e.g., the printing industry); that software wouldbe the driving force behind the personal computer revolution; that shrink-wrappedsoftware products would be purchased by consumers in neighborhood malls; thatsoftware would slowly evolve from a product to a service as “on-demand” softwarecompanies deliver just-in-time functionality via a Web browser; that a softwarecompany would become larger and more influential than almost all industrial-eracompanies; that a vast software-driven network called the Internet would evolve andchange everything from library research to consumer shopping to political discourseto the dating habits of young (and not so young) adults.No one could foresee that software would become embedded in systems of allkinds: transportation, medical, telecommunications, military, industrial, entertain-ment, office machines, . . . the list is almost endless. And if you believe the law ofunintended consequences, there are many effects that we cannot yet predict.No one could predict that millions of computer programs would have to be cor-rected, adapted, and enhanced as time passed. The burden of performing these“maintenance” activities would absorb more people and more resources than allwork applied to the creation of new software.As software’s importance has grown, the software community has continuallyattempted to develop technologies that will make it easier, faster, and less expensive2 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
uote:
“Ideas andtechnologicaldiscoveries are thedriving engines ofeconomic growth.”Wall StreetJournalpre75977_ch01.qxd  11/27/08  3:11 PM  Page 2to build and maintain high-quality computer programs. Some of these technologiesare targeted at a specific application domain (e.g., website design and implementa-tion); others focus on a technology domain (e.g., object-oriented systems or aspect-oriented programming); and still others are broad-based (e.g., operating systemssuch as Linux). However, we have yet to develop a software technology that does itall, and the likelihood of one arising in the future is small. And yet, people bet theirjobs, their comforts, their safety, their entertainment, their decisions, and their verylives on computer software. It better be right.This book presents a framework that can be used by those who build computersoftware—people who must get it right. The framework encompasses a process, aset of methods, and an array of tools that we call software engineering.
1.1 T HENATURE OF SOFTWARE
Today, software takes on a dual role. It is a product, and at the same time, the vehi-cle for delivering a product. As a product, it delivers the computing potential em-bodied by computer hardware or more broadly, by a network of computers that areaccessible by local hardware. Whether it resides within a mobile phone or operatesinside a mainframe computer, software is an information transformer—producing,managing, acquiring, modifying, displaying, or transmitting information that can beas simple as a single bit or as complex as a multimedia presentation derived fromdata acquired from dozens of independent sources. As the vehicle used to deliver theproduct, software acts as the basis for the control of the computer (operating sys-tems), the communication of information (networks), and the creation and controlof other programs (software tools and environments).Software delivers the most important product of our time—information. It trans- forms personal data (e.g., an individual’s financial transactions) so that the data canbe more useful in a local context; it manages business information to enhance com-petitiveness; it provides a gateway to worldwide information networks (e.g., theInternet), and provides the means for acquiring information in all of its forms.The role of computer software has undergone significant change over the lasthalf-century. Dramatic improvements in hardware performance, profound changesin computing architectures, vast increases in memory and storage capacity, and awide variety of exotic input and output options, have all precipitated more sophisti-cated and complex computer-based systems. Sophistication and complexity canproduce dazzling results when a system succeeds, but they can also pose hugeproblems for those who must build complex systems.Today, a huge software industry has become a dominant factor in the economiesof the industrialized world. Teams of software specialists, each focusing on one partof the technology required to deliver a complex application, have replaced the loneprogrammer of an earlier era. And yet, the questions that were asked of the loneCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 3
Software is both aproduct and a vehiclethat delivers a product.
uote:
“Software is aplace wheredreams are plantedand nightmaresharvested, anabstract, mysticalswamp whereterrible demonscompete withmagical panaceas,a world ofwerewolves andsilver bullets.”Brad J. Coxpre75977_ch01.qxd  11/27/08  3:11 PM  Page 3programmer are the same questions that are asked when modern computer-basedsystems are built:
14 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
1 In an excellent book of essays on the software business, Tom DeMarco [DeM95] argues the coun-terpoint. He states: “Instead of asking why software costs so much, we need to begin asking ‘Whathave we done to make it possible for today’s software to cost so little?’ The answer to that ques-tion will help us continue the extraordinary level of achievement that has always distinguished thesoftware industry.”•Why does it take so long to get software finished?
•Why are development costs so high?
•Why can’t we find all errors before we give the software to our customers?
•Why do we spend so much time and effort maintaining existing programs?
•Why do we continue to have difficulty in measuring progress as software isbeing developed and maintained?These, and many other questions, are a manifestation of the concern aboutsoftware and the manner in which it is developed—a concern that has lead to theadoption of software engineering practice.
1.1.1 Defining Software
Today, most professionals and many members of the public at large feel that theyunderstand software. But do they?A textbook description of software might take the following form: 
Software is: (1) instructions (computer programs) that when executed provide desiredfeatures, function, and performance; (2) data structures that enable the programs to ad-equately manipulate information, and (3) descriptive information in both hard copy andvirtual forms that describes the operation and use of the programs.
There is no question that other more complete definitions could be offered.But a more formal definition probably won’t measurably improve your under-standing. To accomplish that, it’s important to examine the characteristics of soft-ware that make it different from other things that human beings build. Software is alogical rather than a physical system element. Therefore, software has characteris-tics that are considerably different than those of hardware:1.Software is developed or engineered; it is not manufactured in the classical sense.Although some similarities exist between software development and hard-ware manufacturing, the two activities are fundamentally different. In bothactivities, high quality is achieved through good design, but the manufactur-ing phase for hardware can introduce quality problems that are nonexistentHow shouldwe definesoftware??
Software isengineered, notmanufactured.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 4(or easily corrected) for software. Both activities are dependent on people,but the relationship between people applied and work accomplished isentirely different (see Chapter 24). Both activities require the construction ofa “product,” but the approaches are different. Software costs are concen-trated in engineering. This means that software projects cannot be managedas if they were manufacturing projects.2.Software doesn’t “wear out.”Figure 1.1 depicts failure rate as a function of time for hardware. The rela-tionship, often called the “bathtub curve,” indicates that hardware exhibitsrelatively high failure rates early in its life (these failures are often attributa-ble to design or manufacturing defects); defects are corrected and the failurerate drops to a steady-state level (hopefully, quite low) for some period oftime. As time passes, however, the failure rate rises again as hardware com-ponents suffer from the cumulative effects of dust, vibration, abuse, tempera-ture extremes, and many other environmental maladies. Stated simply, thehardware begins to wear out.Software is not susceptible to the environmental maladies that causehardware to wear out. In theory, therefore, the failure rate curve for softwareshould take the form of the “idealized curve” shown in Figure 1.2. Undiscov-ered defects will cause high failure rates early in the life of a program.However, these are corrected and the curve flattens as shown. The idealizedcurve is a gross oversimplification of actual failure models for software.However, the implication is clear—software doesn’t wear out. But it doesdeteriorate!CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 5
“Wear out”“Infantmortality”
TimeFailure rateFIGURE 1.1
Failure curvefor hardware
Software doesn’t wearout, but it doesdeteriorate.
If you want to reducesoftware deterioration,you’ll have to dobetter software design(Chapters 8 to 13).pre75977_ch01.qxd  11/27/08  3:11 PM  Page 5This seeming contradiction can best be explained by considering theactual curve in Figure 1.2. During its life,
2 software will undergo change. As changes are made, it is likely that errors will be introduced, causing thefailure rate curve to spike as shown in the “actual curve” (Figure 1.2). Beforethe curve can return to the original steady-state failure rate, another changeis requested, causing the curve to spike again. Slowly, the minimum failurerate level begins to rise—the software is deteriorating due to change.Another aspect of wear illustrates the difference between hardware andsoftware. When a hardware component wears out, it is replaced by a sparepart. There are no software spare parts. Every software failure indicates anerror in design or in the process through which design was translated intomachine executable code. Therefore, the software maintenance tasks thataccommodate requests for change involve considerably more complexitythan hardware maintenance.3.Although the industry is moving toward component-based construction, mostsoftware continues to be custom built.As an engineering discipline evolves, a collection of standard design compo-nents is created. Standard screws and off-the-shelf integrated circuits areonly two of thousands of standard components that are used by mechanicaland electrical engineers as they design new systems. The reusable compo-nents have been created so that the engineer can concentrate on the trulyinnovative elements of a design, that is, the parts of the design that represent6 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
Increased failurerate due to sideeffects
TimeFailure rate ChangeActual curveIdealized curveFIGURE 1.2
Failure curvesfor software
2 In fact, from the moment that development begins and long before the first version is delivered,changes may be requested by a variety of different stakeholders.Software engineeringmethods strive toreduce the magnitudeof the spikes and theslope of the actualcurve in Figure 1.2.
uote:
“Ideas are thebuilding blocks ofideas.”Jason Zebehazypre75977_ch01.qxd  11/27/08  3:11 PM  Page 6something new. In the hardware world, component reuse is a natural part ofthe engineering process. In the software world, it is something that has onlybegun to be achieved on a broad scale.A software component should be designed and implemented so that it canbe reused in many different programs. Modern reusable components encap-sulate both data and the processing that is applied to the data, enabling thesoftware engineer to create new applications from reusable parts.
3 For exam- ple, today’s interactive user interfaces are built with reusable componentsthat enable the creation of graphics windows, pull-down menus, and a widevariety of interaction mechanisms. The data structures and processing detailrequired to build the interface are contained within a library of reusablecomponents for interface construction.
1.1.2 Software Application Domains
Today, seven broad categories of computer software present continuing challengesfor software engineers:System software—a collection of programs written to service other pro-grams. Some system software (e.g., compilers, editors, and file managementutilities) processes complex, but determinate,
4 information structures. Other systems applications (e.g., operating system components, drivers, networkingsoftware, telecommunications processors) process largely indeterminate data.In either case, the systems software area is characterized by heavy interactionwith computer hardware; heavy usage by multiple users; concurrent opera-tion that requires scheduling, resource sharing, and sophisticated processmanagement; complex data structures; and multiple external interfaces.Application software—stand-alone programs that solve a specific businessneed. Applications in this area process business or technical data in a waythat facilitates business operations or management/technical decision mak-ing. In addition to conventional data processing applications, applicationsoftware is used to control business functions in real time (e.g., point-of-saletransaction processing, real-time manufacturing process control).Engineering/scientific software—has been characterized by “numbercrunching” algorithms. Applications range from astronomy to volcanology,from automotive stress analysis to space shuttle orbital dynamics, andfrom molecular biology to automated manufacturing. However, modernapplications within the engineering/scientific area are moving away fromCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 7
3 Component-based development is discussed in Chapter 10.4 Software is determinateif the order and timing of inputs, processing, and outputs is predictable.Software is indeterminateif the order and timing of inputs, processing, and outputs cannot bepredicted in advance.WebRef
One of the mostcomprehensive librariesof shareware/ freewarecan be found atshareware.cnet.compre75977_ch01.qxd  11/27/08  3:11 PM  Page 7conventional numerical algorithms. Computer-aided design, system simula-tion, and other interactive applications have begun to take on real-time andeven system software characteristics.Embedded software—resides within a product or system and is used toimplement and control features and functions for the end user and for thesystem itself. Embedded software can perform limited and esoteric functions(e.g., key pad control for a microwave oven) or provide significant functionand control capability (e.g., digital functions in an automobile such as fuelcontrol, dashboard displays, and braking systems).Product-line software—designed to provide a specific capability for use bymany different customers. Product-line software can focus on a limited andesoteric marketplace (e.g., inventory control products) or address massconsumer markets (e.g., word processing, spreadsheets, computer graphics,multimedia, entertainment, database management, and personal andbusiness financial applications).Web applications—called “WebApps,” this network-centric software cate-gory spans a wide array of applications. In their simplest form, WebApps canbe little more than a set of linked hypertext files that present informationusing text and limited graphics. However, as Web 2.0 emerges, WebApps areevolving into sophisticated computing environments that not only providestand-alone features, computing functions, and content to the end user, butalso are integrated with corporate databases and business applications.Artificial intelligence software—makes use of nonnumerical algorithms tosolve complex problems that are not amenable to computation or straightfor-ward analysis. Applications within this area include robotics, expert systems,pattern recognition (image and voice), artificial neural networks, theoremproving, and game playing.Millions of software engineers worldwide are hard at work on software projects inone or more of these categories. In some cases, new systems are being built, but inmany others, existing applications are being corrected, adapted, and enhanced. It isnot uncommon for a young software engineer to work a program that is older thanshe is! Past generations of software people have left a legacy in each of the cate-gories I have discussed. Hopefully, the legacy to be left behind by this generation willease the burden of future software engineers. And yet, new challenges (Chapter 31)have appeared on the horizon:Open-world computing—the rapid growth of wireless networking maysoon lead to true pervasive, distributed computing. The challenge for soft-ware engineers will be to develop systems and application software that willallow mobile devices, personal computers, and enterprise systems to com-municate across vast networks.8 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
uote:
“There is nocomputer that hascommon sense.”Marvin Minskypre75977_ch01.qxd  11/27/08  3:11 PM  Page 8Netsourcing—the World Wide Web is rapidly becoming a computing engineas well as a content provider. The challenge for software engineers is toarchitect simple (e.g., personal financial planning) and sophisticated applica-tions that provide a benefit to targeted end-user markets worldwide.Open source—a growing trend that results in distribution of source code forsystems applications (e.g., operating systems, database, and development en-vironments) so that many people can contribute to its development. The chal-lenge for software engineers is to build source code that is self-descriptive,but more importantly, to develop techniques that will enable both customersand developers to know what changes have been made and how thosechanges manifest themselves within the software.Each of these new challenges will undoubtedly obey the law of unintended conse-quences and have effects (for businesspeople, software engineers, and end users) thatcannot be predicted today. However, software engineers can prepare by instantiatinga process that is agile and adaptable enough to accommodate dramatic changes intechnology and to business rules that are sure to come over the next decade.
1.1.3 Legacy Software
Hundreds of thousands of computer programs fall into one of the seven broadapplication domains discussed in the preceding subsection. Some of these are state-of-the-art software—just released to individuals, industry, and government. Butother programs are older, in some cases much older. These older programs—often referred to as legacy software—have been the focusof continuous attention and concern since the 1960s. Dayani-Fard and hiscolleagues [Day99] describe legacy software in the following way:
Legacy software systems . . . were developed decades ago and have been continuallymodified to meet changes in business requirements and computing platforms. The pro-liferation of such systems is causing headaches for large organizations who find themcostly to maintain and risky to evolve.
Liu and his colleagues [Liu98] extend this description by noting that “many legacysystems remain supportive to core business functions and are ‘indispensable’ tothe business.” Hence, legacy software is characterized by longevity and businesscriticality.Unfortunately, there is sometimes one additional characteristic that is presentin legacy software—poor quality.
5 Legacy systems sometimes have inextensibledesigns, convoluted code, poor or nonexistent documentation, test cases and resultsCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 9
uote:
“You can’t alwayspredict, but youcan alwaysprepare.”Anonymous
5 In this case, quality is judged based on modern software engineering thinking—a somewhat unfaircriterion since some modern software engineering concepts and principles may not have been wellunderstood at the time that the legacy software was developed.What do I doif I encountera legacy systemthat exhibits poorquality??pre75977_ch01.qxd  11/27/08  3:11 PM  Page 9that were never archived, a poorly managed change history—the list can be quitelong. And yet, these systems support “core business functions and are indispensableto the business.” What to do?The only reasonable answer may be: Do nothing, at least until the legacy system must undergo some significant change. If the legacy software meets the needs of itsusers and runs reliably, it isn’t broken and does not need to be fixed. However, astime passes, legacy systems often evolve for one or more of the following reasons:
•The software must be adapted to meet the needs of new computing environ-ments or technology.
•The software must be enhanced to implement new business requirements.
•The software must be extended to make it interoperable with other moremodern systems or databases.
•The software must be re-architected to make it viable within a networkenvironment.When these modes of evolution occur, a legacy system must be reengineered (Chap-ter 29) so that it remains viable into the future. The goal of modern software engi-neering is to “devise methodologies that are founded on the notion of evolution”;that is, the notion that software systems continually change, new software systemsare built from the old ones, and . . . all must interoperate and cooperate with eachother” [Day99].
1.2 T HEUNIQUE NATURE OF WEBAPPS
In the early days of the World Wide Web (circa 1990 to 1995), websites consisted of little more than a set of linked hypertext files that presented information using textand limited graphics. As time passed, the augmentation of HTML by developmenttools (e.g., XML, Java) enabled Web engineers to provide computing capability alongwith informational content.Web-based systems and applications
6(I refer to these col- lectively as WebApps) were born. Today, WebApps have evolved into sophisticatedcomputing tools that not only provide stand-alone function to the end user, but alsohave been integrated with corporate databases and business applications.As noted in Section 1.1.2, WebApps are one of a number of distinct software cat-egories. And yet, it can be argued that WebApps are different. Powell [Pow98] sug-gests that Web-based systems and applications “involve a mixture between printpublishing and software development, between marketing and computing, between10 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
What typesof changesare made tolegacy systems??
Every softwareengineer mustrecognize that changeis natural. Don’t try tofight it.
uote:
“By the time wesee any sort ofstabilization, theWeb will haveturned intosomethingcompletelydifferent.”Louis Monier
6 In the context of this book, the term Web application (WebApp) encompasses everything from a sim- ple Web page that might help a consumer compute an automobile lease payment to a comprehen-sive website that provides complete travel services for businesspeople and vacationers. Includedwithin this category are complete websites, specialized functionality within websites, and infor-mation processing applications that reside on the Internet or on an Intranet or Extranet.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 10internal communications and external relations, and between art and technology.”The following attributes are encountered in the vast majority of WebApps.Network intensiveness.A WebApp resides on a network and must servethe needs of a diverse community of clients. The network may enable world-wide access and communication (i.e., the Internet) or more limited accessand communication (e.g., a corporate Intranet).Concurrency.A large number of users may access the WebApp at onetime. In many cases, the patterns of usage among end users will vary greatly.Unpredictable load.The number of users of the WebApp may vary byorders of magnitude from day to day. One hundred users may show up onMonday; 10,000 may use the system on Thursday.Performance.If a WebApp user must wait too long (for access, for server-side processing, for client-side formatting and display), he or she may decideto go elsewhere.Availability.Although expectation of 100 percent availability is unreason-able, users of popular WebApps often demand access on a 24/7/365 basis.Users in Australia or Asia might demand access during times when tradi-tional domestic software applications in North America might be taken off-line for maintenance.Data driven.The primary function of many WebApps is to use hypermediato present text, graphics, audio, and video content to the end user. In addi-tion, WebApps are commonly used to access information that exists on data-bases that are not an integral part of the Web-based environment (e.g.,e-commerce or financial applications).Content sensitive.The quality and aesthetic nature of content remains animportant determinant of the quality of a WebApp.Continuous evolution.Unlike conventional application software thatevolves over a series of planned, chronologically spaced releases, Web appli-cations evolve continuously. It is not unusual for some WebApps (specifically,their content) to be updated on a minute-by-minute schedule or for contentto be independently computed for each request.Immediacy.Although immediacy—the compelling need to get software tomarket quickly—is a characteristic of many application domains, WebAppsoften exhibit a time-to-market that can be a matter of a few days or weeks.
7
Security.Because WebApps are available via network access, it is difficult,if not impossible, to limit the population of end users who may access theapplication. In order to protect sensitive content and provide secure modesCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 11
7 With modern tools, sophisticated Web pages can be produced in only a few hours.WhatcharacteristicdifferentiatesWebApps fromother software??pre75977_ch01.qxd  11/27/08  3:11 PM  Page 11of data transmission, strong security measures must be implementedthroughout the infrastructure that supports a WebApp and within the appli-cation itself.Aesthetics.An undeniable part of the appeal of a WebApp is its look andfeel. When an application has been designed to market or sell products orideas, aesthetics may have as much to do with success as technical design.It can be argued that other application categories discussed in Section 1.1.2 canexhibit some of the attributes noted. However, WebApps almost always exhibit all ofthem.
1.3 S OFTWARE ENGINEERING
In order to build software that is ready to meet the challenges of the twenty-firstcentury, you must recognize a few simple realities:
•Software has become deeply embedded in virtually every aspect of our lives,and as a consequence, the number of people who have an interest in thefeatures and functions provided by a specific application
8has grown dramati- cally. When a new application or embedded system is to be built, manyvoices must be heard. And it sometimes seems that each of them has aslightly different idea of what software features and functions should bedelivered. It follows that a concerted effort should be made to understand theproblem before a software solution is developed.
•The information technology requirements demanded by individuals, busi-nesses, and governments grow increasing complex with each passing year.Large teams of people now create computer programs that were once builtby a single individual. Sophisticated software that was once implemented ina predictable, self-contained, computing environment is now embeddedinside everything from consumer electronics to medical devices to weaponssystems. The complexity of these new computer-based systems and productsdemands careful attention to the interactions of all system elements. Itfollows that design becomes a pivotal activity.
•Individuals, businesses, and governments increasingly rely on software forstrategic and tactical decision making as well as day-to-day operations andcontrol. If the software fails, people and major enterprises can experienceanything from minor inconvenience to catastrophic failures. It follows thatsoftware should exhibit high quality.
•As the perceived value of a specific application grows, the likelihood is thatits user base and longevity will also grow. As its user base and time-in-use12 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
8 I will call these people “stakeholders” later in this book.Understand theproblem before youbuild a solution.
Design is a pivotalsoftware engineeringactivity.
Both quality andmaintainability are anoutgrowth of gooddesign.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 12increase, demands for adaptation and enhancement will also grow. It followsthat software should be maintainable.These simple realities lead to one conclusion: software in all of its forms and across all of its application domains should be engineered. And that leads us to the topic of this book—software engineering.Although hundreds of authors have developed personal definitions of softwareengineering, a definition proposed by Fritz Bauer [Nau69] at the seminal conferenceon the subject still serves as a basis for discussion:
[Software engineering is] the establishment and use of sound engineering principles in or-der to obtain economically software that is reliable and works efficiently on real machines.
You will be tempted to add to this definition.9It says little about the technical as- pects of software quality; it does not directly address the need for customer satisfac-tion or timely product delivery; it omits mention of the importance of measurementand metrics; it does not state the importance of an effective process. And yet, Bauer’sdefinition provides us with a baseline. What are the “sound engineering principles”that can be applied to computer software development? How do we “economically”build software so that it is “reliable”? What is required to create computer programsthat work “efficiently” on not one but many different “real machines”? These are thequestions that continue to challenge software engineers.The IEEE [IEE93a] has developed a more comprehensive definition when it states:
Software Engineering: (1) The application of a systematic, disciplined, quantifiable approachto the development, operation, and maintenance of software; that is, the application ofengineering to software. (2) The study of approaches as in (1).
And yet, a “systematic, disciplined, and quantifiable” approach applied by onesoftware team may be burdensome to another. We need discipline, but we also needadaptability and agility.Software engineering is a layered technology. Referring to Figure 1.3, any engineer-ing approach (including software engineering) must rest on an organizational com-mitment to quality. Total quality management, Six Sigma, and similar philosophies
10
foster a continuous process improvement culture, and it is this culture that ultimatelyleads to the development of increasingly more effective approaches to software engi-neering. The bedrock that supports software engineering is a quality focus.The foundation for software engineering is the process layer. The software engi- neering process is the glue that holds the technology layers together and enablesrational and timely development of computer software. Process defines a frameworkCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 13
uote:
“More than adiscipline or a bodyof knowledge,engineering is averb, an actionword, a way ofapproaching aproblem.”Scott Whitmir
How do wedefinesoftwareengineering??
9 For numerous additional definitions of software engineering, see www.answers.com/topic/ software-engineering#wp-_note-13.10 Quality management and related approaches are discussed in Chapter 14 and throughout Part 3 ofthis book.Software engineeringencompasses aprocess, methods formanaging andengineering software,and tools.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 13that must be established for effective delivery of software engineering technology.The software process forms the basis for management control of software projectsand establishes the context in which technical methods are applied, work products(models, documents, data, reports, forms, etc.) are produced, milestones are estab-lished, quality is ensured, and change is properly managed.Software engineering methodsprovide the technical how-to’s for building soft-ware. Methods encompass a broad array of tasks that include communication,requirements analysis, design modeling, program construction, testing, and sup-port. Software engineering methods rely on a set of basic principles that governeach area of the technology and include modeling activities and other descriptivetechniques.Software engineering toolsprovide automated or semiautomated support for theprocess and the methods. When tools are integrated so that information created byone tool can be used by another, a system for the support of software development,called computer-aided software engineering , is established.
1.4 T HESOFTWARE PROCESS
Aprocessis a collection of activities, actions, and tasks that are performed whensome work product is to be created. An activitystrives to achieve a broad objective (e.g., communication with stakeholders) and is applied regardless of the applicationdomain, size of the project, complexity of the effort, or degree of rigor with whichsoftware engineering is to be applied. An action (e.g., architectural design) encom- passes a set of tasks that produce a major work product (e.g., an architectural designmodel). A taskfocuses on a small, but well-defined objective (e.g., conducting a unittest) that produces a tangible outcome.In the context of software engineering, a process is nota rigid prescription for how to build computer software. Rather, it is an adaptable approach that enables the peo-ple doing the work (the software team) to pick and choose the appropriate set ofwork actions and tasks. The intent is always to deliver software in a timely mannerand with sufficient quality to satisfy those who have sponsored its creation and thosewho will use it.14 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
ToolsA quality focusMethodsProcessFIGURE 1.3
Softwareengineeringlayers
WebRef
CrossTalkis a journalthat providespragmaticinformation onprocess, methods,and tools. It can befound at:www.stsc.hill.af.mil.
What are theelements ofa softwareprocess??
uote:
“A process defineswho is doing whatwhenand howtoreach a certaingoal.”Ivar Jacobson,Grady Booch,and JamesRumbaughpre75977_ch01.qxd  11/27/08  3:11 PM  Page 14A process frameworkestablishes the foundation for a complete software engi-neering process by identifying a small number of framework activities that are appli- cable to all software projects, regardless of their size or complexity. In addition, theprocess framework encompasses a set of umbrella activities that are applicable across the entire software process. A generic process framework for software engi-neering encompasses five activities:Communication.Before any technical work can commence, it is criticallyimportant to communicate and collaborate with the customer (and otherstakeholders
11The intent is to understand stakeholders’ objectives for theproject and to gather requirements that help define software features andfunctions.Planning.Any complicated journey can be simplified if a map exists. Asoftware project is a complicated journey, and the planning activity creates a“map” that helps guide the team as it makes the journey. The map—called asoftware project plan—defines the software engineering work by describingthe technical tasks to be conducted, the risks that are likely, the resourcesthat will be required, the work products to be produced, and a workschedule.Modeling.Whether you’re a landscaper, a bridge builder, an aeronauticalengineer, a carpenter, or an architect, you work with models every day. Youcreate a “sketch” of the thing so that you’ll understand the big picture—whatit will look like architecturally, how the constituent parts fit together, andmany other characteristics. If required, you refine the sketch into greater andgreater detail in an effort to better understand the problem and how you’regoing to solve it. A software engineer does the same thing by creating mod-els to better understand software requirements and the design that willachieve those requirements.Construction.This activity combines code generation (either manual orautomated) and the testing that is required to uncover errors in the code.Deployment.The software (as a complete entity or as a partially com-pleted increment) is delivered to the customer who evaluates the deliveredproduct and provides feedback based on the evaluation.These five generic framework activities can be used during the development of small,simple programs, the creation of large Web applications, and for the engineering oflarge, complex computer-based systems. The details of the software process will bequite different in each case, but the framework activities remain the same.CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 15
11 A stakeholderis anyone who has a stake in the successful outcome of the project—business man-agers, end users, software engineers, support people, etc. Rob Thomsett jokes that, “a stakeholderis a person holding a large and sharp stake. . . . If you don’t look after your stakeholders, you knowwhere the stake will end up.”). What are thefive genericprocessframeworkactivities??
uote:
“Einstein arguedthat there must bea simplifiedexplanation ofnature, becauseGod is notcapricious orarbitrary. No suchfaith comforts thesoftware engineer.Much of thecomplexity that hemust master isarbitrarycomplexity.”Fred Brookspre75977_ch01.qxd  11/27/08  3:11 PM  Page 15For many software projects, framework activities are applied iteratively as aproject progresses. That is, communication, planning, modeling, construction,and deploymentare applied repeatedly through a number of project iterations.Each project iteration produces a software increment that provides stakeholders with a subset of overall software features and functionality. As each increment is pro-duced, the software becomes more and more complete.Software engineering process framework activities are complemented by a num-ber of umbrella activities.In general, umbrella activities are applied throughout a soft-ware project and help a software team manage and control progress, quality,change, and risk. Typical umbrella activities include:Software project tracking and control —allows the software team to assess progress against the project plan and take any necessary action tomaintain the schedule.Risk management—assesses risks that may affect the outcome of theproject or the quality of the product.Software quality assurance—defines and conducts the activities requiredto ensure software quality.Technical reviews—assesses software engineering work products in an effortto uncover and remove errors before they are propagated to the next activity.Measurement—defines and collects process, project, and product measuresthat assist the team in delivering software that meets stakeholders’ needs;can be used in conjunction with all other framework and umbrella activities.Software configuration management —manages the effects of change throughout the software process.Reusability management—defines criteria for work product reuse(including software components) and establishes mechanisms to achievereusable components.Work product preparation and production —encompasses the activities required to create work products such as models, documents, logs, forms,and lists.Each of these umbrella activities is discussed in detail later in this book.Earlier in this section, I noted that the software engineering process is not a rigidprescription that must be followed dogmatically by a software team. Rather, it shouldbe agile and adaptable (to the problem, to the project, to the team, and to the organi-zational culture). Therefore, a process adopted for one project might be significantlydifferent than a process adopted for another project. Among the differences are
•Overall flow of activities, actions, and tasks and the interdependenciesamong them
•Degree to which actions and tasks are defined within each framework activity
•Degree to which work products are identified and required16 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
Umbrella activitiesoccur throughout thesoftware process andfocus primarily onproject management,tracking, and control.
Software processadaptation is essentialfor project success.
How doprocessmodels differ fromone another??pre75977_ch01.qxd  11/27/08  3:11 PM  Page 16•Manner in which quality assurance activities are applied
•Manner in which project tracking and control activities are applied
•Overall degree of detail and rigor with which the process is described
•Degree to which the customer and other stakeholders are involved with theproject
•Level of autonomy given to the software team
•Degree to which team organization and roles are prescribedIn Part 1 of this book, I’ll examine software process in considerable detail. Prescriptiveprocess models(Chapter 2) stress detailed definition, identification, and applicationof process activities and tasks. Their intent is to improve system quality, make proj-ects more manageable, make delivery dates and costs more predictable, and guideteams of software engineers as they perform the work required to build a system.Unfortunately, there have been times when these objectives were not achieved. Ifprescriptive models are applied dogmatically and without adaptation, they can in-crease the level of bureaucracy associated with building computer-based systemsand inadvertently create difficulty for all stakeholders.Agile process models(Chapter 3) emphasize project “agility” and follow a set of prin-ciples that lead to a more informal (but, proponents argue, no less effective) approachto software process. These process models are generally characterized as “agile” be-cause they emphasize maneuverability and adaptability. They are appropriate for manytypes of projects and are particularly useful when Web applications are engineered.
1.5 S OFTWARE ENGINEERING PRACTICE
In Section 1.4, I introduced a generic software process model composed of a set ofactivities that establish a framework for software engineering practice. Genericframework activities—communication, planning, modeling, construction, and deployment—and umbrella activities establish a skeleton architecture for softwareengineering work. But how does the practice of software engineering fit in? In thesections that follow, you’ll gain a basic understanding of the generic concepts andprinciples that apply to framework activities.
12
1.5.1 The Essence of Practice
In a classic book, How to Solve It,written before modern computers existed, GeorgePolya [Pol45] outlined the essence of problem solving, and consequently, the essenceof software engineering practice:1.Understand the problem(communication and analysis).2.Plan a solution(modeling and software design).CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 17
Whatcharacterizesan “agile”process??uote:
“I feel a recipe isonly a theme whichan intelligent cookcan play each timewith a variation.”Madame Benoit
WebRef
A variety of thought-provoking quotes onthe practice of softwareengineering can befound at www.literateprogramming.com
You might argue thatPolya’s approach issimply common sense.True. But it’s amazinghow often commonsense is uncommon inthe software world.
12 You should revisit relevant sections within this chapter as specific software engineering methodsand umbrella activities are discussed later in this book.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 173.Carry out the plan(code generation).4.Examine the result for accuracy(testing and quality assurance).In the context of software engineering, these commonsense steps lead to a series ofessential questions [adapted from Pol45]:Understand the problem.It’s sometimes difficult to admit, but most of us sufferfrom hubris when we’re presented with a problem. We listen for a few seconds andthen think, Oh yeah, I understand, let’s get on with solving this thing. Unfortunately, understanding isn’t always that easy. It’s worth spending a little time answering afew simple questions:
•Who has a stake in the solution to the problem? That is, who are the stake- holders?
•What are the unknowns?What data, functions, and features are required toproperly solve the problem?
•Can the problem be compartmentalized? Is it possible to represent smaller problems that may be easier to understand?
•Can the problem be represented graphically? Can an analysis model be created?Plan the solution.Now you understand the problem (or so you think) and youcan’t wait to begin coding. Before you do, slow down just a bit and do a littledesign:
•Have you seen similar problems before? Are there patterns that are recogniz- able in a potential solution? Is there existing software that implements thedata, functions, and features that are required?
•Has a similar problem been solved?If so, are elements of the solutionreusable?
•Can subproblems be defined?If so, are solutions readily apparent for thesubproblems?
•Can you represent a solution in a manner that leads to effective implementation?Can a design model be created?Carry out the plan.The design you’ve created serves as a road map for thesystem you want to build. There may be unexpected detours, and it’s possible thatyou’ll discover an even better route as you go, but the “plan” will allow you toproceed without getting lost.
•Does the solution conform to the plan?Is source code traceable to the designmodel?
•Is each component part of the solution provably correct? Have the design and code been reviewed, or better, have correctness proofs been applied to thealgorithm?18 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
uote:
“There is a grain ofdiscovery in thesolution of anyproblem.”George Polyapre75977_ch01.qxd  11/27/08  3:11 PM  Page 18Examine the result.You can’t be sure that your solution is perfect, but you can besure that you’ve designed a sufficient number of tests to uncover as many errors aspossible.
•Is it possible to test each component part of the solution? Has a reasonable testing strategy been implemented?
•Does the solution produce results that conform to the data, functions, andfeatures that are required?Has the software been validated against allstakeholder requirements?It shouldn’t surprise you that much of this approach is common sense. In fact, it’sreasonable to state that a commonsense approach to software engineering willnever lead you astray.
1.5.2 General Principles
The dictionary defines the word principle as “an important underlying law or as- sumption required in a system of thought.” Throughout this book I’ll discuss princi-ples at many different levels of abstraction. Some focus on software engineering as awhole, others consider a specific generic framework activity (e.g., communication), and still others focus on software engineering actions (e.g., architectural design) ortechnical tasks (e.g., write a usage scenario). Regardless of their level of focus, prin-ciples help you establish a mind-set for solid software engineering practice. They areimportant for that reason.David Hooker [Hoo96] has proposed seven principles that focus on softwareengineering practice as a whole. They are reproduced in the followingparagraphs:
13
The First Principle: The Reason It All ExistsA software system exists for one reason: to provide value to its users. Alldecisions should be made with this in mind. Before specifying a system require-ment, before noting a piece of system functionality, before determining the hard-ware platforms or development processes, ask yourself questions such as: “Doesthis add real value to the system?” If the answer is “no,” don’t do it. All otherprinciples support this one.The Second Principle: KISS (Keep It Simple, Stupid!)Software design is not a haphazard process. There are many factors to considerin any design effort. All design should be as simple as possible, but no simpler . This facilitates having a more easily understood and easily maintained system. This isCHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 19
13 Reproduced with permission of the author [Hoo96]. Hooker defines patterns for these principles athttp:/ /c2.com/cgi/wiki?SevenPrinciplesOfSoftwareDevelopment.Before beginning asoftware project, besure the software hasa business purpose andthat users perceivevalue in it.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 19not to say that features, even internal features, should be discarded in the name ofsimplicity. Indeed, the more elegant designs are usually the more simple ones. Sim-ple also does not mean “quick and dirty.” In fact, it often takes a lot of thought andwork over multiple iterations to simplify. The payoff is software that is more main-tainable and less error-prone.The Third Principle: Maintain the VisionA clear vision is essential to the success of a software project. Without one, aproject almost unfailingly ends up being “of two [or more] minds” about itself.Without conceptual integrity, a system threatens to become a patchwork of in-compatible designs, held together by the wrong kind of screws. . . . Compromis-ing the architectural vision of a software system weakens and will eventuallybreak even the well-designed systems. Having an empowered architect who canhold the vision and enforce compliance helps ensure a very successful softwareproject.The Fourth Principle: What You Produce, Others Will ConsumeSeldom is an industrial-strength software system constructed and used in avacuum. In some way or other, someone else will use, maintain, document, orotherwise depend on being able to understand your system. So, always specify,design, and implement knowing someone else will have to understand what you aredoing. The audience for any product of software development is potentially large.Specify with an eye to the users. Design, keeping the implementers in mind. Codewith concern for those that must maintain and extend the system. Someone mayhave to debug the code you write, and that makes them a user of your code.Making their job easier adds value to the system.The Fifth Principle: Be Open to the FutureA system with a long lifetime has more value. In today’s computing environ-ments, where specifications change on a moment’s notice and hardware platformsare obsolete just a few months old, software lifetimes are typically measured inmonths instead of years. However, true “industrial-strength” software systemsmust endure far longer. To do this successfully, these systems must be ready toadapt to these and other changes. Systems that do this successfully are those thathave been designed this way from the start. Never design yourself into a corner.Always ask “what if,” and prepare for all possible answers by creating systems thatsolve the general problem, not just the specific one.
14This could very possibly lead to the reuse of an entire system.20 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
If software has value,it will change over itsuseful life. For thatreason, software mustbe built to bemaintainable.
14 This advice can be dangerous if it is taken to extremes. Designing for the “general problem” some-times requires performance compromises and can make specific solutions inefficient.uote:
“There is a certainmajesty insimplicity which isfar above all thequaintness of wit.”Alexander Pope(1688–1744)pre75977_ch01.qxd  11/27/08  3:11 PM  Page 20The Sixth Principle: Plan Ahead for ReuseReuse saves time and effort.
15Achieving a high level of reuse is arguably thehardest goal to accomplish in developing a software system. The reuse of code anddesigns has been proclaimed as a major benefit of using object-oriented technolo-gies. However, the return on this investment is not automatic. To leverage thereuse possibilities that object-oriented [or conventional] programming providesrequires forethought and planning. There are many techniques to realize reuseat every level of the system development process. . . . Planning ahead for reuse reduces the cost and increases the value of both the reusable components and thesystems into which they are incorporated.The Seventh principle: Think!This last principle is probably the most overlooked. Placing clear, completethought before action almost always produces better results . When you think about something, you are more likely to do it right. You also gain knowledge about howto do it right again. If you do think about something and still do it wrong, it be-comes a valuable experience. A side effect of thinking is learning to recognizewhen you don’t know something, at which point you can research the answer.When clear thought has gone into a system, value comes out. Applying the first sixprinciples requires intense thought, for which the potential rewards are enormous.If every software engineer and every software team simply followed Hooker’s sevenprinciples, many of the difficulties we experience in building complex computer-based systems would be eliminated.
1.6 S OFTWARE MYTHS
Software myths—erroneous beliefs about software and the process that is used tobuild it—can be traced to the earliest days of computing. Myths have a number ofattributes that make them insidious. For instance, they appear to be reasonablestatements of fact (sometimes containing elements of truth), they have an intuitivefeel, and they are often promulgated by experienced practitioners who “know thescore.”Today, most knowledgeable software engineering professionals recognize mythsfor what they are—misleading attitudes that have caused serious problems formanagers and practitioners alike. However, old attitudes and habits are difficult tomodify, and remnants of software myths remain.CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 21
15 Although this is true for those who reuse the software on future projects, reuse can be expensivefor those who must design and build reusable components. Studies indicate that designing andbuilding reusable components can cost between 25 to 200 percent more than targeted software. Insome cases, the cost differential cannot be justified.uote:
“In the absence ofmeaningfulstandards, a newindustry likesoftware comes todepend instead onfolklore.”Tom DeMarcopre75977_ch01.qxd  11/27/08  3:11 PM  Page 21Management myths.Managers with software responsibility, like managers inmost disciplines, are often under pressure to maintain budgets, keep schedules fromslipping, and improve quality. Like a drowning person who grasps at a straw, a soft-ware manager often grasps at belief in a software myth, if that belief will lessen thepressure (even temporarily).Myth:We already have a book that’s full of standards and procedures forbuilding software. Won’t that provide my people with everything theyneed to know?Reality:The book of standards may very well exist, but is it used? Are soft-ware practitioners aware of its existence? Does it reflect modernsoftware engineering practice? Is it complete? Is it adaptable? Is itstreamlined to improve time-to-delivery while still maintaining afocus on quality? In many cases, the answer to all of these questionsis “no.”Myth:If we get behind schedule, we can add more programmers and catch up(sometimes called the “Mongolian horde” concept).Reality:Software development is not a mechanistic process like manufactur-ing. In the words of Brooks [Bro95]: “adding people to a late soft-ware project makes it later.” At first, this statement may seemcounterintuitive. However, as new people are added, people whowere working must spend time educating the newcomers, therebyreducing the amount of time spent on productive developmenteffort. People can be added but only in a planned and well-coordinated manner.Myth:If I decide to outsource the software project to a third party, I can justrelax and let that firm build it.Reality:If an organization does not understand how to manage and controlsoftware projects internally, it will invariably struggle when it out-sources software projects.Customer myths.A customer who requests computer software may be a personat the next desk, a technical group down the hall, the marketing/sales department,or an outside company that has requested software under contract. In many cases,the customer believes myths about software because software managers and prac-titioners do little to correct misinformation. Myths lead to false expectations (by thecustomer) and, ultimately, dissatisfaction with the developer.Myth:A general statement of objectives is sufficient to begin writingprograms—we can fill in the details later.Reality:Although a comprehensive and stable statement of requirements isnot always possible, an ambiguous “statement of objectives” is arecipe for disaster. Unambiguous requirements (usually derived22 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
WebRef
The Software ProjectManagers Network atwww.spmn.comcan help you dispelthese and other myths.
Work very hard tounderstand what youhave to do before youstart. You may not beable to develop everydetail, but the moreyou know, the less riskyou take.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 22iteratively) are developed only through effective and continuouscommunication between customer and developer.Myth:Software requirements continually change, but change can be easilyaccommodated because software is flexible.Reality:It is true that software requirements change, but the impact ofchange varies with the time at which it is introduced. When require-ments changes are requested early (before design or code has beenstarted), the cost impact is relatively small.
16However, as time passes, the cost impact grows rapidly—resources have been commit-ted, a design framework has been established, and change cancause upheaval that requires additional resources and major designmodification.Practitioner’s myths.Myths that are still believed by software practitioners havebeen fostered by over 50 years of programming culture. During the early days, pro-gramming was viewed as an art form. Old ways and attitudes die hard.Myth:Once we write the program and get it to work, our job is done.Reality:Someone once said that “the sooner you begin ‘writing code,’ thelonger it’ll take you to get done.” Industry data indicate that between60 and 80 percent of all effort expended on software will be ex-pended after it is delivered to the customer for the first time.Myth:Until I get the program “running” I have no way of assessing its quality.Reality:One of the most effective software quality assurance mechanismscan be applied from the inception of a project— the technical review. Software reviews (described in Chapter 15) are a “quality filter” thathave been found to be more effective than testing for finding certainclasses of software defects.Myth:The only deliverable work product for a successful project is the workingprogram.Reality:A working program is only one part of a software configuration thatincludes many elements. A variety of work products (e.g., models,documents, plans) provide a foundation for successful engineeringand, more important, guidance for software support.Myth:Software engineering will make us create voluminous and unnecessarydocumentation and will invariably slow us down.Reality:Software engineering is not about creating documents. It is aboutcreating a quality product. Better quality leads to reduced rework.And reduced rework results in faster delivery times.CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 23
Whenever you think,we don’t have time forsoftware engineering,ask yourself, “Will wehave time to do it overagain?”
16 Many software engineers have adopted an “agile” approach that accommodates change incre-mentally, thereby controlling its impact and cost. Agile methods are discussed in Chapter 3.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 23Many software professionals recognize the fallacy of the myths just described.Regrettably, habitual attitudes and methods foster poor management and technicalpractices, even when reality dictates a better approach. Recognition of softwarerealities is the first step toward formulation of practical solutions for softwareengineering.
1.7 H OWITALLSTARTS
Every software project is precipitated by some business need—the need to correct adefect in an existing application; the need to adapt a “legacy system” to a changingbusiness environment; the need to extend the functions and features of an existingapplication; or the need to create a new product, service, or system.At the beginning of a software project, the business need is often expressedinformally as part of a simple conversation. The conversation presented in thesidebar is typical.24 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
How a Project Starts
The scene:Meeting room at CPICorporation, a (fictional) company that makes consumerproducts for home and commercial use.The players:Mal Golden, senior manager, productdevelopment; Lisa Perez, marketing manager; LeeWarren, engineering manager; Joe Camalleri, executiveVP, business developmentThe conversation:Joe:Okay, Lee, what’s this I hear about your folksdeveloping a what? A generic universal wireless box?Lee:It’s pretty cool . . . about the size of a smallmatchbook . . . we can attach it to sensors of all kinds, adigital camera, just about anything. Using the 802.11gwireless protocol. It allows us to access the device’s outputwithout wires. We think it’ll lead to a whole newgeneration of products.Joe:You agree, Mal?Mal:I do. In fact, with sales as flat as they’ve been thisyear, we need something new. Lisa and I have beendoing a little market research, and we think we’ve got aline of products that could be big.Joe:How big . . . bottom line big?Mal (avoiding a direct commitment): Tell him about our idea, Lisa.Lisa:It’s a whole new generation of what we call “homemanagement products.” We call ’em SafeHome. They use the new wireless interface, provide homeowners or small-business people with a system that’s controlled by theirPC—home security, home surveillance, appliance anddevice control—you know, turn down the home airconditioner while you’re driving home, that sort of thing.Lee (jumping in):Engineering’s done a technicalfeasibility study of this idea, Joe. It’s doable at lowmanufacturing cost. Most hardware is off-the-shelf.Software is an issue, but it’s nothing that we can’t do.Joe:Interesting. Now, I asked about the bottom line.Mal:PCs have penetrated over 70 percent of allhouseholds in the USA. If we could price this thing right, it could be a killer-App. Nobody else has our wirelessbox . . . it’s proprietary. We’ll have a 2-year jump onthe competition. Revenue? Maybe as much as 30 to 40 million dollars in the second year.Joe (smiling):Let’s take this to the next level. I’minterested.SAFEHOME17
17 The SafeHomeproject will be used throughout this book to illustrate the inner workings of a projectteam as it builds a software product. The company, the project, and the people are purely fictitious,but the situations and problems are real.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 24CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 25
With the exception of a passing reference, software was hardly mentioned as partof the conversation. And yet, software will make or break the SafeHomeproduct line. The engineering effort will succeed only if SafeHome software succeeds. The market will accept the product only if the software embedded within it properly meets thecustomer’s (as yet unstated) needs. We’ll follow the progression of SafeHomesoftware engineering in many of the chapters that follow.
1.8 S UMMARY
Software is the key element in the evolution of computer-based systems andproducts and one of the most important technologies on the world stage. Over thepast 50 years, software has evolved from a specialized problem solving and infor-mation analysis tool to an industry in itself. Yet we still have trouble developing high-quality software on time and within budget.Software—programs, data, and descriptive information—addresses a wide arrayof technology and application areas. Legacy software continues to present specialchallenges to those who must maintain it.Web-based systems and applications have evolved from simple collections of in-formation content to sophisticated systems that present complex functionality andmultimedia content. Although these WebApps have unique features and require-ments, they are software nonetheless.Software engineering encompasses process, methods, and tools that enablecomplex computer-based systems to be built in a timely manner with quality. Thesoftware process incorporates five framework activities—communication, planning,modeling, construction, and deployment—that are applicable to all software proj-ects. Software engineering practice is a problem solving activity that follows a set ofcore principles.A wide array of software myths continue to lead managers and practitionersastray, even as our collective knowledge of software and the technologies requiredto build it grows. As you learn more about software engineering, you’ll begin to un-derstand why these myths should be debunked whenever they are encountered.
PROBLEMS AND POINTS TO PONDER
1.1.Provide at least five additional examples of how the law of unintended consequencesapplies to computer software.1.2.Provide a number of examples (both positive and negative) that indicate the impact ofsoftware on our society.1.3.Develop your own answers to the five questions asked at the beginning of Section 1.1.Discuss them with your fellow students.1.4.Many modern applications change frequently—before they are presented to the end userand then after the first version has been put into use. Suggest a few ways to build software tostop deterioration due to change.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 251.5.Consider the seven software categories presented in Section 1.1.2. Do you think that thesame approach to software engineering can be applied for each? Explain your answer.1.6.Figure 1.3 places the three software engineering layers on top of a layer entitled “a qualityfocus.” This implies an organizational quality program such as total quality management .Do a bit of research and develop an outline of the key tenets of a total quality management program.1.7.Is software engineering applicable when WebApps are built? If so, how might it be modi-fied to accommodate the unique characteristics of WebApps?1.8.As software becomes more pervasive, risks to the public (due to faulty programs) becomean increasingly significant concern. Develop a doomsday but realistic scenario in which the fail-ure of a computer program could do great harm (either economic or human).1.9.Describe a process framework in your own words. When we say that framework activitiesare applicable to all projects, does this mean that the same work tasks are applied for allprojects, regardless of size and complexity? Explain.1.10.Umbrella activities occur throughout the software process. Do you think they are appliedevenly across the process, or are some concentrated in one or more framework activities.1.11.Add two additional myths to the list presented in Section 1.6. Also state the reality thataccompanies the myth.
FURTHER READINGS AND INFORMATION SOURCES18
There are literally thousands of books written about computer software. The vast majoritydiscuss programming languages or software applications, but a few discuss software itself.Pressman and Herron (Software Shock, Dorset House, 1991) presented an early discussion (directed at the layperson) of software and the way professionals build it. Negroponte’s best-selling book (Being Digital, Alfred A. Knopf, Inc., 1995) provides a view of computing and itsoverall impact in the twenty-first century. DeMarco (Why Does Software Cost So Much? Dorset House, 1995) has produced a collection of amusing and insightful essays on software and theprocess through which it is developed.Minasi (The Software Conspiracy: Why Software Companies Put out Faulty Products, How TheyCan Hurt You, and What You Can Do, McGraw-Hill, 2000) argues that the “modern scourge” of software bugs can be eliminated and suggests ways to accomplish this. Compaine ( Digital Divide: Facing a Crisis or Creating a Myth, MIT Press, 2001) argues that the “divide” between those who have access to information resources (e.g., the Web) and those that do not is narrowing aswe move into the first decade of this century. Books by Greenfield (Everyware: The Dawning Ageof Ubiquitous Computing,New Riders Publishing, 2006) and Loke ( Context-Aware Pervasive Systems: Architectures for a New Breed of Applications, Auerbach, 2006) introduce the concept of “open-world” software and predict a wireless environment in which software must adapt torequirements that emerge in real time.The current state of the software engineering and the software process can best be deter-mined from publications such as IEEE Software, IEEE Computer, CrossTalk, and IEEE Transactions on Software Engineering.Industry periodicals such as Application Development Trends andCutter26 CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING
18 The Further Reading and Information Sources section presented at the conclusion of each chapter presents a brief overview of print sources that can help to expand your understanding of the majortopics presented in the chapter. I have created a comprehensive website to support SoftwareEngineering: A Practitioner’s Approach at www.mhhe.com/compsci/pressman. Among the many topics addressed within the website are chapter-by-chapter software engineering resourcesto Web-based information that can complement the material presented in each chapter. AnAmazon.com link to every book noted in this section is contained within these resources.pre75977_ch01.qxd  11/27/08  3:11 PM  Page 26IT Journaloften contain articles on software engineering topics. The discipline is “summarized”every year in the Proceeding of the International Conference on Software Engineering, sponsored by the IEEE and ACM, and is discussed in depth in journals such as ACM Transactions on SoftwareEngineering and Methodology, ACM Software Engineering Notes, andAnnals of Software Engineer- ing.Tens of thousands of websites are dedicated to software engineering and the softwareprocess.Many books addressing the software process and software engineering have been publishedin recent years. Some present an overview of the entire process, while others delve into a fewimportant topics to the exclusion of others. Among the more popular offerings (in addition tothis book!) areAbran, A., and J. Moore, SWEBOK: Guide to the Software Engineering Body of Knowledge, IEEE, 2002.Andersson, E., et al., Software Engineering for Internet Applications, The MIT Press, 2006. Christensen, M., and R. Thayer, A Project Manager’s Guide to Software Engineering Best Prac-tices,IEEE-CS Press (Wiley), 2002.Glass, R., Fact and Fallacies of Software Engineering, Addison-Wesley, 2002. Jacobson, I., Object-Oriented Software Engineering: A Use Case Driven Approach, 2d ed., Addison-Wesley, 2008.Jalote, P., An Integrated Approach to Software Engineering, Springer, 2006. Pfleeger, S., Software Engineering: Theory and Practice, 3d ed., Prentice-Hall, 2005. Schach, S., Object-Oriented and Classical Software Engineering, 7th ed., McGraw-Hill, 2006. Sommerville, I., Software Engineering, 8th ed., Addison-Wesley, 2006. Tsui, F., and O. Karam, Essentials of Software Engineering, Jones & Bartlett Publishers, 2006. Many software engineering standards have been published by the IEEE, ISO, and their stan-dards organizations over the past few decades. Moore (The Road Map to Software Engineering:A Standards-Based Guide,Wiley-IEEE Computer Society Press, 2006) provides a useful survey ofrelevant standards and how they apply to real projects.A wide variety of information sources on software engineering and the software process areavailable on the Internet. An up-to-date list of World Wide Web references that are relevant tothe software process can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 1SOFTWARE AND SOFTWARE ENGINEERING 27pre75977_ch01.qxd  11/27/08  3:11 PM  Page 27pre75977_ch01.qxd  11/27/08  3:11 PM  Page 28THESOFTWARE
PROCESS
29PART
One
In this part of Software Engineering: A Practitioner’s Approach you’ll learn about the process that provides a framework forsoftware engineering practice. These questions are addressedin the chapters that follow:•What is a software process?•What are the generic framework activities that are present inevery software process?•How are processes modeled and what are process patterns?•What are the prescriptive process models and what are theirstrengths and weaknesses?•Why is agilitya watchword in modern software engineeringwork?•What is agile software development and how does it differfrom more traditional process models?Once these questions are answered you’ll be better prepared tounderstand the context in which software engineering practice isapplied.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 29In a fascinating book that provides an economist’s view of software and soft-ware engineering, Howard Baetjer, Jr. [Bae98], comments on the softwareprocess: 
Because software, like all capital, is embodied knowledge, and because that knowl-edge is initially dispersed, tacit, latent, and incomplete in large measure, software de-velopment is a social learning process. The process is a dialogue in which theknowledge that must become the software is brought together and embodied in thesoftware. The process provides interaction between users and designers, betweenusers and evolving tools, and between designers and evolving tools [technology]. It isan iterative process in which the evolving tool itself serves as the medium for com-munication, with each new round of the dialogue eliciting more useful knowledgefrom the people involved.
Indeed, building computer software is an iterative social learning process, andthe outcome, something that Baetjer would call “software capital,” is an embodi-ment of knowledge collected, distilled, and organized as the process is conducted.
30CHAPTER
2PROCESS
MODELS
KEY
CONCEPTS
component-baseddevelopment . . . . . .50concurrent models  . .48evolutionary processmodels  . . . . . . . . . .42formal methods model . . . . . . . . . . .51generic process model . . . . . . . . . . .31incremental processmodels  . . . . . . . . . .41personal softwareprocess . . . . . . . . . .57prescriptive processmodels  . . . . . . . . . .38process patterns  . . .35task set  . . . . . . . . .34team software process . . . . . . . . . .58Unified Process  . . . .53
What is it?When you work to builda product or system, it’s important togo through a series of predictablesteps—a road map that helps youcreate a timely, high-quality result. The road mapthat you follow is called a “software process.” Who does it?Software engineers and theirmanagers adapt the process to their needs andthen follow it. In addition, the people who haverequested the software have a role to play in theprocess of defining, building, and testing it. Why is it important?Because it providesstability, control, and organization to an activitythat can, if left uncontrolled, become quitechaotic. However, a modern software engineer-ing approach must be “agile.” It must demandonly those activities, controls, and work productsthat are appropriate for the project team and theproduct that is to be produced.QUICK
LOOKWhat are the steps?At a detailed level, theprocess that you adopt depends on the softwarethat you’re building. One process might be ap-propriate for creating software for an aircraftavionics system, while an entirely different processwould be indicated for the creation of a website.What is the work product?From the point ofview of a software engineer, the work productsare the programs, documents, and data that areproduced as a consequence of the activities andtasks defined by the process. How do I ensure that I’ve done it right?There are a number of software processassessment mechanisms that enable organiza-tions to determine the “maturity” of their soft-ware process. However, the quality, timeliness,and long-term viability of the product youbuild are the best indicators of the efficacy ofthe process that you use.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 30CHAPTER 2PROCESS MODELS 31
But what exactly is a software process from a technical point of view? Within thecontext of this book, I define a software process as a framework for the activities, ac- tions, and tasks that are required to build high-quality software. Is “process” syn-onymous with software engineering? The answer is “yes and no.” A software processdefines the approach that is taken as software is engineered. But software engi-neering also encompasses technologies that populate the process—technical meth-ods and automated tools.More important, software engineering is performed by creative, knowledgeablepeople who should adapt a mature software process so that it is appropriate for theproducts that they build and the demands of their marketplace.
2.1 A G ENERIC PROCESS MODEL
In Chapter 1, a process was defined as a collection of work activities, actions, andtasks that are performed when some work product is to be created. Each of theseactivities, actions, and tasks reside within a framework or model that defines theirrelationship with the process and with one another.The software process is represented schematically in Figure 2.1. Referring to thefigure, each framework activity is populated by a set of software engineering actions.Each software engineering action is defined by a task set that identifies the work tasks that are to be completed, the work products that will be produced, the qualityassurance points that will be required, and the milestones that will be used to indi-cate progress.As I discussed in Chapter 1, a generic process framework for software engineer-ing defines five framework activities—communication, planning, modeling,construction,and deployment.In addition, a set of umbrella activities—projecttracking and control, risk management, quality assurance, configuration manage-ment, technical reviews, and others—are applied throughout the process.You should note that one important aspect of the software process has notyet been discussed. This aspect—called process flow—describes how the frame- work activities and the actions and tasks that occur within each frameworkactivity are organized with respect to sequence and time and is illustrated inFigure 2.2.A linear process flowexecutes each of the five framework activities in sequence,beginning with communication and culminating with deployment (Figure 2.2a). Aniterative process flowrepeats one or more of the activities before proceeding to thenext (Figure 2.2b). An evolutionary process flow executes the activities in a “circular” manner. Each circuit through the five activities leads to a more complete versionof the software (Figure 2.2c). A parallel process flow (Figure 2.2d) executes one or more activities in parallel with other activities (e.g., modeling for one aspect of thesoftware might be executed in parallel with construction of another aspect of thesoftware).
The hierarchy oftechnical work withinthe software process isactivities,encompassing actions,populated by tasks.
uote:
“We think thatsoftwaredevelopers aremissing a vitaltruth: mostorganizations don’tknow what theydo. They think theyknow, but theydon’t know.”Tom DeMarcopre75977_ch02.qxd  11/27/08  3:21 PM  Page 312.1.1 Defining a Framework Activity
Although I have described five framework activities and provided a basic defini-tion of each in Chapter 1, a software team would need significantly more infor-mation before it could properly execute any one of these activities as part of thesoftware process. Therefore, you are faced with a key question: What actions are appropriate for a framework activity, given the nature of the problem to be solved, thecharacteristics of the people doing the work, and the stakeholders who are sponsor-ing the project?32 PART ONETHE SOFTWARE PROCESS
Process frameworkUmbrella activities
framework activity # 1
Task setswork taskswork productsquality assurance pointsproject milestonessoftware engineering action #1.1
Task setswork taskswork productsquality assurance pointsproject milestonessoftware engineering action #1. k
framework activity # n
Task setswork taskswork productsquality assurance pointsproject milestonessoftware engineering action #n.1
Task setswork taskswork productsquality assurance pointsproject milestonessoftware engineering action #n. mSoftware processFIGURE 2.1
A softwareprocessframeworkpre75977_ch02.qxd  11/27/08  3:21 PM  Page 32CHAPTER 2PROCESS MODELS 33
(d) Parallel process flow(c) Evolutionary process flowCommunication Planning Modeling(a) Linear process flowConstruction Deployment
Communication Planning Modeling Construction Deployment
Construction DeploymentCommunication PlanningModelingTime(b) Iterative process flowPlanningModeling
ConstructionDeploymentIncrementreleasedCommunicationFIGURE 2.2 Process flow
For a small software project requested by one person (at a remote location) withsimple, straightforward requirements, the communication activity might encompasslittle more than a phone call with the appropriate stakeholder. Therefore, the onlynecessary action is phone conversation, and the work tasks (the task set) that this action encompasses are:1.Make contact with stakeholder via telephone.2.Discuss requirements and take notes.How does aframeworkactivity change asthe nature of theproject changes??pre75977_ch02.qxd  11/27/08  3:21 PM  Page 333.Organize notes into a brief written statement of requirements.4.E-mail to stakeholder for review and approval.If the project was considerably more complex with many stakeholders, each witha different set of (sometime conflicting) requirements, the communication activitymight have six distinct actions (described in Chapter 5): inception, elicitation, elabo-ration, negotiation, specification,andvalidation. Each of these software engineering actions would have many work tasks and a number of distinct work products.
2.1.2 Identifying a Task Set
Referring again to Figure 2.1, each software engineering action (e.g., elicitation, an action associated with the communication activity) can be represented by a numberof different task sets—each a collection of software engineering work tasks, relatedwork products, quality assurance points, and project milestones. You should choosea task set that best accommodates the needs of the project and the characteristics ofyour team. This implies that a software engineering action can be adapted to the spe-cific needs of the software project and the characteristics of the project team. 34 PART ONETHE SOFTWARE PROCESS
Task Set
A task set defines the actual work to be doneto accomplish the objectives of a softwareengineering action. For example,elicitation(more commonly called “requirements gathering”) is animportant software engineering action that occurs duringthe communication activity. The goal of requirementsgathering is to understand what various stakeholders wantfrom the software that is to be built.For a small, relatively simple project, the task set forrequirements gathering might look like this:1. Make a list of stakeholders for the project.2. Invite all stakeholders to an informal meeting.3. Ask each stakeholder to make a list of features andfunctions required.4. Discuss requirements and build a final list.5. Prioritize requirements.6. Note areas of uncertainty.For a larger, more complex software project, adifferent task set would be required. It might encompassthe following work tasks:1. Make a list of stakeholders for the project.2. Interview each stakeholder separately to determineoverall wants and needs.3. Build a preliminary list of functions and featuresbased on stakeholder input.4. Schedule a series of facilitated applicationspecification meetings.5. Conduct meetings.6. Produce informal user scenarios as part of eachmeeting.7. Refine user scenarios based on stakeholderfeedback.8. Build a revised list of stakeholder requirements.9. Use quality function deployment techniques toprioritize requirements.10. Package requirements so that they can be deliveredincrementally.11. Note constraints and restrictions that will be placedon the system.12. Discuss methods for validating the system.Both of these task sets achieve “requirements gathering,”but they are quite different in their depth and formality. Thesoftware team chooses the task set that will allow it toachieve the goal of each action and still maintain qualityand agility.INFODifferent projectsdemand different tasksets. The softwareteam chooses the taskset based on problemand projectcharacteristics.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 342.1.3 Process Patterns
Every software team encounters problems as it moves through the software process.It would be useful if proven solutions to these problems were readily available to theteam so that the problems could be addressed and resolved quickly. A process pattern
1describes a process-related problem that is encountered during software en-gineering work, identifies the environment in which the problem has been encoun-tered, and suggests one or more proven solutions to the problem. Stated in moregeneral terms, a process pattern provides you with a template [Amb98]—a consis-tent method for describing problem solutions within the context of the softwareprocess. By combining patterns, a software team can solve problems and constructa process that best meets the needs of a project.Patterns can be defined at any level of abstraction.
2In some cases, a pattern might be used to describe a problem (and solution) associated with a complete processmodel (e.g., prototyping). In other situations, patterns can be used to describe a prob-lem (and solution) associated with a framework activity (e.g., planning) or an actionwithin a framework activity (e.g., project estimating).Ambler [Amb98] has proposed a template for describing a process pattern:Pattern Name.The pattern is given a meaningful name describing itwithin the context of the software process (e.g., TechnicalReviews ). Forces.The environment in which the pattern is encountered and theissues that make the problem visible and may affect its solution.Type.The pattern type is specified. Ambler [Amb98] suggests three types:1.Stage pattern—defines a problem associated with a framework activity forthe process. Since a framework activity encompasses multiple actions andwork tasks, a stage pattern incorporates multiple task patterns (see the fol-lowing) that are relevant to the stage (framework activity). An example of astage pattern might beEstablishingCommunication.This pattern would incorporate the task patternRequirementsGatheringand others. 2.Task pattern—defines a problem associated with a software engineeringaction or work task and relevant to successful software engineeringpractice (e.g., RequirementsGathering is a task pattern).3.Phase pattern—define the sequence of framework activities that occurswithin the process, even when the overall flow of activities is iterativein nature. An example of a phase pattern might be SpiralModelor Prototyping.
3CHAPTER 2PROCESS MODELS 35
1 A detailed discussion of patterns is presented in Chapter 12.2 Patterns are applicable to many software engineering activities. Analysis, design, and testingpatterns are discussed in Chapters 7, 9, 10, 12, and 14. Patterns and “antipatterns” for projectmanagement activities are discussed in Part 4 of this book.3 These phase patterns are discussed in Section 2.3.3.What is aprocesspattern??
uote:
“The repetition ofpatterns is quite adifferent thing thanthe repetition ofparts. Indeed, thedifferent parts willbe unique becausethe patterns are thesame.”ChristopherAlexander
A pattern templateprovides a consistentmeans for describing apattern.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 35Initial context.Describes the conditions under which the pattern applies.Prior to the initiation of the pattern: (1) What organizational or team-related ac-tivities have already occurred? (2) What is the entry state for the process?(3) What software engineering information or project information already exists?For example, the Planningpattern (a stage pattern) requires that (1) cus-tomers and software engineers have established a collaborative communi-cation; (2) successful completion of a number of task patterns [specified] forthe Communicationpattern has occurred; and (3) the project scope, basicbusiness requirements, and project constraints are known.Problem.The specific problem to be solved by the pattern.Solution.Describes how to implement the pattern successfully. This sec-tion describes how the initial state of the process (that exists before the pat-tern is implemented) is modified as a consequence of the initiation of thepattern. It also describes how software engineering information or projectinformation that is available before the initiation of the pattern is transformedas a consequence of the successful execution of the pattern.Resulting Context.Describes the conditions that will result once the pat-tern has been successfully implemented. Upon completion of the pattern:(1) What organizational or team-related activities must have occurred?(2) What is the exit state for the process? (3) What software engineeringinformation or project information has been developed? Related Patterns.Provide a list of all process patterns that are directlyrelated to this one. This may be represented as a hierarchy or in some otherdiagrammatic form. For example, the stage pattern Communication encompasses the task patterns: ProjectTeam, CollaborativeGuidelines,ScopeIsolation, RequirementsGathering, ConstraintDescription, and ScenarioCreation.Known Uses and Examples.Indicate the specific instances in which thepattern is applicable. For example, Communicationis mandatory at the beginning of every software project, is recommended throughout the softwareproject, and is mandatory once the deployment activity is under way.Process patterns provide an effective mechanism for addressing problems asso-ciated with any software process. The patterns enable you to develop a hierarchicalprocess description that begins at a high level of abstraction (a phase pattern). Thedescription is then refined into a set of stage patterns that describe frameworkactivities and are further refined in a hierarchical fashion into more detailed taskpatterns for each stage pattern. Once process patterns have been developed, theycan be reused for the definition of process variants—that is, a customized processmodel can be defined by a software team using the patterns as building blocks forthe process model.36 PART ONETHE SOFTWARE PROCESS
WebRef
Comprehensiveresources on processpatterns can be foundat www.ambysoft.com/processPatternsPage.html.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 362.2 P ROCESS ASSESSMENT AND IMPROVEMENT
The existence of a software process is no guarantee that software will be deliveredon time, that it will meet the customer’s needs, or that it will exhibit the technicalcharacteristics that will lead to long-term quality characteristics (Chapters 14 and16). Process patterns must be coupled with solid software engineering practice(Part 2 of this book). In addition, the process itself can be assessed to ensure that itmeets a set of basic process criteria that have been shown to be essential for a suc-cessful software engineering.
4
A number of different approaches to software process assessment andimprovement have been proposed over the past few decades:Standard CMMI Assessment Method for Process Improvement(SCAMPI)—provides a five-step process assessment model that incorporatesfive phases: initiating, diagnosing, establishing, acting, and learning. TheSCAMPI method uses the SEI CMMI as the basis for assessment [SEI00].CHAPTER 2PROCESS MODELS 37
4 The SEI’s CMMI [CMM07] describes the characteristics of a software process and the criteria for asuccessful process in voluminous detail.Assessment attempts tounderstand the currentstate of the softwareprocess with the intentof improving it.
What formaltechniquesare available forassessing thesoftware process??INFO
An Example Process Pattern
The following abbreviated process patterndescribes an approach that may be applicablewhen stakeholders have a general idea of what must bedone but are unsure of specific software requirements.Pattern name.RequirementsUnclearIntent.This pattern describes an approach for building amodel (a prototype) that can be assessed iteratively bystakeholders in an effort to identify or solidify softwarerequirements.Type.Phase pattern.Initial context.The following conditions must be metprior to the initiation of this pattern: (1) stakeholders havebeen identified; (2) a mode of communication betweenstakeholders and the software team has been established;(3) the overriding software problem to be solved has beenidentified by stakeholders; (4) an initial understanding ofproject scope, basic business requirements, and projectconstraints has been developed.Problem.Requirements are hazy or nonexistent, yetthere is clear recognition that there is a problem to besolved, and the problem must be addressed with asoftware solution. Stakeholders are unsure of what theywant; that is, they cannot describe software requirementsin any detail.Solution.A description of the prototyping processwould be presented here and is described later inSection 2.3.3.Resulting context.A software prototype that identifiesbasic requirements (e.g., modes of interaction,computational features, processing functions) is approvedby stakeholders. Following this, (1) the prototype mayevolve through a series of increments to become theproduction software or (2) the prototype may be discardedand the production software built using some other processpattern.Related patterns.The following patterns are related tothis pattern: CustomerCommunication,IterativeDesign, IterativeDevelopment,CustomerAssessment, RequirementExtraction.Known uses and examples.Prototyping isrecommended when requirements are uncertain. pre75977_ch02.qxd  11/27/08  3:21 PM  Page 37CMM-Based Appraisal for Internal Process Improvement (CBA IPI) — provides a diagnostic technique for assessing the relative maturity of asoftware organization; uses the SEI CMM as the basis for the assessment[Dun01].SPICE (ISO/IEC15504)—a standard that defines a set of requirements forsoftware process assessment. The intent of the standard is to assist organi-zations in developing an objective evaluation of the efficacy of any definedsoftware process [ISO08].ISO 9001:2000 for Software—a generic standard that applies to any or-ganization that wants to improve the overall quality of the products, systems,or services that it provides. Therefore, the standard is directly applicable tosoftware organizations and companies [Ant06].A more detailed discussion of software assessment and process improvementmethods is presented in Chapter 30.
2.3 P RESCRIPTIVE PROCESS MODELS
Prescriptive process models were originally proposed to bring order to the chaosof software development. History has indicated that these traditional modelshave brought a certain amount of useful structure to software engineering work andhave provided a reasonably effective road map for software teams. However, softwareengineering work and the product that it produces remain on “the edge of chaos.”In an intriguing paper on the strange relationship between order and chaos in thesoftware world, Nogueira and his colleagues [Nog00] state
The edge of chaos is defined as “a natural state between order and chaos, a grand com-promise between structure and surprise” [Kau95]. The edge of chaos can be visualized asan unstable, partially structured state. . . . It is unstable because it is constantly attractedto chaos or to absolute order.We have the tendency to think that order is the ideal state of nature. This could be a mis-take. Research . . . supports the theory that operation away from equilibrium generates cre-ativity, self-organized processes, and increasing returns [Roo96]. Absolute order means theabsence of variability, which could be an advantage under unpredictable environments.Change occurs when there is some structure so that the change can be organized, but notso rigid that it cannot occur. Too much chaos, on the other hand, can make coordinationand coherence impossible. Lack of structure does not always mean disorder.
The philosophical implications of this argument are significant for software engineer-ing. If prescriptive process models
5strive for structure and order, are they inappropri-ate for a software world that thrives on change? Yet, if we reject traditional process38 PART ONETHE SOFTWARE PROCESS
5 Prescriptive process models are sometimes referred to as “traditional” process models.uote:
“Softwareorganizations haveexhibitedsignificantshortcomings intheir ability tocapitalize on theexperiences gainedfrom completedprojects.”NASA
uote:
“If the process isright, the resultswill take care ofthemselves.”Takashi Osadapre75977_ch02.qxd  11/27/08  3:21 PM  Page 38models (and the order they imply) and replace them with something less structured,do we make it impossible to achieve coordination and coherence in software work?There are no easy answers to these questions, but there are alternatives availableto software engineers. In the sections that follow, I examine the prescriptive processapproach in which order and project consistency are dominant issues. I call them“prescriptive” because they prescribe a set of process elements—framework activi-ties, software engineering actions, tasks, work products, quality assurance, andchange control mechanisms for each project. Each process model also prescribes aprocess flow (also called a work flow)—that is, the manner in which the processelements are interrelated to one another.All software process models can accommodate the generic framework activitiesdescribed in Chapter 1, but each applies a different emphasis to these activities anddefines a process flow that invokes each framework activity (as well as softwareengineering actions and tasks) in a different manner.
2.3.1 The Waterfall Model
There are times when the requirements for a problem are well understood—whenwork flows from communicationthrough deploymentin a reasonably linear fash- ion. This situation is sometimes encountered when well-defined adaptations or en-hancements to an existing system must be made (e.g., an adaptation to accountingsoftware that has been mandated because of changes to government regulations). Itmay also occur in a limited number of new development efforts, but only whenrequirements are well defined and reasonably stable.The waterfall model,sometimes called the classic life cycle, suggests a systematic,sequential approach
6to software development that begins with customer specifica-tion of requirements and progresses through planning, modeling, construction, anddeployment, culminating in ongoing support of the completed software (Figure 2.3).A variation in the representation of the waterfall model is called the V-model. Represented in Figure 2.4, the V-model [Buc99] depicts the relationship of qualityCHAPTER 2PROCESS MODELS 39
Communication
 project initiation requirements gatheringPlanning
 estimating scheduling trackingModeling
 analysis design Deployment
 delivery support feedbackConstruction
 code testFIGURE 2.3 The waterfall model
6 Although the original waterfall model proposed by Winston Royce [Roy70] made provision for“feedback loops,” the vast majority of organizations that apply this process model treat it as if itwere strictly linear.Prescriptive processmodels define aprescribed set ofprocess elements anda predictable processwork flow.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 39assurance actions to the actions associated with communication, modeling, andearly construction activities. As a software team moves down the left side of the V,basic problem requirements are refined into progressively more detailed and techni-cal representations of the problem and its solution. Once code has been generated,the team moves up the right side of the V, essentially performing a series of tests(quality assurance actions) that validate each of the models created as the teammoved down the left side.
7In reality, there is no fundamental difference between theclassic life cycle and the V-model. The V-model provides a way of visualizing howverification and validation actions are applied to earlier engineering work.The waterfall model is the oldest paradigm for software engineering. However,over the past three decades, criticism of this process model has caused even ardentsupporters to question its efficacy [Han95]. Among the problems that are sometimesencountered when the waterfall model is applied are:1.Real projects rarely follow the sequential flow that the model proposes.Although the linear model can accommodate iteration, it does so indirectly.As a result, changes can cause confusion as the project team proceeds.40 PART ONETHE SOFTWARE PROCESS
7 A detailed discussion of quality assurance actions is presented in Part 3 of this book.The V-model illustrateshow verification andvalidation actions areassociated with earlierengineering actions.
Why doesthe waterfallmodel sometimesfail??CodegenerationArchitecturaldesignComponentdesignRequirementsmodeling AcceptancetestingSystemtestingIntegrationtestingUnittesting
ExecutablesoftwareFIGURE 2.4
The V-modelpre75977_ch02.qxd  11/27/08  3:21 PM  Page 402.It is often difficult for the customer to state all requirements explicitly. Thewaterfall model requires this and has difficulty accommodating the naturaluncertainty that exists at the beginning of many projects.3.The customer must have patience. A working version of the program(s) willnot be available until late in the project time span. A major blunder, if unde-tected until the working program is reviewed, can be disastrous.In an interesting analysis of actual projects, Bradac [Bra94] found that the linearnature of the classic life cycle leads to “blocking states” in which some project teammembers must wait for other members of the team to complete dependent tasks. Infact, the time spent waiting can exceed the time spent on productive work! Theblocking states tend to be more prevalent at the beginning and end of a linearsequential process.Today, software work is fast-paced and subject to a never-ending stream ofchanges (to features, functions, and information content). The waterfall model isoften inappropriate for such work. However, it can serve as a useful process modelin situations where requirements are fixed and work is to proceed to completion ina linear manner.
2.3.2 Incremental Process Models
There are many situations in which initial software requirements are reasonably welldefined, but the overall scope of the development effort precludes a purely linearprocess. In addition, there may be a compelling need to provide a limited set of soft-ware functionality to users quickly and then refine and expand on that functionalityin later software releases. In such cases, you can choose a process model that isdesigned to produce the software in increments.The incrementalmodel combines elements of linear and parallel process flowsdiscussed in Section 2.1. Referring to Figure 2.5, the incremental model applies linearsequences in a staggered fashion as calendar time progresses. Each linear sequenceproduces deliverable “increments” of the software [McD93] in a manner that is sim-ilar to the increments produced by an evolutionary process flow (Section 2.3.3).For example, word-processing software developed using the incremental para-digm might deliver basic file management, editing, and document production func-tions in the first increment; more sophisticated editing and document productioncapabilities in the second increment; spelling and grammar checking in the third in-crement; and advanced page layout capability in the fourth increment. It should benoted that the process flow for any increment can incorporate the prototypingparadigm. When an incremental model is used, the first increment is often a core product.That is, basic requirements are addressed but many supplementary features (someknown, others unknown) remain undelivered. The core product is used by the cus-tomer (or undergoes detailed evaluation). As a result of use and/or evaluation, aCHAPTER 2PROCESS MODELS 41
uote:
“Too often,software workfollows the first lawof bicycling: Nomatter whereyou’re going, it’suphill and againstthe wind.”Author unknown
The incremental modeldelivers a series ofreleases, calledincrements, thatprovide progressivelymore functionality forthe customer as eachincrement is delivered.
Your customerdemands delivery by adate that is impossibleto meet. Suggest deliv-ering one or moreincrements by thatdate and the rest ofthe software (addi-tional increments)later.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 41plan is developed for the next increment. The plan addresses the modification of thecore product to better meet the needs of the customer and the delivery of additionalfeatures and functionality. This process is repeated following the delivery of eachincrement, until the complete product is produced.The incremental process model focuses on the delivery of an operational productwith each increment. Early increments are stripped-down versions of the final prod-uct, but they do provide capability that serves the user and also provide a platformfor evaluation by the user.
8
Incremental development is particularly useful when staffing is unavailable for acomplete implementation by the business deadline that has been established for theproject. Early increments can be implemented with fewer people. If the core productis well received, then additional staff (if required) can be added to implement the nextincrement. In addition, increments can be planned to manage technical risks. For ex-ample, a major system might require the availability of new hardware that is underdevelopment and whose delivery date is uncertain. It might be possible to plan earlyincrements in a way that avoids the use of this hardware, thereby enabling partialfunctionality to be delivered to end users without inordinate delay.
2.3.3 Evolutionary Process Models
Software, like all complex systems, evolves over a period of time. Business and prod-uct requirements often change as development proceeds, making a straight line pathto an end product unrealistic; tight market deadlines make completion of a compre-hensive software product impossible, but a limited version must be introduced to42 PART ONETHE SOFTWARE PROCESS
Evolutionary processmodels produce anincreasingly morecomplete version ofthe software with eachiteration.
8 It is important to note that an incremental philosophy is also used for all “agile” process models dis-cussed in Chapter 3.increment # 1increment # 2
delivery of1st incrementdelivery of2nd incrementdelivery of nth incrementincrement # n
Project Calendar TimeSoftware Functionality and FeaturesCommunication
Planning
Modeling (analysis, design)
Construction (code, test)
Deployment (delivery, feedback)FIGURE 2.5
The incrementalmodelpre75977_ch02.qxd  11/27/08  3:21 PM  Page 42meet competitive or business pressure; a set of core product or system requirementsis well understood, but the details of product or system extensions have yet to bedefined. In these and similar situations, you need a process model that has beenexplicitly designed to accommodate a product that evolves over time.Evolutionary models are iterative. They are characterized in a manner thatenables you to develop increasingly more complete versions of the software. In theparagraphs that follow, I present two common evolutionary process models.Prototyping.Often, a customer defines a set of general objectives for software,but does not identify detailed requirements for functions and features. In othercases, the developer may be unsure of the efficiency of an algorithm, the adapt-ability of an operating system, or the form that human-machine interaction shouldtake. In these, and many other situations, a prototyping paradigmmay offer the best approach.Although prototyping can be used as a stand-alone process model, it is more com-monly used as a technique that can be implemented within the context of any oneof the process models noted in this chapter. Regardless of the manner in which it isapplied, the prototyping paradigm assists you and other stakeholders to betterunderstand what is to be built when requirements are fuzzy.The prototyping paradigm (Figure 2.6) begins with communication. You meet withother stakeholders to define the overall objectives for the software, identify whateverrequirements are known, and outline areas where further definition is mandatory. Aprototyping iteration is planned quickly, and modeling (in the form of a “quick de-sign”) occurs. A quick design focuses on a representation of those aspects of the soft-ware that will be visible to end users (e.g., human interface layout or output displayCHAPTER 2PROCESS MODELS 43
uote:
“Plan to throw oneaway. You will dothat, anyway. Youronly choice iswhether to try tosell the throwawayto customers.”Frederick P .Brooks
When your customerhas a legitimate need,but is clueless aboutthe details, develop aprototype as a firststep.
CommunicationQuick plan
ConstructionofprototypeModeling Quick design  
Deployment  Delivery   & FeedbackFIGURE 2.6
The prototypingparadigmpre75977_ch02.qxd  11/27/08  3:21 PM  Page 43formats). The quick design leads to the construction of a prototype. The prototype isdeployed and evaluated by stakeholders, who provide feedback that is used to fur-ther refine requirements. Iteration occurs as the prototype is tuned to satisfy theneeds of various stakeholders, while at the same time enabling you to better under-stand what needs to be done.Ideally, the prototype serves as a mechanism for identifying software require-ments. If a working prototype is to be built, you can make use of existing programfragments or apply tools (e.g., report generators and window managers) that enableworking programs to be generated quickly.But what do you do with the prototype when it has served the purpose describedearlier? Brooks [Bro95] provides one answer:
In most projects, the first system built is barely usable. It may be too slow, too big, awk-ward in use or all three. There is no alternative but to start again, smarting but smarter,and build a redesigned version in which these problems are solved.
The prototype can serve as “the first system.” The one that Brooks recommendsyou throw away. But this may be an idealized view. Although some prototypes arebuilt as “throwaways,” others are evolutionary in the sense that the prototype slowlyevolves into the actual system.Both stakeholders and software engineers like the prototyping paradigm. Usersget a feel for the actual system, and developers get to build something immediately.Yet, prototyping can be problematic for the following reasons:1.Stakeholders see what appears to be a working version of the software,unaware that the prototype is held together haphazardly, unaware that in therush to get it working you haven’t considered overall software quality orlong-term maintainability. When informed that the product must be rebuilt sothat high levels of quality can be maintained, stakeholders cry foul anddemand that “a few fixes” be applied to make the prototype a workingproduct. Too often, software development management relents.2.As a software engineer, you often make implementation compromises inorder to get a prototype working quickly. An inappropriate operating systemor programming language may be used simply because it is available andknown; an inefficient algorithm may be implemented simply to demonstratecapability. After a time, you may become comfortable with these choices andforget all the reasons why they were inappropriate. The less-than-idealchoice has now become an integral part of the system.Although problems can occur, prototyping can be an effective paradigm for soft-ware engineering. The key is to define the rules of the game at the beginning; that is,all stakeholders should agree that the prototype is built to serve as a mechanism fordefining requirements. It is then discarded (at least in part), and the actual softwareis engineered with an eye toward quality.44 PART ONETHE SOFTWARE PROCESS
Resist pressure toextend a roughprototype into aproduction product.Quality almost alwayssuffers as a result.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 44The Spiral Model.Originally proposed by Barry Boehm [Boe88], the spiral model is an evolutionary software process model that couples the iterative nature of proto-typing with the controlled and systematic aspects of the waterfall model. It providesthe potential for rapid development of increasingly more complete versions of thesoftware. Boehm [Boe01a] describes the model in the following manner:
The spiral development model is a risk-driven process model generator that is used to guide multi-stakeholder concurrent engineering of software intensive systems. It has twomain distinguishing features. One is a cyclic approach for incrementally growing a sys- tem’s degree of definition and implementation while decreasing its degree of risk. Theother is a set of anchor point milestones for ensuring stakeholder commitment to feasible and mutually satisfactory system solutions.
Using the spiral model, software is developed in a series of evolutionary releases.During early iterations, the release might be a model or prototype. During later iter-ations, increasingly more complete versions of the engineered system are produced.CHAPTER 2PROCESS MODELS 45
The scene:Meeting room for thesoftware engineering group at CPI Corporation, a(fictional) company that makes consumer products forhome and commercial use.The players:Lee Warren, engineering manager; DougMiller, software engineering manager; Jamie Lazar,software team member; Vinod Raman, software teammember; and Ed Robbins, software team member.The conversation:Lee:So let’s recapitulate. I’ve spent some time discussingthe SafeHomeproduct line as we see it at the moment.No doubt, we’ve got a lot of work to do to simply definethe thing, but I’d like you guys to begin thinking abouthow you’re going to approach the software part of thisproject.Doug:Seems like we’ve been pretty disorganized in ourapproach to software in the past.Ed:I don’t know, Doug, we always got product outthe door.Doug:True, but not without a lot of grief, and thisproject looks like it’s bigger and more complex thananything we’ve done in the past.Jamie:Doesn’t look that hard, but I agree . . . ourad hoc approach to past projects won’t work here,particularly if we have a very tight time line.Doug (smiling):I want to be a bit more professional inour approach. I went to a short course last week andlearned a lot about software engineering . . . good stuff.We need a process here.Jamie (with a frown):My job is to build computerprograms, not push paper around.Doug:Give it a chance before you go negative onme. Here’s what I mean. [Doug proceeds to describethe process framework described in this chapter andthe prescriptive process models presented to this point.]Doug:So anyway, it seems to me that a linear model isnot for us . . . assumes we have all requirements up frontand, knowing this place, that’s not likely.Vinod:Yeah, and it sounds way too IT-oriented . . .probably good for building an inventory control systemor something, but it’s just not right for SafeHome.Doug:I agree.Ed:That prototyping approach seems OK. A lot like whatwe do here anyway.Vinod:That’s a problem. I’m worried that it doesn’tprovide us with enough structure.Doug:Not to worry. We’ve got plenty of other options,and I want you guys to pick what’s best for the team andbest for the project.SAFEHOMESelecting a Process Model, Part 1pre75977_ch02.qxd  11/27/08  3:21 PM  Page 45A spiral model is divided into a set of framework activities defined by the softwareengineering team. For illustrative purposes, I use the generic framework activitiesdiscussed earlier.
9Each of the framework activities represent one segment of the spi-ral path illustrated in Figure 2.7. As this evolutionary process begins, the softwareteam performs activities that are implied by a circuit around the spiral in a clockwisedirection, beginning at the center. Risk (Chapter 28) is considered as each revolutionis made. Anchor point milestones—a combination of work products and conditionsthat are attained along the path of the spiral—are noted for each evolutionary pass.The first circuit around the spiral might result in the development of a productspecification; subsequent passes around the spiral might be used to develop a pro-totype and then progressively more sophisticated versions of the software. Each passthrough the planning region results in adjustments to the project plan. Cost andschedule are adjusted based on feedback derived from the customer after delivery.In addition, the project manager adjusts the planned number of iterations requiredto complete the software.Unlike other process models that end when software is delivered, the spiral modelcan be adapted to apply throughout the life of the computer software. Therefore, thefirst circuit around the spiral might represent a “concept development project” thatstarts at the core of the spiral and continues for multiple iterations
10until concept46 PART ONETHE SOFTWARE PROCESS
9 The spiral model discussed in this section is a variation on the model proposed by Boehm. Forfurther information on the original spiral model, see [Boe88]. More recent discussion of Boehm’sspiral model can be found in [Boe98].10 The arrows pointing inward along the axis separating the deploymentregion from the commu- nicationregion indicate a potential for local iteration along the same spiral path.CommunicationPlanning 
Modeling
ConstructionDeployment 
delivery feedbackStartanalysis design
code testestimation scheduling risk analysisFIGURE 2.7
A typicalspiral model
The spiral model canbe adapted to applythroughout the entirelife cycle of anapplication, fromconcept developmentto maintenance.
WebRef
Useful informationabout the spiral modelcan be obtained at:www.sei.cmu.edu/publications/documents/00.reports/00sr008.html.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 46development is complete. If the concept is to be developed into an actual product,the process proceeds outward on the spiral and a “new product development proj-ect” commences. The new product will evolve through a number of iterations aroundthe spiral. Later, a circuit around the spiral might be used to represent a “product en-hancement project.” In essence, the spiral, when characterized in this way, remainsoperative until the software is retired. There are times when the process is dormant,but whenever a change is initiated, the process starts at the appropriate entry point(e.g., product enhancement).The spiral model is a realistic approach to the development of large-scale systemsand software. Because software evolves as the process progresses, the developerand customer better understand and react to risks at each evolutionary level. Thespiral model uses prototyping as a risk reduction mechanism but, more important,enables you to apply the prototyping approach at any stage in the evolution of theproduct. It maintains the systematic stepwise approach suggested by the classic lifecycle but incorporates it into an iterative framework that more realistically reflectsthe real world. The spiral model demands a direct consideration of technical risks atall stages of the project and, if properly applied, should reduce risks before theybecome problematic.But like other paradigms, the spiral model is not a panacea. It may be difficult toconvince customers (particularly in contract situations) that the evolutionaryapproach is controllable. It demands considerable risk assessment expertise andrelies on this expertise for success. If a major risk is not uncovered and managed,problems will undoubtedly occur.CHAPTER 2PROCESS MODELS 47
If your managementdemands fixed-budgetdevelopment(generally a bad idea),the spiral can be aproblem. As eachcircuit is completed,project cost is revisitedand revised.
uote:
“I’m only this farand only tomorrowleads my way.”Dave MatthewsBand
The scene:Meeting room for thesoftware engineering group at CPI Corporation, acompany that makes consumer products for home andcommercial use.The players:Lee Warren, engineering manager; DougMiller, software engineering manager; Vinod and Jamie,members of the software engineering team.The conversation:[Doug describes evolutionaryprocess options.]Jamie:Now I see something I like. An incrementalapproach makes sense, and I really like the flow of thatspiral model thing. That’s keepin’ it real.Vinod:I agree. We deliver an increment, learn fromcustomer feedback, replan, and then deliver anotherincrement. It also fits into the nature of the product. Wecan have something on the market fast and then addfunctionality with each version, er, increment.Lee:Wait a minute. Did you say that we regenerate theplan with each tour around the spiral, Doug? That’s not sogreat; we need one plan, one schedule, and we’ve got tostick to it.Doug:That’s old-school thinking, Lee. Like the guys said,we’ve got to keep it real. I submit that it’s better to tweakthe plan as we learn more and as changes are requested.It’s way more realistic. What’s the point of a plan if itdoesn’t reflect reality?Lee(frowning): I suppose so, but . . . senior management’snot going to like this . . . they want a fixed plan.Doug(smiling): Then you’ll have to reeducate them,buddy.SAFEHOMESelecting a Process Model, Part 2pre75977_ch02.qxd  11/27/08  3:21 PM  Page 472.3.4 Concurrent Models
The concurrent development model,sometimes called concurrent engineering, allows a software team to represent iterative and concurrent elements of any of the processmodels described in this chapter. For example, the modeling activity defined for thespiral model is accomplished by invoking one or more of the following softwareengineering actions: prototyping, analysis, and design.
11
Figure 2.8 provides a schematic representation of one software engineeringactivity within the modeling activity using a concurrent modeling approach. Theactivity—modeling—may be in any one of the states
12noted at any given time. Sim- ilarly, other activities, actions, or tasks (e.g., communicationor construction) can be represented in an analogous manner. All software engineering activities existconcurrently but reside in different states.48 PART ONETHE SOFTWARE PROCESS
11 It should be noted that analysis and design are complex tasks that require substantial discussion.Part 2 of this book considers these topics in detail.12 A stateis some externally observable mode of behavior.Under review
BaselinedUnderrevisionAwaitingchangesUnderdevelopmentInactiveModeling activity
Represents the state of a software engineering activity or task 
DoneFIGURE 2.8
One element ofthe concurrentprocess model
The concurrent modelis often more appro-priate for product engi-neering projects wheredifferent engineeringteams are involved.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 48For example, early in a project the communication activity (not shown in the figure)has completed its first iteration and exists in the awaiting changesstate. The model- ing activity (which existed in theinactivestate while initial communication was com- pleted, now makes a transition into theunder developmentstate. If, however, the customer indicates that changes in requirements must be made, the modeling activitymoves from theunder developmentstate into theawaiting changesstate. Concurrent modeling defines a series of events that will trigger transitions fromstate to state for each of the software engineering activities, actions, or tasks. Forexample, during early stages of design (a major software engineering action thatoccurs during the modeling activity), an inconsistency in the requirements model isuncovered. This generates the eventanalysis model correction,which will trigger the requirements analysis action from thedonestate into theawaiting changesstate. Concurrent modeling is applicable to all types of software development and pro-vides an accurate picture of the current state of a project. Rather than confining soft-ware engineering activities, actions, and tasks to a sequence of events, it defines aprocess network. Each activity, action, or task on the network exists simultaneouslywith other activities, actions, or tasks. Events generated at one point in the processnetwork trigger transitions among the states.
2.3.5 A Final Word on Evolutionary Processes
I have already noted that modern computer software is characterized by continualchange, by very tight time lines, and by an emphatic need for customer–usersatisfaction. In many cases, time-to-market is the most important managementrequirement. If a market window is missed, the software project itself may bemeaningless.
13
Evolutionary process models were conceived to address these issues, and yet, asa general class of process models, they too have weaknesses. These are summarizedby Nogueira and his colleagues [Nog00] : 
Despite the unquestionable benefits of evolutionary software processes, we have someconcerns. The first concern is that prototyping [and other more sophisticated evolution-ary processes] poses a problem to project planning because of the uncertain number ofcycles required to construct the product. Most project management and estimation tech-niques are based on linear layouts of activities, so they do not fit completely. Second, evolutionary software processes do not establish the maximum speed of theevolution. If the evolutions occur too fast, without a period of relaxation, it is certain thatthe process will fall into chaos. On the other hand if the speed is too slow then produc-tivity could be affected . . .CHAPTER 2PROCESS MODELS 49
13 It is important to note, however, that being the first to reach a market is no guarantee of success.In fact, many very successful software products have been second or even third to reach the market(learning from the mistakes of their predecessors).uote:
“Every process inyour organizationhas a customer,and without acustomer a processhas no purpose.”V. Daniel Huntpre75977_ch02.qxd  11/27/08  3:21 PM  Page 49Third, software processes should be focused on flexibility and extensibility rather thanon high quality. This assertion sounds scary. However, we should prioritize the speed ofthe development over zero defects. Extending the development in order to reach highquality could result in a late delivery of the product, when the opportunity niche hasdisappeared. This paradigm shift is imposed by the competition on the edge of chaos.
Indeed, a software process that focuses on flexibility, extensibility, and speed of de-velopment over high quality does sound scary. And yet, this idea has been proposedby a number of well-respected software engineering experts (e.g., [You95], [Bac97]).The intent of evolutionary models is to develop high-quality software
14in an iter- ative or incremental manner. However, it is possible to use an evolutionary processto emphasize flexibility, extensibility, and speed of development. The challenge forsoftware teams and their managers is to establish a proper balance between thesecritical project and product parameters and customer satisfaction (the ultimatearbiter of software quality).
2.4 S PECIALIZED PROCESS MODELS
Specialized process models take on many of the characteristics of one or more of thetraditional models presented in the preceding sections. However, these models tendto be applied when a specialized or narrowly defined software engineering approachis chosen.
15
2.4.1 Component-Based Development
Commercial off-the-shelf (COTS) software components, developed by vendors whooffer them as products, provide targeted functionality with well-defined interfacesthat enable the component to be integrated into the software that is to be built. Thecomponent-based development modelincorporates many of the characteristics of thespiral model. It is evolutionary in nature [Nie92], demanding an iterative approach tothe creation of software. However, the component-based development model con-structs applications from prepackaged software components.Modeling and construction activities begin with the identification of candidatecomponents. These components can be designed as either conventional softwaremodules or object-oriented classes or packages
16of classes. Regardless of the50 PART ONETHE SOFTWARE PROCESS
14 In this context software quality is defined quite broadly to encompass not only customer satisfac-tion, but also a variety of technical criteria discussed in Chapters 14 and 16.15 In some cases, these specialized process models might better be characterized as a collection oftechniques or a “methodology” for accomplishing a specific software development goal. However,they do imply a process.16 Object-oriented concepts are discussed in Appendix 2 and are used throughout Part 2 of this book.In this context, a class encompasses a set of data and the procedures that process the data. A pack-age of classes is a collection of related classes that work together to achieve some end result.WebRef
Useful information oncomponent-baseddevelopment can beobtained at: www.cbd-hq.com.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 50technology that is used to create the components, the component-based develop-ment model incorporates the following steps (implemented using an evolutionaryapproach):1.Available component-based products are researched and evaluated for theapplication domain in question.2.Component integration issues are considered.3.A software architecture is designed to accommodate the components.4.Components are integrated into the architecture.5.Comprehensive testing is conducted to ensure proper functionality.The component-based development model leads to software reuse, and reusabil-ity provides software engineers with a number of measurable benefits. Your softwareengineering team can achieve a reduction in development cycle time as well as areduction in project cost if component reuse becomes part of your culture. Component-based development is discussed in more detail in Chapter 10.
2.4.2 The Formal Methods Model
The formal methods modelencompasses a set of activities that leads to formal math-ematical specification of computer software. Formal methods enable you to specify,develop, and verify a computer-based system by applying a rigorous, mathematicalnotation. A variation on this approach, called cleanroom software engineering[Mil87, Dye92], is currently applied by some software development organizations.When formal methods (Chapter 21) are used during development, they provide amechanism for eliminating many of the problems that are difficult to overcome usingother software engineering paradigms. Ambiguity, incompleteness, and inconsis-tency can be discovered and corrected more easily—not through ad hoc review, butthrough the application of mathematical analysis. When formal methods are usedduring design, they serve as a basis for program verification and therefore enableyou to discover and correct errors that might otherwise go undetected.Although not a mainstream approach, the formal methods model offers the prom-ise of defect-free software. Yet, concern about its applicability in a business envi-ronment has been voiced:
•The development of formal models is currently quite time consuming andexpensive.
•Because few software developers have the necessary background to applyformal methods, extensive training is required.
•It is difficult to use the models as a communication mechanism for techni-cally unsophisticated customers.These concerns notwithstanding, the formal methods approach has gainedadherents among software developers who must build safety-critical software CHAPTER 2PROCESS MODELS 51
If formalmethods candemonstratesoftwarecorrectness, whyis it they are notwidely used??pre75977_ch02.qxd  11/27/08  3:21 PM  Page 51(e.g., developers of aircraft avionics and medical devices) and among developersthat would suffer severe economic hardship should software errors occur. 
2.4.3 Aspect-Oriented Software Development
Regardless of the software process that is chosen, the builders of complex softwareinvariably implement a set of localized features, functions, and information content.These localized software characteristics are modeled as components (e.g., object-oriented classes) and then constructed within the context of a system architecture.As modern computer-based systems become more sophisticated (and complex),certain concerns—customer required properties or areas of technical interest—spanthe entire architecture. Some concerns are high-level properties of a system (e.g.,security, fault tolerance). Other concerns affect functions (e.g., the application ofbusiness rules), while others are systemic (e.g., task synchronization or memorymanagement).When concerns cut across multiple system functions, features, and information,they are often referred to as crosscutting concerns. Aspectual requirements definethose crosscutting concerns that have an impact across the software architecture.Aspect-oriented software development (AOSD), often referred to as aspect-orientedprogramming(AOP), is a relatively new software engineering paradigm that providesa process and methodological approach for defining, specifying, designing, and con-structing aspects—“mechanisms beyond subroutines and inheritance for localizingthe expression of a crosscutting concern” [Elr01].Grundy [Gru02] provides further discussion of aspects in the context of what hecalls aspect-oriented component engineering (AOCE):
AOCE uses a concept of horizontal slices through vertically-decomposed software com-ponents, called “aspects,” to characterize cross-cutting functional and non-functionalproperties of components. Common, systemic aspects include user interfaces, collabora-tive work, distribution, persistency, memory management, transaction processing, secu-rity, integrity and so on. Components may provide or require one or more “aspect details”relating to a particular aspect, such as a viewing mechanism, extensible affordance andinterface kind (user interface aspects); event generation, transport and receiving(distribution aspects); data store/retrieve and indexing (persistency aspects); authentica-tion, encoding and access rights (security aspects); transaction atomicity, concurrencycontrol and logging strategy (transaction aspects); and so on. Each aspect detail has anumber of properties, relating to functional and/or non-functional characteristics of theaspect detail.
A distinct aspect-oriented process has not yet matured. However, it is likely thatsuch a process will adopt characteristics of both evolutionary and concurrentprocess models. The evolutionary model is appropriate as aspects are identified andthen constructed. The parallel nature of concurrent development is essential be-cause aspects are engineered independently of localized software components andyet, aspects have a direct impact on these components. Hence, it is essential to52 PART ONETHE SOFTWARE PROCESS
WebRef
A wide array ofresources andinformation on AOPcan be found at:aosd.net.
AOSD defines“aspects” that expresscustomer concerns thatcut across multiplesystem functions,features, andinformation.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 52instantiate asynchronous communication between the software process activitiesapplied to the engineering and construction of aspects and components.A detailed discussion of aspect-oriented software development is best left tobooks dedicated to the subject. If you have further interest, see [Saf08], [Cla05],[Jac04], and [Gra03].CHAPTER 2PROCESS MODELS 53
17 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Process Management
Objective:To assist in the definition,execution, and management of prescriptiveprocess models.Mechanics:Process management tools allow a softwareorganization or team to define a complete softwareprocess model (framework activities, actions, tasks, QAcheckpoints, milestones, and work products). In addition,the tools provide a road map as software engineers dotechnical work and a template for managers who musttrack and control the software process.Representative Tools:
17
GDPA, a research process definition tool suite, developed at Bremen University in Germany (www.informatik.uni-bremen.de/uniform/gdpa/home.htm ), provides a wide array of process modeling andmanagement functions.SpeeDev, developed by SpeeDev Corporation(www.speedev.com) encompasses a suite of toolsfor process definition, requirements management, issueresolution, project planning, and tracking.ProVision BPMx,developed by Proforma(www.proformacorp.com), is representative ofmany tools that assist in process definition andworkflow automation.A worthwhile listing of many different tools associated with the software process can be found at www.processwave.net/Links/tool_links.htm .SOFTWARE TOOLS
2.5 T HEUNIFIED PROCESS
In their seminal book on the Unified Process, Ivar Jacobson, Grady Booch, and James Rumbaugh [Jac99] discuss the need for a “use case driven, architecture-centric, iter-ative and incremental” software process when they state:
Today, the trend in software is toward bigger, more complex systems. That is due in partto the fact that computers become more powerful every year, leading users to expectmore from them. This trend has also been influenced by the expanding use of the Inter-net for exchanging all kinds of information. . . . Our appetite for ever-more sophisticatedsoftware grows as we learn from one product release to the next how the product couldbe improved. We want software that is better adapted to our needs, but that, in turn,merely makes the software more complex. In short, we want more.
In some ways the Unified Process is an attempt to draw on the best features andcharacteristics of traditional software process models, but characterize them in away that implements many of the best principles of agile software developmentpre75977_ch02.qxd  11/27/08  3:21 PM  Page 53(Chapter 3). The Unified Process recognizes the importance of customer communi-cation and streamlined methods for describing the customer’s view of a system(the use case
18). It emphasizes the important role of software architecture and“helps the architect focus on the right goals, such as understandability, reliance tofuture changes, and reuse” [Jac99]. It suggests a process flow that is iterative andincremental, providing the evolutionary feel that is essential in modern softwaredevelopment.
2.5.1 A Brief History
During the early 1990s James Rumbaugh [Rum91], Grady Booch [Boo94], and IvarJacobson [Jac92] began working on a “unified method” that would combine the bestfeatures of each of their individual object-oriented analysis and design methods andadopt additional features proposed by other experts (e.g., [Wir90]) in object-orientedmodeling. The result was UML—a unified modeling language that contains a robust notation for the modeling and development of object-oriented systems. By 1997,UML became a de facto industry standard for object-oriented software development.UML is used throughout Part 2 of this book to represent both requirements anddesign models. Appendix 1 presents an introductory tutorial for those who are unfa-miliar with basic UML notation and modeling rules. A comprehensive presentationof UML is best left to textbooks dedicated to the subject. Recommended books arelisted in Appendix 1.UML provided the necessary technology to support object-oriented software engi-neering practice, but it did not provide the process framework to guide project teamsin their application of the technology. Over the next few years, Jacobson, Rumbaugh,and Booch developed the Unified Process, a framework for object-oriented software engineering using UML. Today, the Unified Process (UP) and UML are widely used onobject-oriented projects of all kinds. The iterative, incremental model proposed by theUP can and should be adapted to meet specific project needs. 
2.5.2 Phases of the Unified Process19
Earlier in this chapter, I discussed five generic framework activities and argued thatthey may be used to describe any software process model. The Unified Process is noexception. Figure 2.9 depicts the “phases” of the UP and relates them to the genericactivities that have been discussed in Chapter 1 and earlier in this chapter. 54 PART ONETHE SOFTWARE PROCESS
18 A use case(Chapter 5) is a text narrative or template that describes a system function or featurefrom the user’s point of view. A use case is written by the user and serves as a basis for the creationof a more comprehensive requirements model.19 The Unified Process is sometimes called the Rational Unified Process (RUP) after the Rational Cor- poration (subsequently acquired by IBM), an early contributor to the development and refinementof the UP and a builder of complete environments (tools and technology) that support the process.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 54The inception phaseof the UP encompasses both customer communication andplanning activities. By collaborating with stakeholders, business requirements forthe software are identified; a rough architecture for the system is proposed; and aplan for the iterative, incremental nature of the ensuing project is developed.Fundamental business requirements are described through a set of preliminary usecases (Chapter 5) that describe which features and functions each major class ofusers desires. Architecture at this point is nothing more than a tentative outline ofmajor subsystems and the function and features that populate them. Later, the ar-chitecture will be refined and expanded into a set of models that will representdifferent views of the system. Planning identifies resources, assesses major risks,defines a schedule, and establishes a basis for the phases that are to be applied asthe software increment is developed.The elaboration phaseencompasses the communication and modeling activities ofthe generic process model (Figure 2.9). Elaboration refines and expands the prelimi-nary use cases that were developed as part of the inception phase and expands thearchitectural representation to include five different views of the software—the usecase model, the requirements model, the design model, the implementation model,and the deployment model. In some cases, elaboration creates an “executablearchitectural baseline” [Arl02] that represents a “first cut” executable system.
20The architectural baseline demonstrates the viability of the architecture but does notprovide all features and functions required to use the system. In addition, the plan iscarefully reviewed at the culmination of the elaboration phase to ensure that scope,risks, and delivery dates remain reasonable. Modifications to the plan are often madeat this time.CHAPTER 2PROCESS MODELS 55
Transition
Productionsoftware incrementReleasemodelingconstructionplanning
communication
deployment
ConstructionInceptionElaborationFIGURE 2.9
The UnifiedProcess
UP phases are similarin intent to the genericframework activitiesdefined in this book.
20 It is important to note that the architectural baseline is not a prototype in that it is not thrown away.Rather, the baseline is fleshed out during the next UP phase.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 55The construction phaseof the UP is identical to the construction activity definedfor the generic software process. Using the architectural model as input, the con-struction phase develops or acquires the software components that will make eachuse case operational for end users. To accomplish this, requirements and designmodels that were started during the elaboration phase are completed to reflect thefinal version of the software increment. All necessary and required features andfunctions for the software increment (i.e., the release) are then implemented insource code. As components are being implemented, unit tests
21are designed and executed for each. In addition, integration activities (component assembly and inte-gration testing) are conducted. Use cases are used to derive a suite of acceptancetests that are executed prior to the initiation of the next UP phase.The transition phaseof the UP encompasses the latter stages of the generic con-struction activity and the first part of the generic deployment (delivery and feedback)activity. Software is given to end users for beta testing and user feedback reportsboth defects and necessary changes. In addition, the software team creates the nec-essary support information (e.g., user manuals, troubleshooting guides, installationprocedures) that is required for the release. At the conclusion of the transition phase,the software increment becomes a usable software release.The production phaseof the UP coincides with the deployment activity of thegeneric process. During this phase, the ongoing use of the software is monitored,support for the operating environment (infrastructure) is provided, and defect reportsand requests for changes are submitted and evaluated.It is likely that at the same time the construction, transition, and productionphases are being conducted, work may have already begun on the next softwareincrement. This means that the five UP phases do not occur in a sequence, but ratherwith staggered concurrency.A software engineering workflow is distributed across all UP phases. In the con-text of UP, a workflowis analogous to a task set (described earlier in this chapter).That is, a workflow identifies the tasks required to accomplish an important softwareengineering action and the work products that are produced as a consequence ofsuccessfully completing the tasks. It should be noted that not every task identified fora UP workflow is conducted for every software project. The team adapts the process(actions, tasks, subtasks, and work products) to meet its needs. 
2.6 P ERSONAL AND TEAM PROCESS MODELS
The best software process is one that is close to the people who will be doing thework. If a software process model has been developed at a corporate or organiza-tional level, it can be effective only if it is amenable to significant adaptation to meet56 PART ONETHE SOFTWARE PROCESS
21 A comprehensive discussion of software testing (including unit tests) is presented in Chapters 17through 20.WebRef
An interestingdiscussion of the UP inthe context of agiledevelopment can befound atwww.ambysoft.com/unifiedprocess/agileUP .html.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 56the needs of the project team that is actually doing software engineering work. In anideal setting, you would create a process that best fits your needs, and at the sametime, meets the broader needs of the team and the organization. Alternatively, theteam itself can create its own process, and at the same time meet the narrower needsof individuals and the broader needs of the organization. Watts Humphrey ([Hum97]and [Hum00]) argues that it is possible to create a “personal software process”and/or a “team software process.” Both require hard work, training, and coordina-tion, but both are achievable.
22
2.6.1 Personal Software Process (PSP)
Every developer uses some process to build computer software. The process may behaphazard or ad hoc; may change on a daily basis; may not be efficient, effective, oreven successful; but a “process” does exist. Watts Humphrey [Hum97] suggests thatin order to change an ineffective personal process, an individual must move throughfour phases, each requiring training and careful instrumentation. The Personal Soft-ware Process(PSP) emphasizes personal measurement of both the work product thatis produced and the resultant quality of the work product. In addition PSP makes thepractitioner responsible for project planning (e.g., estimating and scheduling) andempowers the practitioner to control the quality of all software work products thatare developed. The PSP model defines five framework activities: Planning.This activity isolates requirements and develops both size andresource estimates. In addition, a defect estimate (the number of defectsprojected for the work) is made. All metrics are recorded on worksheets ortemplates. Finally, development tasks are identified and a project schedule iscreated.High-level design.External specifications for each component to be con-structed are developed and a component design is created. Prototypes arebuilt when uncertainty exists. All issues are recorded and tracked.High-level design review.Formal verification methods (Chapter 21) areapplied to uncover errors in the design. Metrics are maintained for all impor-tant tasks and work results.Development.The component-level design is refined and reviewed. Codeis generated, reviewed, compiled, and tested. Metrics are maintained for allimportant tasks and work results.Postmortem.Using the measures and metrics collected (this is a substan-tial amount of data that should be analyzed statistically), the effectiveness ofthe process is determined. Measures and metrics should provide guidance formodifying the process to improve its effectiveness.CHAPTER 2PROCESS MODELS 57
22 It’s worth noting the proponents of agile software development (Chapter 3) also argue that theprocess should remain close to the team. They propose an alternative method for achieving this.uote:
“A person who issuccessful hassimply formed thehabit of doingthings thatunsuccessful peoplewill not do.”Dexter Yager
WebRef
A wide array ofresources for PSP canbe found at www.ipd.uka.de/PSP/.
Whatframeworkactivities are usedduring PSP??pre75977_ch02.qxd  11/27/08  3:21 PM  Page 57PSP stresses the need to identify errors early and, just as important, to understandthe types of errors that you are likely to make. This is accomplished through a rigor-ous assessment activity performed on all work products you produce.PSP represents a disciplined, metrics-based approach to software engineeringthat may lead to culture shock for many practitioners. However, when PSP is prop-erly introduced to software engineers [Hum96], the resulting improvement in soft-ware engineering productivity and software quality are significant [Fer97]. However,PSP has not been widely adopted throughout the industry. The reasons, sadly, havemore to do with human nature and organizational inertia than they do with thestrengths and weaknesses of the PSP approach. PSP is intellectually challenging anddemands a level of commitment (by practitioners and their managers) that is not al-ways possible to obtain. Training is relatively lengthy, and training costs are high.The required level of measurement is culturally difficult for many software people.Can PSP be used as an effective software process at a personal level? The answeris an unequivocal “yes.” But even if PSP is not adopted in its entirely, many of thepersonal process improvement concepts that it introduces are well worth learning. 
2.6.2 Team Software Process (TSP)
Because many industry-grade software projects are addressed by a team of practi-tioners, Watts Humphrey extended the lessons learned from the introduction of PSPand proposed a Team Software Process (TSP). The goal of TSP is to build a “self- directed” project team that organizes itself to produce high-quality software.Humphrey [Hum98] defines the following objectives for TSP:
•Build self-directed teams that plan and track their work, establish goals, andown their processes and plans. These can be pure software teams or inte-grated product teams (IPTs) of 3 to about 20 engineers. 
•Show managers how to coach and motivate their teams and how to helpthem sustain peak performance. 
•Accelerate software process improvement by making CMM23Level 5 behavior normal and expected. 
•Provide improvement guidance to high-maturity organizations. 
•Facilitate university teaching of industrial-grade team skills.A self-directed team has a consistent understanding of its overall goals and objec-tives; defines roles and responsibilities for each team member; tracks quantitativeproject data (about productivity and quality); identifies a team process that is appro-priate for the project and a strategy for implementing the process; defines local stan-dards that are applicable to the team’s software engineering work; continuallyassesses risk and reacts to it; and tracks, manages, and reports project status.58 PART ONETHE SOFTWARE PROCESS
PSP emphasizes theneed to record andanalyze the types oferrors you make, sothat you can developstrategies to eliminatethem.
To form a self-directedteam, you must collab-orate well internallyand communicate wellexternally.WebRef
Information on buildinghigh-performance teamsusing TSP and PSP canbe obtained at:www.sei.cmu.edu/tsp/.
23 The Capability Maturity Model (CMM), a measure of the effectiveness of a software process, isdiscussed in Chapter 30.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 58TSP defines the following framework activities: project launch, high-leveldesign, implementation, integration and test, and postmortem.Like their counterparts in PSP (note that terminology is somewhat different), these activitiesenable the team to plan, design, and construct software in a disciplined mannerwhile at the same time quantitatively measuring the process and the product. Thepostmortem sets the stage for process improvements.TSP makes use of a wide variety of scripts, forms, and standards that serve to guideteam members in their work. “Scripts” define specific process activities (i.e., projectlaunch, design, implementation, integration and system testing, postmortem) and othermore detailed work functions (e.g., development planning, requirements development,software configuration management, unit test) that are part of the team process.TSP recognizes that the best software teams are self-directed.
24Team members set project objectives, adapt the process to meet their needs, control the projectschedule, and through measurement and analysis of the metrics collected, work con-tinually to improve the team’s approach to software engineering.Like PSP, TSP is a rigorous approach to software engineering that provides dis-tinct and quantifiable benefits in productivity and quality. The team must make a fullcommitment to the process and must undergo thorough training to ensure that theapproach is properly applied. 
2.7 P ROCESS TECHNOLOGY
One or more of the process models discussed in the preceding sections must beadapted for use by a software team. To accomplish this, process technology toolshave been developed to help software organizations analyze their current process,organize work tasks, control and monitor progress, and manage technical quality.Process technology tools allow a software organization to build an automatedmodel of the process framework, task sets, and umbrella activities discussed inSection 2.1. The model, normally represented as a network, can then be analyzed todetermine typical workflow and examine alternative process structures that mightlead to reduced development time or cost.Once an acceptable process has been created, other process technology tools canbe used to allocate, monitor, and even control all software engineering activities,actions, and tasks defined as part of the process model. Each member of a softwareteam can use such tools to develop a checklist of work tasks to be performed, workproducts to be produced, and quality assurance activities to be conducted. Theprocess technology tool can also be used to coordinate the use of other software en-gineering tools that are appropriate for a particular work task.CHAPTER 2PROCESS MODELS 59
24 In Chapter 3 I discuss the importance of “self-organizing” teams as a key element in agile softwaredevelopment.TSP scripts defineelements of the teamprocess and activitiesthat occur within theprocess.pre75977_ch02.qxd  11/27/08  3:21 PM  Page 5960 PART ONETHE SOFTWARE PROCESS
25 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Process Modeling Tools
Objective:If an organization works toimprove a business (or software) process, itmust first understand it. Process modeling tools (also calledprocess technologyor process management tools) areused to represent the key elements of a process so that itcan be better understood. Such tools can also provide linksto process descriptions that help those involved in theprocess to understand the actions and work tasks that arerequired to perform it. Process modeling tools provide linksto other tools that provide support to defined processactivities.Mechanics:Tools in this category allow a team to definethe elements of a unique process model (actions, tasks,work products, QA points), provide detailed guidance onthe content or description of each process element, andthen manage the process as it is conducted. In some cases,the process technology tools incorporate standard projectmanagement tasks such as estimating, scheduling,tracking, and control.Representative Tools:
25
Igrafx Process Tools—tools that enable a team to map,measure, and model the software process(www.micrografx.com)Adeptia BPM Server—designed to manage, automate, andoptimize business processes (www.adeptia.com) SpeedDev Suite—a collection of six tools with a heavyemphasis on the management of communication andmodeling activities (www.speedev.com)SOFTWARE TOOLS
2.8 P RODUCT AND PROCESS
If the process is weak, the end product will undoubtedly suffer. But an obsessive over-reliance on process is also dangerous. In a brief essay written many years ago, Mar-garet Davis [Dav95a] makes timeless comments on the duality of product and process:
About every ten years give or take five, the software community redefines “the problem”by shifting its focus from product issues to process issues. Thus, we have embracedstructured programming languages (product) followed by structured analysis methods(process) followed by data encapsulation (product) followed by the current emphasison the Software Engineering Institute’s Software Development Capability Maturity Model (process) [followed by object-oriented methods, followed by agile softwaredevelopment].While the natural tendency of a pendulum is to come to rest at a point midway be-tween two extremes, the software community’s focus constantly shifts because new forceis applied when the last swing fails. These swings are harmful in and of themselves be-cause they confuse the average software practitioner by radically changing what it meansto perform the job let alone perform it well. The swings also do not solve “the problem”for they are doomed to fail as long as product and process are treated as forming adichotomy instead of a duality.There is precedence in the scientific community to advance notions of duality whencontradictions in observations cannot be fully explained by one competing theory oranother. The dual nature of light, which seems to be simultaneously particle and wave,has been accepted since the 1920s when Louis de Broglie proposed it. I believe that thepre75977_ch02.qxd  11/27/08  3:21 PM  Page 60observations we can make on the artifacts of software and its development demonstratea fundamental duality between product and process. You can never derive or understandthe full artifact, its context, use, meaning, and worth if you view it as only a process oronly a product . . .All of human activity may be a process, but each of us derives a sense of self-worthfrom those activities that result in a representation or instance that can be used orappreciated either by more than one person, used over and over, or used in some othercontext not considered. That is, we derive feelings of satisfaction from reuse of our prod-ucts by ourselves or others.Thus, while the rapid assimilation of reuse goals into software development poten-tially increases the satisfaction software practitioners derive from their work, it also in-creases the urgency for acceptance of the duality of product and process. Thinking of areusable artifact as only product or only process either obscures the context and ways touse it or obscures the fact that each use results in product that will, in turn, be used asinput to some other software development activity. Taking one view over the otherdramatically reduces the opportunities for reuse and, hence, loses the opportunity forincreasing job satisfaction.
People derive as much (or more) satisfaction from the creative process as they dofrom the end product. An artist enjoys the brush strokes as much as the framed re-sult. A writer enjoys the search for the proper metaphor as much as the finishedbook. As creative software professional, you should also derive as much satisfactionfrom the process as the end product. The duality of product and process is oneimportant element in keeping creative people engaged as software engineeringcontinues to evolve.
2.9 S UMMARY
A generic process model for software engineering encompasses a set of frameworkand umbrella activities, actions, and work tasks. Each of a variety of process modelscan be described by a different process flow—a description of how the frameworkactivities, actions, and tasks are organized sequentially and chronologically. Processpatterns can be used to solve common problems that are encountered as part of thesoftware process.Prescriptive process models have been applied for many years in an effort to bringorder and structure to software development. Each of these models suggests a some-what different process flow, but all perform the same set of generic frameworkactivities: communication, planning, modeling, construction, and deployment.Sequential process models, such as the waterfall and V models, are the oldestsoftware engineering paradigms. They suggest a linear process flow that is often in-consistent with modern realities (e.g., continuous change, evolving systems, tighttime lines) in the software world. They do, however, have applicability in situationswhere requirements are well defined and stable.CHAPTER 2PROCESS MODELS 61pre75977_ch02.qxd  11/27/08  3:21 PM  Page 61Incremental process models are iterative in nature and produce working versionsof software quite rapidly. Evolutionary process models recognize the iterative, in-cremental nature of most software engineering projects and are designed to accom-modate change. Evolutionary models, such as prototyping and the spiral model,produce incremental work products (or working versions of the software) quickly.These models can be adopted to apply across all software engineering activities—from concept development to long-term system maintenance.The concurrent process model allows a software team to represent iterativeand concurrent elements of any process model. Specialized models include thecomponent-based model that emphasizes component reuse and assembly; the for-mal methods model that encourages a mathematically based approach to softwaredevelopment and verification; and the aspect-oriented model that accommodatescrosscutting concerns spanning the entire system architecture. The Unified Processis a “use case driven, architecture-centric, iterative and incremental” softwareprocess designed as a framework for UML methods and tools.Personal and team models for the software process have been proposed. Bothemphasize measurement, planning, and self-direction as key ingredients for a suc-cessful software process.
PROBLEMS AND POINTS TO PONDER
2.1.In the introduction to this chapter Baetjer notes: “The process provides interactionbetween users and designers, between users and evolving tools, and between designers andevolving tools [technology].” List five questions that (a) designers should ask users, (b) usersshould ask designers, (c) users should ask themselves about the software product that is to bebuilt, (d) designers should ask themselves about the software product that is to be built and theprocess that will be used to build it.2.2.Try to develop a set of actions for the communication activity. Select one action and definea task set for it.2.3.A common problem during communication occurs when you encounter two stakehold- ers who have conflicting ideas about what the software should be. That is, you have mutuallyconflicting requirements.Develop a process pattern (this would be a stage pattern) using thetemplate presented in Section 2.1.3 that addresses this problem and suggest an effectiveapproach to it.2.4.Do some research on PSP and present a brief presentation that describes the types ofmeasurements that an individual software engineer is asked to make and how those measure-ment can be used to improve personal effectiveness.2.5.The use of “scripts” (a required mechanism in TSP) is not universally praised within thesoftware community. Make a list of pros and cons regarding scripts and suggest at least two sit-uations in which they would be useful and another two situations where they might provide lessbenefit.2.6.Read [Nog00] and write a two- or three-page paper that discusses the impact of “chaos”on software engineering.2.7.Provide three examples of software projects that would be amenable to the waterfallmodel. Be specific.62 PART ONETHE SOFTWARE PROCESSpre75977_ch02.qxd  11/27/08  3:21 PM  Page 622.8.Provide three examples of software projects that would be amenable to the prototypingmodel. Be specific.2.9.What process adaptations are required if the prototype will evolve into a deliverablesystem or product?2.10.Provide three examples of software projects that would be amenable to the incrementalmodel. Be specific.2.11.As you move outward along the spiral process flow, what can you say about the softwarethat is being developed or maintained?2.12.Is it possible to combine process models? If so, provide an example.2.13.The concurrent process model defines a set of “states.” Describe what these states rep-resent in your own words, and then indicate how they come into play within the concurrentprocess model.2.14.What are the advantages and disadvantages of developing software in which quality is“good enough”? That is, what happens when we emphasize development speed over productquality?2.15.Provide three examples of software projects that would be amenable to the component-based model. Be specific.2.16.It is possible to prove that a software component and even an entire program is correct.So why doesn’t everyone do this?2.17.Are the Unified Process and UML the same thing? Explain your answer.
FURTHER READINGS AND INFORMATION SOURCES
Most software engineering textbooks consider traditional process models in some detail. Booksby Sommerville (Software Engineering, 8th ed., Addison-Wesley, 2006), Pfleeger and Atlee (Software Engineering, 3d ed., Prentice-Hall, 2005), and Schach ( Object-Oriented and Classical Software Engineering,7th ed., McGraw-Hill, 2006) consider traditional paradigms and discusstheir strengths and weaknesses. Glass (Facts and Fallacies of Software Engineering, Prentice-Hall, 2002) provides an unvarnished, pragmatic view of the software engineering process. Althoughnot specifically dedicated to process, Brooks (The Mythical Man-Month, 2d ed., Addison-Wesley, 1995) presents age-old project wisdom that has everything to do with process.Firesmith and Henderson-Sellers ( The OPEN Process Framework: An Introduction, Addison- Wesley, 2001) present a general template for creating “flexible, yet discipline softwareprocesses” and discuss process attributes and objectives. Madachy (Software Process Dynamics,Wiley-IEEE, 2008) discusses modeling techniques that allow the interrelated technical andsocial elements of the software process to be analyzed. Sharpe and McDermott (Workflow Mod-eling: Tools for Process Improvement and Application Development, Artech House, 2001) present tools for modeling both software and business processes.Lim (Managing Software Reuse,Prentice Hall, 2004) discusses reuse from a manager’s perspective. Ezran, Morisio, and Tully (Practical Software Reuse, Springer, 2002) and Jacobson,Griss, and Jonsson (Software Reuse, Addison-Wesley, 1997) present much useful information on component-based development. Heineman and Council (Component-Based Software Engineer-ing, Addison-Wesley, 2001) describe the process required to implement component-basedsystems. Kenett and Baker (Software Process Quality: Management and Control, Marcel Dekker,1999) consider how quality management and process design are intimately connected to oneanother.Nygard (Release It!: Design and Deploy Production-Ready Software, Pragmatic Bookshelf, 2007) and Richardson and Gwaltney ( Ship it! A Practical Guide to Successful Software Projects, Pragmatic Bookshelf, 2005) present a broad collection of useful guidelines that are applicable tothe deployment activity.CHAPTER 2PROCESS MODELS 63pre75977_ch02.qxd  11/27/08  3:21 PM  Page 63In addition to Jacobson, Rumbaugh, and Booch’s seminal book on the Unified Process[Jac99], books by Arlow and Neustadt ( UML 2 and the Unified Process,Addison-Wesley, 2005), Kroll and Kruchten (The Rational Unified Process Made Easy, Addison-Wesley, 2003), and Farve (UML and the Unified Process,IRM Press, 2003) provide excellent complementary information.Gibbs (Project Management with the IBM Rational Unified Process, IBM Press, 2006) discusses project management within the context of the UP.A wide variety of information sources on software engineering and the software process areavailable on the Internet. An up-to-date list of World Wide Web references that are relevant tothe software process can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.64 PART ONETHE SOFTWARE PROCESSpre75977_ch02.qxd  11/27/08  3:21 PM  Page 64In 2001, Kent Beck and 16 other noted software developers, writers, and con-sultants [Bec01a] (referred to as the “Agile Alliance”) signed the “Manifesto forAgile Software Development.” It stated:
We are uncovering better ways of developing software by doing it and helping othersdo it. Through this work we have come to value: Individuals and interactionsover processes and toolsWorking softwareover comprehensive documentationCustomer collaborationover contract negotiationResponding to changeover following a planThat is, while there is value in the items on the right, we value the items on the left more.
65CHAPTER
3AGILEDEVELOPMENT
What is it? Agile software engi-neering combines a philosophy anda set of development guidelines. Thephilosophy encourages customersatisfaction and early incremental delivery ofsoftware; small, highly motivated project teams;informal methods; minimal software engineer-ing work products; and overall developmentsimplicity. The development guidelines stressdelivery over analysis and design (althoughthese activities are not discouraged), and activeand continuous communication between devel-opers and customers.
Who does it? Software engineers and otherproject stakeholders (managers, customers, endusers) work together on an agile team—a teamthat is self-organizing and in control of its owndestiny. An agile team fosters communicationand collaboration among all who serve on it.
Why is it important? The modern business envi-ronment that spawns computer-based systemsand software products is fast-paced and ever-changing. Agile software engineering repre-sents a reasonable alternative to conventionalQUICK
LOOKsoftware engineering for certain classes of soft-ware and certain types of software projects. Ithas been demonstrated to deliver successful sys-tems quickly.
What are the steps? Agile development might bestbe termed “software engineering lite.” The basicframework activities—communication, planning,modeling, construction, and deployment—remain. But they morph into a minimal task setthat pushes the project team toward constructionand delivery (some would argue that this isdone at the expense of problem analysis andsolution design).
What is the work product? Both the customerand the software engineer have the sameview—the only really important work productis an operational “software increment” that isdelivered to the customer on the appropriatecommitment date.
How do I ensure that I’ve done it right? If theagile team agrees that the process works, andthe team produces deliverable softwareincrements that satisfy the customer, you’vedone it right.KEY
CONCEPTS
Adaptive SoftwareDevelopment  . . .81agile process  . . .68Agile UnifiedProcess  . . . . . . .89agility  . . . . . . . .67Crystal . . . . . . . .85DSDM  . . . . . . . .84Extreme Programming  . . .72pre75977_ch03.qxd  11/27/08  3:24 PM  Page 65A manifesto is normally associated with an emerging political movement—onethat attacks the old guard and suggests revolutionary change (hopefully for thebetter). In some ways, that’s exactly what agile development is all about.Although the underlying ideas that guide agile development have been with us formany years, it has been less than two decades since these ideas have crystallizedinto a “movement.” In essence, agile
1methods were developed in an effort to over-come perceived and actual weaknesses in conventional software engineering. Agiledevelopment can provide important benefits, but it is not applicable to all projects,all products, all people, and all situations. It is also not antithetical to solid software engineering practice and can be applied as an overriding philosophy for all softwarework.In the modern economy, it is often difficult or impossible to predict how acomputer-based system (e.g., a Web-based application) will evolve as time passes.Market conditions change rapidly, end-user needs evolve, and new competitivethreats emerge without warning. In many situations, you won’t be able to definerequirements fully before the project begins. You must be agile enough to respond toa fluid business environment.Fluidity implies change, and change is expensive. Particularly if it is uncontrolledor poorly managed. One of the most compelling characteristics of the agile approachis its ability to reduce the costs of change throughout the software process.Does this mean that a recognition of challenges posed by modern realities causesyou to discard valuable software engineering principles, concepts, methods, andtools? Absolutely not! Like all engineering disciplines, software engineering contin-ues to evolve. It can be adapted easily to meet the challenges posed by a demand foragility.In a thought-provoking book on agile software development, Alistair Cockburn[Coc02] argues that the prescriptive process models introduced in Chapter 2 have amajor failing: they forget the frailties of the people who build computer software. Software engineers are not robots. They exhibit great variation in working styles; significant dif-ferences in skill level, creativity, orderliness, consistency, and spontaneity. Some com-municate well in written form, others do not. Cockburn argues that process modelscan “deal with people’s common weaknesses with [either] discipline or tolerance” andthat most prescriptive process models choose discipline. He states: “Because consis-tency in action is a human weakness, high discipline methodologies are fragile.”If process models are to work, they must provide a realistic mechanism for en-couraging the discipline that is necessary, or they must be characterized in a man-ner that shows “tolerance” for the people who do software engineering work.Invariably, tolerant practices are easier for software people to adopt and sustain, but(as Cockburn admits) they may be less productive. Like most things in life, trade-offsmust be considered.66 PART ONETHE SOFTWARE PROCESS
FDD  . . . . . . . . . .86Industrial XP  . . .77Lean SoftwareDevelopment  . . .87pair programming  . . .76project velocity  . . . . . . .74refactoring  . . . . .75Scrum  . . . . . . . .82stories  . . . . . . . .74XP process  . . . . .73
1 Agile methods are sometimes referred to as light methods or lean methods.uote:
“Agility: 1,everything else: 0.”Tom DeMarcopre75977_ch03.qxd  11/27/08  3:24 PM  Page 663.1 W HATISAGILITY ?
Just what is agility in the context of software engineering work? Ivar Jacobson[Jac02a] provides a useful discussion:
Agilityhas become today’s buzzword when describing a modern software process. Every-one is agile. An agile team is a nimble team able to appropriately respond to changes.Change is what software development is very much about. Changes in the software be-ing built, changes to the team members, changes because of new technology, changes ofall kinds that may have an impact on the product they build or the project that creates theproduct. Support for changes should be built-in everything we do in software, somethingwe embrace because it is the heart and soul of software. An agile team recognizes thatsoftware is developed by individuals working in teams and that the skills of these people,their ability to collaborate is at the core for the success of the project.
In Jacobson’s view, the pervasiveness of change is the primary driver for agility. Soft-ware engineers must be quick on their feet if they are to accommodate the rapidchanges that Jacobson describes.But agility is more than an effective response to change. It also encompasses thephilosophy espoused in the manifesto noted at the beginning of this chapter. Itencourages team structures and attitudes that make communication (among teammembers, between technologists and business people, between software engineersand their managers) more facile. It emphasizes rapid delivery of operational soft-ware and de-emphasizes the importance of intermediate work products (not alwaysa good thing); it adopts the customer as a part of the development team and worksto eliminate the “us and them” attitude that continues to pervade many softwareprojects; it recognizes that planning in an uncertain world has its limits and that aproject plan must be flexible.Agility can be applied to any software process. However, to accomplish this, it isessential that the process be designed in a way that allows the project team to adapttasks and to streamline them, conduct planning in a way that understands the fluid-ity of an agile development approach, eliminate all but the most essential work prod-ucts and keep them lean, and emphasize an incremental delivery strategy that getsworking software to the customer as rapidly as feasible for the product type andoperational environment.
3.2 A GILITY AND THE COST OF CHANGE
The conventional wisdom in software development (supported by decades of expe-rience) is that the cost of change increases nonlinearly as a project progresses(Figure 3.1, solid black curve). It is relatively easy to accommodate a change when asoftware team is gathering requirements (early in a project). A usage scenario mighthave to be modified, a list of functions may be extended, or a written specificationcan be edited. The costs of doing this work are minimal, and the time required willCHAPTER 3AGILE DEVELOPMENT 67
Don’t make themistake of assumingthat agility gives youlicense to hack outsolutions. A process isrequired and disciplineis essential.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 67not adversely affect the outcome of the project. But what if we fast-forward a num-ber of months? The team is in the middle of validation testing (something that occursrelatively late in the project), and an important stakeholder is requesting a majorfunctional change. The change requires a modification to the architectural design ofthe software, the design and construction of three new components, modificationsto another five components, the design of new tests, and so on. Costs escalatequickly, and the time and cost required to ensure that the change is made withoutunintended side effects is nontrivial.Proponents of agility (e.g., [Bec00], [Amb04]) argue that a well-designed agileprocess “flattens” the cost of change curve (Figure 3.1, shaded, solid curve), allowinga software team to accommodate changes late in a software project without dramaticcost and time impact. You’ve already learned that the agile process encompasses in-cremental delivery. When incremental delivery is coupled with other agile practicessuch as continuous unit testing and pair programming (discussed later in this chap-ter), the cost of making a change is attenuated. Although debate about the degree towhich the cost curve flattens is ongoing, there is evidence [Coc01a] to suggest that asignificant reduction in the cost of change can be achieved.
3.3 W HATISA N AGILE PROCESS ?
Any agile software process is characterized in a manner that addresses a number ofkey assumptions [Fow02] about the majority of software projects: 1.It is difficult to predict in advance which software requirements will persistand which will change. It is equally difficult to predict how customerpriorities will change as the project proceeds.68 PART ONETHE SOFTWARE PROCESS
Cost of changeusing conventionalsoftware processesCost of changeusing agile processesIdealized cost of changeusing agile process
Development schedule progressDevelopment costFIGURE 3.1
Change costsas a functionof time indevelopment
uote:
“Agility is dynamic,content specific,aggressivelychange embracing,and growthoriented.”–StevenGoldman et al.
An agile processreduces the cost ofchange becausesoftware is released inincrements and changecan be bettercontrolled within anincrement.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 682.For many types of software, design and construction are interleaved. That is,both activities should be performed in tandem so that design models areproven as they are created. It is difficult to predict how much design isnecessary before construction is used to prove the design.3.Analysis, design, construction, and testing are not as predictable (from aplanning point of view) as we might like.Given these three assumptions, an important question arises: How do we create aprocess that can manage unpredictability? The answer, as I have already noted, lies in process adaptability (to rapidly changing project and technical conditions). Anagile process, therefore, must be adaptable.But continual adaptation without forward progress accomplishes little. Therefore,an agile software process must adapt incrementally.To accomplish incremental adap- tation, an agile team requires customer feedback (so that the appropriate adaptationscan be made). An effective catalyst for customer feedback is an operational prototypeor a portion of an operational system. Hence, an incremental development strategyshould be instituted. Software increments (executable prototypes or portions of an op- erational system) must be delivered in short time periods so that adaptation keeps pacewith change (unpredictability). This iterative approach enables the customer to evalu-ate the software increment regularly, provide necessary feedback to the software team,and influence the process adaptations that are made to accommodate the feedback.
3.3.1 Agility Principles
The Agile Alliance (see [Agi03], [Fow01]) defines 12 agility principles for those whowant to achieve agility: 1.Our highest priority is to satisfy the customer through early and continuousdelivery of valuable software.2.Welcome changing requirements, even late in development. Agile processesharness change for the customer’s competitive advantage.3.Deliver working software frequently, from a couple of weeks to a couple ofmonths, with a preference to the shorter timescale.4.Business people and developers must work together daily throughout theproject.5.Build projects around motivated individuals. Give them the environment andsupport they need, and trust them to get the job done.6.The most efficient and effective method of conveying information to andwithin a development team is face-to-face conversation.7.Working software is the primary measure of progress.8.Agile processes promote sustainable development. The sponsors, developers,and users should be able to maintain a constant pace indefinitely.CHAPTER 3AGILE DEVELOPMENT 69
WebRef
A comprehensivecollection of articles onthe agile process can be found atwww.aanpo.org/articles/index.
Although agileprocesses embracechange, it is stillimportant to examinethe reasons forchange.
Working software isimportant, but don’tforget that it must alsoexhibit a variety ofquality attributesincluding reliability,usability, and maintainability.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 699.Continuous attention to technical excellence and good design enhancesagility.10.Simplicity—the art of maximizing the amount of work not done—is essential.11.The best architectures, requirements, and designs emerge from self–organizing teams.12.At regular intervals, the team reflects on how to become more effective, thentunes and adjusts its behavior accordingly.Not every agile process model applies these 12 principles with equal weight, andsome models choose to ignore (or at least downplay) the importance of one or moreof the principles. However, the principles define an agile spirit that is maintained in each of the process models presented in this chapter.
3.3.2 The Politics of Agile Development
There is considerable debate (sometimes strident) about the benefits and applicabil-ity of agile software development as opposed to more conventional software engi-neering processes. Jim Highsmith [Hig02a] (facetiously) states the extremes when hecharacterizes the feeling of the pro-agility camp (“agilists”). “Traditional methodolo-gists are a bunch of stick-in-the-muds who’d rather produce flawless documentationthan a working system that meets business needs.” As a counterpoint, he states(again, facetiously) the position of the traditional software engineering camp: “Light-weight, er, ‘agile’ methodologists are a bunch of glorified hackers who are going tobe in for a heck of a surprise when they try to scale up their toys into enterprise-widesoftware.”Like all software technology arguments, this methodology debate risks degener-ating into a religious war. If warfare breaks out, rational thought disappears andbeliefs rather than facts guide decision making.No one is against agility. The real question is: What is the best way to achieve it?As important, how do you build software that meets customers’ needs today andexhibits the quality characteristics that will enable it to be extended and scaled tomeet customers’ needs over the long term?There are no absolute answers to either of these questions. Even within the agileschool itself, there are many proposed process models (Section 3.4), each with asubtly different approach to the agility problem. Within each model there is a set of“ideas” (agilists are loath to call them “work tasks”) that represent a significantdeparture from traditional software engineering. And yet, many agile concepts aresimply adaptations of good software engineering concepts. Bottom line: there ismuch that can be gained by considering the best of both schools and virtuallynothing to be gained by denigrating either approach.If you have further interest, see [Hig01], [Hig02a], and [DeM02] for an entertain-ing summary of other important technical and political issues.70 PART ONETHE SOFTWARE PROCESS
You don’t have tochoose between agilityand software engi-neering. Rather, definea software engineeringapproach that is agile.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 703.3.3 Human Factors
Proponents of agile software development take great pains to emphasize the impor-tance of “people factors.” As Cockburn and Highsmith [Coc01a] state, “Agile devel-opment focuses on the talents and skills of individuals, molding the process tospecific people and teams.” The key point in this statement is that the process moldsto the needs of the people and team,not the other way around.
2
If members of the software team are to drive the characteristics of the process thatis applied to build software, a number of key traits must exist among the people onan agile team and the team itself:Competence.In an agile development (as well as software engineering)context, “competence” encompasses innate talent, specific software-relatedskills, and overall knowledge of the process that the team has chosen toapply. Skill and knowledge of process can and should be taught to all peoplewho serve as agile team members.Common focus.Although members of the agile team may perform differ-ent tasks and bring different skills to the project, all should be focused on onegoal—to deliver a working software increment to the customer within thetime promised. To achieve this goal, the team will also focus on continualadaptations (small and large) that will make the process fit the needs of theteam.Collaboration.Software engineering (regardless of process) is about as-sessing, analyzing, and using information that is communicated to the soft-ware team; creating information that will help all stakeholders understandthe work of the team; and building information (computer software and rele-vant databases) that provides business value for the customer. To accomplishthese tasks, team members must collaborate—with one another and all otherstakeholders.Decision-making ability.Any good software team (including agile teams)must be allowed the freedom to control its own destiny. This implies that theteam is given autonomy—decision-making authority for both technical andproject issues.
Fuzzy problem-solving ability. Software managers must recognize thatthe agile team will continually have to deal with ambiguity and will continu-ally be buffeted by change. In some cases, the team must accept the fact thatthe problem they are solving today may not be the problem that needs to besolved tomorrow. However, lessons learned from any problem-solvingCHAPTER 3AGILE DEVELOPMENT 71
2 Successful software engineering organizations recognize this reality regardless of the processmodel they choose.uote:
“Agile methodsderive much oftheir agility byrelying on thetacit knowledgeembodied in theteam, rather thanwriting theknowledge downin plans.”Barry Boehm
What keytraits mustexist among thepeople on aneffective softwareteam??
uote:
“What counts asbarely sufficientfor one team iseither overlysufficient orinsufficient foranother.”AlistairCockburnpre75977_ch03.qxd  11/27/08  3:24 PM  Page 71activity (including those that solve the wrong problem) may be of benefit tothe team later in the project.Mutual trust and respect.The agile team must become what DeMarcoand Lister [DeM98] call a “jelled” team (Chapter 24). A jelled team exhibitsthe trust and respect that are necessary to make them “so strongly knit thatthe whole is greater than the sum of the parts.” [DeM98]Self-organization.In the context of agile development, self-organizationimplies three things: (1) the agile team organizes itself for the work to bedone, (2) the team organizes the process to best accommodate its local envi-ronment, (3) the team organizes the work schedule to best achieve deliveryof the software increment. Self-organization has a number of technical bene-fits, but more importantly, it serves to improve collaboration and boost teammorale. In essence, the team serves as its own management. Ken Schwaber[Sch02] addresses these issues when he writes: “The team selects how muchwork it believes it can perform within the iteration, and the team commits tothe work. Nothing demotivates a team as much as someone else makingcommitments for it. Nothing motivates a team as much as accepting theresponsibility for fulfilling commitments that it made itself.”
3.4 E XTREME PROGRAMMING (XP)
In order to illustrate an agile process in a bit more detail, I’ll provide you with anoverview of Extreme Programming(XP), the most widely used approach to agile soft-ware development. Although early work on the ideas and methods associated withXP occurred during the late 1980s, the seminal work on the subject has been writtenby Kent Beck [Bec04a]. More recently, a variant of XP, called Industrial XP (IXP) has been proposed [Ker05]. IXP refines XP and targets the agile process specifically foruse within large organizations.
3.4.1 XP Values
Beck [Bec04a] defines a set of five values that establish a foundation for all work per- formed as part of XP—communication, simplicity, feedback, courage, and respect. Eachof these values is used as a driver for specific XP activities, actions, and tasks.In order to achieve effective communication between software engineers and other stakeholders (e.g., to establish required features and functions for the soft-ware), XP emphasizes close, yet informal (verbal) collaboration between customersand developers, the establishment of effective metaphors
3for communicating important concepts, continuous feedback, and the avoidance of voluminous docu-mentation as a communication medium.72 PART ONETHE SOFTWARE PROCESS
A self-organizing teamis in control of thework it performs. Theteam makes its owncommitments anddefines plans toachieve them.
3 In the XP context, a metaphor is “a story that everyone—customers, programmers, and managers—can tell about how the system works” [Bec04a].pre75977_ch03.qxd  11/27/08  3:24 PM  Page 72To achieve simplicity,XP restricts developers to design only for immediate needs,rather than consider future needs. The intent is to create a simple design that can beeasily implemented in code). If the design must be improved, it can be refactored
4at a later time.Feedbackis derived from three sources: the implemented software itself, thecustomer, and other software team members. By designing and implementing aneffective testing strategy (Chapters 17 through 20), the software (via test results) pro-vides the agile team with feedback. XP makes use of the unit test as its primary test- ing tactic. As each class is developed, the team develops a unit test to exercise eachoperation according to its specified functionality. As an increment is delivered to acustomer, the user storiesor use cases(Chapter 5) that are implemented by the increment are used as a basis for acceptance tests. The degree to which the softwareimplements the output, function, and behavior of the use case is a form of feedback.Finally, as new requirements are derived as part of iterative planning, the team pro-vides the customer with rapid feedback regarding cost and schedule impact.Beck [Bec04a] argues that strict adherence to certain XP practices demandscourage.A better word might be discipline.For example, there is often significant pressure to design for future requirements. Most software teams succumb, arguingthat “designing for tomorrow” will save time and effort in the long run. An agile XPteam must have the discipline (courage) to design for today, recognizing that futurerequirements may change dramatically, thereby demanding substantial rework ofthe design and implemented code.By following each of these values, the agile team inculcates respect among it members, between other stakeholders and team members, and indirectly, for thesoftware itself. As they achieve successful delivery of software increments, the teamdevelops growing respect for the XP process.
3.4.2 The XP Process
Extreme Programming uses an object-oriented approach (Appendix 2) as its pre-ferred development paradigm and encompasses a set of rules and practices thatoccur within the context of four framework activities: planning, design, coding, andtesting. Figure 3.2 illustrates the XP process and notes some of the key ideas andtasks that are associated with each framework activity. Key XP activities are sum-marized in the paragraphs that follow.Planning.The planning activity (also called the planning game) begins with listening—a requirements gathering activity that enables the technical members ofthe XP team to understand the business context for the software and to get a broadCHAPTER 3AGILE DEVELOPMENT 73
4 Refactoring allows a software engineer to improve the internal structure of a design (or sourcecode) without changing its external functionality or behavior. In essence, refactoring can be usedto improve the efficiency, readability, or performance of a design or the code that implements adesign.Keep it simplewhenever you can, butrecognize thatcontinual “refactoring”can absorb significanttime and resources.
uote:
“XP is the answerto the question,‘How little can wedo and still buildgreat software?’“Anonymous
WebRef
An excellent overviewof “rules” for XP canbe found at www.extremeprogramming.org/rules.html.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 73feel for required output and major features and functionality. Listening leads to thecreation of a set of “stories” (also called user stories) that describe required output,features, and functionality for software to be built. Each story (similar to use cases described in Chapter 5) is written by the customer and is placed on an index card.The customer assigns a value(i.e., a priority) to the story based on the overall busi-ness value of the feature or function.
5Members of the XP team then assess each story and assign a cost—measured in development weeks—to it. If the story is esti-mated to require more than three development weeks, the customer is asked to splitthe story into smaller stories and the assignment of value and cost occurs again. Itis important to note that new stories can be written at any time.Customers and developers work together to decide how to group stories into thenext release (the next software increment) to be developed by the XP team. Once abasic commitment(agreement on stories to be included, delivery date, and otherproject matters) is made for a release, the XP team orders the stories that will be de-veloped in one of three ways: (1) all stories will be implemented immediately (withina few weeks), (2) the stories with highest value will be moved up in the schedule andimplemented first, or (3) the riskiest stories will be moved up in the schedule andimplemented first.After the first project release (also called a software increment) has been deliv-ered, the XP team computes project velocity. Stated simply, project velocity is the74 PART ONETHE SOFTWARE PROCESS
user stories values acceptance test criteriaiteration plansimple design CRC cards
unit test continuous integrationsoftware increment project velocity computedspike solutions prototypes
refactoringpair programming
acceptance testingRelease
design
coding
planning
testFIGURE 3.2
The ExtremeProgrammingprocess
5 The value of a story may also be dependent on the presence of another story.WebRef
A worthwhile XP“planning game” canbe found at:c2.com/cgi/wiki?planningGame.What is anXP “story”??pre75977_ch03.qxd  11/27/08  3:24 PM  Page 74number of customer stories implemented during the first release. Project velocity canthen be used to (1) help estimate delivery dates and schedule for subsequent releasesand (2) determine whether an overcommitment has been made for all stories acrossthe entire development project. If an overcommitment occurs, the content of releasesis modified or end delivery dates are changed.As development work proceeds, the customer can add stories, change the valueof an existing story, split stories, or eliminate them. The XP team then reconsiders allremaining releases and modifies its plans accordingly.Design.XP design rigorously follows the KIS (keep it simple) principle. A simpledesign is always preferred over a more complex representation. In addition, the de-sign provides implementation guidance for a story as it is written—nothing less,nothing more. The design of extra functionality (because the developer assumes itwill be required later) is discouraged.
6
XP encourages the use of CRC cards (Chapter 7) as an effective mechanism forthinking about the software in an object-oriented context. CRC (class-responsibility-collaborator) cards identify and organize the object-oriented classes
7that are rele- vant to the current software increment. The XP team conducts the design exerciseusing a process similar to the one described in Chapter 8. The CRC cards are the onlydesign work product produced as part of the XP process.If a difficult design problem is encountered as part of the design of a story, XP rec-ommends the immediate creation of an operational prototype of that portion of thedesign. Called a spike solution, the design prototype is implemented and evaluated.The intent is to lower risk when true implementation starts and to validate the orig-inal estimates for the story containing the design problem.In the preceding section, we noted that XP encourages refactoring—a constructiontechnique that is also a method for design optimization. Fowler [Fow00] describesrefactoring in the following manner:
Refactoring is the process of changing a software system in such a way that it does notalter the external behavior of the code yet improves the internal structure. It is a disci-plined way to clean up code [and modify/simplify the internal design] that minimizes thechances of introducing bugs. In essence, when you refactor you are improving the designof the code after it has been written.
Because XP design uses virtually no notation and produces few, if any, work prod-ucts other than CRC cards and spike solutions, design is viewed as a transient arti-fact that can and should be continually modified as construction proceeds. The intentof refactoring is to control these modifications by suggesting small design changesCHAPTER 3AGILE DEVELOPMENT 75
Project velocity is asubtle measure ofteam productivity.
6 These design guidelines should be followed in every software engineering method, although thereare times when sophisticated design notation and terminology may get in the way of simplicity.7 Object-oriented classes are discussed in Appendix 2, in Chapter 8, and throughout Part 2 of thisbook.XP deemphasizes theimportance of design.Not everyone agrees.In fact, there are timeswhen design should beemphasized.
WebRef
Refactoring techniquesand tools can befound at:www.refactoring.com.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 75that “can radically improve the design” [Fow00]. It should be noted, however, thatthe effort required for refactoring can grow dramatically as the size of an applicationgrows.A central notion in XP is that design occurs both before and after coding com- mences. Refactoring means that design occurs continuously as the system is con-structed. In fact, the construction activity itself will provide the XP team withguidance on how to improve the design.Coding.After stories are developed and preliminary design work is done, the teamdoes notmove to code, but rather develops a series of unit tests that will exerciseeach of the stories that is to be included in the current release (software increment).
8
Once the unit test9has been created, the developer is better able to focus on whatmust be implemented to pass the test. Nothing extraneous is added (KIS). Once thecode is complete, it can be unit-tested immediately, thereby providing instantaneousfeedback to the developers.A key concept during the coding activity (and one of the most talked about aspectsof XP) is pair programming. XP recommends that two people work together at onecomputer workstation to create code for a story. This provides a mechanism for real-time problem solving (two heads are often better than one) and real-time quality as-surance (the code is reviewed as it is created). It also keeps the developers focusedon the problem at hand. In practice, each person takes on a slightly different role. Forexample, one person might think about the coding details of a particular portion ofthe design while the other ensures that coding standards (a required part of XP) arebeing followed or that the code for the story will satisfy the unit test that has beendeveloped to validate the code against the story.As pair programmers complete their work, the code they develop is integratedwith the work of others. In some cases this is performed on a daily basis by an inte-gration team. In other cases, the pair programmers have integration responsibility.This “continuous integration” strategy helps to avoid compatibility and interfacingproblems and provides a “smoke testing” environment (Chapter 17) that helps touncover errors early.Testing.I have already noted that the creation of unit tests before coding com-mences is a key element of the XP approach. The unit tests that are created shouldbe implemented using a framework that enables them to be automated (hence, theycan be executed easily and repeatedly). This encourages a regression testing strat-egy (Chapter 17) whenever code is modified (which is often, given the XP refactor-ing philosophy).76 PART ONETHE SOFTWARE PROCESS
Refactoring improvesthe internal structure ofa design (or sourcecode) withoutchanging its externalfunctionality orbehavior.
WebRef
Useful information onXP can be obtained at www.xprogramming.com.
8 This approach is analogous to knowing the exam questions before you begin to study. It makesstudying much easier by focusing attention only on the questions that will be asked.9 Unit testing, discussed in detail in Chapter 17, focuses on an individual software component, exer-cising the component’s interface, data structures, and functionality in an effort to uncover errorsthat are local to the component.What is pairprogramming??
Many software teamsare populated by indi-vidualists. You’ll haveto work to change thatculture if pair program-ming is to work effec-tively.
How are unittests used inXP??pre75977_ch03.qxd  11/27/08  3:24 PM  Page 76As the individual unit tests are organized into a “universal testing suite” [Wel99],integration and validation testing of the system can occur on a daily basis. This pro-vides the XP team with a continual indication of progress and also can raise warn-ing flags early if things go awry. Wells [Wel99] states: “Fixing small problems everyfew hours takes less time than fixing huge problems just before the deadline.”XP acceptance tests, also called customer tests, are specified by the customer and focus on overall system features and functionality that are visible and reviewable bythe customer. Acceptance tests are derived from user stories that have been imple-mented as part of a software release.
3.4.3 Industrial XP
Joshua Kerievsky [Ker05] describes Industrial Extreme Programming (IXP) in the fol- lowing manner: “IXP is an organic evolution of XP. It is imbued with XP’s minimal-ist, customer-centric, test-driven spirit. IXP differs most from the original XP in itsgreater inclusion of management, its expanded role for customers, and its upgradedtechnical practices.” IXP incorporates six new practices that are designed to helpensure that an XP project works successfully for significant projects within a largeorganization.Readiness assessment.Prior to the initiation of an IXP project, the organ-ization should conduct a readiness assessment. The assessment ascertains whether (1) an appropriate development environment exists to support IXP,(2) the team will be populated by the proper set of stakeholders, (3) the or-ganization has a distinct quality program and supports continuous improve-ment, (4) the organizational culture will support the new values of an agileteam, and (5) the broader project community will be populated appropriately.Project community.Classic XP suggests that the right people be used topopulate the agile team to ensure success. The implication is that people onthe team must be well-trained, adaptable and skilled, and have the propertemperament to contribute to a self-organizing team. When XP is to beapplied for a significant project in a large organization, the concept of the“team” should morph into that of a community.A community may have a technologist and customers who are central to the success of a project aswell as many other stakeholders (e.g., legal staff, quality auditors, manufac-turing or sales types) who “are often at the periphery of an IXP project yetthey may play important roles on the project” [Ker05]. In IXP, the communitymembers and their roles should be explicitly defined and mechanisms forcommunication and coordination between community members should beestablished.Project chartering.The IXP team assesses the project itself to determinewhether an appropriate business justification for the project exists andwhether the project will further the overall goals and objectives of theCHAPTER 3AGILE DEVELOPMENT 77
XP acceptance testsare derived from userstories.
What newpractices areappended to XPto create IXP??
uote:
“Ability is whatyou’re capable ofdoing. Motivationdetermines whatyou do. Attitudedetermines howwell you do it.”Lou Holtzpre75977_ch03.qxd  11/27/08  3:24 PM  Page 77organization. Chartering also examines the context of the project to deter-mine how it complements, extends, or replaces existing systems orprocesses.Test-driven management.An IXP project requires measurable criteria forassessing the state of the project and the progress that has been made todate. Test-driven management establishes a series of measurable “destina-tions” [Ker05] and then defines mechanisms for determining whether or notthese destinations have been reached.Retrospectives.An IXP team conducts a specialized technical review(Chapter 15) after a software increment is delivered. Called a retrospective,the review examines “issues, events, and lessons-learned” [Ker05] across asoftware increment and/or the entire software release. The intent is toimprove the IXP process.Continuous learning.Because learning is a vital part of continuousprocess improvement, members of the XP team are encouraged (and possi-bly, incented) to learn new methods and techniques that can lead to a higher-quality product.In addition to the six new practices discussed, IXP modifies a number of existingXP practices. Story-driven development (SDD) insists that stories for acceptance tests be written before a single line of code is generated. Domain-driven design (DDD) is an improvement on the “system metaphor” concept used in XP. DDD [Eva03] sug-gests the evolutionary creation of a domain model that “accurately represents howdomain experts think about their subject” [Ker05]. Pairing extends the XP pair- programming concept to include managers and other stakeholders. The intent is toimprove knowledge sharing among XP team members who may not be directly in-volved in technical development. Iterative usability discourages front-loaded inter- face design in favor of usability design that evolves as software increments aredelivered and users’ interaction with the software is studied.IXP makes smaller modifications to other XP practices and redefines certain rolesand responsibilities to make them more amenable to significant projects for largeorganizations. For further discussion of IXP, visit http://industrialxp.org .
3.4.4 The XP Debate
All new process models and methods spur worthwhile discussion and in some in-stances heated debate. Extreme Programming has done both. In an interesting bookthat examines the efficacy of XP, Stephens and Rosenberg [Ste03] argue that manyXP practices are worthwhile, but others have been overhyped, and a few are prob-lematic. The authors suggest that the codependent nature of XP practices are bothits strength and its weakness. Because many organizations adopt only a subset of XPpractices, they weaken the efficacy of the entire process. Proponents counter thatXP is continuously evolving and that many of the issues raised by critics have been78 PART ONETHE SOFTWARE PROCESSpre75977_ch03.qxd  11/27/08  3:24 PM  Page 78addressed as XP practice matures. Among the issues that continue to trouble somecritics of XP are:
10
•Requirements volatility. Because the customer is an active member of the XPteam, changes to requirements are requested informally. As a consequence,the scope of the project can change and earlier work may have to bemodified to accommodate current needs. Proponents argue that this happensregardless of the process that is applied and that XP provides mechanisms forcontrolling scope creep.
•Conflicting customer needs. Many projects have multiple customers, each withhis own set of needs. In XP, the team itself is tasked with assimilating theneeds of different customers, a job that may be beyond their scope ofauthority.
•Requirements are expressed informally. User stories and acceptance tests arethe only explicit manifestation of requirements in XP. Critics argue that amore formal model or specification is often needed to ensure that omissions,inconsistencies, and errors are uncovered before the system is built. Propo-nents counter that the changing nature of requirements makes such modelsand specification obsolete almost as soon as they are developed.
•Lack of formal design. XP deemphasizes the need for architectural design andin many instances, suggests that design of all kinds should be relativelyinformal. Critics argue that when complex systems are built, design must beemphasized to ensure that the overall structure of the software will exhibitquality and maintainability. XP proponents suggest that the incrementalnature of the XP process limits complexity (simplicity is a core value) andtherefore reduces the need for extensive design.You should note that every software process has flaws and that many software or-ganizations have used XP successfully. The key is to recognize where a process mayhave weaknesses and to adapt it to the specific needs of your organization.CHAPTER 3AGILE DEVELOPMENT 79
10 For a detailed look at some thoughtful criticism that has been leveled at XP, visitwww.softwarereality.com/ExtremeProgramming.jsp.What aresome of theissues that lead toan XP debate??
The scene:Doug Miller’s office.The Players:Doug Miller, software engineeringmanager; Jamie Lazar, software team member; VinodRaman, software team member.The conversation:(A knock on the door, Jamie and Vinod enter Doug’s office)Jamie:Doug, you got a minute?SAFEHOMEConsidering Agile Software Developmentpre75977_ch03.qxd  11/27/08  3:24 PM  Page 793.5 O THER AGILE PROCESS MODELS
The history of software engineering is littered with dozens of obsolete processdescriptions and methodologies, modeling methods and notations, tools, andtechnology. Each flared in notoriety and was then eclipsed by something new and(purportedly) better. With the introduction of a wide array of agile process models—each contending for acceptance within the software development community—theagile movement is following the same historical path.
11
As I noted in the last section, the most widely used of all agile process modelsis Extreme Programming (XP). But many other agile process models have beenproposed and are in use across the industry. Among the most common are:
•Adaptive Software Development (ASD)
•Scrum
•Dynamic Systems Development Method (DSDM)80 PART ONETHE SOFTWARE PROCESS
Doug:Sure Jamie, what’s up?Jamie:We’ve been thinking about our processdiscussion yesterday . . . you know, what process we’regoing to choose for this new SafeHomeproject.Doug:And?Vinod:I was talking to a friend at another company,and he was telling me about Extreme Programming. It’san agile process model . . . heard of it?Doug:Yeah, some good, some bad.Jamie:Well, it sounds pretty good to us. Lets youdevelop software really fast, uses something called pairprogramming to do real-time quality checks . . . it’s prettycool, I think.Doug:It does have a lot of really good ideas. I like thepair-programming concept, for instance, and the ideathat stakeholders should be part of the team.Jamie:Huh? You mean that marketing will work on theproject team with us?Doug (nodding):They’re a stakeholder, aren’t they?Jamie:Jeez . . . they’ll be requesting changes every fiveminutes.Vinod:Not necessarily. My friend said that there areways to “embrace” changes during an XP project.Doug:So you guys think we should use XP?Jamie:It’s definitely worth considering.Doug:I agree. And even if we choose an incrementalmodel as our approach, there’s no reason why we can’tincorporate much of what XP has to offer.Vinod:Doug, before you said “some good, some bad.”What was the “bad”?Doug:The thing I don’t like is the way XP downplaysanalysis and design . . . sort of says that writing code iswhere the action is . . . (The team members look at one another and smile.)Doug:So you agree with the XP approach?Jamie (speaking for both):Writing code is whatwe do, Boss!Doug (laughing):True, but I’d like to see you spend alittle less time coding and then recoding and a little moretime analyzing what has to be done and designing asolution that works.Vinod:Maybe we can have it both ways, agility with alittle discipline.Doug:I think we can, Vinod. In fact, I’m sure of it.
uote:
“Our professiongoes throughmethodologies likea 14-year-old goesthrough clothing.”StephenHawrysh andJim Ruprecht
11 This is not a bad thing. Before one or more models or methods are accepted as a de facto standard,all must contend for the hearts and minds of software engineers. The “winners” evolve into bestpractice, while the “losers” either disappear or merge with the winning models.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 80•Crystal
•Feature Drive Development (FDD)
•Lean Software Development (LSD)
•Agile Modeling (AM)
•Agile Unified Process (AUP)In the sections that follow, I present a very brief overview of each of these agileprocess models. It is important to note that all agile process models conform (to a greater or lesser degree) to the Manifesto for Agile Software Development and the prin- ciples noted in Section 3.3.1. For additional detail, refer to the references noted ineach subsection or for a survey, examine the “agile software development” entryin Wikipedia.
12
3.5.1 Adaptive Software Development (ASD)
Adaptive Software Development(ASD) has been proposed by Jim Highsmith [Hig00] asa technique for building complex software and systems. The philosophical under-pinnings of ASD focus on human collaboration and team self-organization.Highsmith argues that an agile, adaptive development approach based on collab-oration is “as much a source of orderin our complex interactions as discipline andengineering.” He defines an ASD “life cycle” (Figure 3.3) that incorporates threephases, speculation, collaboration, and learning.CHAPTER 3AGILE DEVELOPMENT 81
12 See http://en.wikipedia.org/wiki/Agile_software_development#Agile_methods.WebRef
Useful resources forASD can be found atwww.adaptivesd.com.
adaptive cycle planning mission statement project constraints basic requirementstime-boxed release plan
components implemented/tested focus groups for feedback formal technical reviewspostmortemsRequirements gathering JAD mini-specs
software increment adjustments for subsequent cyclesRelease
collaboration
speculation
learningFIGURE 3.3
Adaptivesoftwaredevelopmentpre75977_ch03.qxd  11/27/08  3:24 PM  Page 81During speculation,the project is initiated and adaptive cycle planning is con- ducted. Adaptive cycle planning uses project initiation information—the customer’smission statement, project constraints (e.g., delivery dates or user descriptions), andbasic requirements—to define the set of release cycles (software increments) thatwill be required for the project.No matter how complete and farsighted the cycle plan, it will invariably change.Based on information obtained at the completion of the first cycle, the plan is re-viewed and adjusted so that planned work better fits the reality in which an ASDteam is working.Motivated people use collaborationin a way that multiplies their talent and cre- ative output beyond their absolute numbers. This approach is a recurring theme inall agile methods. But collaboration is not easy. It encompasses communication andteamwork, but it also emphasizes individualism, because individual creativity playsan important role in collaborative thinking. It is, above all, a matter of trust. Peopleworking together must trust one another to (1) criticize without animosity, (2) assistwithout resentment, (3) work as hard as or harder than they do, (4) have the skill setto contribute to the work at hand, and (5) communicate problems or concerns in away that leads to effective action.As members of an ASD team begin to develop the components that are part of anadaptive cycle, the emphasis is on “learning” as much as it is on progress towarda completed cycle. In fact, Highsmith [Hig00] argues that software developers oftenoverestimate their own understanding (of the technology, the process, and the proj-ect) and that learning will help them to improve their level of real understanding.ASD teams learn in three ways: focus groups (Chapter 5), technical reviews (Chap-ter 14), and project postmortems.The ASD philosophy has merit regardless of the process model that is used. ASD’soverall emphasis on the dynamics of self-organizing teams, interpersonal collabo-ration, and individual and team learning yield software project teams that have amuch higher likelihood of success.
3.5.2 Scrum
Scrum (the name is derived from an activity that occurs during a rugby match13)i s an agile software development method that was conceived by Jeff Sutherland and hisdevelopment team in the early 1990s. In recent years, further development on theScrum methods has been performed by Schwaber and Beedle [Sch01a].Scrum principles are consistent with the agile manifesto and are used to guidedevelopment activities within a process that incorporates the following frameworkactivities: requirements, analysis, design, evolution, and delivery. Within each82 PART ONETHE SOFTWARE PROCESS
Effective collaborationwith your customer willonly occur if youjettison any “us andthem” attitudes.
ASD emphasizeslearning as a keyelement in achieving a “self-organizing”team.
13 A group of players forms around the ball and the teammates work together (sometimes violently!)to move the ball downfield.WebRef
Useful Scruminformation andresources can be foundat www.controlchaos.com.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 82every 24hours
30 daysScrum: 15 minute daily meeting.Team members respond to basics:1) What did you do since last Scrum meeting?2) Do you have any obstacles?3) What will you do before next meeting?
Sprint Backlog:
Feature(s)assignedto sprint
Product Backlog:
Prioritized product features desired by the customerBacklogitemsexpandedby teamNew functionalityis demonstratedat end of sprint
framework activity, work tasks occur within a process pattern (discussed in the fol-lowing paragraph) called a sprint.The work conducted within a sprint (the numberof sprints required for each framework activity will vary depending on product com-plexity and size) is adapted to the problem at hand and is defined and often modifiedin real time by the Scrum team. The overall flow of the Scrum process is illustratedin Figure 3.4.Scrum emphasizes the use of a set of software process patterns [Noy02] that haveproven effective for projects with tight timelines, changing requirements, and businesscriticality. Each of these process patterns defines a set of development actions:Backlog—a prioritized list of project requirements or features that provide busi-ness value for the customer. Items can be added to the backlog at any time (this ishow changes are introduced). The product manager assesses the backlog andupdates priorities as required.Sprints—consist of work units that are required to achieve a requirement de-fined in the backlog that must be fit into a predefined time-box
14(typically 30 days).CHAPTER 3AGILE DEVELOPMENT 83
14 A time-boxis a project management term (see Part 4 of this book) that indicates a period of timethat has been allocated to accomplish some task.FIGURE 3.4
Scrum processflow
Scrum incorporates aset of process patternsthat emphasize projectpriorities,compartmentalizedwork units,communication, andfrequent customerfeedback.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 83Changes (e.g., backlog work items) are not introduced during the sprint. Hence, thesprint allows team members to work in a short-term, but stable environment.Scrum meetings—are short (typically 15 minutes) meetings held daily by the Scrumteam. Three key questions are asked and answered by all team members [Noy02]:
•What did you do since the last team meeting?
•What obstacles are you encountering?
•What do you plan to accomplish by the next team meeting?A team leader, called a Scrum master,leads the meeting and assesses the responsesfrom each person. The Scrum meeting helps the team to uncover potential problemsas early as possible. Also, these daily meetings lead to “knowledge socialization”[Bee99] and thereby promote a self-organizing team structure.Demos—deliver the software increment to the customer so that functionality thathas been implemented can be demonstrated and evaluated by the customer. It is im-portant to note that the demo may not contain all planned functionality, but ratherthose functions that can be delivered within the time-box that was established.Beedle and his colleagues [Bee99] present a comprehensive discussion of these pat-terns in which they state: “Scrum assumes up-front the existence of chaos. . . . ” TheScrum process patterns enable a software team to work successfully in a worldwhere the elimination of uncertainty is impossible.
3.5.3 Dynamic Systems Development Method (DSDM)
The Dynamic Systems Development Method(DSDM) [Sta97] is an agile software devel- opment approach that “provides a framework for building and maintaining systemswhich meet tight time constraints through the use of incremental prototyping in a con-trolled project environment” [CCS02]. The DSDM philosophy is borrowed from a mod-ified version of the Pareto principle—80 percent of an application can be delivered in20 percent of the time it would take to deliver the complete (100 percent) application.DSDM is an iterative software process in which each iteration follows the 80 per-cent rule. That is, only enough work is required for each increment to facilitatemovement to the next increment. The remaining detail can be completed later whenmore business requirements are known or changes have been requested andaccommodated.The DSDM Consortium (www.dsdm.org) is a worldwide group of member com-panies that collectively take on the role of “keeper” of the method. The consortiumhas defined an agile process model, called the DSDM life cycle that defines three dif- ferent iterative cycles, preceded by two additional life cycle activities:Feasibility study—establishes the basic business requirements and constraintsassociated with the application to be built and then assesses whether the applica-tion is a viable candidate for the DSDM process.84 PART ONETHE SOFTWARE PROCESS
WebRef
Useful resources forDSSD can be found atwww.dsdm.org.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 84Business study—establishes the functional and information requirements thatwill allow the application to provide business value; also, defines the basicapplication architecture and identifies the maintainability requirements for theapplication.Functional model iteration—produces a set of incremental prototypes thatdemonstrate functionality for the customer. (Note: All DSDM prototypes are in-tended to evolve into the deliverable application.) The intent during this iterativecycle is to gather additional requirements by eliciting feedback from users as theyexercise the prototype.Design and build iteration—revisits prototypes built during functional model iterationto ensure that each has been engineered in a manner that will enable it toprovide operational business value for end users. In some cases, functional model iterationand design and build iterationoccur concurrently.Implementation—places the latest software increment (an “operationalized” pro-totype) into the operational environment. It should be noted that (1) the incrementmay not be 100 percent complete or (2) changes may be requested as the incre-ment is put into place. In either case, DSDM development work continues byreturning to the functional model iteration activity.DSDM can be combined with XP (Section 3.4) to provide a combination approachthat defines a solid process model (the DSDM life cycle) with the nuts and bolts prac-tices (XP) that are required to build software increments. In addition, the ASD con-cepts of collaboration and self-organizing teams can be adapted to a combinedprocess model.
3.5.4 Crystal
Alistair Cockburn [Coc05] and Jim Highsmith [Hig02b] created the Crystal family of agile methods
15in order to achieve a software development approach that puts apremium on “maneuverability” during what Cockburn characterizes as “a resource-limited, cooperative game of invention and communication, with a primary goal ofdelivering useful, working software and a secondary goal of setting up for the nextgame” [Coc02].To achieve maneuverability, Cockburn and Highsmith have defined a set ofmethodologies, each with core elements that are common to all, and roles, processpatterns, work products, and practice that are unique to each. The Crystal family isactually a set of example agile processes that have been proven effective for differ-ent types of projects. The intent is to allow agile teams to select the member of thecrystal family that is most appropriate for their project and environment.CHAPTER 3AGILE DEVELOPMENT 85
15 The name “crystal” is derived from the characteristics of geological crystals, each with its owncolor, shape, and hardness.Crystal is a family ofprocess models withthe same “geneticcode” but differentmethods for adaptingto projectcharacteristics.DSDM is a processframework that canadopt the tactics ofanother agile approachsuch as XP .pre75977_ch03.qxd  11/27/08  3:24 PM  Page 853.5.5 Feature Driven Development (FDD)
Feature Driven Development(FDD) was originally conceived by Peter Coad and hiscolleagues [Coa99] as a practical process model for object-oriented software engi-neering. Stephen Palmer and John Felsing [Pal02] have extended and improvedCoad’s work, describing an adaptive, agile process that can be applied to moderatelysized and larger software projects.Like other agile approaches, FDD adopts a philosophy that (1) emphasizes col-laboration among people on an FDD team; (2) manages problem and projectcomplexity using feature-based decomposition followed by the integration ofsoftware increments, and (3) communication of technical detail using verbal,graphical, and text-based means. FDD emphasizes software quality assuranceactivities by encouraging an incremental development strategy, the use of designand code inspections, the application of software quality assurance audits (Chap-ter 16), the collection of metrics, and the use of patterns (for analysis, design, andconstruction).In the context of FDD, a feature“is a client-valued function that can be imple-mented in two weeks or less” [Coa99]. The emphasis on the definition of featuresprovides the following benefits:
•Because features are small blocks of deliverable functionality, users candescribe them more easily; understand how they relate to one another morereadily; and better review them for ambiguity, error, or omissions.
•Features can be organized into a hierarchical business-related grouping.
•Since a feature is the FDD deliverable software increment, the team developsoperational features every two weeks.
•Because features are small, their design and code representations are easierto inspect effectively.
•Project planning, scheduling, and tracking are driven by the featurehierarchy, rather than an arbitrarily adopted software engineering task set.Coad and his colleagues [Coa99] suggest the following template for defining afeature:<action> the<result> <by for of to> a(n)<object> where an <object>is “a person, place, or thing (including roles, moments in time orintervals of time, or catalog-entry-like descriptions).” Examples of features for an e-commerce application might be:Add the product to shopping cartDisplay the technical-specifications of the productStore the shipping-information for the customer86 PART ONETHE SOFTWARE PROCESS
WebRef
A wide variety ofarticles andpresentations on FDDcan be found at:www.featuredrivendevelopment.com/.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 86A feature set groups related features into business-related categories and is defined[Coa99] as:<action><-ing> a(n)<object>For example: Making a product saleis a feature set that would encompass the fea-tures noted earlier and others.The FDD approach defines five “collaborating” [Coa99] framework activities (inFDD these are called “processes”) as shown in Figure 3.5.FDD provides greater emphasis on project management guidelines and tech-niques than many other agile methods. As projects grow in size and complexity,ad hoc project management is often inadequate. It is essential for developers, theirmanagers, and other stakeholders to understand project status—what accomplish-ments have been made and problems have been encountered. If deadline pressureis significant, it is critical to determine if software increments (features) are properlyscheduled. To accomplish this, FDD defines six milestones during the design andimplementation of a feature: “design walkthrough, design, design inspection, code,code inspection, promote to build” [Coa99].
3.5.6 Lean Software Development (LSD)
Lean Software Development(LSD) has adapted the principles of lean manufacturingto the world of software engineering. The lean principles that inspire the LSD processcan be summarized ([Pop03], [Pop06a]) as eliminate waste, build quality in, create knowledge, defer commitment, deliver fast, respect people, and optimize the whole. Each of these principles can be adapted to the software process. For example,eliminate wastewithin the context of an agile software project can be interpretedto mean [Das05]: (1) adding no extraneous features or functions, (2) assessing thecost and schedule impact of any newly requested requirement, (3) removing anysuperfluous process steps, (4) establishing mechanisms to improve the way teammembers find information, (5) ensuring the testing finds as many errors as possible,CHAPTER 3AGILE DEVELOPMENT 87
DevelopanOverallModelBuild aFeaturesListPlanByFeatureDesignByFeatureBuildByFeature
(more shapethan content)A list of featuresgrouped into setsand subject areasA development planClass ownersFeature Set OwnersA designpackage(sequences)Completedclient-valuefunctionFIGURE 3.5
Feature DrivenDevelopment[Coa99] (withpermission)pre75977_ch03.qxd  11/27/08  3:24 PM  Page 87(6) reducing the time required to request and get a decision that affects the softwareor the process that is applied to create it, and (7) streamlining the manner in whichinformation is transmitted to all stakeholders involved in the process.For a detailed discussion of LSD and pragmatic guidelines for implementing theprocess, you should examine [Pop06a] and [Pop06b].
3.5.7 Agile Modeling (AM)
There are many situations in which software engineers must build large, business-critical systems. The scope and complexity of such systems must be modeled so that(1) all constituencies can better understand what needs to be accomplished, (2) theproblem can be partitioned effectively among the people who must solve it, and(3) quality can be assessed as the system is being engineered and built.Over the past 30 years, a wide variety of software engineering modeling methodsand notation have been proposed for analysis and design (both architectural andcomponent-level). These methods have merit, but they have proven to be difficultto apply and challenging to sustain (over many projects). Part of the problem is the“weight” of these modeling methods. By this I mean the volume of notation required,the degree of formalism suggested, the sheer size of the models for large projects,and the difficulty in maintaining the model(s) as changes occur. Yet analysis and de-sign modeling have substantial benefit for large projects—if for no other reason thanto make these projects intellectually manageable. Is there an agile approach to soft-ware engineering modeling that might provide an alternative?At “The Official Agile Modeling Site,” Scott Ambler [Amb02a] describes agile mod- eling(AM) in the following manner:
Agile Modeling (AM) is a practice-based methodology for effective modeling and documen-tation of software-based systems. Simply put, Agile Modeling (AM) is a collection of values,principles, and practices for modeling software that can be applied on a software develop-ment project in an effective and light-weight manner. Agile models are more effective thantraditional models because they are just barely good, they don’t have to be perfect.
Agile modeling adopts all of the values that are consistent with the agile manifesto.The agile modeling philosophy recognizes that an agile team must have the courageto make decisions that may cause it to reject a design and refactor. The team mustalso have the humility to recognize that technologists do not have all the answers andthat business experts and other stakeholders should be respected and embraced.Although AM suggests a wide array of “core” and “supplementary” modeling prin-ciples, those that make AM unique are [Amb02a]:Model with a purpose.A developer who uses AM should have a specificgoal (e.g., to communicate information to the customer or to help better un-derstand some aspect of the software) in mind before creating the model.Once the goal for the model is identified, the type of notation to be used andlevel of detail required will be more obvious.88 PART ONETHE SOFTWARE PROCESS
WebRef
Comprehensiveinformation on agilemodeling can be foundat: www.agilemodeling.com.
uote:
“I was in the drugstore the other daytrying to get a coldmedication . . . noteasy. There’s anentire wall ofproducts you need.You stand theregoing, Well, thisone is quick actingbut this is longlasting. . . . Whichis more important,the present or thefuture?”Jerry Seinfeldpre75977_ch03.qxd  11/27/08  3:24 PM  Page 88Use multiple models.There are many different models and notations thatcan be used to describe software. Only a small subset is essential for mostprojects. AM suggests that to provide needed insight, each model shouldpresent a different aspect of the system and only those models that providevalue to their intended audience should be used.Travel light.As software engineering work proceeds, keep only those mod-els that will provide long-term value and jettison the rest. Every work productthat is kept must be maintained as changes occur. This represents work thatslows the team down. Ambler [Amb02a] notes that “Every time you decide tokeep a model you trade-off agility for the convenience of having that informa-tion available to your team in an abstract manner (hence potentially enhanc-ing communication within your team as well as with project stakeholders).”Content is more important than representation. Modeling should im- part information to its intended audience. A syntactically perfect model thatimparts little useful content is not as valuable as a model with flawed nota-tion that nevertheless provides valuable content for its audience.Know the models and the tools you use to create them. Understand the strengths and weaknesses of each model and the tools that are used tocreate it.Adapt locally.The modeling approach should be adapted to the needs ofthe agile team.A major segment of the software engineering community has adopted the UnifiedModeling Language (UML)
16as the preferred method for representing analysis anddesign models. The Unified Process (Chapter 2) has been developed to provide aframework for the application of UML. Scott Ambler [Amb06] has developed a sim-plified version of the UP that integrates his agile modeling philosophy.
3.5.8 Agile Unified Process (AUP)
The Agile Unified Process(AUP) adopts a “serial in the large” and “iterative in thesmall” [Amb06] philosophy for building computer-based systems. By adopting theclassic UP phased activities—inception, elaboration, construction, and transition—AUP provides a serial overlay (i.e., a linear sequence of software engineering activities)that enables a team to visualize the overall process flow for a software project. How-ever, within each of the activities, the team iterates to achieve agility and to delivermeaningful software increments to end users as rapidly as possible. Each AUP iter-ation addresses the following activities [Amb06]: 
•Modeling.UML representations of the business and problem domains arecreated. However, to stay agile, these models should be “just barely goodenough” [Amb06] to allow the team to proceed.CHAPTER 3AGILE DEVELOPMENT 89
“Traveling light” is anappropriate philosophyfor all software engi-neering work. Buildonly those models thatprovide value … nomore, no less.
16 A brief tutorial on UML is presented in Appendix 1.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 89•Implementation.Models are translated into source code.
•Testing.Like XP, the team designs and executes a series of tests to uncovererrors and ensure that the source code meets its requirements.
•Deployment.Like the generic process activity discussed in Chapters 1 and 2,deployment in this context focuses on the delivery of a software incrementand the acquisition of feedback from end users.
•Configuration and project management. In the context of AUP, configuration management (Chapter 22) addresses change management, risk manage-ment, and the control of any persistent work products
17that are produced by the team. Project management tracks and controls the progress of the teamand coordinates team activities.
•Environment management.Environment management coordinates a processinfrastructure that includes standards, tools, and other support technologyavailable to the team.Although the AUP has historical and technical connections to the Unified ModelingLanguage, it is important to note that UML modeling can be using in conjunctionwith any of the agile process models described in Section 3.5.90 PART ONETHE SOFTWARE PROCESS
17 A persistent work productis a model or document or test case produced by the team that will be keptfor an indeterminate period of time. It will not be discarded once the software increment is delivered.18 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Agile Development
Objective:The objective of agile developmenttools is to assist in one or more aspects of agiledevelopment with an emphasis on facilitating the rapidgeneration of operational software. These tools can alsobe used when prescriptive process models (Chapter 2) areapplied.Mechanics:Tool mechanics vary. In general, agile toolsets encompass automated support for project planning,use case development and requirements gathering, rapiddesign, code generation, and testing.Representative Tools:
18
Note:Because agile development is a hot topic, mostsoftware tools vendors purport to sell tools that support the agile approach. The tools noted here havecharacteristics that make them particularly useful foragile projects.OnTime,developed by Axosoft (www.axosoft.com),provides agile process management support forvarious technical activities within the process.Ideogramic UML,developed by Ideogramic(www.ideogramic.com) is a UML tool setspecifically developed for use within an agile process.Together Tool Set,distributed by Borland(www.borland.com), provides a tools suite thatsupports many technical activities within XP and otheragile processes.SOFTWARE TOOLSpre75977_ch03.qxd  11/27/08  3:24 PM  Page 903.6 A T OOL SET FOR THE AGILE PROCESS
Some proponents of the agile philosophy argue that automated software tools (e.g.,design tools) should be viewed as a minor supplement to the team’s activities, andnot at all pivotal to the success of the team. However, Alistair Cockburn [Coc04] sug-gests that tools can have a benefit and that “agile teams stress using tools that per-mit the rapid flow of understanding. Some of those tools are social, starting even atthe hiring stage. Some tools are technological, helping distributed teams simulatebeing physically present. Many tools are physical, allowing people to manipulatethem in workshops.”Because acquiring the right people (hiring), team collaboration, stakeholder com-munication, and indirect management are key elements in virtually all agile processmodels, Cockburn argues that “tools” that address these issues are critical successfactors for agility. For example, a hiring “tool” might be the requirement to have aprospective team member spend a few hours pair programming with an existingmember of the team. The “fit” can be assessed immediately.Collaborative and communication “tools” are generally low tech and incorporateany mechanism (“physical proximity, whiteboards, poster sheets, index cards, andsticky notes” [Coc04]) that provides information and coordination among agile de-velopers. Active communication is achieved via the team dynamics (e.g., pair pro-gramming), while passive communication is achieved by “information radiators”(e.g., a flat panel display that presents the overall status of different components ofan increment). Project management tools deemphasize the Gantt chart and replaceit with earned value charts or “graphs of tests created versus passed . . . other agiletools are used to optimize the environment in which the agile team works (e.g., moreefficient meeting areas), improve the team culture by nurturing social interactions(e.g., collocated teams), physical devices (e.g., electronic whiteboards), and processenhancement (e.g., pair programming or time-boxing)” [Coc04].Are any of these things really tools? They are, if they facilitate the work performedby an agile team member and enhance the quality of the end product.
3.7 S UMMARY
In a modern economy, market conditions change rapidly, customer and end-userneeds evolve, and new competitive threats emerge without warning. Practitionersmust approach software engineering in a manner that allows them to remain agile—to define maneuverable, adaptive, lean processes that can accommodate the needsof modern business.An agile philosophy for software engineering stresses four key issues: the impor-tance of self-organizing teams that have control over the work they perform, com-munication and collaboration between team members and between practitionersand their customers, a recognition that change represents an opportunity, andCHAPTER 3AGILE DEVELOPMENT 91
The “tool set” thatsupports agileprocesses focusesmore on people issuesthan it does ontechnology issues.pre75977_ch03.qxd  11/27/08  3:24 PM  Page 91an emphasis on rapid delivery of software that satisfies the customer. Agile processmodels have been designed to address each of these issues.Extreme programming (XP) is the most widely used agile process. Organized asfour framework activities—planning, design, coding, and testing—XP suggests anumber of innovative and powerful techniques that allow an agile team to createfrequent software releases that deliver features and functionality that have been de-scribed and then prioritized by stakeholders.Other agile process models also stress human collaboration and team self-organization, but define their own framework activities and select different points ofemphasis. For example, ASD uses an iterative process that incorporates adaptivecycle planning, relatively rigorous requirement gathering methods, and an iterativedevelopment cycle that incorporates customer focus groups and formal technical re-views as real-time feedback mechanisms. Scrum emphasizes the use of a set of soft-ware process patterns that have proven effective for projects with tight time lines,changing requirements, and business criticality. Each process pattern defines a setof development tasks and allows the Scrum team to construct a process that isadapted to the needs of the project. The Dynamic Systems Development Method(DSDM) advocates the use of time-box scheduling and suggests that only enoughwork is required for each software increment to facilitate movement to the nextincrement. Crystal is a family of agile process models that can be adopted to the spe-cific characteristics of a project.Feature Driven Development (FDD) is somewhat more “formal” than other agilemethods, but still maintains agility by focusing the project team on the developmentof features—a client-valued function that can be implemented in two weeks or less.Lean Software Development (LSD) has adapted the principles of lean manufacturingto the world of software engineering. Agile modeling (AM) suggests that modeling isessential for all systems, but that the complexity, type, and size of the model must betuned to the software to be built. The Agile Unified Process (AUP) adopts a “serial inthe large” and “iterative in the small” philosophy for building software.
PROBLEMS AND POINTS TO PONDER
3.1.Reread “The Manifesto for Agile Software Development” at the beginning of this chapter.Can you think of a situation in which one or more of the four “values” could get a software teaminto trouble?3.2.Describe agility (for software projects) in your own words.3.3.Why does an iterative process make it easier to manage change? Is every agile process dis-cussed in this chapter iterative? Is it possible to complete a project in just one iteration and stillbe agile? Explain your answers.3.4.Could each of the agile processes be described using the generic framework activitiesnoted in Chapter 2? Build a table that maps the generic activities into the activities defined foreach agile process.3.5.Try to come up with one more “agility principle” that would help a software engineeringteam become even more maneuverable.92 PART ONETHE SOFTWARE PROCESSpre75977_ch03.qxd  11/27/08  3:24 PM  Page 923.6.Select one agility principle noted in Section 3.3.1 and try to determine whether each of theprocess models presented in this chapter exhibits the principle. [Note: I have presented anoverview of these process models only, so it may not be possible to determine whether a prin-ciple has been addressed by one or more of the models, unless you do additional research(which is not required for this problem).]3.7.Why do requirements change so much? After all, don’t people know what they want?3.8.Most agile process models recommend face-to-face communication. Yet today, membersof a software team and their customers may be geographically separated from one another. Doyou think this implies that geographical separation is something to avoid? Can you think of waysto overcome this problem?3.9.Write an XP user story that describes the “favorite places” or “bookmarks” feature avail-able on most Web browsers.3.10.What is a spike solution in XP?3.11.Describe the XP concepts of refactoring and pair programming in your own words.3.12.Do a bit more reading and describe what a time-box is. How does this assist an ASD teamin delivering software increments in a short time period?3.13.Do the 80 percent rule in DSDM and the time-boxing approach defined for ASD achievethe same result?3.14.Using the process pattern template presented in Chapter 2, develop a process pattern forany one of the Scrum patterns presented in Section 3.5.2.3.15.Why is Crystal called a family of agile methods?3.16.Using the FDD feature template described in Section 3.5.5, define a feature set for a Webbrowser. Now develop a set of features for the feature set.3.17.Visit the Official Agile Modeling Site and make a complete list of all core and supple-mentary AM principles.3.18.The tool set proposed in Section 3.6 supports many of the “soft” aspects of agile meth-ods. Since communication is so important, recommend an actual tool set that might be used toenhance communication among stakeholders on an agile team.
FURTHER READINGS AND INFORMATION SOURCES
The overall philosophy and underlying principles of agile software development are consideredin depth in many of the books referenced in the body of this chapter. In addition, books by Shawand Warden (The Art of Agile Development, O’Reilly Media, Inc., 2008), Hunt (Agile Software Con- struction,Springer, 2005), and Carmichael and Haywood ( Better Software Faster,Prentice-Hall, 2002) present useful discussions of the subject. Aguanno (Managing Agile Projects, Multi- Media Publications, 2005), Highsmith ( Agile Project Management: Creating Innovative Products, Addison-Wesley, 2004), and Larman (Agile and Iterative Development: A Manager’s Guide,Addison-Wesley, 2003) present a management overview and consider project managementissues. Highsmith (Agile Software Development Ecosystems, Addison-Wesley, 2002) presents a survey of agile principles, processes, and practices. A worthwhile discussion of the delicate bal-ance between agility and discipline is presented by Booch and his colleagues (Balancing Agilityand Discipline,Addison-Wesley, 2004).Martin (Clean Code: A Handbook of Agile Software Craftsmanship, Prentice-Hall, 2009) pres- ents the principles, patterns, and practices required to develop “clean code” in an agile softwareengineering environment. Leffingwell (Scaling Software Agility: Best Practices for Large Enter-prises,Addison-Wesley, 2007) discusses strategies for scaling up agile practices for large proj-ects. Lippert and Rook (Refactoring in Large Software Projects: Performing Complex RestructuringsSuccessfully,Wiley, 2006) discuss the use of refactoring when applied in large, complex systems.CHAPTER 3AGILE DEVELOPMENT 93pre75977_ch03.qxd  11/27/08  3:24 PM  Page 93Stamelos and Sfetsos (Agile Software Development Quality Assurance, IGI Global, 2007) discuss SQA techniques that conform to the agile philosophy.Dozens of books have been written about Extreme Programming over the past decade. Beck(Extreme Programming Explained: Embrace Change, 2d ed., Addison-Wesley, 2004) remains the definitive treatment of the subject. In addition, Jeffries and his colleagues ( Extreme Programming Installed,Addison-Wesley, 2000), Succi and Marchesi ( Extreme Programming Examined, Addison-Wesley, 2001), Newkirk and Martin ( Extreme Programming in Practice,Addison-Wesley, 2001), and Auer and his colleagues ( Extreme Programming Applied: Play to Win, Addison-Wesley, 2001) provide a nuts-and-bolts discussion of XP along with guidance on how best to apply it.McBreen (Questioning Extreme Programming, Addison-Wesley, 2003) takes a critical look at XP, defining when and where it is appropriate. An in-depth consideration of pair programming ispresented by McBreen (Pair Programming Illuminated, Addison-Wesley, 2003). ASD is addressed in depth by Highsmith [Hig00]. Schwaber (The Enterprise and Scrum,Microsoft Press, 2007) discusses the use of Scrum for projects that have a major businessimpact. The nuts and bolts of Scrum are discussed by Schwaber and Beedle (Agile SoftwareDevelopment with SCRUM,Prentice-Hall, 2001). Worthwhile treatments of DSDM have beenwritten by the DSDM Consortium (DSDM: Business Focused Development, 2d ed., Pearson Edu- cation, 2003) and Stapleton (DSDM: The Method in Practice, Addison-Wesley, 1997). Cockburn (Crystal Clear,Addison-Wesley, 2005) presents an excellent overview of the Crystal family ofprocesses. Palmer and Felsing [Pal02] present a detailed treatment of FDD. Carmichael andHaywood (Better Software Faster,Prentice-Hall, 2002) provides another useful treatment of FDDthat includes a step-by-step journey through the mechanics of the process. Poppendieck and Poppendieck (Lean Development: An Agile Toolkit for Software Development Managers, Addison- Wesley, 2003) provide guidelines for managing and controlling agile projects. Ambler andJeffries (Agile Modeling,Wiley, 2002) discuss AM in some depth.A wide variety of information sources on agile software development are available on theInternet. An up-to-date list of World Wide Web references that are relevant to the agile processcan be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.94 PART ONETHE SOFTWARE PROCESSpre75977_ch03.qxd  11/27/08  3:24 PM  Page 94MODELING
95PART
Two
In this part of Software Engineering: A Practitioner’s Approachyou’ll learn about the principles, concepts, and methods that areused to create high-quality requirements and design models.These questions are addressed in the chapters that follow:•What concepts and principles guide software engineeringpractice?•What is requirements engineering and what are the underly-ing concepts that lead to good requirements analysis?•How is the requirements model created and what are itselements?•What are the elements of a good design?•How does architectural design establish a framework for allother design actions and what models are used?•How do we design high-quality software components?•What concepts, models, and methods are applied as a userinterface is designed?•What is pattern-based design?•What specialized strategies and methods are used to designWebApps?Once these questions are answered you’ll be better prepared toapply software engineering practice.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 95In a book that explores the lives and thoughts of software engineers, EllenUllman [Ull97] depicts a slice of life as she relates the thoughts of practitionerunder pressure:
I have no idea what time it is. There are no windows in this office and no clock, onlythe blinking red LED display of a microwave, which flashes 12:00, 12:00, 12:00, 12:00.Joel and I have been programming for days. We have a bug, a stubborn demon of abug. So the red pulse no-time feels right, like a read-out of our brains, which havesomehow synchronized themselves at the same blink rate . . . What are we working on? . . . The details escape me just now. We may be helpingpoor sick people or tuning a set of low-level routines to verify bits on a distributeddatabase protocol—I don’t care. I should care; in another part of my being—later, per-haps when we emerge from this room full of computers—I will care very much whyand for whom and for what purpose I am writing software. But just now: no. I havepassed through a membrane where the real world and its uses no longer matter. I ama software engineer. . . .
96CHAPTER
4PRINCIPLES THAT
GUIDEPRACTICE
KEY
CONCEPTSCore principles  . . .98Principles that govern:coding . . . . . . . .111communication . .101deployment  . . .113design  . . . . . . .109modeling  . . . . .105planning . . . . . .103requirements  . .107testing  . . . . . . .112
What is it? Software engineeringpractice is a broad array of princi-ples, concepts, methods, and toolsthat you must consider as software isplanned and developed. Principles that guidepractice establish a foundation from which soft-ware engineering is conducted.
Who does it? Practitioners (software engineers)and their managers conduct a variety of soft-ware engineering tasks.
Why is it important? The software process pro-vides everyone involved in the creation of acomputer-based system or product with a roadmap for getting to a successful destination.Practice provides you with the detail you’ll needto drive along the road. It tells you where thebridges, the roadblocks, and the forks are located.It helps you understand the concepts and princi-ples that must be understood and followed todrive safely and rapidly. It instructs you on howto drive, where to slow down, and where tospeed up. In the context of software engineering,QUICK
LOOKpractice is what you do day in and day out assoftware evolves from an idea to a reality.
What are the steps? Three elements of practiceapply regardless of the process model that is cho-sen. They are: principles, concepts, and methods.A fourth element of practice—tools—supportsthe application of methods.
What is the work product? Practice encom-passes the technical activities that produce allwork products that are defined by the softwareprocess model that has been chosen.
How do I ensure that I’ve done it right? First,have a firm understanding of the principles thatapply to the work (e.g., design) that you’re doingat the moment. Then, be certain that you’ve cho-sen an appropriate method for the work, be surethat you understand how to apply the method, useautomated tools when they’re appropriate for thetask, and be adamant about the need for tech-niques to ensure the quality of work products thatare produced.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 96CHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 97
A dark image of software engineering practice to be sure, but upon reflection,many of the readers of this book will be able to relate to it.People who create computer software practice the art or craft or discipline
1that is software engineering. But what is software engineering “practice”? In a genericsense, practiceis a collection of concepts, principles, methods, and tools that a soft-ware engineer calls upon on a daily basis. Practice allows managers to manage soft-ware projects and software engineers to build computer programs. Practicepopulates a software process model with the necessary technical and managementhow-to’s to get the job done. Practice transforms a haphazard unfocused approachinto something that is more organized, more effective, and more likely to achievesuccess.Various aspects of software engineering practice will be examined throughout theremainder of this book. In this chapter, my focus is on principles and concepts thatguide software engineering practice in general.
4.1 S OFTWARE ENGINEERING KNOWLEDGE
In an editorial published in IEEE Software a decade ago, Steve McConnell [McC99] made the following comment:
Many software practitioners think of software engineering knowledge almost exclusivelyas knowledge of specific technologies: Java, Perl, html, C /H11001/H11001, Linux, Windows NT, and so on. Knowledge of specific technology details is necessary to perform computer program-ming. If someone assigns you to write a program in C/H11001/H11001 , you have to know something about C/H11001/H11001to get your program to work.You often hear people say that software development knowledge has a 3-year half-life: half of what you need to know today will be obsolete within 3 years. In thedomain of technology-related knowledge, that’s probably about right. But there isanother kind of software development knowledge—a kind that I think of as “softwareengineering principles”—that does not have a three-year half-life. These software engi-neering principles are likely to serve a professional programmer throughout his or hercareer.
McConnell goes on to argue that the body of software engineering knowledge(circa the year 2000) had evolved to a “stable core” that he estimated representedabout “75 percent of the knowledge needed to develop a complex system.” But whatresides within this stable core?As McConnell indicates, core principles—the elemental ideas that guide softwareengineers in the work that they do—now provide a foundation from which softwareengineering models, methods, and tools can be applied and evaluated.
1 Some writers argue for one of these terms to the exclusion of the others. In reality, softwareengineering is all three.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 974.2 C OREPRINCIPLES
Software engineering is guided by a collection of core principles that help in the ap-plication of a meaningful software process and the execution of effective softwareengineering methods. At the process level, core principles establish a philosophicalfoundation that guides a software team as it performs framework and umbrella ac-tivities, navigates the process flow, and produces a set of software engineering workproducts. At the level of practice, core principles establish a collection of values andrules that serve as a guide as you analyze a problem, design a solution, implementand test the solution, and ultimately deploy the software in the user community.In Chapter 1, I identified a set of general principles that span software engineeringprocess and practice: (1) provide value to end users, (2) keep it simple, (3) maintainthe vision (of the product and the project), (4) recognize that others consume (andmust understand) what you produce, (5) be open to the future, (6) plan ahead forreuse, and (7) think! Although these general principles are important, they are char-acterized at such a high level of abstraction that they are sometimes difficult to trans-late into day-to-day software engineering practice. In the subsections that follow, Itake a more detailed look at the core principles that guide process and practice.
4.2.1 Principles That Guide Process
In Part 1 of this book I discussed the importance of the software process anddescribed the many different process models that have been proposed for softwareengineering work. Regardless of whether a model is linear or iterative, prescriptiveor agile, it can be characterized using the generic process framework that is appli-cable for all process models. The following set of core principles can be applied tothe framework, and by extension, to every software process.Principle 1.Be agile.Whether the process model you choose is prescrip-tive or agile, the basic tenets of agile development should govern yourapproach. Every aspect of the work you do should emphasize economy ofaction—keep your technical approach as simple as possible, keep the workproducts you produce as concise as possible, and make decisions locallywhenever possible.Principle 2.Focus on quality at every step.The exit condition for every process activity, action, and task should focus on the quality of the workproduct that has been produced.Principle 3.Be ready to adapt.Process is not a religious experience, anddogma has no place in it. When necessary, adapt your approach to con-straints imposed by the problem, the people, and the project itself.Principle 4.Build an effective team.Software engineering process and practice are important, but the bottom line is people. Build a self-organizingteam that has mutual trust and respect.98 PART TWOMODELING
uote:
“In theory there isno differencebetween theory andpractice. But, inpractice, there is.”Jan van deSnepscheut
Every project andevery team is unique.That means that youmust adapt yourprocess to best fit yourneeds.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 98Principle 5.Establish mechanisms for communication and coordination.Projects fail because important information falls into the cracks and/orstakeholders fail to coordinate their efforts to create a successful end prod-uct. These are management issues and they must be addressed.Principle 6.Manage change.The approach may be either formal or infor-mal, but mechanisms must be established to manage the way changes arerequested, assessed, approved, and implemented.Principle 7.Assess risk.Lots of things can go wrong as software is beingdeveloped. It’s essential that you establish contingency plans.Principle 8.Create work products that provide value for others.Create only those work products that provide value for other processactivities, actions, or tasks. Every work product that is produced as part ofsoftware engineering practice will be passed on to someone else. A list ofrequired functions and features will be passed along to the person (people)who will develop a design, the design will be passed along to those whogenerate code, and so on. Be sure that the work product imparts the necessaryinformation without ambiguity or omission.Part 4 of this book focuses on project and process management issues andconsiders various aspects of each of these principles in some detail.
4.2.2 Principles That Guide Practice
Software engineering practice has a single overriding goal—to deliver on-time, high-quality, operational software that contains functions and features that meet theneeds of all stakeholders. To achieve this goal, you should adopt a set of core prin-ciples that guide your technical work. These principles have merit regardless of theanalysis and design methods that you apply, the construction techniques (e.g., pro-gramming language, automated tools) that you use, or the verification and valida-tion approach that you choose. The following set of core principles are fundamentalto the practice of software engineering:Principle 1.Divide and conquer.Stated in a more technical manner,analysis and design should always emphasize separation of concerns(SoC). A large problem is easier to solve if it is subdivided into a collection of elements(or concerns). Ideally, each concern delivers distinct functionality that can bedeveloped, and in some cases validated, independently of other concerns.Principle 2.Understand the use of abstraction. At its core, an abstrac- tion is a simplification of some complex element of a system used to commu-nicate meaning in a single phrase. When I use the abstraction spreadsheet, itis assumed that you understand what a spreadsheet is, the general structureof content that a spreadsheet presents, and the typical functions that can beapplied to it. In software engineering practice, you use many different levelsCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 99
uote:
“The truth of thematter is that youalways know theright thing to do.The hard part isdoing it.”General H.NormanSchwarzkopf
Problems are easier tosolve when they aresubdivided intoseparate concerns,each distinct,individually solvable,and verifiable.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 99of abstraction, each imparting or implying meaning that must be communi-cated. In analysis and design work, a software team normally begins withmodels that represent high levels of abstraction (e.g., a spreadsheet) andslowly refines those models into lower levels of abstraction (e.g., a columnor the SUMfunction).Joel Spolsky [Spo02] suggests that “all non-trivial abstractions, to somedegree, are leaky.” The intent of an abstraction is to eliminate the need tocommunicate details. But sometimes, problematic effects precipitated bythese details “leak” through. Without an understanding of the details, thecause of a problem cannot be easily diagnosed.Principle 3. Strive for consistency. Whether it’s creating a requirements model, developing a software design, generating source code, or creatingtest cases, the principle of consistency suggests that a familiar context makessoftware easier to use. As an example, consider the design of a user interfacefor a WebApp. Consistent placement of menu options, the use of a consistentcolor scheme, and the consistent use of recognizable icons all help to makethe interface ergonomically sound.Principle 4.Focus on the transfer of information. Software is about information transfer—from a database to an end user, from a legacy systemto a WebApp, from an end user into a graphic user interface (GUI), from anoperating system to an application, from one software component to an-other—the list is almost endless. In every case, information flows across aninterface, and as a consequence, there are opportunities for error, or omis-sion, or ambiguity. The implication of this principle is that you must pay spe-cial attention to the analysis, design, construction, and testing of interfaces.Principle 5.Build software that exhibits effective modularity.Separation of concerns (Principle 1) establishes a philosophy for software.Modularityprovides a mechanism for realizing the philosophy. Any complexsystem can be divided into modules (components), but good software engi-neering practice demands more. Modularity must be effective. That is, eachmodule should focus exclusively on one well-constrained aspect of thesystem—it should be cohesive in its function and/or constrained in thecontent it represents. Additionally, modules should be interconnected in arelatively simple manner—each module should exhibit low coupling to othermodules, to data sources, and to other environmental aspects.Principle 6.Look for patterns.Brad Appleton [App00] suggests that: 
The goal of patterns within the software community is to create a body of literatureto help software developers resolve recurring problems encountered throughoutall of software development. Patterns help create a shared language for commu-nicating insight and experience about these problems and their solutions. Formallycodifying these solutions and their relationships lets us successfully capture the100 PART TWOMODELING
Use patterns (Chapter 12) tocapture knowledge andexperience for futuregenerations ofsoftware engineers.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 100body of knowledge which defines our understanding of good architectures thatmeet the needs of their users.
Principle 7.When possible, represent the problem and its solutionfrom a number of different perspectives. When a problem and its solution are examined from a number of different perspectives, it is more likely thatgreater insight will be achieved and that errors and omissions will be uncov-ered. For example, a requirements model can be represented using a data-oriented viewpoint, a function-oriented viewpoint, or a behavioral viewpoint(Chapters 6 and 7). Each provides a different view of the problem and itsrequirements.Principle 8.Remember that someone will maintain the software. Over the long term, software will be corrected as defects are uncovered, adaptedas its environment changes, and enhanced as stakeholders request morecapabilities. These maintenance activities can be facilitated if solid softwareengineering practice is applied throughout the software process.These principles are not all you’ll need to build high-quality software, but they doestablish a foundation for every software engineering method discussed in this book.
4.3 P RINCIPLES THATGUIDE EACH FRAMEWORK ACTIVITY
In the sections that follow I consider principles that have a strong bearing on the suc-cess of each generic framework activity defined as part of the software process. Inmany cases, the principles that are discussed for each of the framework activities area refinement of the principles presented in Section 4.2. They are simply core princi-ples stated at a lower level of abstraction.
4.3.1 Communication Principles
Before customer requirements can be analyzed, modeled, or specified they mustbe gathered through the communication activity. A customer has a problem that maybe amenable to a computer-based solution. You respond to the customer’s requestfor help. Communication has begun. But the road from communication to under-standing is often full of potholes.Effective communication (among technical peers, with the customer and otherstakeholders, and with project managers) is among the most challenging activitiesthat you will confront. In this context, I discuss communication principles as theyapply to customer communication. However, many of the principles apply equally toall forms of communication that occur within a software project.Principle 1.Listen.Try to focus on the speaker’s words, rather than formu-lating your response to those words. Ask for clarification if something is un-clear, but avoid constant interruptions.Neverbecome contentious in your words or actions (e.g., rolling your eyes or shaking your head) as a person is talking.CHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 101
uote:
“The ideal engineeris a composite. . . .He is not ascientist, he is not amathematician, heis not a sociologistor a writer; but hemay use theknowledge andtechniques of anyor all of thesedisciplines insolving engineeringproblems.”N. W.Doughertypre75977_ch04.qxd  11/27/08  3:27 PM  Page 101Principle 2.Prepare before you communicate. Spend the time to under- stand the problem before you meet with others. If necessary, do some re-search to understand business domain jargon. If you have responsibility forconducting a meeting, prepare an agenda in advance of the meeting.Principle 3.Someone should facilitate the activity. Every communica- tion meeting should have a leader (a facilitator) to keep the conversationmoving in a productive direction, (2) to mediate any conflict that does occur,and (3) to ensure than other principles are followed.Principle 4.Face-to-face communication is best. But it usually works better when some other representation of the relevant information is present.For example, a participant may create a drawing or a “strawman” documentthat serves as a focus for discussion.Principle 5.Take notes and document decisions. Things have a way of falling into the cracks. Someone participating in the communication shouldserve as a “recorder” and write down all important points and decisions.Principle 6.Strive for collaboration.Collaboration and consensus occur when the collective knowledge of members of the team is used todescribe product or system functions or features. Each small collaborationserves to build trust among team members and creates a common goal forthe team.Principle 7.Stay focused; modularize your discussion. The more people involved in any communication, the more likely that discussion willbounce from one topic to the next. The facilitator should keep the conversationmodular, leaving one topic only after it has been resolved (however, seePrinciple 9).Principle 8.If something is unclear, draw a picture. Verbal communica- tion goes only so far. A sketch or drawing can often provide clarity whenwords fail to do the job.Principle 9.(a) Once you agree to something, move on. (b) If you can’tagree to something, move on. (c) If a feature or function is unclearand cannot be clarified at the moment, move on. Communication, like any software engineering activity, takes time. Rather than iterating endlessly,the people who participate should recognize that many topics require discus-sion (see Principle 2) and that “moving on” is sometimes the best way toachieve communication agility.Principle 10.Negotiation is not a contest or a game. It works bestwhen both parties win.There are many instances in which you and otherstakeholders must negotiate functions and features, priorities, and deliverydates. If the team has collaborated well, all parties have a common goal. Still,negotiation will demand compromise from all parties.102 PART TWOMODELING
Before communicatingbe sure you under-stand the point of viewof the other party,know a bit about his orher needs, and thenlisten.
uote:
“Plain questionsand plain answersmake the shortestroad to mostperplexities.”Mark Twain
Whathappens if Ican’t come to anagreement withthe customer onsome project-related issue??pre75977_ch04.qxd  11/27/08  3:27 PM  Page 102CHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 103
Communication Mistakes
The scene:Software engineeringteam workspaceThe players:Jamie Lazar, software team member;Vinod Raman, software team member; Ed Robbins,software team member.The conversation:Ed:“What have you heard about this SafeHomeproject?”Vinod:“The kick-off meeting is scheduled for nextweek.”Jamie:“I’ve already done a little bit of investigation, butit didn’t go well.”Ed:“What do you mean?”Jamie:“Well, I gave Lisa Perez a call. She’s themarketing honcho on this thing.”Vinod:“And . . . ?”Jamie:“I wanted her to tell me about SafeHomefeatures and functions . . . that sort of thing. Instead, she beganasking me questions about security systems, surveillancesystems . . . I’m no expert.”Vinod:“What does that tell you?”(Jamie shrugs.)Vinod:“That marketing will need us to act as consultantsand that we’d better do some homework on this productarea before our kick-off meeting. Doug said that hewanted us to ‘collaborate’ with our customer, so we’dbetter learn how to do that.”Ed:“Probably would have been better to stop by her office.Phone calls just don’t work as well for this sort of thing.”Jamie:“You’re both right. We’ve got to get our acttogether or our early communications will be a struggle.”Vinod:“I saw Doug reading a book on ‘requirementsengineering.’ I’ll bet that lists some principles of goodcommunication. I’m going to borrow it from him.”Jamie:“Good idea . . . then you can teach us.”Vinod (smiling):“Yeah, right.”SAFEHOME
4.3.2 Planning Principles
The communication activity helps you to define your overall goals and objectives(subject, of course, to change as time passes). However, understanding these goalsand objectives is not the same as defining a plan for getting there. The planningactivity encompasses a set of management and technical practices that enable thesoftware team to define a road map as it travels toward its strategic goal and tacti-cal objectives.The Difference Between Customers and End Users
Software engineers communicate with manydifferent stakeholders, but customers and endusers have the most significant impact on the technicalwork that follows. In some cases the customer and the enduser are one and the same, but for many projects, thecustomer and the end user are different people, workingfor different managers, in different business organizations.A customeris the person or group who (1) originallyrequested the software to be built, (2) defines overallbusiness objectives for the software, (3) provides basicproduct requirements, and (4) coordinates funding for theproject. In a product or system business, the customeris often the marketing department. In an informationtechnology (IT) environment, the customer might be abusiness component or department.An end useris the person or group who (1) willactually use the software that is built to achieve somebusiness purpose and (2) will define operational details of the software so the business purpose can beachieved.INFOpre75977_ch04.qxd  11/27/08  3:27 PM  Page 103Try as we might, it’s impossible to predict exactly how a software project willevolve. There is no easy way to determine what unforeseen technical problems willbe encountered, what important information will remain undiscovered until late inthe project, what misunderstandings will occur, or what business issues will change.And yet, a good software team must plan its approach.There are many different planning philosophies.
2Some people are “minimalists,” arguing that change often obviates the need for a detailed plan. Others are “tradi-tionalists,” arguing that the plan provides an effective road map and the more detailit has, the less likely the team will become lost. Still others are “agilists,” arguing thata quick “planning game” may be necessary, but that the road map will emerge as“real work” on the software begins.What to do? On many projects, overplanning is time consuming and fruitless (toomany things change), but underplanning is a recipe for chaos. Like most things inlife, planning should be conducted in moderation, enough to provide useful guidancefor the team—no more, no less. Regardless of the rigor with which planning is con-ducted, the following principles always apply:Principle 1.Understand the scope of the project. It’s impossible to use a road map if you don’t know where you’re going. Scope provides the soft-ware team with a destination.Principle 2.Involve stakeholders in the planning activity. Stakeholders define priorities and establish project constraints. To accommodate theserealities, software engineers must often negotiate order of delivery, timelines, and other project-related issues.Principle 3.Recognize that planning is iterative. A project plan is never engraved in stone. As work begins, it is very likely that things will change. Asa consequence, the plan must be adjusted to accommodate these changes. Inaddition, iterative, incremental process models dictate replanning after thedelivery of each software increment based on feedback received from users.Principle 4.Estimate based on what you know. The intent of estimation is to provide an indication of effort, cost, and task duration, based on theteam’s current understanding of the work to be done. If information is vagueor unreliable, estimates will be equally unreliable.Principle 5.Consider risk as you define the plan. If you have identified risks that have high impact and high probability, contingency planning isnecessary. In addition, the project plan (including the schedule) should beadjusted to accommodate the likelihood that one or more of these risks willoccur.104 PART TWOMODELING
uote:
“In preparing forbattle I havealways found thatplans are useless,but planning isindispensable.”General DwightD. Eisenhower
WebRef
An excellent repositoryof planning and projectmanagementinformation can befound atwww.4pm.com/repository.htm.
2 A detailed discussion of software project planning and management is presented in Part 4 of thisbook.uote:
“Success is morea function ofconsistent commonsense than it is ofgenius.”An Wangpre75977_ch04.qxd  11/27/08  3:27 PM  Page 104Principle 6.Be realistic.People don’t work 100 percent of every day.Noise always enters into any human communication. Omissions andambiguity are facts of life. Change will occur. Even the best softwareengineers make mistakes. These and other realities should be consideredas a project plan is established.Principle 7.Adjust granularity as you define the plan. Granularity refers to the level of detail that is introduced as a project plan is developed.A “high-granularity” plan provides significant work task detail that is plannedover relatively short time increments (so that tracking and control occurfrequently). A “low-granularity” plan provides broader work tasks that areplanned over longer time periods. In general, granularity moves from high tolow as the project time line moves away from the current date. Over thenext few weeks or months, the project can be planned in significant detail.Activities that won’t occur for many months do not require high granularity(too much can change).Principle 8.Define how you intend to ensure quality. The plan should identify how the software team intends to ensure quality. If technicalreviews
3are to be conducted, they should be scheduled. If pair programming(Chapter 3) is to be used during construction, it should be explicitly definedwithin the plan.Principle 9.Describe how you intend to accommodate change. Even the best planning can be obviated by uncontrolled change. You should iden-tify how changes are to be accommodated as software engineering workproceeds. For example, can the customer request a change at any time? If achange is requested, is the team obliged to implement it immediately? How isthe impact and cost of the change assessed?Principle 10.Track the plan frequently and make adjustments as re-quired.Software projects fall behind schedule one day at a time. Therefore,it makes sense to track progress on a daily basis, looking for problem areasand situations in which scheduled work does not conform to actual workconducted. When slippage is encountered, the plan is adjusted accordingly.To be most effective, everyone on the software team should participate in theplanning activity. Only then will team members “sign up” to the plan.
4.3.3 Modeling Principles
We create models to gain a better understanding of the actual entity to be built. Whenthe entity is a physical thing (e.g., a building, a plane, a machine), we can build amodel that is identical in form and shape but smaller in scale. However, when theCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 105
The term granularityrefers to the detailwith which someelement of planning isrepresented orconducted.
3 Technical reviews are discussed in Chapter 15.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 105entity to be built is software, our model must take a different form. It must be capa-ble of representing the information that software transforms, the architecture andfunctions that enable the transformation to occur, the features that users desire, andthe behavior of the system as the transformation is taking place. Models mustaccomplish these objectives at different levels of abstraction—first depicting the soft-ware from the customer’s viewpoint and later representing the software at a moretechnical level.In software engineering work, two classes of models can be created: require-ments models and design models. Requirements models (also called analysis models) represent customer requirements by depicting the software in three different do-mains: the information domain, the functional domain, and the behavioral domain.Design modelsrepresent characteristics of the software that help practitioners toconstruct it effectively: the architecture, the user interface, and component-leveldetail.In their book on agile modeling, Scott Ambler and Ron Jeffries [Amb02b] define aset of modeling principles
4that are intended for those who use the agile processmodel (Chapter 3) but are appropriate for all software engineers who perform mod-eling actions and tasks: Principle 1.The primary goal of the software team is to build soft-ware, not create models.Agility means getting software to the customerin the fastest possible time. Models that make this happen are worth creat-ing, but models that slow the process down or provide little new insightshould be avoided.Principle 2.Travel light—don’t create more models than you need.Every model that is created must be kept up-to-date as changes occur. Moreimportantly, every new model takes time that might otherwise be spent onconstruction (coding and testing). Therefore, create only those models thatmake it easier and faster to construct the software.Principle 3.Strive to produce the simplest model that will describe theproblem or the software.Don’t overbuild the software [Amb02b]. Bykeeping models simple, the resultant software will also be simple. The resultis software that is easier to integrate, easier to test, and easier to maintain (tochange). In addition, simple models are easier for members of the softwareteam to understand and critique, resulting in an ongoing form of feedbackthat optimizes the end result.Principle 4.Build models in a way that makes them amenable to change.Assume that your models will change, but in making this assumption don’t106 PART TWOMODELING
Requirements modelsrepresent customerrequirements. Designmodels provide aconcrete specificationfor the construction ofthe software.
4 The principles noted in this section have been abbreviated and rephrased for the purposes of thisbook.The intent of anymodel is to communi-cate information. Toaccomplish this, use aconsistent format.Assume that you won’tbe there to explain themodel. It should standon its own.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 106get sloppy. For example, since requirements will change, there is a tendencyto give requirements models short shrift. Why? Because you know that they’llchange anyway. The problem with this attitude is that without a reasonablycomplete requirements model, you’ll create a design (design model) that willinvariably miss important functions and features.Principle 5.Be able to state an explicit purpose for each model thatis created.Every time you create a model, ask yourself why you’re doingso. If you can’t provide solid justification for the existence of the model,don’t spend time on it.Principle 6.Adapt the models you develop to the system at hand. It may be necessary to adapt model notation or rules to the application; for ex-ample, a video game application might require a different modeling techniquethan real-time, embedded software that controls an automobile engine.Principle 7.Try to build useful models, but forget about building per-fect models.When building requirements and design models, a softwareengineer reaches a point of diminishing returns. That is, the effort required tomake the model absolutely complete and internally consistent is not worththe benefits of these properties. Am I suggesting that modeling should besloppy or low quality? The answer is “no.” But modeling should be conductedwith an eye to the next software engineering steps. Iterating endlessly tomake a model “perfect” does not serve the need for agility.Principle 8.Don’t become dogmatic about the syntax of the model. Ifit communicates content successfully, representation is secondary.Although everyone on a software team should try to use consistent notationduring modeling, the most important characteristic of the model is to com-municate information that enables the next software engineering task. If amodel does this successfully, incorrect syntax can be forgiven.Principle 9.If your instincts tell you a model isn’t right even though itseems okay on paper, you probably have reason to be concerned. If you are an experienced software engineer, trust your instincts. Softwarework teaches many lessons—some of them on a subconscious level. If some-thing tells you that a design model is doomed to fail (even though you can’tprove it explicitly), you have reason to spend additional time examining themodel or developing a different one.Principle 10.Get feedback as soon as you can.Every model should be reviewed by members of the software team. The intent of these reviews is toprovide feedback that can be used to correct modeling mistakes, change mis-interpretations, and add features or functions that were inadvertently omitted.Requirements modeling principles. Over the past three decades, a large num- ber of requirements modeling methods have been developed. Investigators haveCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 107pre75977_ch04.qxd  11/27/08  3:27 PM  Page 107identified requirements analysis problems and their causes and have developeda variety of modeling notations and corresponding sets of heuristics to overcomethem. Each analysis method has a unique point of view. However, all analysis meth-ods are related by a set of operational principles:Principle 1.The information domain of a problem must be representedand understood.The information domainencompasses the data that flow into the system (from end users, other systems, or external devices), the datathat flow out of the system (via the user interface, network interfaces, reports,graphics, and other means), and the data stores that collect and organize per-sistent data objects (i.e., data that are maintained permanently).Principle 2.The functions that the software performs must be defined.Software functions provide direct benefit to end users and also provide inter-nal support for those features that are user visible. Some functions transformdata that flow into the system. In other cases, functions effect some level ofcontrol over internal software processing or external system elements. Func-tions can be described at many different levels of abstraction, ranging from ageneral statement of purpose to a detailed description of the processingelements that must be invoked.Principle 3.The behavior of the software (as a consequence of externalevents) must be represented.The behavior of computer software is drivenby its interaction with the external environment. Input provided by end users,control data provided by an external system, or monitoring data collectedover a network all cause the software to behave in a specific way.Principle 4.The models that depict information, function, and behaviormust be partitioned in a manner that uncovers detail in a layered (orhierarchical) fashion.Requirements modeling is the first step in softwareengineering problem solving. It allows you to better understand the problemand establishes a basis for the solution (design). Complex problems are difficultto solve in their entirety. For this reason, you should use a divide-and-conquerstrategy. A large, complex problem is divided into subproblems until each sub-problem is relatively easy to understand. This concept is called partitioningor separation of concerns,and it is a key strategy in requirements modeling.Principle 5.The analysis task should move from essential informationtoward implementation detail.Requirements modeling begins by describ-ing the problem from the end-user’s perspective. The “essence” of theproblem is described without any consideration of how a solution will beimplemented. For example, a video game requires that the player “instruct”its protagonist on what direction to proceed as she moves into a dangerousmaze. That is the essence of the problem. Implementation detail (normallydescribed as part of the design model) indicates how the essence will beimplemented. For the video game, voice input might be used. Alternatively,108 PART TWOMODELING
Analysis modelingfocuses on threeattributes of software:information to beprocessed, function tobe delivered, andbehavior to beexhibited.
uote:
“The engineer’sfirst problem inany designsituation is todiscover what theproblem really is.”Author unknownpre75977_ch04.qxd  11/27/08  3:27 PM  Page 108a keyboard command might be typed, a joystick (or mouse) might be pointedin a specific direction, or a motion-sensitive device might be waved in the air.By applying these principles, a software engineer approaches a problem system-atically. But how are these principles applied in practice? This question will be an-swered in Chapters 5 through 7.Design Modeling Principles.The software design model is analogous to anarchitect’s plans for a house. It begins by representing the totality of the thing to bebuilt (e.g., a three-dimensional rendering of the house) and slowly refines the thingto provide guidance for constructing each detail (e.g., the plumbing layout). Similarly,the design model that is created for software provides a variety of different views ofthe system.There is no shortage of methods for deriving the various elements of a softwaredesign. Some methods are data driven, allowing the data structure to dictate the pro-gram architecture and the resultant processing components. Others are patterndriven, using information about the problem domain (the requirements model) to de-velop architectural styles and processing patterns. Still others are object oriented,using problem domain objects as the driver for the creation of data structures andthe methods that manipulate them. Yet all embrace a set of design principles that canbe applied regardless of the method that is used:Principle 1.Design should be traceable to the requirements model.The requirements model describes the information domain of the problem,user-visible functions, system behavior, and a set of requirements classesthat package business objects with the methods that service them. The de-sign model translates this information into an architecture, a set of subsys-tems that implement major functions, and a set of components that are therealization of requirements classes. The elements of the design model shouldbe traceable to the requirements model.Principle 2.Always consider the architecture of the system to be built.Software architecture (Chapter 9) is the skeleton of the system to be built. Itaffects interfaces, data structures, program control flow and behavior, themanner in which testing can be conducted, the maintainability of the result-ant system, and much more. For all of these reasons, design should start witharchitectural considerations. Only after the architecture has been establishedshould component-level issues be considered.Principle 3.Design of data is as important as design of processingfunctions.Data design is an essential element of architectural design. Themanner in which data objects are realized within the design cannot be left tochance. A well-structured data design helps to simplify program flow, makesthe design and implementation of software components easier, and makesoverall processing more efficient.CHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 109
uote:
“See first that thedesign is wiseand just: thatascertained, pursueit resolutely; do notfor one repulseforego the purposethat you resolvedto effect.”WilliamShakespeare
WebRef
Insightful commentson the design process,along with a discussionof design aesthetics,can be found atcs.wwc.edu/~aabyan/Design/.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 109Principle 4.Interfaces (both internal and external) must be designedwith care.The manner in which data flows between the components of asystem has much to do with processing efficiency, error propagation, anddesign simplicity. A well-designed interface makes integration easier andassists the tester in validating component functions.Principle 5. User interface design should be tuned to the needs of theend user. However, in every case, it should stress ease of use. The user interface is the visible manifestation of the software. No matter howsophisticated its internal functions, no matter how comprehensive its datastructures, no matter how well designed its architecture, a poor interfacedesign often leads to the perception that the software is “bad.”Principle 6. Component-level design should be functionally independ-ent.Functional independence is a measure of the “single-mindedness” of asoftware component. The functionality that is delivered by a componentshould be cohesive—that is, it should focus on one and only one function orsubfunction.
5
Principle 7. Components should be loosely coupled to one anotherand to the external environment.Coupling is achieved in many ways—via a component interface, by messaging, through global data. As the level ofcoupling increases, the likelihood of error propagation also increases and theoverall maintainability of the software decreases. Therefore, component cou-pling should be kept as low as is reasonable.Principle 8. Design representations (models) should be easily under-standable.The purpose of design is to communicate information to practi-tioners who will generate code, to those who will test the software, and toothers who may maintain the software in the future. If the design is difficultto understand, it will not serve as an effective communication medium.Principle 9. The design should be developed iteratively. With eachiteration, the designer should strive for greater simplicity. Like almost all creative activities, design occurs iteratively. The first iterations work torefine the design and correct errors, but later iterations should strive to makethe design as simple as is possible.When these design principles are properly applied, you create a design that exhibitsboth external and internal quality factors [Mye78]. External quality factors are those properties of the software that can be readily observed by users (e.g., speed, reliability,correctness, usability). Internal quality factors are of importance to software engineers. They lead to a high-quality design from the technical perspective. To achieve internalquality factors, the designer must understand basic design concepts (Chapter 8).110 PART TWOMODELING
uote:
“The differencesare not minor—they are rather likethe differencesbetween Salieriand Mozart. Studyafter study showsthat the very bestdesigners producestructures that arefaster, smaller,simpler, clearer,and produced withless effort.”Frederick P .Brooks
5 Additional discussion of cohesion can be found in Chapter 8.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 1104.3.4 Construction Principles
The construction activity encompasses a set of coding and testing tasks that lead tooperational software that is ready for delivery to the customer or end user. In mod-ern software engineering work, coding may be (1) the direct creation of program-ming language source code (e.g., Java), (2) the automatic generation of source codeusing an intermediate design-like representation of the component to be built, or(3) the automatic generation of executable code using a “fourth-generation pro-gramming language” (e.g., Visual C/H11001/H11001).The initial focus of testing is at the component level, often called unit testing. Other levels of testing include (1) integration testing (conducted as the system is con- structed), validation testingthat assesses whether requirements have been met forthe complete system (or software increment), and (3) acceptance testing that is con- ducted by the customer in an effort to exercise all required features and functions.The following set of fundamental principles and concepts are applicable to codingand testing:Coding Principles.The principles that guide the coding task are closely alignedwith programming style, programming languages, and programming methods.However, there are a number of fundamental principles that can be stated:Preparation principles: Before you write one line of code, be sure you
•Understand of the problem you’re trying to solve.
•Understand basic design principles and concepts.
•Pick a programming language that meets the needs of the software to bebuilt and the environment in which it will operate.
•Select a programming environment that provides tools that will make yourwork easier.
•Create a set of unit tests that will be applied once the component you code iscompleted.Programming principles: As you begin writing code, be sure you
•Constrain your algorithms by following structured programming [Boh00]practice.
•Consider the use of pair programming.
•Select data structures that will meet the needs of the design.
•Understand the software architecture and create interfaces that areconsistent with it.
•Keep conditional logic as simple as possible.
•Create nested loops in a way that makes them easily testable.
•Select meaningful variable names and follow other local coding standards.CHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 111
uote:
“For much of mylife, I have been asoftware voyeur,peeking furtivelyat other people’sdirty code.Occasionally, I finda real jewel, a well-structured programwritten in aconsistent style,free of kludges,developed so thateach component issimple andorganized, anddesigned so thatthe product is easyto change.”David Parnas
Avoid developing anelegant program thatsolves the wrongproblem. Pay particularattention to the firstpreparation principle.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 111•Write code that is self-documenting.
•Create a visual layout (e.g., indentation and blank lines) that aidsunderstanding.Validation Principles: After you’ve completed your first coding pass, be sure you
•Conduct a code walkthrough when appropriate.
•Perform unit tests and correct errors you’ve uncovered.
•Refactor the code.More books have been written about programming (coding) and the principles andconcepts that guide it than about any other topic in the software process. Books onthe subject include early works on programming style [Ker78], practical softwareconstruction [McC04], programming pearls [Ben99], the art of programming[Knu98], pragmatic programming issues [Hun99], and many, many other subjects.A comprehensive discussion of these principles and concepts is beyond the scopeof this book. If you have further interest, examine one or more of the referencesnoted.Testing Principles.In a classic book on software testing, Glen Myers [Mye79]states a number of rules that can serve well as testing objectives:
•Testing is a process of executing a program with the intent of findingan error.
•A good test case is one that has a high probability of finding an as-yet-undiscovered error.
•A successful test is one that uncovers an as-yet-undiscovered error.These objectives imply a dramatic change in viewpoint for some software develop-ers. They move counter to the commonly held view that a successful test is one inwhich no errors are found. Your objective is to design tests that systematically un-cover different classes of errors and to do so with a minimum amount of time andeffort.If testing is conducted successfully (according to the objectives stated previously),it will uncover errors in the software. As a secondary benefit, testing demonstratesthat software functions appear to be working according to specification, and thatbehavioral and performance requirements appear to have been met. In addition, thedata collected as testing is conducted provide a good indication of software reliabil-ity and some indication of software quality as a whole. But testing cannot show theabsence of errors and defects; it can show only that software errors and defects arepresent. It is important to keep this (rather gloomy) statement in mind as testing isbeing conducted.112 PART TWOMODELING
WebRef
A wide variety of linksto coding standards canbe found at www.literateprogramming.com/fpstyle.html.
What are theobjectives ofsoftware testing??
In a broader softwaredesign context, recallthat you begin “in thelarge” by focusing onsoftware architectureand end “in the small“focusing on compo-nents. For testing, yousimply reverse thefocus and test yourway out.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 112Davis [Dav95b] suggests a set of testing principles6that have been adapted for use in this book:Principle 1.All tests should be traceable to customer requirements.
7
The objective of software testing is to uncover errors. It follows that the mostsevere defects (from the customer’s point of view) are those that cause theprogram to fail to meet its requirements.Principle 2.Tests should be planned long before testing begins. Test planning (Chapter 17) can begin as soon as the requirements model is com-plete. Detailed definition of test cases can begin as soon as the design modelhas been solidified. Therefore, all tests can be planned and designed beforeany code has been generated.Principle 3.The Pareto principle applies to software testing. In this context the Pareto principle implies that 80 percent of all errors uncoveredduring testing will likely be traceable to 20 percent of all program compo-nents. The problem, of course, is to isolate these suspect components and tothoroughly test them.Principle 4.Testing should begin “in the small” and progress towardtesting “in the large.”The first tests planned and executed generally focuson individual components. As testing progresses, focus shifts in an attemptto find errors in integrated clusters of components and ultimately in theentire system.Principle 5.Exhaustive testing is not possible. The number of path per- mutations for even a moderately sized program is exceptionally large. Forthis reason, it is impossible to execute every combination of paths duringtesting. It is possible, however, to adequately cover program logic and to en-sure that all conditions in the component-level design have been exercised.
4.3.5 Deployment Principles
As I noted earlier in Part 1 of this book, the deployment activity encompasses threeactions: delivery, support, and feedback. Because modern software process modelsare evolutionary or incremental in nature, deployment happens not once, but a num-ber of times as software moves toward completion. Each delivery cycle provides thecustomer and end users with an operational software increment that provides usablefunctions and features. Each support cycle provides documentation and humanassistance for all functions and features introduced during all deployment cycles toCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 113
6 Only a small subset of Davis’s testing principles are noted here. For more information, see[Dav95b].7 This principle refers to functional tests, i.e., tests that focus on requirements. Structural tests(tests that focus on architectural or logical detail) may not address specific requirements directly.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 113date. Each feedback cycle provides the software team with important guidance thatresults in modifications to the functions, features, and approach taken for the nextincrement.The delivery of a software increment represents an important milestone for anysoftware project. A number of key principles should be followed as the team pre-pares to deliver an increment:Principle 1.Customer expectations for the software must be managed.Too often, the customer expects more than the team has promised to deliver,and disappointment occurs immediately. This results in feedback that is notproductive and ruins team morale. In her book on managing expectations,Naomi Karten [Kar94] states: “The starting point for managing expectationsis to become more conscientious about what you communicate and how.”She suggests that a software engineer must be careful about sending the cus-tomer conflicting messages (e.g., promising more than you can reasonablydeliver in the time frame provided or delivering more than you promise forone software increment and then less than promised for the next).Principle 2.A complete delivery package should be assembled andtested.A CD-ROM or other media (including Web-based downloads)containing all executable software, support data files, support documents,and other relevant information should be assembled and thoroughly beta-tested with actual users. All installation scripts and other operationalfeatures should be thoroughly exercised in as many different computingconfigurations (i.e., hardware, operating systems, peripheral devices, net-working arrangements) as possible.Principle 3.A support regime must be established before the softwareis delivered.An end user expects responsiveness and accurate informationwhen a question or problem arises. If support is ad hoc, or worse, nonexist-ent, the customer will become dissatisfied immediately. Support should beplanned, support materials should be prepared, and appropriate record-keeping mechanisms should be established so that the software team canconduct a categorical assessment of the kinds of support requested.Principle 4.Appropriate instructional materials must be provided toend users.The software team delivers more than the software itself.Appropriate training aids (if required) should be developed; troubleshootingguidelines should be provided, and when necessary, a “what’s different aboutthis software increment” description should be published.
8114 PART TWOMODELING
Be sure that your cus-tomer knows what toexpect before a soft-ware increment isdelivered. Otherwise,you can bet the cus-tomer will expect morethan you deliver.
8 During the communication activity, the software team should determine what types of help mate-rials users want.pre75977_ch04.qxd  11/27/08  3:27 PM  Page 114Principle 5.Buggy software should be fixed first, delivered later. Under time pressure, some software organizations deliver low-quality incrementswith a warning to the customer that bugs “will be fixed in the next release.”This is a mistake. There’s a saying in the software business: “Customers willforget you delivered a high-quality product a few days late, but they willnever forget the problems that a low-quality product caused them. The soft-ware reminds them every day.”The delivered software provides benefit for the end user, but it also provides use-ful feedback for the software team. As the increment is put into use, end users shouldbe encouraged to comment on features and functions, ease of use, reliability, andany other characteristics that are appropriate.
4.4 S UMMARY
Software engineering practice encompasses principles, concepts, methods, andtools that software engineers apply throughout the software process. Every softwareengineering project is different. Yet, a set of generic principles apply to the processas a whole and to the practice of each framework activity regardless of the projector the product.A set of core principles help in the application of a meaningful software processand the execution of effective software engineering methods. At the process level,core principles establish a philosophical foundation that guides a software team asit navigates through the software process. At the level of practice, core principlesestablish a collection of values and rules that serve as a guide as you analyze a prob-lem, design a solution, implement and test the solution, and ultimately deploy thesoftware in the user community.Communication principles focus on the need to reduce noise and improve band-width as the conversation between developer and customer progresses. Both partiesmust collaborate for the best communication to occur.Planning principles provide guidelines for constructing the best map for thejourney to a completed system or product. The plan may be designed solely for asingle software increment, or it may be defined for the entire project. Regardless,it must address what will be done, who will do it, and when the work will becompleted.Modeling encompasses both analysis and design, describing representations ofthe software that progressively become more detailed. The intent of the models is tosolidify understanding of the work to be done and to provide technical guidance tothose who will implement the software. Modeling principles serve as a founda-tion for the methods and notation that are used to create representations of thesoftware.Construction incorporates a coding and testing cycle in which source code for acomponent is generated and tested. Coding principles define generic actions thatCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 115pre75977_ch04.qxd  11/27/08  3:27 PM  Page 115should occur before code is written, while it is being created, and after it has beencompleted. Although there are many testing principles, only one is dominant: test-ing is a process of executing a program with the intent of finding an error.Deployment occurs as each software increment is presented to the customer andencompasses delivery, support, and feedback. Key principles for delivery considermanaging customer expectations and providing the customer with appropriate sup-port information for the software. Support demands advance preparation. Feedbackallows the customer to suggest changes that have business value and provide thedeveloper with input for the next iterative software engineering cycle.
PROBLEMS AND POINTS TO PONDER
4.1.Since a focus on quality demands resources and time, is it possible to be agile and stillmaintain a quality focus?4.2.Of the eight core principles that guide process (discussed in Section 4.2.1), which do youbelieve is most important?4.3.Describe the concept of separation of concerns in your own words. 4.4.An important communication principle states “prepare before you communicate.” Howshould this preparation manifest itself in the early work that you do? What work products mightresult as a consequence of early preparation?4.5.Do some research on “facilitation” for the communication activity (use the references pro-vided or others) and prepare a set of guidelines that focus solely on facilitation.4.6.How does agile communication differ from traditional software engineering communica-tion? How is it similar?4.7.Why is it necessary to “move on”?4.8.Do some research on “negotiation” for the communication activity and prepare a set ofguidelines that focus solely on negotiation.4.9.Describe what granularitymeans in the context of a project schedule.4.10.Why are models important in software engineering work? Are they always necessary?Are there qualifiers to your answer about necessity?4.11.What three “domains” are considered during requirements modeling?4.12.Try to add one additional principle to those stated for coding in Section 4.3.4.4.13.What is a successful test?4.14.Do you agree or disagree with the following statement: “Since we deliver multiple incre-ments to the customer, why should we be concerned about quality in the early increments—wecan fix problems in later iterations.” Explain your answer.4.15.Why is feedback important to the software team?
FURTHER READINGS AND INFORMATION SOURCES
Customer communication is a critically important activity in software engineering, yet few prac-titioners spend any time reading about it. Withall (Software Requirements Patterns, Microsoft Press, 2007) presents a variety of useful patterns that address communications problems. Sutliff116 PART TWOMODELINGpre75977_ch04.qxd  11/27/08  3:27 PM  Page 116(User-Centred Requirements Engineering, Springer, 2002) focuses heavily on communications- related challenges. Books by Weigers (Software Requirements, 2d ed., Microsoft Press, 2003), Pardee (To Satisfy and Delight Your Customer, Dorset House, 1996), and Karten [Kar94] provide much insight into methods for effective customer interaction. Although their book does notfocus on software, Hooks and Farry (Customer Centered Products, American Management Asso-ciation, 2000) present useful generic guidelines for customer communication. Young (EffectiveRequirements Practices,Addison-Wesley, 2001) emphasizes a “joint team” of customers anddevelopers who develop requirements collaboratively. Somerville and Kotonya ( Requirements Engineering: Processes and Techniques, Wiley, 1998) discuss “elicitation” concepts and tech- niques and other requirements engineering principles.Communication and planning concepts and principles are considered in many project man-agement books. Useful project management offerings include books by Bechtold ( Essentials of Software Project Management,2d ed., Management Concepts, 2007), Wysocki ( Effective Project Management: Traditional, Adaptive, Extreme, 4th ed., Wiley, 2006), Leach (Lean Project Manage- ment: Eight Principles for Success,BookSurge Publishing, 2006), Hughes ( Software Project Man- agement,McGraw-Hill, 2005), and Stellman and Greene (Applied Software Project Management,O’Reilly Media, Inc., 2005).Davis [Dav95] has compiled an excellent collection of software engineering principles. In ad-dition, virtually every book on software engineering contains a useful discussion of conceptsand principles for analysis, design, and testing. Among the most widely used offerings (in addi-tion to this book!) are:Abran, A., and J. Moore, SWEBOK: Guide to the Software Engineering Body of Knowledge, IEEE, 2002.Christensen, M., and R. Thayer, A Project Manager’s Guide to Software Engineering Best Prac-tices,IEEE-CS Press (Wiley), 2002.Jalote, P., An Integrated Approach to Software Engineering, Springer, 2006. Pfleeger, S., Software Engineering: Theory and Practice, 3d ed., Prentice-Hall, 2005. Schach, S., Object-Oriented and Classical Software Engineering, McGraw-Hill, 7th ed., 2006. Sommerville, I., Software Engineering, 8th ed., Addison-Wesley, 2006. These books also present detailed discussion of modeling and construction principles.Modeling principles are considered in many books dedicated to requirements analysisand/or software design. Books by Lieberman ( The Art of Software Modeling,Auerbach, 2007), Rosenberg and Stephens (Use Case Driven Object Modeling with UML: Theory and Practice,Apress, 2007), Roques (UML in Practice,Wiley, 2004), Penker and Eriksson ( Business Modeling with UML: Business Patterns at Work, Wiley, 2001) discuss modeling principles and methods.Norman’s (The Design of Everyday Things, Currency/Doubleday, 1990) is must reading for every software engineer who intends to do design work. Winograd and his colleagues (BringingDesign to Software,Addison-Wesley, 1996) have edited an excellent collection of essays thataddress practical issues for software design. Constantine and Lockwood (Software for Use,Addison-Wesley, 1999) present the concepts associated with “user centered design.” Tognazzini(Tog on Software Design,Addison-Wesley, 1995) presents a worthwhile philosophical discussionof the nature of design and the impact of decisions on quality and a team’s ability to producesoftware that provides great value to its customer. Stahl and his colleagues ( Model- Driven Software Development: Technology, Engineering, Wiley, 2006) discuss the principles of model-driven development.Hundreds of books address one or more elements of the construction activity. Kernighanand Plauger [Ker78] have written a classic text on programming style, McConnell [McC93]presents pragmatic guidelines for practical software construction, Bentley [Ben99] suggestsa wide variety of programming pearls, Knuth [Knu99] has written a classic three-volumeseries on the art of programming, and Hunt [Hun99] suggests pragmatic programmingguidelines.Myers and his colleagues (The Art of Software Testing, 2d ed., Wiley, 2004) have developed a major revision of his classic text and discuss many important testing principles. Books by PerryCHAPTER 4PRINCIPLES THAT GUIDE PRACTICE 117pre75977_ch04.qxd  11/27/08  3:27 PM  Page 117(Effective Methods for Software Testing, 3d ed., Wiley, 2006), Whittaker (How to Break Software, Addison-Wesley, 2002), Kaner and his colleagues (Lessons Learned in Software Testing, Wiley, 2001), and Marick (The Craft of Software Testing,Prentice-Hall, 1997) each present important testing concepts and principles and much pragmatic guidance.A wide variety of information sources on software engineering practice are available on theInternet. An up-to-date list of World Wide Web references that are relevant to software engi-neering practice can be found at the SEPA website: www.mhhe.com/engcs/compsci/ pressman/professional/olc/ser.htm.118 PART TWOMODELINGpre75977_ch04.qxd  11/27/08  3:27 PM  Page 118Understanding the requirements of a problem is among the most difficulttasks that face a software engineer. When you first think about it, devel-oping a clear understanding of requirements doesn’t seem that hard. Afterall, doesn’t the customer know what is required? Shouldn’t the end users havea good understanding of the features and functions that will provide benefit?Surprisingly, in many instances the answer to these questions is “no.” And even ifcustomers and end-users are explicit in their needs, those needs will changethroughout the project.In the forward to a book by Ralph Young [You01] on effective requirementspractices, I wrote:
It’s your worst nightmare. A customer walks into your office, sits down, looks youstraight in the eye, and says, “I know you think you understand what I said, but whatyou don’t understand is what I said is not what I meant.” Invariably, this happens late
119CHAPTER
5UNDERSTANDING
REQUIREMENTS
What is it? Before you begin anytechnical work, it’s a good idea toapply a set of requirements engi-neering tasks. These tasks lead to anunderstanding of what the business impact of thesoftware will be, what the customer wants, andhow end users will interact with the software.
Who does it? Software engineers (sometimesreferred to as system engineers or “analysts” inthe IT world) and other project stakeholders(managers, customers, end users) all participatein requirements engineering.
Why is it important? Designing and building anelegant computer program that solves the wrongproblem serves no one’s needs. That’s why it’simportant to understand what the customerwants before you begin to design and build acomputer-based system.
What are the steps? Requirements engineeringbegins with inception—a task that defines thescope and nature of the problem to be solved. Itmoves onwards to elicitation—a task that helpsstakeholders define what is required, and thenQUICK
LOOKelaboration—where basic requirements arerefined and modified. As stakeholders define theproblem, negotiation occurs—what are thepriorities, what is essential, when is it required?Finally, the problem is specified in some mannerand then reviewed or validated to ensure thatyour understanding of the problem and thestakeholders’ understanding of the problemcoincide.
What is the work product? The intent of require-ments engineering is to provide all parties witha written understanding of the problem. This canbe achieved though a number of work products:usage scenarios, functions and features lists,requirements models, or a specification.
How do I ensure that I’ve done it right?
Requirements engineering work products arereviewed with stakeholders to ensure that whatyou have learned is what they really meant. Aword of warning: even after all parties agree,things will change, and they will continue tochange throughout the project.KEY
CONCEPTS
analysis model  . . . . . . .138analysis patterns . . . . . .142collaboration  . .126elaboration . . . .122elicitation . . . . .121inception  . . . . .121negotiation . . . .122quality functiondeployment  . . .131pre75977_ch05.qxd  11/27/08  3:30 PM  Page 119It’s reasonable to argue that the techniques I’ll discuss in this chapter are not atrue “solution” to the challenges just noted. But they do provide a solid approach foraddressing these challenges.
5.1 R EQUIREMENTS ENGINEERING
Designing and building computer software is challenging, creative, and just plainfun. In fact, building software is so compelling that many software developers wantto jump right in before they have a clear understanding of what is needed. They arguethat things will become clear as they build, that project stakeholders will be able tounderstand need only after examining early iterations of the software, that thingschange so rapidly that any attempt to understand requirements in detail is a wasteof time, that the bottom line is producing a working program and all else is second-ary. What makes these arguments seductive is that they contain elements of truth.
1
But each is flawed and can lead to a failed software project.The broad spectrum of tasks and techniques that lead to an understanding of re-quirements is called requirements engineering. From a software process perspective, requirements engineering is a major software engineering action that begins duringthe communication activity and continues into the modeling activity. It must beadapted to the needs of the process, the project, the product, and the people doingthe work.Requirements engineering builds a bridge to design and construction. But wheredoes the bridge originate? One could argue that it begins at the feet of the projectstakeholders (e.g., managers, customers, end users), where business need isdefined, user scenarios are described, functions and features are delineated, andproject constraints are identified. Others might suggest that it begins with a broadersystem definition, where software is but one component of the larger systemdomain. But regardless of the starting point, the journey across the bridge takes you120 PART TWOMODELING
uote:
“The hardest singlepart of building asoftware systemis deciding what tobuild. No part of thework so cripples theresulting system ifdone wrong. Noother part is moredifficult to rectifylater.”Fred Brooks
Requirementsengineering establishesa solid base for designand construction.Without it, theresulting software hasa high probability ofnot meetingcustomer’s needs.
1 This is particularly true for small projects (less than one month) and smaller, relatively simple soft-ware efforts. As software grows in size and complexity, these arguments begin to break down.requirementsengineering  . . .120requirementsgathering  . . . . .128requirementsmanagement  . .124specification  . . .122stakeholders  . .125use cases  . . . . .133validatingrequirements  . .144validation . . . . .123viewpoints . . . .126work products . . . . . .133in the project, after deadline commitments have been made, reputations are on the line,and serious money is at stake.All of us who have worked in the systems and software business for more than a fewyears have lived this nightmare, and yet, few of us have learned to make it go away. Westruggle when we try to elicit requirements from our customers. We have trouble under-standing the information that we do acquire. We often record requirements in a disor-ganized manner, and we spend far too little time verifying what we do record. We allowchange to control us, rather than establishing mechanisms to control change. In short, wefail to establish a solid foundation for the system or software. Each of these problems ischallenging. When they are combined, the outlook is daunting for even the most experi-enced managers and practitioners. But solutions do exist.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 120high above the project, allowing you to examine the context of the software work tobe performed; the specific needs that design and construction must address; the pri-orities that guide the order in which work is to be completed; and the information,functions, and behaviors that will have a profound impact on the resultant design.Requirements engineering provides the appropriate mechanism for understand-ing what the customer wants, analyzing need, assessing feasibility, negotiating a rea-sonable solution, specifying the solution unambiguously, validating the specification,and managing the requirements as they are transformed into an operational system[Tha97]. It encompasses seven distinct tasks: inception, elicitation, elaboration,negotiation, specification, validation, and management. It is important to note thatsome of these tasks occur in parallel and all are adapted to the needs of the project.Inception.How does a software project get started? Is there a single event thatbecomes the catalyst for a new computer-based system or product, or does the needevolve over time? There are no definitive answers to these questions. In some cases,a casual conversation is all that is needed to precipitate a major software engineer-ing effort. But in general, most projects begin when a business need is identifiedor a potential new market or service is discovered. Stakeholders from the businesscommunity (e.g., business managers, marketing people, product managers) definea business case for the idea, try to identify the breadth and depth of the market, do arough feasibility analysis, and identify a working description of the project’s scope.All of this information is subject to change, but it is sufficient to precipitate discus-sions with the software engineering organization.
2
At project inception,3you establish a basic understanding of the problem, the peo-ple who want a solution, the nature of the solution that is desired, and the effective-ness of preliminary communication and collaboration between the other stakeholdersand the software team.Elicitation.It certainly seems simple enough—ask the customer, the users, andothers what the objectives for the system or product are, what is to be accomplished,how the system or product fits into the needs of the business, and finally, how the sys-tem or product is to be used on a day-to-day basis. But it isn’t simple—it’s very hard.Christel and Kang [Cri92] identify a number of problems that are encountered aselicitation occurs.
•Problems of scope.The boundary of the system is ill-defined or thecustomers/users specify unnecessary technical detail that may confuse,rather than clarify, overall system objectives.CHAPTER 5UNDERSTANDING REQUIREMENTS 121
Expect to do a bit ofdesign during require-ments work and a bitof requirements workduring design.
uote:
“The seeds ofmajor softwaredisasters areusually sown in thefirst three monthsof commencing thesoftware project.”Caper Jones
2 If a computer-based system is to be developed, discussions begin within the context of a systemengineering process. For a detailed discussion of system engineering, visit the website thataccompanies this book.3 Recall that the Unified Process (Chapter 2) defines a more comprehensive “inception phase” thatencompasses the inception, elicitation, and elaboration tasks discussed in this chapter.Why is itdifficult togain a clearunderstanding ofwhat thecustomer wants??pre75977_ch05.qxd  11/27/08  3:30 PM  Page 121122 PART TWOMODELING
•Problems of understanding.The customers/users are not completely sureof what is needed, have a poor understanding of the capabilities and limita-tions of their computing environment, don’t have a full understanding of theproblem domain, have trouble communicating needs to the system engineer,omit information that is believed to be “obvious,” specify requirements thatconflict with the needs of other customers/users, or specify requirementsthat are ambiguous or untestable.
•Problems of volatility.The requirements change over time.To help overcome these problems, you must approach requirements gathering in anorganized manner.Elaboration.The information obtained from the customer during inception andelicitation is expanded and refined during elaboration. This task focuses on devel-oping a refined requirements model (Chapters 6 and 7) that identifies various aspectsof software function, behavior, and information.Elaboration is driven by the creation and refinement of user scenarios that de-scribe how the end user (and other actors) will interact with the system. Each userscenario is parsed to extract analysis classes—business domain entities that arevisible to the end user. The attributes of each analysis class are defined, and the serv-ices
4that are required by each class are identified. The relationships and collabora-tion between classes are identified, and a variety of supplementary diagrams areproduced.Negotiation.It isn’t unusual for customers and users to ask for more than can beachieved, given limited business resources. It’s also relatively common for differentcustomers or users to propose conflicting requirements, arguing that their version is“essential for our special needs.”You have to reconcile these conflicts through a process of negotiation. Customers,users, and other stakeholders are asked to rank requirements and then discuss con-flicts in priority. Using an iterative approach that prioritizes requirements, assessestheir cost and risk, and addresses internal conflicts, requirements are eliminated,combined, and/or modified so that each party achieves some measure of satisfaction.Specification.In the context of computer-based systems (and software), the termspecificationmeans different things to different people. A specification can be a writ-ten document, a set of graphical models, a formal mathematical model, a collectionof usage scenarios, a prototype, or any combination of these.Some suggest that a “standard template” [Som97] should be developed and usedfor a specification, arguing that this leads to requirements that are presented in aElaboration is a goodthing, but you have toknow when to stop.The key is to describethe problem in a waythat establishes a firmbase for design. If youwork beyond thatpoint, you’re doingdesign.
4A  servicemanipulates the data encapsulated by the class. The terms operationand methodare also used. If you are unfamiliar with object-oriented concepts, a basic introduction is presented inAppendix 2.There should be nowinner and no loser inan effective negotia-tion. Both sides win,because a “deal” thatboth can live with issolidified.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 122The formality andformat of a specifica-tion varies with the sizeand the complexity ofthe software to be built.consistent and therefore more understandable manner. However, it is sometimesnecessary to remain flexible when a specification is to be developed. For large sys-tems, a written document, combining natural language descriptions and graphicalmodels may be the best approach. However, usage scenarios may be all that are re-quired for smaller products or systems that reside within well-understood technicalenvironments.CHAPTER 5UNDERSTANDING REQUIREMENTS 123
Software Requirements Specification Template
A software requirements specification(SRS) isa document that is created when a detaileddescription of all aspects of the software to be built must bespecified before the project is to commence. It is importantto note that a formal SRS is not always written. In fact,there are many instances in which effort expended on anSRS might be better spent in other software engineeringactivities. However, when software is to be developed bya third party, when a lack of specification would createsevere business issues, or when a system is extremelycomplex or business critical, an SRS may be justified.Karl Wiegers [Wie03] of Process Impact Inc. hasdeveloped a worthwhile template (available atwww.processimpact.com/process_assets/srs_template.doc) that can serve as a guideline for thosewho must create a complete SRS. A topic outline follows:Table of ContentsRevision History1. Introduction1.1 Purpose1.2 Document Conventions1.3 Intended Audience and Reading Suggestions1.4 Project Scope1.5 References2. Overall Description2.1 Product Perspective2.2 Product Features2.3 User Classes and Characteristics2.4 Operating Environment2.5 Design and Implementation Constraints2.6 User Documentation2.7 Assumptions and Dependencies3. System Features3.1 System Feature 13.2 System Feature 2 (and so on)4. External Interface Requirements4.1 User Interfaces4.2 Hardware Interfaces4.3 Software Interfaces4.4 Communications Interfaces5. Other Nonfunctional Requirements5.1 Performance Requirements5.2 Safety Requirements5.3 Security Requirements5.4 Software Quality Attributes6. Other RequirementsAppendix A: GlossaryAppendix B: Analysis ModelsAppendix C: Issues ListA detailed description of each SRS topic can be obtainedby downloading the SRS template at the URL noted earlierin this sidebar.INFO
Validation.The work products produced as a consequence of requirements engi-neering are assessed for quality during a validation step. Requirements validationexamines the specification
5to ensure that all software requirements have been
5 Recall that the nature of the specification will vary with each project. In some cases, the “specifi-cation” is a collection of user scenarios and little else. In others, the specification may be a docu-ment that contains scenarios, models, and written descriptions.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 123stated unambiguously; that inconsistencies, omissions, and errors have beendetected and corrected; and that the work products conform to the standards estab-lished for the process, the project, and the product.The primary requirements validation mechanism is the technical review (Chap-ter 15). The review team that validates requirements includes software engineers,customers, users, and other stakeholders who examine the specification lookingfor errors in content or interpretation, areas where clarification may be required,missing information, inconsistencies (a major problem when large products orsystems are engineered), conflicting requirements, or unrealistic (unachievable)requirements.124 PART TWOMODELING
INFO
Requirements management.Requirements for computer-based systemschange, and the desire to change requirements persists throughout the life of thesystem. Requirements management is a set of activities that help the project teamidentify, control, and track requirements and changes to requirements at any time asthe project proceeds.
6Many of these activities are identical to the software configu-ration management (SCM) techniques discussed in Chapter 22.
6 Formal requirements management is initiated only for large projects that have hundreds of identi-fiable requirements. For small projects, this requirements engineering action is considerably lessformal.Requirements ValidationChecklist
It is often useful to examine each requirementagainst a set of checklist questions. Here is a small subsetof those that might be asked:
•Are requirements stated clearly? Can they bemisinterpreted?
•Is the source (e.g., a person, a regulation, a document)of the requirement identified? Has the final statement ofthe requirement been examined by or against theoriginal source?
•Is the requirement bounded in quantitative terms?
•What other requirements relate to this requirement? Arethey clearly noted via a cross-reference matrix or othermechanism?•Does the requirement violate any system domainconstraints?
•Is the requirement testable? If so, can we specify tests(sometimes called validation criteria) to exercise therequirement?
•Is the requirement traceable to any system model thathas been created?
•Is the requirement traceable to overall system/productobjectives?
•Is the specification structured in a way that leads toeasy understanding, easy reference, and easytranslation into more technical work products?
•Has an index for the specification been created?
•Have requirements associated with performance,behavior, and operational characteristics been clearlystated? What requirements appear to be implicit?A key concern duringrequirements valida-tion is consistency. Usethe analysis model toensure that require-ments have been con-sistently stated.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 1245.2 E STABLISHING THE GROUNDWORK
In an ideal setting, stakeholders and software engineers work together on the sameteam.
8In such cases, requirements engineering is simply a matter of conductingmeaningful conversations with colleagues who are well-known members of theteam. But reality is often quite different.Customer(s) or end users may be located in a different city or country, may haveonly a vague idea of what is required, may have conflicting opinions about the sys-tem to be built, may have limited technical knowledge, and may have limited time tointeract with the requirements engineer. None of these things are desirable, but allare fairly common, and you are often forced to work within the constraints imposedby this situation.In the sections that follow, I discuss the steps required to establish the ground-work for an understanding of software requirements—to get the project started in away that will keep it moving forward toward a successful solution.
5.2.1 Identifying Stakeholders
Sommerville and Sawyer [Som97] define a stakeholder as “anyone who benefitsin a direct or indirect way from the system which is being developed.” I have alreadyCHAPTER 5UNDERSTANDING REQUIREMENTS 125
Requirements Engineering
Objective:Requirements engineering toolsassist in requirements gathering, requirementsmodeling, requirements management, and requirementsvalidation.Mechanics:Tool mechanics vary. In general,requirements engineering tools build a variety ofgraphical (e.g., UML) models that depict the informational,functional, and behavioral aspects of a system. Thesemodels form the basis for all other activities in thesoftware process.Representative Tools:
7
A reasonably comprehensive (and up-to-date) listing ofrequirements engineering tools can be found at the VolvereRequirements resources site at www.volere.co.uk/tools.htm. Requirements modeling tools are discussed inChapters 6 and 7. Tools noted below focus on requirementmanagement.EasyRM,developed by Cybernetic Intelligence GmbH(www.easy-rm.com), builds a project-specificdictionary/glossary that contains detailed requirementsdescriptions and attributes.Rational RequisitePro,developed by Rational Software(www-306.ibm.com/software/awdtools/reqpro/), allows users to build a requirementsdatabase; represent relationships among requirements;and organize, prioritize, and trace requirements.Many additional requirements management tools can befound at the Volvere site noted earlier and at www.jiludwig.com/Requirements_Management_Tools.html.SOFTWARE TOOLS
7 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.8 This approach is strongly recommended for projects that adopt an agile software developmentphilosophy.A stakeholderisanyone who has adirect interest in orbenefits from thesystem that is to bedeveloped.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 125identified the usual suspects: business operations managers, product managers,marketing people, internal and external customers, end users, consultants, productengineers, software engineers, support and maintenance engineers, and others.Each stakeholder has a different view of the system, achieves different benefits whenthe system is successfully developed, and is open to different risks if the developmenteffort should fail.At inception, you should create a list of people who will contribute input as re-quirements are elicited (Section 5.3). The initial list will grow as stakeholders arecontacted because every stakeholder will be asked: “Whom else do you think Ishould talk to?”
5.2.2 Recognizing Multiple Viewpoints
Because many different stakeholders exist, the requirements of the system will beexplored from many different points of view. For example, the marketing group is in-terested in functions and features that will excite the potential market, making thenew system easy to sell. Business managers are interested in a feature set that canbe built within budget and that will be ready to meet defined market windows. Endusers may want features that are familiar to them and that are easy to learn and use.Software engineers may be concerned with functions that are invisible to nontech-nical stakeholders but that enable an infrastructure that supports more marketablefunctions and features. Support engineers may focus on the maintainability of thesoftware.Each of these constituencies (and others) will contribute information to the re-quirements engineering process. As information from multiple viewpoints is col-lected, emerging requirements may be inconsistent or may conflict with oneanother. You should categorize all stakeholder information (including inconsistentand conflicting requirements) in a way that will allow decision makers to choose aninternally consistent set of requirements for the system.
5.2.3 Working toward Collaboration
If five stakeholders are involved in a software project, you may have five (or more)different opinions about the proper set of requirements. Throughout earlier chapters,I have noted that customers (and other stakeholders) must collaborate among them-selves (avoiding petty turf battles) and with software engineering practitioners if asuccessful system is to result. But how is this collaboration accomplished?The job of a requirements engineer is to identify areas of commonality (i.e., re-quirements on which all stakeholders agree) and areas of conflict or inconsistency(i.e., requirements that are desired by one stakeholder but conflict with theneeds of another stakeholder). It is, of course, the latter category that presents achallenge.126 PART TWOMODELING
uote:
“Put threestakeholders in aroom and ask themwhat kind ofsystem they want.You’re likely to getfour or moredifferent opinions.”Author unknownpre75977_ch05.qxd  11/27/08  3:30 PM  Page 126Collaboration does not necessarily mean that requirements are defined bycommittee. In many cases, stakeholders collaborate by providing their view ofrequirements, but a strong “project champion”(e.g., a business manager or a seniortechnologist) may make the final decision about which requirements make the cut.
5.2.4 Asking the First Questions
Questions asked at the inception of the project should be “context free” [Gau89]. Thefirst set of context-free questions focuses on the customer and other stakeholders,the overall project goals and benefits. For example, you might ask:
•Who is behind the request for this work?
•Who will use the solution?
•What will be the economic benefit of a successful solution?
•Is there another source for the solution that you need?These questions help to identify all stakeholders who will have interest in thesoftware to be built. In addition, the questions identify the measurable benefit ofa successful implementation and possible alternatives to custom software devel-opment.The next set of questions enables you to gain a better understanding of the prob-lem and allows the customer to voice his or her perceptions about a solution:
•How would you characterize “good” output that would be generated by asuccessful solution?
•What problem(s) will this solution address?
•Can you show me (or describe) the business environment in which thesolution will be used?
•Will special performance issues or constraints affect the way the solution isapproached?CHAPTER 5UNDERSTANDING REQUIREMENTS 127
INFO
uote:
“It is better toknow some of thequestions than allof the answers.”James Thurber
Whatquestionswill help you gaina preliminaryunderstanding ofthe problem??Using “Priority Points”
One way of resolving conflictingrequirements and at the same time betterunderstanding the relative importance of all requirementsis to use a “voting” scheme based onpriority points.All stakeholders are provided with some number ofpriority points that can be “spent” on any number ofrequirements. A list of requirements is presented, andeach stakeholder indicates the relative importance ofeach (from his or her viewpoint) by spending one ormore priority points on it. Points spent cannot be reused.Once a stakeholder’s priority points are exhausted,no further action on requirements can be taken by thatperson. Overall points spent on each requirement byall stakeholders provide an indication of the overallimportance of each requirement.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 127The final set of questions focuses on the effectiveness of the communicationactivity itself. Gause and Weinberg [Gau89] call these “meta-questions” and proposethe following (abbreviated) list:
•Are you the right person to answer these questions? Are your answers“official”?
•Are my questions relevant to the problem that you have?
•Am I asking too many questions?
•Can anyone else provide additional information?
•Should I be asking you anything else?These questions (and others) will help to “break the ice” and initiate the communi-cation that is essential to successful elicitation. But a question-and-answer meetingformat is not an approach that has been overwhelmingly successful. In fact, the Q&Asession should be used for the first encounter only and then replaced by a require-ments elicitation format that combines elements of problem solving, negotiation,and specification. An approach of this type is presented in Section 5.3.
5.3 E LICITING REQUIREMENTS
Requirements elicitation (also called requirements gathering) combines elements ofproblem solving, elaboration, negotiation, and specification. In order to encouragea collaborative, team-oriented approach to requirements gathering, stakeholderswork together to identify the problem, propose elements of the solution, negotiatedifferent approaches and specify a preliminary set of solution requirements [Zah90].
9
5.3.1 Collaborative Requirements Gathering
Many different approaches to collaborative requirements gathering have been pro-posed. Each makes use of a slightly different scenario, but all apply some variationon the following basic guidelines:
•Meetings are conducted and attended by both software engineers and otherstakeholders.
•Rules for preparation and participation are established.
•An agenda is suggested that is formal enough to cover all important pointsbut informal enough to encourage the free flow of ideas.
•A “facilitator” (can be a customer, a developer, or an outsider) controls themeeting.
•A “definition mechanism” (can be work sheets, flip charts, or wall stickers oran electronic bulletin board, chat room, or virtual forum) is used.128 PART TWOMODELING
9 This approach is sometimes called a facilitated application specification technique (FAST).uote:
“He who asks aquestion is a foolfor five minutes;he who does notask a question is afool forever.”Chinese proverb
What are the basicguidelines forconducting acollaborativerequirementsgatheringmeeting??pre75977_ch05.qxd  11/27/08  3:30 PM  Page 128The goal is to identify the problem, propose elements of the solution, negotiatedifferent approaches, and specify a preliminary set of solution requirements in an at-mosphere that is conducive to the accomplishment of the goal. To better understandthe flow of events as they occur, I present a brief scenario that outlines the sequenceof events that lead up to the requirements gathering meeting, occur during the meet-ing, and follow the meeting.During inception (Section 5.2) basic questions and answers establish the scope ofthe problem and the overall perception of a solution. Out of these initial meetings,the developer and customers write a one- or two-page “product request.” A meeting place, time, and date are selected; a facilitator is chosen; and attendeesfrom the software team and other stakeholder organizations are invited to partici-pate. The product request is distributed to all attendees before the meeting date.As an example,
10consider an excerpt from a product request written by a mar-keting person involved in the SafeHome project. This person writes the following nar- rative about the home security function that is to be part of SafeHome:
Our research indicates that the market for home management systems is growing at arate of 40 percent per year. The first SafeHome function we bring to market should be the home security function. Most people are familiar with “alarm systems” so this would bean easy sell.The home security function would protect against and/or recognize a variety of un-desirable “situations” such as illegal entry, fire, flooding, carbon monoxide levels, andothers. It’ll use our wireless sensors to detect each situation. It can be programmed by thehomeowner, and will automatically telephone a monitoring agency when a situation isdetected.
In reality, others would contribute to this narrative during the requirements gath-ering meeting and considerably more information would be available. But even withadditional information, ambiguity would be present, omissions would likely exist,and errors might occur. For now, the preceding “functional description” will suffice.While reviewing the product request in the days before the meeting, each at-tendee is asked to make a list of objects that are part of the environment that sur-rounds the system, other objects that are to be produced by the system, and objectsthat are used by the system to perform its functions. In addition, each attendee isasked to make another list of services (processes or functions) that manipulate or in-teract with the objects. Finally, lists of constraints (e.g., cost, size, business rules) andperformance criteria (e.g., speed, accuracy) are also developed. The attendees are in-formed that the lists are not expected to be exhaustive but are expected to reflecteach person’s perception of the system.CHAPTER 5UNDERSTANDING REQUIREMENTS 129
uote:
“We spend a lot oftime—themajority of projecteffort—notimplementing ortesting, but tryingto decide what tobuild.”Brian Lawrence
WebRef
Joint ApplicationDevelopment(JAD) isa popular technique for requirementsgathering. A gooddescription can befound atwww.carolla.com/wp-jad.htm.
If a system or productwill serve many users,be absolutely certainthat requirements areelicited from a repre-sentative cross sectionof users. If only oneuser defines all require-ments, acceptance riskis high.
10 This example (with extensions and variations) is used to illustrate important software engineeringmethods in many of the chapters that follow. As an exercise, it would be worthwhile to conductyour own requirements gathering meeting and develop a set of lists for it.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 129Objects described for SafeHomemight include the control panel, smoke detectors,window and door sensors, motion detectors, an alarm, an event (a sensor has beenactivated), a display, a PC, telephone numbers, a telephone call, and so on. The listof services might include configuringthe system, settingthe alarm, monitoringthe sensors, dialingthe phone, programmingthe control panel, and readingthe display (note that services act on objects). In a similar fashion, each attendee will developlists of constraints (e.g., the system must recognize when sensors are not operating,must be user-friendly, must interface directly to a standard phone line) and perform-ance criteria (e.g., a sensor event should be recognized within one second, and anevent priority scheme should be implemented).The lists of objects can be pinned to the walls of the room using large sheets ofpaper, stuck to the walls using adhesive-backed sheets, or written on a wall board.Alternatively, the lists may have been posted on an electronic bulletin board, at aninternal website, or posed in a chat room environment for review prior to the meet-ing. Ideally, each listed entry should be capable of being manipulated separately sothat lists can be combined, entries can be modified, and additions can be made. Atthis stage, critique and debate are strictly prohibited.After individual lists are presented in one topic area, the group creates a com-bined list by eliminating redundant entries, adding any new ideas that come up dur-ing the discussion, but not deleting anything. After you create combined lists for alltopic areas, discussion—coordinated by the facilitator—ensues. The combined list isshortened, lengthened, or reworded to properly reflect the product/system to be de-veloped. The objective is to develop a consensus list of objects, services, constraints,and performance for the system to be built.In many cases, an object or service described on a list will require further expla-nation. To accomplish this, stakeholders develop mini-specifications for entries on the lists.
11Each mini-specification is an elaboration of an object or service. Forexample, the mini-spec for the SafeHome object Control Panelmight be:
The control panel is a wall-mounted unit that is approximately 9 /H11003 5 inches in size. The control panel has wireless connectivity to sensors and a PC. User interaction occursthrough a keypad containing 12 keys. A 3 /H110033 inch LCD color display provides user feed- back. Software provides interactive prompts, echo, and similar functions.
The mini-specs are presented to all stakeholders for discussion. Additions, deletions,and further elaboration are made. In some cases, the development of mini-specs willuncover new objects, services, constraints, or performance requirements that will beadded to the original lists. During all discussions, the team may raise an issue thatcannot be resolved during the meeting. An issues list is maintained so that these ideas will be acted on later.130 PART TWOMODELING
Avoid the impulse toshoot down a cus-tomer’s idea as “toocostly” or “impracti-cal.” The idea here isto negotiate a list thatis acceptable to all. Todo this, you must keepan open mind.
11 Rather than creating a mini-specification, many software teams elect to develop user scenarioscalled use cases.These are considered in detail in Section 5.4 and in Chapter 6.uote:
“Facts do not ceaseto exist becausethey are ignored.”Aldous Huxleypre75977_ch05.qxd  11/27/08  3:30 PM  Page 1305.3.2 Quality Function Deployment
Quality function deployment(QFD) is a quality management technique that translatesthe needs of the customer into technical requirements for software. QFD “concen-trates on maximizing customer satisfaction from the software engineering process”[Zul92]. To accomplish this, QFD emphasizes an understanding of what is valuableto the customer and then deploys these values throughout the engineering process.QFD identifies three types of requirements [Zul92]:Normal requirements.The objectives and goals that are stated for a prod-uct or system during meetings with the customer. If these requirements arepresent, the customer is satisfied. Examples of normal requirements might berequested types of graphical displays, specific system functions, and definedlevels of performance.Expected requirements.These requirements are implicit to the productor system and may be so fundamental that the customer does not explicitlystate them. Their absence will be a cause for significant dissatisfaction.Examples of expected requirements are: ease of human/machine interaction,overall operational correctness and reliability, and ease of softwareinstallation.CHAPTER 5UNDERSTANDING REQUIREMENTS 131
The scene:A meeting room. The firstrequirements gathering meeting is in progress.The players:Jamie Lazar, software team member;Vinod Raman, software team member; Ed Robbins,software team member; Doug Miller, softwareengineering manager; three members of marketing; aproduct engineering representative; and a facilitator.The conversation:Facilitator (pointing at whiteboard): So that’s the current list of objects and services for the home securityfunction.Marketing person:That about covers it from ourpoint of view.Vinod:Didn’t someone mention that they wanted allSafeHomefunctionality to be accessible via the Internet?That would include the home security function, no?Marketing person:Yes, that’s right. . . we’ll have toadd that functionality and the appropriate objects.Facilitator:Does that also add some constraints?Jamie:It does, both technical and legal.Production rep:Meaning?Jamie:We better make sure an outsider can’t hack intothe system, disarm it, and rob the place or worse. Heavyliability on our part.Doug:Very true.Marketing:But we still need that . . . just be sure to stopan outsider from getting in.Ed:That’s easier said than done and . . .Facilitator (interrupting):I don’t want to debate thisissue now. Let’s note it as an action item and proceed.(Doug, serving as the recorder for the meeting, makes anappropriate note.)Facilitator:I have a feeling there’s still more to considerhere.(The group spends the next 20 minutes refining andexpanding the details of the home security function.)SAFEHOME
QFD defines require-ments in a way thatmaximizes customersatisfaction.
Everyone wants toimplement lots ofexciting requirements,but be careful. That’show “requirementscreep” sets in. On theother hand, excitingrequirements lead to abreakthrough product!Conducting a Requirements Gathering Meetingpre75977_ch05.qxd  11/27/08  3:30 PM  Page 131Exciting requirements.These features go beyond the customer’s expecta-tions and prove to be very satisfying when present. For example, software fora new mobile phone comes with standard features, but is coupled with a setof unexpected capabilities (e.g., multitouch screen, visual voice mail) thatdelight every user of the product.Although QFD concepts can be applied across the entire software process [Par96a],specific QFD techniques are applicable to the requirements elicitation activity. QFDuses customer interviews and observation, surveys, and examination of historicaldata (e.g., problem reports) as raw data for the requirements gathering activity.These data are then translated into a table of requirements—called the customervoice table—that is reviewed with the customer and other stakeholders. A variety ofdiagrams, matrices, and evaluation methods are then used to extract expected re-quirements and to attempt to derive exciting requirements [Aka04].
5.3.3 Usage Scenarios
As requirements are gathered, an overall vision of system functions and features be-gins to materialize. However, it is difficult to move into more technical software en-gineering activities until you understand how these functions and features will beused by different classes of end users. To accomplish this, developers and users cancreate a set of scenarios that identify a thread of usage for the system to be con-structed. The scenarios, often called use cases [ Jac92], provide a description of how the system will be used. Use cases are discussed in greater detail in Section 5.4.132 PART TWOMODELING
WebRef
Useful information onQFD can be obtained atwww.qfdi.org.
The scene:A meeting room,continuing the first requirements gathering meeting.The players:Jamie Lazar, software team member;Vinod Raman, software team member; Ed Robbins,software team member; Doug Miller, softwareengineering manager; three members of marketing; aproduct engineering representative; and a facilitator.The conversation:Facilitator:We’ve been talking about security foraccess to SafeHomefunctionality that will be accessiblevia the Internet. I’d like to try something. Let’s develop ausage scenario for access to the home security function.Jamie:How?Facilitator:We can do it a couple of different ways, butfor now, I’d like to keep things really informal. Tell us (hepoints at a marketing person) how you envision accessingthe system.Marketing person:Um . . . well, this is the kind ofthing I’d do if I was away from home and I had to letsomeone into the house, say a housekeeper or repair guy,who didn’t have the security code.Facilitator (smiling):That’s the reason you’d do it . . .tell me how you’d actually do this.Marketing person:Um . . . the first thing I’d need is aPC. I’d log on to a website we’d maintain for all users ofSafeHome. I’d provide my user id and . . .Vinod (interrupting):The Web page would have to besecure, encrypted, to guarantee that we’re safe and . . .Facilitator (interrupting):That’s good information,Vinod, but it’s technical. Let’s just focus on how the enduser will use this capability. OK?Vinod:No problem.Marketing person:So as I was saying, I’d log on to awebsite and provide my user ID and two levels of passwords.SAFEHOMEDeveloping a Preliminary User Scenariopre75977_ch05.qxd  11/27/08  3:30 PM  Page 1325.3.4 Elicitation Work Products
The work products produced as a consequence of requirements elicitation will varydepending on the size of the system or product to be built. For most systems, thework products include
•A statement of need and feasibility.
•A bounded statement of scope for the system or product.
•A list of customers, users, and other stakeholders who participated inrequirements elicitation.
•A description of the system’s technical environment.
•A list of requirements (preferably organized by function) and the domainconstraints that apply to each.
•A set of usage scenarios that provide insight into the use of the system orproduct under different operating conditions.
•Any prototypes developed to better define requirements.Each of these work products is reviewed by all people who have participated in re-quirements elicitation.
5.4 D EVELOPING USECASES
In a book that discusses how to write effective use cases, Alistair Cockburn[Coc01b] notes that “a use case captures a contract ... [that] describes the system’sbehavior under various conditions as the system responds to a request from one ofits stakeholders . . .” In essence, a use case tells a stylized story about how an enduser (playing one of a number of possible roles) interacts with the system under aspecific set of circumstances. The story may be narrative text, an outline of tasksor interactions, a template-based description, or a diagrammatic representation.Regardless of its form, a use case depicts the software or system from the enduser’s point of view.CHAPTER 5UNDERSTANDING REQUIREMENTS 133
Jamie:What if I forget my password?Facilitator (interrupting):Good point, Jamie, butlet’s not address that now. We’ll make a note of that andcall it an exception. I’m sure there’ll be others.Marketing person:After I enter the passwords, ascreen representing all SafeHomefunctions will appear.I’d select the home security function. The system mightrequest that I verify who I am, say, by asking for myaddress or phone number or something. It would thendisplay a picture of the security system control panelalong with a list of functions that I can perform—arm thesystem, disarm the system, disarm one or more sensors.I suppose it might also allow me to reconfigure securityzones and other things like that, but I’m not sure.(As the marketing person continues talking, Doug takescopious notes; these form the basis for the first informalusage scenario. Alternatively, the marketing person couldhave been asked to write the scenario, but this would bedone outside the meeting.)
Whatinformationis produced as aconsequence ofrequirementsgathering??pre75977_ch05.qxd  11/27/08  3:30 PM  Page 133The first step in writing a use case is to define the set of “actors” that will beinvolved in the story. Actorsare the different people (or devices) that use the systemor product within the context of the function and behavior that is to be described.Actors represent the roles that people (or devices) play as the system operates.Defined somewhat more formally, an actor is anything that communicates with thesystem or product and that is external to the system itself. Every actor has one ormore goals when using the system.It is important to note that an actor and an end user are not necessarily the samething. A typical user may play a number of different roles when using a system,whereas an actor represents a class of external entities (often, but not always, peo-ple) that play just one role in the context of the use case. As an example, consider amachine operator (a user) who interacts with the control computer for a manufac-turing cell that contains a number of robots and numerically controlled machines.After careful review of requirements, the software for the control computer requiresfour different modes (roles) for interaction: programming mode, test mode, moni-toring mode, and troubleshooting mode. Therefore, four actors can be defined: pro-grammer, tester, monitor, and troubleshooter. In some cases, the machine operatorcan play all of these roles. In others, different people may play the role of each actor.Because requirements elicitation is an evolutionary activity, not all actors areidentified during the first iteration. It is possible to identify primary actors [ Jac92]during the first iteration and secondary actors as more is learned about the system.Primary actorsinteract to achieve required system function and derive the intendedbenefit from the system. They work directly and frequently with the software.Secondary actorssupport the system so that primary actors can do their work.Once actors have been identified, use cases can be developed. Jacobson [ Jac92]suggests a number of questions
12that should be answered by a use case:
•Who is the primary actor, the secondary actor(s)?
•What are the actor’s goals?
•What preconditions should exist before the story begins?
•What main tasks or functions are performed by the actor?
•What exceptions might be considered as the story is described?
•What variations in the actor’s interaction are possible?
•What system information will the actor acquire, produce, or change?
•Will the actor have to inform the system about changes in the externalenvironment?
•What information does the actor desire from the system?
•Does the actor wish to be informed about unexpected changes?134 PART TWOMODELING
Use cases are definedfrom an actor’s pointof view. An actor isa role that people(users) or devices playas they interact withthe software.
WebRef
An excellent paper onuse cases can bedownloaded fromwww.ibm.com/developerworks/webservices/library/codesign7.html.
What do Ineed toknow in order todevelop aneffective usecase??
12 Jacobson’s questions have been extended to provide a more complete view of use-case content.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 134Recalling basic SafeHomerequirements, we define four actors: homeowner(a user), setup manager(likely the same person as homeowner, but playing a dif- ferent role), sensors(devices attached to the system), and the monitoring andresponse subsystem(the central station that monitors the SafeHome home secu- rity function). For the purposes of this example, we consider only the homeowneractor. The homeowneractor interacts with the home security function in a numberof different ways using either the alarm control panel or a PC:
•Enters a password to allow all other interactions.
•Inquires about the status of a security zone.
•Inquires about the status of a sensor.
•Presses the panic button in an emergency.
•Activates/deactivates the security system.Considering the situation in which the homeowner uses the control panel, the basicuse case for system activation follows:
13
1. The homeowner observes the SafeHome control panel (Figure 5.1) to determine if the system is ready for input. If the system is not ready, a not readymessage is displayed on the LCD display, and the homeowner must physically close windows or doors sothat the not readymessage disappears. [Anot readymessage implies that a sensor is open; i.e., that a door or window is open.]CHAPTER 5UNDERSTANDING REQUIREMENTS 135
123456789*0offSAFEHOMEaway staymax test bypassinstant code chimeready# armed poweralarmcheckfireawaystayinstantbypassnot ready
panicFIGURE 5.1
SafeHomecontrol panel
13 Note that this use case differs from the situation in which the system is accessed via the Internet.In this case, interaction occurs via the control panel, not the graphical user interface (GUI) providedwhen a PC is used.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 1352. The homeowner uses the keypad to key in a four-digit password. The password is com-pared with the valid password stored in the system. If the password is incorrect, the con-trol panel will beep once and reset itself for additional input. If the password is correct,the control panel awaits further action.3. The homeowner selects and keys in stay or away(see Figure 5.1) to activate the system. Stayactivates only perimeter sensors (inside motion detecting sensors are deacti-vated). Awayactivates all sensors.4. When activation occurs, a red alarm light can be observed by the homeowner.
The basic use case presents a high-level story that describes the interaction betweenthe actor and the system.In many instances, uses cases are further elaborated to provide considerablymore detail about the interaction. For example, Cockburn [Coc01b] suggests the fol-lowing template for detailed descriptions of use cases:
Use case:InitiateMonitoringPrimary actor:Homeowner.Goal in context:To set the system to monitor sensors when the homeownerleaves the house or remains inside.Preconditions:System has been programmed for a password and to recognizevarious sensors.Trigger:The homeowner decides to “set” the system, i.e., to turn on thealarm functions.Scenario:1. Homeowner: observes control panel2. Homeowner: enters password3. Homeowner: selects “stay” or “away”4. Homeowner: observes read alarm light to indicate that SafeHome has been armed Exceptions:1. Control panel is not ready:homeowner checks all sensors to determine which areopen; closes them.2. Password is incorrect (control panel beeps once): homeowner reenters correct password.3. Password not recognized: monitoring and response subsystem must be contacted toreprogram password.4.Stayis selected: control panel beeps twice and a stay light is lit; perimeter sensors are activated.5.Awayis selected: control panel beeps three times and an away light is lit; all sensors are activated.Priority:Essential, must be implementedWhen available:First increment136 PART TWOMODELING
Use cases are oftenwritten informally.However, use the tem-plate shown here toensure that you’veaddressed all keyissues.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 136Frequency of use:Many times per dayChannel to actor:Via control panel interfaceSecondary actors:Support technician, sensorsChannels to secondary actors:Support technician: phone lineSensors: hardwired and radio frequency interfacesOpen issues:1. Should there be a way to activate the system without the use of a password or with anabbreviated password?2. Should the control panel display additional text messages?3. How much time does the homeowner have to enter the password from the time thefirst key is pressed?4. Is there a way to deactivate the system before it actually activates?
Use cases for otherhomeownerinteractions would be developed in a similar manner.It is important to review each use case with care. If some element of the interactionis ambiguous, it is likely that a review of the use case will indicate a problem.CHAPTER 5UNDERSTANDING REQUIREMENTS 137
The scene:A meeting room,continuing the requirements gathering meetingThe players:Jamie Lazar, software team member;Vinod Raman, software team member; Ed Robbins,software team member; Doug Miller, softwareengineering manager; three members of marketing; aproduct engineering representative; and a facilitator.The conversation:Facilitator:We’ve spent a fair amount of time talkingaboutSafeHomehome security functionality. During thebreak I sketched a use case diagram to summarize theimportant scenarios that are part of this function. Takea look.(All attendees look at Figure 5.2.)Jamie:I’m just beginning to learn UML notation.
14So the home security function is represented by the big boxwith the ovals inside it? And the ovals represent use casesthat we’ve written in text?Facilitator:Yep. And the stick figures represent actors—the people or things that interact with the system as describedby the use case. . . oh, I use the labeled square to representan actor that’s not a person...i nthis case, sensors.Doug:Is that legal in UML?Facilitator:Legality isn’t the issue. The point is tocommunicate information. I view the use of a humanlikestick figure for representing a device to be misleading. SoI’ve adapted things a bit. I don’t think it creates a problem.Vinod:Okay, so we have use-case narratives for eachof the ovals. Do we need to develop the more detailedtemplate-based narratives I’ve read about?Facilitator:Probably, but that can wait until we’veconsidered other SafeHomefunctions.Marketing person:Wait, I’ve been looking at thisdiagram and all of a sudden I realize we missed something.Facilitator:Oh really. Tell me what we’ve missed.(The meeting continues.)SAFEHOME
14A brief UML tutorial is presented in Appendix 1 for those who are unfamiliar with the notation.Developing a High-Level Use-Case Diagrampre75977_ch05.qxd  11/27/08  3:30 PM  Page 137138 PART TWOMODELING
15Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.16 Throughout this book, I use the terms analysis model and requirements modelsynonymously. Both refer to representations of the information, functional, and behavioral domains that describe prob-lem requirements.Use-Case Development
Objective:Assist in the development ofuse cases by providing automated templatesand mechanisms for assessing clarity and consistency.Mechanics:Tool mechanics vary. In general, use-casetools provide fill-in-the-blank templates for creating effectiveuse cases. Most use-case functionality is embedded into aset of broader requirements engineering functions.Representative Tools:15
The vast majority of UML-based analysis modeling toolsprovide both text and graphical support for use-casedevelopment and modeling.Objects by Design(www.objectsbydesign.com/tools/umltools_byCompany.html) providescomprehensive links to tools of this type.SOFTWARE TOOLS
5.5 B UILDING THE REQUIREMENTS MODEL16
The intent of the analysis model is to provide a description of the required informational,functional, and behavioral domains for a computer-based system. The model changesdynamically as you learn more about the system to be built, and other stakeholders un-derstand more about what they really require. For that reason, the analysis model is asnapshot of requirements at any given time. You should expect it to change.Homeowner
System administratorArms/disarmssystem
Responds to alarm eventAccessessystemvia Internet
Encountersan errorconditionReconfiguressensors andrelated system featuresSensorsFIGURE 5.2
UML use casediagram forSafeHomehome securityfunctionpre75977_ch05.qxd  11/27/08  3:30 PM  Page 138As the requirements model evolves, certain elements will become relativelystable, providing a solid foundation for the design tasks that follow. However, otherelements of the model may be more volatile, indicating that stakeholders do not yetfully understand requirements for the system. The analysis model and the methodsthat are used to build it are presented in detail in Chapters 6 and 7. I present a briefoverview in the sections that follow.
5.5.1 Elements of the Requirements Model
There are many different ways to look at the requirements for a computer-basedsystem. Some software people argue that it’s best to select one mode of represen-tation (e.g., the use case) and apply it to the exclusion of all other modes. Otherpractitioners believe that it’s worthwhile to use a number of different modes of rep-resentation to depict the requirements model. Different modes of representationforce you to consider requirements from different viewpoints—an approach that hasa higher probability of uncovering omissions, inconsistencies, and ambiguity.The specific elements of the requirements model are dictated by the analysismodeling method (Chapters 6 and 7) that is to be used. However, a set of genericelements is common to most requirements models.Scenario-based elements.The system is described from the user’s point of viewusing a scenario-based approach. For example, basic use cases (Section 5.4) andtheir corresponding use-case diagrams (Figure 5.2) evolve into more elaboratetemplate-based use cases. Scenario-based elements of the requirements modelare often the first part of the model that is developed. As such, they serve as input forthe creation of other modeling elements. Figure 5.3 depicts a UML activity diagram
17
for eliciting requirements and representing them using use cases. Three levels ofelaboration are shown, culminating in a scenario-based representation.Class-based elements.Each usage scenario implies a set of objects that aremanipulated as an actor interacts with the system. These objects are categorized intoclasses—a collection of things that have similar attributes and common behaviors. Forexample, a UML class diagram can be used to depict a Sensorclass for theSafeHome security function (Figure 5.4). Note that the diagram lists the attributes of sensors (e.g.,name, type) and the operations (e.g.,identify, enable) that can be applied to modify these attributes. In addition to class diagrams, other analysis modeling elements de-pict the manner in which classes collaborate with one another and the relationshipsand interactions between classes. These are discussed in more detail in Chapter 7.Behavioral elements.The behavior of a computer-based system can have a pro-found effect on the design that is chosen and the implementation approach that isapplied. Therefore, the requirements model must provide modeling elements thatdepict behavior.CHAPTER 5UNDERSTANDING REQUIREMENTS 139
17 A brief UML tutorial is presented in Appendix 1 for those who are unfamiliar with the notation.It is always a goodidea to get stakehold-ers involved. One ofthe best ways to dothis is to have eachstakeholder write usecases that describehow the software willbe used.
One way to isolateclasses is to look fordescriptive nouns in ause-case script. At leastsome of the nouns willbe candidate classes.More on this in theChapter 8.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 139140 PART TWOMODELING
Formal prioritization?
YesNoConductmeetingsMake lists of functions, classesMake lists of constraints, etc.
  Use QFD toprioritize requirementsInformallyprioritize requirementsCreateuse casesDraw use-casediagramDefineactorsWritescenarioCompletetemplateElicit requirementsFIGURE 5.3
UML activitydiagrams forelicitingrequirements
NameTypeLocationAreaCharacteristics
Identify()Enable()Disable()Reconfigure()SensorFIGURE 5.4
Class diagramfor sensor
A state is an externallyobservable mode ofbehavior. Externalstimuli cause transi-tions between states.The state diagramis one method for representing the behavior of a system by de-picting its states and the events that cause the system to change state. A state is any externally observable mode of behavior. In addition, the state diagram indicatesactions (e.g., process activation) taken as a consequence of a particular event.To illustrate the use of a state diagram, consider software embedded within theSafeHomecontrol panel that is responsible for reading user input. A simplified UMLstate diagram is shown in Figure 5.5.pre75977_ch05.qxd  11/27/08  3:30 PM  Page 140Flow-oriented elements.Information is transformed as it flows through acomputer-based system. The system accepts input in a variety of forms, applies func-tions to transform it, and produces output in a variety of forms. Input may be a controlsignal transmitted by a transducer, a series of numbers typed by a human operator, aCHAPTER 5UNDERSTANDING REQUIREMENTS 141
The scene:A meeting room,continuing the requirements meeting.The players:Jamie Lazar, software team member;Vinod Raman, software team member; Ed Robbins,software team member; Doug Miller, softwareengineering manager; three members of marketing;a product engineering representative; and a facilitator.The conversation:Facilitator:We’ve just about finished talking aboutSafeHomehome security functionality. But before we do,I want to discuss the behavior of the function.Marketing person:I don’t understand what you meanby behavior.Ed (smiling):That’s when you give the product a“timeout” if it misbehaves.Facilitator:Not exactly. Let me explain.(The facilitator explains the basics of behavioral modelingto the requirements gathering team.)Marketing person:This seems a little technical. I’mnot sure I can help here.Facilitator:Sure you can. What behavior do youobserve from the user’s point of view?Marketing person:Uh . . . well, the system will bemonitoringthe sensors. It’ll be reading commandsfrom the homeowner. It’ll be displayingits status.Facilitator:See, you can do it.Jamie:It’ll also be pollingthe PC to determine if there isany input from it, for example, Internet-based access orconfiguration information.Vinod:Yeah, in fact, configuring the systemis a state in its own right.Doug:You guys are rolling. Let’s give this a bit morethought . . . is there a way to diagram this stuff?Facilitator:There is, but let’s postpone that until afterthe meeting.SAFEHOMESystem status = "Ready"Display msg = "enter cmd"Display status = steadyState nameState variablesState activities
Entry/subsystems readyDo: poll user input panelDo: read user inputDo: interpret user inputReadingcommandsFIGURE 5.5
UML statediagramnotation
In addition to behavioral representations of the system as a whole, the behaviorof individual classes can also be modeled. Further discussion of behavioral model-ing is presented in Chapter 7.
Preliminary Behavioral Modelingpre75977_ch05.qxd  11/27/08  3:30 PM  Page 141packet of information transmitted on a network link, or a voluminous data fileretrieved from secondary storage. The transform(s) may comprise a single logicalcomparison, a complex numerical algorithm, or a rule-inference approach of an expertsystem. Output may light a single LED or produce a 200-page report. In effect, we cancreate a flow model for any computer-based system, regardless of size and complex-ity. A more detailed discussion of flow modeling is presented in Chapter 7.
5.5.2 Analysis Patterns
Anyone who has done requirements engineering on more than a few softwareprojects begins to notice that certain problems reoccur across all projects within aspecific application domain.
18These analysis patterns[Fow97] suggest solutions (e.g., a class, a function, a behavior) within the application domain that can bereused when modeling many applications.Geyer-Schulz and Hahsler [Gey01] suggest two benefits that can be associatedwith the use of analysis patterns:
First, analysis patterns speed up the development of abstract analysis models that cap-ture the main requirements of the concrete problem by providing reusable analysis mod-els with examples as well as a description of advantages and limitations. Second, analysispatterns facilitate the transformation of the analysis model into a design model by sug-gesting design patterns and reliable solutions for common problems.
Analysis patterns are integrated into the analysis model by reference to the patternname. They are also stored in a repository so that requirements engineers can usesearch facilities to find and apply them. Information about an analysis pattern (andother types of patterns) is presented in a standard template [Gey01]
19that is dis- cussed in more detail in Chapter 12. Examples of analysis patterns and further dis-cussion of this topic are presented in Chapter 7.
5.6 N EGOTIATING REQUIREMENTS
In an ideal requirements engineering context, the inception, elicitation, and elabo-ration tasks determine customer requirements in sufficient detail to proceed to sub-sequent software engineering activities. Unfortunately, this rarely happens. In reality,you may have to enter into a negotiation with one or more stakeholders. In mostcases, stakeholders are asked to balance functionality, performance, and other prod-uct or system characteristics against cost and time-to-market. The intent of thisnegotiation is to develop a project plan that meets stakeholder needs while at the142 PART TWOMODELING
18 In some cases, problems reoccur regardless of the application domain. For example, the featuresand functions used to solve user interface problems are common regardless of the applicationdomain under consideration.19 A variety of patterns templates have been proposed in the literature. If you have interest, see[Fow97], [Gam95], [Yac03], and [Bus07] among many sources.uote:
“A compromise isthe art of dividinga cake in such away that everyonebelieves he has thebiggest piece.”Ludwig Erhardpre75977_ch05.qxd  11/27/08  3:30 PM  Page 142same time reflecting the real-world constraints (e.g., time, people, budget) that havebeen placed on the software team.The best negotiations strive for a “win-win” result.
20That is, stakeholders win by getting the system or product that satisfies the majority of their needs and you (as amember of the software team) win by working to realistic and achievable budgetsand deadlines.Boehm [Boe98] defines a set of negotiation activities at the beginning of each soft-ware process iteration. Rather than a single customer communication activity, thefollowing activities are defined:1.Identification of the system or subsystem’s key stakeholders.2.Determination of the stakeholders’ “win conditions.”3.Negotiation of the stakeholders’ win conditions to reconcile them into a setof win-win conditions for all concerned (including the software team).Successful completion of these initial steps achieves a win-win result, which becomesthe key criterion for proceeding to subsequent software engineering activities.CHAPTER 5UNDERSTANDING REQUIREMENTS 143
20 Dozens of books have been written on negotiating skills (e.g., [Lew06], [Rai06], [Fis06]). It is one ofthe more important skills that you can learn. Read one.WebRef
A brief paper onnegotiation for softwarerequirements can bedownloaded fromwww.alexander-egyed.com/publications/Software_Requirements_Negotiation-Some_Lessons_Learned.html.
The Art of Negotiation
Learning how to negotiate effectively can serveyou well throughout your personal and technicallife. The following guidelines are well worth considering:1.Recognize that it’s not a competition.To besuccessful, both parties have to feel they’ve won orachieved something. Both will have to compromise.2.Map out a strategy.Decide what you’d like toachieve; what the other party wants to achieve, andhow you’ll go about making both happen.3.Listen actively.Don’t work on formulating yourresponse while the other party is talking. Listento her. It’s likely you’ll gain knowledge that will helpyou to better negotiate your position.4.Focus on the other party’s interests.Don’t take hardpositions if you want to avoid conflict.5.Don’t let it get personal.Focus on the problem thatneeds to be solved.6.Be creative.Don’t be afraid to think out of the box ifyou’re at an impasse.7.Be ready to commit.Once an agreement has beenreached, don’t waffle; commit to it and move on.INFO
The Start of a Negotiation
The scene:Lisa Perez’s office, afterthe first requirements gathering meeting.The players:Doug Miller, software engineeringmanager and Lisa Perez, marketing manager.The conversation:Lisa:So, I hear the first meeting went really well.Doug:Actually, it did. You sent some good people to themeeting . . . they really contributed.SAFEHOMEpre75977_ch05.qxd  11/27/08  3:30 PM  Page 1435.7 V ALIDATING REQUIREMENTS144 PART TWOMODELING
When Ireviewrequirements,what questionsshould I ask??As each element of the requirements model is created, it is examined for inconsis-tency, omissions, and ambiguity. The requirements represented by the model are pri-oritized by the stakeholders and grouped within requirements packages that will beimplemented as software increments. A review of the requirements model addressesthe following questions:
•Is each requirement consistent with the overall objectives for thesystem/product?
•Have all requirements been specified at the proper level of abstraction? Thatis, do some requirements provide a level of technical detail that is inappro-priate at this stage?
•Is the requirement really necessary or does it represent an add-on featurethat may not be essential to the objective of the system?
•Is each requirement bounded and unambiguous?
•Does each requirement have attribution? That is, is a source (generally, aspecific individual) noted for each requirement?
•Do any requirements conflict with other requirements?
•Is each requirement achievable in the technical environment that will housethe system or product?
•Is each requirement testable, once implemented?
•Does the requirements model properly reflect the information, function, andbehavior of the system to be built?Lisa (smiling):Yeah, they actually told me they got intoit and it wasn’t a “propeller head activity.”Doug (laughing):I’ll be sure to take off my techiebeanie the next time I visit. . . Look, Lisa, I think we mayhave a problem with getting all of the functionality for thehome security system out by the dates your managementis talking about. It’s early, I know, but I’ve already beendoing a little back-of-the-envelope planning and . . .Lisa (frowning):We’ve got to have it by that date,Doug. What functionality are you talking about?Doug:I figure we can get full home security functionalityout by the drop-dead date, but we’ll have to delayInternet access ‘til the second release.Lisa:Doug, it’s the Internet access that gives SafeHome “gee whiz” appeal. We’re going to build our entiremarketing campaign around it. We’ve gotta have it!Doug:I understand your situation, I really do. Theproblem is that in order to give you Internet access,we’ll have to have a fully secure website up andrunning. That takes time and people. We’ll also haveto build a lot of additional functionality into the firstrelease...Idon’t think we can do it with the resourceswe’ve got.Lisa (still frowning):I see, but you’ve got to figure outa way to get it done. It’s pivotal to home security functionsand to other functions as well . . . those can wait until thenext releases. . . I’ll agree to that.Lisa and Doug appear to be at an impasse, and yet theymust negotiate a solution to this problem. Can they both“win” here? Playing the role of a mediator, what would yousuggest?pre75977_ch05.qxd  11/27/08  3:30 PM  Page 144•Has the requirements model been “partitioned” in a way that exposesprogressively more detailed information about the system?
•Have requirements patterns been used to simplify the requirements model?Have all patterns been properly validated? Are all patterns consistent withcustomer requirements?These and other questions should be asked and answered to ensure that the re-quirements model is an accurate reflection of stakeholder needs and that it providesa solid foundation for design.
5.8 S UMMARY
Requirements engineering tasks are conducted to establish a solid foundation for de-sign and construction. Requirements engineering occurs during the communicationand modeling activities that have been defined for the generic software process.Seven distinct requirements engineering functions—inception, elicitation, elabora-tion, negotiation, specification, validation, and management—are conducted bymembers of the software team.At project inception, stakeholders establish basic problem requirements, defineoverriding project constraints, and address major features and functions that mustbe present for the system to meet its objectives. This information is refined and ex-panded during elicitation—a requirements gathering activity that makes use of facil-itated meetings, QFD, and the development of usage scenarios.Elaboration further expands requirements in a model—a collection of scenario-based, class-based, behavioral, and flow-oriented elements. The model may refer-ence analysis patterns, solutions for analysis problems that have been seen toreoccur across different applications.As requirements are identified and the requirements model is being created, thesoftware team and other project stakeholders negotiate the priority, availability, andrelative cost of each requirement. The intent of this negotiation is to develop a realis-tic project plan. In addition, each requirement and the requirements model as a wholeare validated against customer need to ensure that the right system is to be built.
PROBLEMS AND POINTS TO PONDER
5.1.Why is it that many software developers don’t pay enough attention to requirements engi-neering? Are there ever circumstances where you can skip it?5.2.You have been given the responsibility to elicit requirements from a customer who tellsyou he is too busy to meet with you. What should you do?5.3.Discuss some of the problems that occur when requirements must be elicited from threeor four different customers.5.4.Why do we say that the requirements model represents a snapshot of a system in time?CHAPTER 5UNDERSTANDING REQUIREMENTS 145pre75977_ch05.qxd  11/27/08  3:30 PM  Page 1455.5.Let’s assume that you’ve convinced the customer (you’re a very good salesperson) to agreeto every demand that you have as a developer. Does that make you a master negotiator? Why?5.6.Develop at least three additional “context-free questions” that you might ask a stakeholderduring inception.5.7.Develop a requirements gathering “kit.” The kit should include a set of guidelines for con-ducting a requirements gathering meeting and materials that can be used to facilitate the cre-ation of lists and any other items that might help in defining requirements.5.8.Your instructor will divide the class into groups of four to six students. Half of the groupwill play the role of the marketing department and half will take on the role of softwareengineering. Your job is to define requirements for the SafeHomesecurity function described in this chapter. Conduct a requirements gathering meeting using the guidelines presented inthis chapter.5.9.Develop a complete use case for one of the following activities:a. Making a withdrawal at an ATMb. Using your charge card for a meal at a restaurantc. Buying a stock using an on-line brokerage accountd. Searching for books (on a specific topic) using an on-line bookstoree. An activity specified by your instructor.5.10.What do use case “exceptions” represent?5.11.Describe what an analysis patternis in your own words. 5.12.Using the template presented in Section 5.5.2, suggest one or more analysis pattern forthe following application domains:a. Accounting softwareb. E-mail softwarec. Internet browsersd. Word-processing softwaree. Website creation softwaref. An application domain specified by your instructor5.13.What does win-winmean in the context of negotiation during the requirements engi-neering activity?5.14.What do you think happens when requirement validation uncovers an error? Who isinvolved in correcting the error?
FURTHER READINGS AND INFORMATION SOURCES
Because it is pivotal to the successful creation of any complex computer-based system, re-quirements engineering is discussed in a wide array of books. Hood and his colleagues(Requirements Management,Springer, 2007) discuss a variety of requirements engineering is-sues that span both systems and software engineering. Young ( The Requirements Engineering Handbook,Artech House Publishers, 2007) presents an in-depth discussion of requirements en-gineering tasks. Wiegers (More About Software Requirements, Microsoft Press, 2006) provides many practical techniques for requirements gathering and management. Hull and hercolleagues (Requirements Engineering, 2d ed., Springer-Verlag, 2004), Bray (An Introduction to Requirements Engineering,Addison-Wesley, 2002), Arlow (Requirements Engineering,Addison- Wesley, 2001), Gilb (Requirements Engineering,Addison-Wesley, 2000), Graham (Requirements Engineering and Rapid Development, Addison-Wesley, 1999), and Sommerville and Kotonya (Requirement Engineering: Processes and Techniques, Wiley, 1998) are but a few of many books dedicated to the subject. Gottesdiener (Requirements by Collaboration: Workshops for Defining146 PART TWOMODELINGpre75977_ch05.qxd  11/27/08  3:30 PM  Page 146Needs,Addison-Wesley, 2002) provides useful guidance for those who must establish a collab-orative requirements gathering environment with stakeholders.Lauesen (Software Requirements: Styles and Techniques, Addison-Wesley, 2002) presents a comprehensive survey of requirement analysis methods and notation. Weigers ( Software Requirements,Microsoft Press, 1999) and Leffingwell and his colleagues (Managing SoftwareRequirements: A Use Case Approach, 2d ed., Addison-Wesley, 2003) present a useful collection of requirement best practices and suggest pragmatic guidelines for most aspects of the require-ments engineering process.A patterns-based view of requirements engineering is described by Withall ( Software Require- ment Patterns,Microsoft Press, 2007). Ploesch (Assertions, Scenarios and Prototypes, Springer- Verlag, 2003) discusses advanced techniques for developing software requirements. Windle andAbreo (Software Requirements Using the Unified Process, Prentice-Hall, 2002) discuss require- ments engineering within the context of the Unified Process and UML notation. Alexander andSteven (Writing Better Requirements, Addison-Wesley, 2002) present a brief set of guidelines for writing clear requirements, representing them as scenarios, and reviewing the end result.Use-case modeling is often the driver for the creation of all other aspects of the analysismodel. The subject is discussed at length by Rosenberg and Stephens (Use Case Driven ObjectModeling with UML: Theory and Practice, Apress, 2007), Denny (Succeeding with Use Cases: Work- ing Smart to Deliver Quality,Addison-Wesley, 2005), Alexander and Maiden (eds.) (Scenarios,Stories, Use Cases: Through the Systems Development Life-Cycle, Wiley, 2004), Leffingwell and his colleagues (Managing Software Requirements: A Use Case Approach, 2d ed., Addison-Wesley, 2003) present a useful collection of requirement best practices. Bittner and Spence ( Use Case Modeling,Addison-Wesley, 2002), Cockburn [Coc01], Armour and Miller ( Advanced Use Case Modeling: Software Systems, Addison-Wesley, 2000), and Kulak and his colleagues (Use Cases: Requirements in Context,Addison-Wesley, 2000) discuss requirements gathering with anemphasis on use-case modeling.A wide variety of information sources on requirements engineering and analysis is availableon the Internet. An up-to-date list of World Wide Web references that are relevant to require-ments engineering and analysis can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm .CHAPTER 5UNDERSTANDING REQUIREMENTS 147pre75977_ch05.qxd  11/27/08  3:30 PM  Page 147At a technical level, software engineering begins with a series ofmodeling tasks that lead to a specification of requirements and a designrepresentation for the software to be built. The requirements model
1— actually a set of models—is the first technical representation of a system.In a seminal book on requirements modeling methods, Tom DeMarco [DeM79]describes the process in this way:
Looking back over the recognized problems and failings of the analysis phase, I sug-gest that we need to make the following additions to our set of analysis phase goals.The products of analysis must be highly maintainable. This applies particularly to the 
148CHAPTER
6REQUIREMENTS MODELING : SCENARIOS ,I
NFORMATION , ANDANALYSIS CLASSES
KEY
CONCEPTSactivity diagram . .161analysis classes . .167analysispackages  . . . . . .182associations  . . . .180class-basedmodeling  . . . . . .167CRC modeling  . . .173data modeling . . .164domain analysis . .151grammaticalparse  . . . . . . . . .167
What is it? The written word is awonderful vehicle for communica-tion, but it is not necessarily the bestway to represent the requirements forcomputer software. Requirements modeling usesa combination of text and diagrammatic formsto depict requirements in a way that is relativelyeasy to understand, and more important,straightforward to review for correctness, com-pleteness, and consistency.
Who does it? A software engineer (sometimescalled an “analyst”) builds the model usingrequirements elicited from the customer.
Why is it important? To validate software require-ments, you need to examine them from a numberof different points of view. In this chapter you’llconsider requirements modeling from three dif-ferent perspectives: scenario-based models, data(information) models, and class-based models.Each represents requirements in a different“dimension,” thereby increasing the probabilitythat errors will be found, that inconsistency willsurface, and that omissions will be uncovered.QUICK
LOOKWhat are the steps? Scenario-based modelingrepresents the system from the user’s point of view.Data modeling represents the information spaceand depicts the data objects that the software willmanipulate and the relationships among them.Class-based modeling defines objects, attributes,and relationships. Once preliminary models arecreated, they are refined and analyzed to assesstheir clarity, completeness, and consistency. InChapter 7, we extend the modeling dimensionsnoted here with additional representations, pro-viding a more robust view of requirements.
What is the work product? A wide array of text-based and diagrammatic forms may be chosenfor the requirements model. Each of these repre-sentations provides a view of one or more of themodel elements.
How do I ensure that I’ve done it right?
Requirements modeling work products must bereviewed for correctness, completeness, andconsistency. They must reflect the needs of allstakeholders and establish a foundation fromwhich design can be conducted.
1 In past editions of this book, I used the term analysis model, rather than requirements model. In this edition, I’ve decided to use both phrases to represent the modeling activity that defines various as-pects of the problem to be solved. Analysis is the action that occurs as requirements are derived.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 148Target Document [software requirements specification]. Problems of size must be dealtwith using an effective method of partitioning. The Victorian novel specification isout. Graphics have to be used whenever possible. We have to differentiate between log-ical [essential] and physical [implementation] considerations. . . . At the very least, weneed.. . . Something to help us partition our requirements and document that partition-ing before specification. . . . Some means of keeping track of and evaluating interfaces. . . .New tools to describe logic and policy, something better than narrative text.
Although DeMarco wrote about the attributes of analysis modeling more than aquarter century ago, his comments still apply to modern requirements modelingmethods and notation.
6.1 R EQUIREMENTS ANALYSIS
Requirements analysis results in the specification of software’s operational charac-teristics, indicates software’s interface with other system elements, and establishesconstraints that software must meet. Requirements analysis allows you (regardlessof whether you’re called a software engineer, an analyst,or a modeler) to elaborate on basic requirements established during the inception, elicitation, and negotiationtasks that are part of requirements engineering (Chapter 5).The requirements modeling action results in one or more of the following typesof models:
•Scenario-based modelsof requirements from the point of view of varioussystem “actors”
•Data modelsthat depict the information domain for the problem
•Class-oriented modelsthat represent object-oriented classes (attributes andoperations) and the manner in which classes collaborate to achieve systemrequirements
•Flow-oriented modelsthat represent the functional elements of the systemand how they transform data as it moves through the system
•Behavioral modelsthat depict how the software behaves as a consequence ofexternal “events”These models provide a software designer with information that can be translatedto architectural, interface, and component-level designs. Finally, the requirementsmodel (and the software requirements specification) provides the developer and thecustomer with the means to assess quality once software is built.In this chapter, I focus on scenario-based modeling —a technique that is growing increasingly popular throughout the software engineering community; data modeling—a more specialized technique that is particularly appropriate when anapplication must create or manipulate a complex information space; and classCHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 149
requirementsmodeling  . . . . . .153scenario-basedmodeling  . . . . . .154swimlanediagram  . . . . . . .162UML models  . . . .161use cases  . . . . . .156
uote:
“Any one ‘view’of requirementsis insufficientto understandor describe thedesired behavior ofa complex system.”Alan M. Davis
The analysis modeland requirementsspecification providea means for assessingquality once thesoftware is built.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 149150 PART TWOMODELING
modeling—a representation of the object-oriented classes and the resultant collabo-rations that allow a system to function. Flow-oriented models, behavioral models,pattern-based modeling, and WebApp models are discussed in Chapter 7.
6.1.1 Overall Objectives and Philosophy
Throughout requirements modeling, your primary focus is on what, not how.What user interaction occurs in a particular circumstance, what objects does the systemmanipulate, what functions must the system perform, what behaviors does the sys-tem exhibit, what interfaces are defined, and what constraints apply?
2
In earlier chapters, I noted that complete specification of requirements may notbe possible at this stage. The customer may be unsure of precisely what is requiredfor certain aspects of the system. The developer may be unsure that a specific ap-proach will properly accomplish function and performance. These realities mitigatein favor of an iterative approach to requirements analysis and modeling. The analystshould model what is known and use that model as the basis for design of the soft-ware increment.
3
The requirements model must achieve three primary objectives: (1) to describewhat the customer requires, (2) to establish a basis for the creation of a software de-sign, and (3) to define a set of requirements that can be validated once the softwareis built. The analysis model bridges the gap between a system-level description thatdescribes overall system or business functionality as it is achieved by applying soft-ware, hardware, data, human, and other system elements and a software design(Chapters 8 through 13) that describes the software’s application architecture, user in-terface, and component-level structure. This relationship is illustrated in Figure 6.1.uote:
“Requirements arenot architecture.Requirementsare not design, norare they theuser interface.Requirements areneed.”Andrew Huntand DavidThomas
2 It should be noted that as customers become more technologically sophisticated, there is a trendtoward the specification of how as well as what.However, the primary focus should remain on what.3 Alternatively, the software team may choose to create a prototype (Chapter 2) in an effort to betterunderstand requirements for the system.The analysis modelshould describe whatthe customer wants,establish a basis fordesign, and establish atarget for validation.SystemdescriptionAnalysismodelDesignmodelFIGURE 6.1
Therequirementsmodel asa bridgebetween thesystemdescriptionand the designmodelpre75977_ch06.qxd  11/27/08  3:34 PM  Page 150It is important to note that all elements of the requirements model will be directlytraceable to parts of the design model. A clear division of analysis and design tasksbetween these two important modeling activities is not always possible. Somedesign invariably occurs as part of analysis, and some analysis will be conductedduring design.
6.1.2 Analysis Rules of Thumb
Arlow and Neustadt [Arl02] suggest a number of worthwhile rules of thumb thatshould be followed when creating the analysis model:
•The model should focus on requirements that are visible within the problem orbusiness domain. The level of abstraction should be relatively high. “Don’t get bogged down in details” [Arl02] that try to explain how the system will work.
•Each element of the requirements model should add to an overall understandingof software requirements and provide insight into the information domain,function, and behavior of the system.
•Delay consideration of infrastructure and other nonfunctional models untildesign.That is, a database may be required, but the classes necessary toimplement it, the functions required to access it, and the behavior that will beexhibited as it is used should be considered only after problem domainanalysis has been completed.
•Minimize coupling throughout the system. It is important to represent relation- ships between classes and functions. However, if the level of “interconnect-edness” is extremely high, effort should be made to reduce it.
•Be certain that the requirements model provides value to all stakeholders. Each constituency has its own use for the model. For example, business stake-holders should use the model to validate requirements; designers should usethe model as a basis for design; QA people should use the model to help planacceptance tests.
•Keep the model as simple as it can be.Don’t create additional diagrams whenthey add no new information. Don’t use complex notational forms, when asimple list will do.
6.1.3 Domain Analysis
In the discussion of requirements engineering (Chapter 5), I noted that analysis pat-terns often reoccur across many applications within a specific business domain. Ifthese patterns are defined and categorized in a manner that allows you to recognizeand apply them to solve common problems, the creation of the analysis model isexpedited. More important, the likelihood of applying design patterns and executa-ble software components grows dramatically. This improves time-to-market andreduces development costs.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 151
uote:
“Problems worthyof attack, provetheir worth byhitting back.”Piet Hein
WebRef
Many useful resourcesfor domain analysis can be found atwww.iturls.com/English/SoftwareEngineering/SE_mod5.asp.Are therebasic guidelines thatcan help us as wedo requirementsanalysis work??pre75977_ch06.qxd  11/27/08  3:34 PM  Page 151152 PART TWOMODELING
But how are analysis patterns and classes recognized in the first place? Who de-fines them, categorizes them, and readies them for use on subsequent projects? Theanswers to these questions lie in domain analysis.Firesmith [Fir93] describes domain analysis in the following way:
Software domain analysis is the identification, analysis, and specification of common re-quirements from a specific application domain, typically for reuse on multiple projectswithin that application domain. . . . [Object-oriented domain analysis is] the identification,analysis, and specification of common, reusable capabilities within a specific applicationdomain, in terms of common objects, classes, subassemblies, and frameworks.
The “specific application domain” can range from avionics to banking, from multi-media video games to software embedded within medical devices. The goal of do-main analysis is straightforward: to find or create those analysis classes and/oranalysis patterns that are broadly applicable so that they may be reused.
4
Using terminology that was introduced earlier in this book, domain analysis maybe viewed as an umbrella activity for the software process. By this I mean that do-main analysis is an ongoing software engineering activity that is not connected toany one software project. In a way, the role of a domain analyst is similar to the roleof a master toolsmith in a heavy manufacturing environment. The job of the tool-smith is to design and build tools that may be used by many people doing similar butnot necessarily the same jobs. The role of the domain analyst
5is to discover and de- fine analysis patterns, analysis classes, and related information that may be used bymany people working on similar but not necessarily the same applications.Figure 6.2 [Ara89] illustrates key inputs and outputs for the domain analysisprocess. Sources of domain knowledge are surveyed in an attempt to identify objectsthat can be reused across the domain.Domain analysisdoesn’t look at aspecific application, butrather at the domain inwhich the applicationresides. The intent isto identify commonproblem solvingelements that areapplicable to allapplications withinthe domain.DomainanalysisSources ofdomainknowledge Customer surveysExpert adviceCurrent/future requirementsExisting applicationsTechnical literature Domainanalysismodel
Functional modelsDomain languagesReuse standardsClass taxonomiesFIGURE 6.2 Input and output for domain analysis
4 A complementary view of domain analysis “involves modeling the domain so that software engi-neers and other stakeholders can better learn about it . . . not all domain classes necessarily resultin the development of reusable classes . . .” [Let03a].5 Do not make the assumption that because a domain analyst is at work, a software engineer neednot understand the application domain. Every member of a software team should have some un-derstanding of the domain in which the software is to be placed.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 152CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 153
Domain Analysis
The scene:Doug Miller’s office, aftera meeting with marketing.The players:Doug Miller, software engineeringmanager, and Vinod Raman, a member of the softwareengineering team.The conversation:Doug:I need you for a special project, Vinod. I’m goingto pull you out of the requirements gathering meetings.Vinod (frowning):Too bad. That format actuallyworks . . . I was getting something out of it. What’s up?Doug:Jamie and Ed will cover for you. Anyway,marketing insists that we deliver the Internet capabilityalong with the home security function in the first release ofSafeHome.We’re under the gun on this . . . not enoughtime or people, so we’ve got to solve both problems—thePC interface and the Web interface—at once.Vinod (looking confused):I didn’t know the plan wasset . . . we’re not even finished with requirements gathering.Doug (a wan smile):I know, but the time lines are soshort that I decided to begin strategizing with marketingright now . . . anyhow, we’ll revisit any tentative planonce we have the info from all of the requirementsgathering meetings.Vinod:Okay, what’s up? What do you want me to do?Doug:Do you know what “domain analysis” is?Vinod:Sort of. You look for similar patterns in Appsthat do the same kinds of things as the App you’rebuilding. If possible, you then steal the patterns and reusethem in your work.Doug:Not sure I like the word steal,but basically youhave it right. What I’d like you to do is to begin researchingexisting user interfaces for systems that control somethinglike SafeHome. I want you to propose a set of patterns andanalysis classes that can be common to both the PC-basedinterface that’ll sit in the house and the browser-basedinterface that is accessible via the Internet.Vinod:We can save time by making them the same . . .why don’t we just do that?Doug:Ah . . . it’s nice to have people who think like youdo. That’s the whole point—we can save time and effort ifboth interfaces are nearly identical, implemented with thesame code, blah, blah, that marketing insists on.Vinod:So you want, what—classes, analysis patterns,design patterns?Doug:All of ‘em. Nothing formal at this point. I just wantto get a head start on our internal analysis and design work.Vinod:I’ll go to our class library and see what we’vegot. I’ll also use a patterns template I saw in a book I wasreading a few months back.Doug:Good. Go to work.SAFEHOME
6.1.4 Requirements Modeling Approaches
One view of requirements modeling, called structured analysis, considers data and the processes that transform the data as separate entities. Data objects are modeledin a way that defines their attributes and relationships. Processes that manipulatedata objects are modeled in a manner that shows how they transform data as dataobjects flow through the system.A second approach to analysis modeling, called object-oriented analysis,focuses on the definition of classes and the manner in which they collaborate with one an-other to effect customer requirements. UML and the Unified Process (Chapter 2) arepredominantly object oriented.Although the requirements model proposed in this book combines features ofboth approaches, software teams often choose one approach and exclude all repre-sentations from the other. The question is not which is best, but rather, whatuote:
“… analysis isfrustrating, fullof complexinterpersonalrelationships,indefinite, anddifficult. In a word, itis fascinating. Onceyou’re hooked, theold easy pleasures ofsystem building arenever again enoughto satisfy you.”Tom DeMarcopre75977_ch06.qxd  11/27/08  3:34 PM  Page 153154 PART TWOMODELING
combination of representations will provide stakeholders with the best model ofsoftware requirements and the most effective bridge to software design.Each element of the requirements model (Figure 6.3) presents the problem froma different point of view. Scenario-based elements depict how the user interacts withthe system and the specific sequence of activities that occur as the software is used.Class-based elements model the objects that the system will manipulate, the opera-tions that will be applied to the objects to effect the manipulation, relationships(some hierarchical) between the objects, and the collaborations that occur betweenthe classes that are defined. Behavioral elements depict how external events changethe state of the system or the classes that reside within it. Finally, flow-oriented ele-ments represent the system as an information transform, depicting how data objectsare transformed as they flow through various system functions.Analysis modeling leads to the derivation of each of these modeling elements.However, the specific content of each element (i.e., the diagrams that are used toconstruct the element and the model) may differ from project to project. As we havenoted a number of times in this book, the software team must work to keep it sim-ple. Only those modeling elements that add value to the model should be used.
6.2 S CENARIO -BASED MODELING
Although the success of a computer-based system or product is measured in manyways, user satisfaction resides at the top of the list. If you understand how end users(and other actors) want to interact with a system, your software team will be betterable to properly characterize requirements and build meaningful analysis and designWhatdifferentpoints of view can be used todescribe therequirementsmodel??
uote:
“Why should webuild models? Whynot just build thesystem itself? Theanswer is that wecan constructmodels in such away as to highlight,or emphasize,certain criticalfeatures of asystem, whilesimultaneouslyde-emphasizingother aspects ofthe system.”Ed YourdonSoftwareRequirementsClassmodelse.g.,class diagramscollaboration diagrams
Flowmodelse.g.,DFDsdata modelsScenario-basedmodelse.g.,use casesuser stories
Behavioralmodelse.g.,state diagramssequence diagramsFIGURE 6.3
Elements ofthe analysismodelpre75977_ch06.qxd  11/27/08  3:34 PM  Page 154models. Hence, requirements modeling with UML6begins with the creation of sce- narios in the form of use cases, activity diagrams, and swimlane diagrams.
6.2.1 Creating a Preliminary Use Case
Alistair Cockburn characterizes a use case as a “contract for behavior” [Coc01b]. Aswe discussed in Chapter 5, the “contract” defines the way in which an actor
7uses a computer-based system to accomplish some goal. In essence, a use case capturesthe interactions that occur between producers and consumers of information andthe system itself. In this section, I examine how use cases are developed as partof the requirements modeling activity.
8
In Chapter 5, I noted that a use case describes a specific usage scenario in straight-forward language from the point of view of a defined actor. But how do you know(1) what to write about, (2) how much to write about it, (3) how detailed to make yourdescription, and (4) how to organize the description? These are the questions thatmust be answered if use cases are to provide value as a requirements modeling tool.What to write about?The first two requirements engineering tasks—inceptionand elicitation—provide you with the information you’ll need to begin writing usecases. Requirements gathering meetings, QFD, and other requirements engineeringmechanisms are used to identify stakeholders, define the scope of the problem, spec-ify overall operational goals, establish priorities, outline all known functional re-quirements, and describe the things (objects) that will be manipulated by the system.To begin developing a set of use cases, list the functions or activities performedby a specific actor. You can obtain these from a list of required system functions,through conversations with stakeholders, or by an evaluation of activity diagrams(Section 6.3.1) developed as part of requirements modeling.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 155
uote:
“[Use cases] aresimply an aid todefining whatexists outside thesystem (actors)and what should beperformed by thesystem (usecases).”Ivar Jacobson
In some situations, usecases become thedominant requirementsengineeringmechanism. However,this does not meanthat you should discardother modelingmethods when theyare appropriate.
6 UML will be used as the modeling notation throughout this book. Appendix 1 provides a brief tuto-rial for those readers who may be unfamiliar with basic UML notation.7 An actor is not a specific person, but rather a role that a person (or a device) plays within a specificcontext. An actor “calls on the system to deliver one of its services” [Coc01b].8 Use cases are a particularly important part of analysis modeling for user interfaces. Interface analy-sis is discussed in detail in Chapter 11.The scene:A meeting room, duringthe second requirements gathering meeting.The players:Jamie Lazar, software team member; Ed Robbins, software team member; Doug Miller,software engineering manager; three members ofmarketing; a product engineering representative; and afacilitator.The conversation:Facilitator:It’s time that we begin talking abouttheSafeHomesurveillance function. Let’s develop a user scenario for access to the surveillance function.Jamie:Who plays the role of the actor on this?SAFEHOMEDeveloping Another Preliminary User Scenariopre75977_ch06.qxd  11/27/08  3:34 PM  Page 155156 PART TWOMODELING
The SafeHomehome surveillance function (subsystem) discussed in the sidebaridentifies the following functions (an abbreviated list) that are performed by thehomeowneractor:
•Select camera to view.
•Request thumbnails from all cameras.
•Display camera views in a PC window.
•Control pan and zoom for a specific camera.
•Selectively record camera output.
•Replay camera output.
•Access camera surveillance via the Internet.As further conversations with the stakeholder (who plays the role of a homeowner)progress, the requirements gathering team develops use cases for each of the func-tions noted. In general, use cases are written first in an informal narrative fashion. Ifmore formality is required, the same use case is rewritten using a structured formatsimilar to the one proposed in Chapter 5 and reproduced later in this section as asidebar.Facilitator:I think Meredith (a marketing person) hasbeen working on that functionality. Why don’t you playthe role?Meredith:You want to do it the same way we did it lasttime, right?Facilitator:Right. . . same way.Meredith:Well, obviously the reason for surveillance isto allow the homeowner to check out the house while heor she is away, to record and play back video that iscaptured . . . that sort of thing.Ed:Will we use compression to store the video?Facilitator:Good question, Ed, but let’s postponeimplementation issues for now. Meredith?Meredith:Okay, so basically there are two parts to thesurveillance function . . . the first configures the systemincluding laying out a floor plan—we have to have toolsto help the homeowner do this—and the second part isthe actual surveillance function itself. Since the layout ispart of the configuration activity, I’ll focus on thesurveillance function.Facilitator (smiling):Took the words right out of mymouth.Meredith:U m...I  want to gain access to thesurveillance function either via the PC or via the Internet.My feeling is that the Internet access would be morefrequently used. Anyway, I want to be able to displaycamera views on a PC and control pan and zoom for aspecific camera. I specify the camera by selecting it fromthe house floor plan. I want to selectively record cameraoutput and replay camera output. I also want to be ableto block access to one or more cameras with a specificpassword. I also want the option of seeing small windowsthat show views from all cameras and then be able topick the one I want enlarged.Jamie:Those are called thumbnail views.Meredith:Okay, then I want thumbnail views ofall the cameras. I also want the interface for thesurveillance function to have the same look and feelas all other SafeHomeinterfaces. I want it to beintuitive, meaning I don’t want to have to read a manualto use it.Facilitator:Good job. Now, let’s go into this function ina bit more detail . . .pre75977_ch06.qxd  11/27/08  3:34 PM  Page 156To illustrate, consider the function access camera surveillance via the Internet—display camera views(ACS-DCV).The stakeholder who takes on the role of thehomeowneractor might write the following narrative:
Use case: Access camera surveillance via the Internet—display camera views(ACS-DCV)Actor: homeownerIf I’m at a remote location, I can use any PC with appropriate browser software to logon to the SafeHome Productswebsite. I enter my user ID and two levels of passwords andonce I’m validated, I have access to all functionality for my installed SafeHomesystem. To access a specific camera view, I select “surveillance” from the major function buttons dis-played. I then select “pick a camera” and the floor plan of the house is displayed. I then se-lect the camera that I’m interested in. Alternatively, I can look at thumbnail snapshots fromall cameras simultaneously by selecting “all cameras” as my viewing choice. Once I choosea camera, I select “view” and a one-frame-per-second view appears in a viewing windowthat is identified by the camera ID. If I want to switch cameras, I select “pick a camera” andthe original viewing window disappears and the floor plan of the house is displayed again.I then select the camera that I’m interested in. A new viewing window appears.
A variation of a narrative use case presents the interaction as an ordered sequenceof user actions. Each action is represented as a declarative sentence. Revisiting theACS-DCVfunction, you would write:
Use case: Access camera surveillance via the Internet—display camera views(ACS-DCV)Actor: homeowner1. The homeowner logs onto the SafeHome Products website.2. The homeowner enters his or her user ID.3. The homeowner enters two passwords (each at least eight characters in length).4. The system displays all major function buttons.5. The homeowner selects the “surveillance” from the major function buttons.6. The homeowner selects “pick a camera.”7. The system displays the floor plan of the house.8. The homeowner selects a camera icon from the floor plan.9. The homeowner selects the “view” button.10. The system displays a viewing window that is identified by the camera ID.11. The system displays video output within the viewing window at one frame persecond.
It is important to note that this sequential presentation does not consider any alterna-tive interactions (the narrative is more free-flowing and did represent a few alterna-tives). Use cases of this type are sometimes referred to as primary scenarios[Sch98a].CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 157
uote:
“Use cases can beused in many[software]processes. Ourfavorite is aprocess that isiterative and riskdriven.”Geri Schneiderand JasonWinterspre75977_ch06.qxd  11/27/08  3:34 PM  Page 157158 PART TWOMODELING
6.2.2 Refining a Preliminary Use Case
A description of alternative interactions is essential for a complete understanding ofthe function that is being described by a use case. Therefore, each step in the primaryscenario is evaluated by asking the following questions [Sch98a]:
•Can the actor take some other action at this point?
•Is it possible that the actor will encounter some error condition at this point? If so, what might it be?
•Is it possible that the actor will encounter some other behavior at this point (e.g.,behavior that is invoked by some event outside the actor’s control)? If so, what might it be?Answers to these questions result in the creation of a set of secondary scenarios that are part of the original use case but represent alternative behavior. For example, con-sider steps 6 and 7 in the primary scenario presented earlier:
6. The homeowner selects “pick a camera.”7. The system displays the floor plan of the house.
Can the actor take some other action at this point? The answer is “yes.” Referring to the free-flowing narrative, the actor may choose to view thumbnail snapshots of allcameras simultaneously. Hence, one secondary scenario might be  “View thumbnailsnapshots for all cameras.”Is it possible that the actor will encounter some error condition at this point? Any number of error conditions can occur as a computer-based system operates. In thiscontext, we consider only error conditions that are likely as a direct result of the ac-tion described in step 6 or step 7. Again the answer to the question is “yes.” A floorplan with camera icons may have never been configured. Hence, selecting “pick acamera” results in an error condition: “No floor plan configured for this house.”
9This error condition becomes a secondary scenario.Is it possible that the actor will encounter some other behavior at this point? Again the answer to the question is “yes.” As steps 6 and 7 occur, the system may encounteran alarm condition. This would result in the system displaying a special alarm noti-fication (type, location, system action) and providing the actor with a number of op-tions relevant to the nature of the alarm. Because this secondary scenario can occurat any time for virtually all interactions, it will not become part of the ACS-DCV use case. Rather, a separate use case—Alarm condition encountered —would be de- veloped and referenced from other use cases as required.How do Iexaminealternativecourses of actionwhen I develop ause case??
9 In this case, another actor, the system administrator, would have to configure the floor plan, install and initialize (e.g., assign an equipment ID) all cameras, and test each camera to be certainthat it is accessible via the system and through the floor plan.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 158CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 159
Each of the situations described in the preceding paragraphs is characterized asa use-case exception. An exceptiondescribes a situation (either a failure condition oran alternative chosen by the actor) that causes the system to exhibit somewhatdifferent behavior.Cockburn [Coc01b] recommends using a “brainstorming” session to derive areasonably complete set of exceptions for each use case. In addition to the threegeneric questions suggested earlier in this section, the following issues should alsobe explored:
•Are there cases in which some “validation function” occurs during this use case?This implies that validation function is invoked and a potential error conditionmight occur.
•Are there cases in which a supporting function (or actor) will fail to respondappropriately?For example, a user action awaits a response but the functionthat is to respond times out.
•Can poor system performance result in unexpected or improper user actions? For example, a Web-based interface responds too slowly, resulting in a usermaking multiple selects on a processing button. These selects queue inap-propriately and ultimately generate an error condition.The list of extensions developed as a consequence of asking and answering thesequestions should be “rationalized” [Co01b] using the following criteria: an exceptionshould be noted within the use case if the software can detect the conditiondescribed and then handle the condition once it has been detected. In some cases,an exception will precipitate the development of another use case (to handle thecondition noted).
6.2.3 Writing a Formal Use Case
The informal use cases presented in Section 6.2.1 are sometimes sufficient forrequirements modeling. However, when a use case involves a critical activity ordescribes a complex set of steps with a significant number of exceptions, a more for-mal approach may be desirable.The ACS-DCVuse case shown in the sidebar follows a typical outline for formaluse cases. The goal in contextidentifies the overall scope of the use case. Thepreconditiondescribes what is known to be true before the use case is initiated.Thetriggeridentifies the event or condition that “gets the use case started” [Coc01b].The scenariolists the specific actions that are required by the actor and the appro-priate system responses. Exceptionsidentify the situations uncovered as the prelim-inary use case is refined (Section 6.2.2). Additional headings may or may not beincluded and are reasonably self-explanatory.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 159160 PART TWOMODELING
WebRef
When are you finishedwriting use cases? Fora worthwhile discussionof this topic, seeootips.org/use-cases-done.html.In many cases, there is no need to create a graphical representation of a usagescenario. However, diagrammatic representation can facilitate understanding, par-ticularly when the scenario is complex. As we noted earlier in this book, UML doesprovide use-case diagramming capability. Figure 6.4 depicts a preliminary use-casediagram for the SafeHomeproduct. Each use case is represented by an oval. Only theACS-DCVuse case  has been discussed in this section.Use case: Access camera surveillancevia the Internet—display cameraviews (ACS-DCV)Iteration:2, last modification: January 14 byV. Raman.Primary actor:Homeowner.Goal in context:To view output of camera placedthroughout the house from anyremote location via the Internet.Preconditions:System must be fully configured;appropriate user ID and passwordsmust be obtained.Trigger:The homeowner decides to take a look inside the house while away.Scenario:1. The homeowner logs onto the SafeHome Productswebsite.2. The homeowner enters his or her user ID.3. The homeowner enters two passwords (each at leasteight characters in length).4. The system displays all major function buttons.5. The homeowner selects the “surveillance” from themajor function buttons.6. The homeowner selects “pick a camera.”7. The system displays the floor plan of the house.8. The homeowner selects a camera icon from the floorplan.9. The homeowner selects the “view” button.10. The system displays a viewing window that isidentified by the camera ID.11. The system displays video output within the viewingwindow at one frame per second.Exceptions:1. ID or passwords are incorrect or not recognized—see use case Validate ID and passwords.2. Surveillance function not configured for thissystem—system displays appropriate error message;see use case Configure surveillance function.3. Homeowner selects “View thumbnail snapshots forall camera”—see use case View thumbnailsnapshots for all cameras.4. A floor plan is not available or has not beenconfigured—display appropriate error message andsee use case Configure floor plan.5. An alarm condition is encountered—see use caseAlarm condition encountered.Priority:Moderate priority, to beimplemented after basic functions.When available:Third increment.Frequency of use:Moderate frequency.Channel to actor:Via PC-based browser andInternet connection.Secondary actors:System administrator, cameras.Channels to secondary actors:1. System administrator: PC-based system.2. Cameras: wireless connectivity.Open issues:1. What mechanisms protect unauthorized use of thiscapability by employees of SafeHome Products ? 2. Is security sufficient? Hacking into this feature wouldrepresent a major invasion of privacy.3. Will system response via the Internet be acceptablegiven the bandwidth required for camera views?4. Will we develop a capability to provide video at ahigher frames-per-second rate when high-bandwidth connections are available?SAFEHOMEUse Case Template for Surveillancepre75977_ch06.qxd  11/27/08  3:34 PM  Page 160Every modeling notation has limitations, and the use case is no exception. Likeany other form of written description, a use case is only as good as its author(s). Ifthe description is unclear, the use case can be misleading or ambiguous. A use casefocuses on functional and behavioral requirements and is generally inappropriate fornonfunctional requirements. For situations in which the requirements model musthave significant detail and precision (e.g., safety critical systems), a use case may notbe sufficient.However, scenario-based modeling is appropriate for a significant majority of allsituations that you will encounter as a software engineer. If developed properly, theuse case can provide substantial benefit as a modeling tool.
6.3 UML M ODELS THATSUPPLEMENT THE USECASE
There are many requirements modeling situations in which a text-based model—even one as simple as a use case—may not impart information in a clear and con-cise manner. In such cases, you can choose from a broad array of UML graphicalmodels.
6.3.1 Developing an Activity Diagram
The UML activity diagram supplements the use case by providing a graphical repre-sentation of the flow of interaction within a specific scenario. Similar to the flowchart,an activity diagram uses rounded rectangles to imply a specific system function,arrows to represent flow through the system, decision diamonds to depict a branch-ing decision (each arrow emanating from the diamond is labeled), and solid horizon-tal lines to indicate that parallel activities are occurring. An activity diagram for theACS-DCVuse case is shown in Figure 6.5. It should be noted that the activity dia-gram adds additional detail not directly mentioned (but implied) by the use case.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 161
A UML activity diagramrepresents the actionsand decisions thatoccur as some functionis performed.Home-ownerAccess camera surveillance via the Internet
Configure SafeHome system parameters
Set alarmCamerasSafeHomeFIGURE 6.4
Preliminaryuse-casediagram forthe SafeHomesystempre75977_ch06.qxd  11/27/08  3:34 PM  Page 161162 PART TWOMODELING
For example, a user may only attempt to enter userID and passworda limited num- ber of times. This is represented by a decision diamond below “Prompt for reentry.”
6.3.2 Swimlane Diagrams
The UML swimlane diagramis a useful variation of the activity diagram and allowsyou to represent the flow of activities described by the use case and at the same timeindicate which actor (if there are multiple actors involved in a specific use case) oranalysis class (discussed later in this chapter) has responsibility for the action de-scribed by an activity rectangle. Responsibilities are represented as parallel seg-ments that divide the diagram vertically, like the lanes in a swimming pool.Three analysis classes—Homeowner, Camera, and Interface—have direct or indirect responsibilities in the context of the activity diagram represented in Figure 6.5.Enter password and user ID
Select majorfunctionValid passwords/IDPrompt for reentryInvalid passwords/ID
Input tries remain
No input tries remainSelect surveillanceOther functionsmay also be selected 
Thumbnail viewsSelect a specific camera
Select camera icon
Prompt for another viewSelect specific camera - thumbnails
Exit this function See another cameraView camera output in labeled windowFIGURE 6.5
Activitydiagram forAccesscamerasurveillancevia theInternet—displaycamera viewsfunction.
A UML swimlanediagram represents theflow of actions anddecisions and indicateswhich actors performeach.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 162CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 163
Enter password and user ID
Select major functionValid passwords/IDPrompt for reentryInvalid passwords/IDInput tries remain
No inputtries remainSelect surveillanceOther functionsmay also beselected 
Thumbnail viewsSelect a specific camera
Select camera iconGenerate videooutputSelect specificcamera - thumbnails
Exit thisfunction
SeeanothercameraHomeownerCameraInterface
Prompt foranother view View camera outputin labelled window FIGURE 6.6 Swimlane diagram for Access camera surveillance via the Internet—display cameraviews function
Referring to Figure 6.6, the activity diagram is rearranged so that activities associatedwith a particular analysis class fall inside the swimlane for that class. For example, theInterfaceclass represents the user interface as seen by the homeowner. The activitydiagram notes two prompts that are the responsibility of the interface—“prompt forreentry” and “prompt for another view.” These prompts and the decisions associatedwith them fall within the Interfaceswimlane. However, arrows lead from that swim-lane back to the Homeownerswimlane, where homeowner actions occur.Use cases, along with the activity and swimlane diagrams, are procedurally ori-ented. They represent the manner in which various actors invoke specific functions
uote:
“A good modelguides yourthinking, a bad onewarps it.”Brian Marickpre75977_ch06.qxd  11/27/08  3:34 PM  Page 163164 PART TWOMODELING
(or other procedural steps) to meet the requirements of the system. But a proceduralview of requirements represents only a single dimension of a system. In Section 6.4,I examine the information space and how data requirements can be represented.
6.4 D ATAMODELING CONCEPTS
If software requirements include the need to create, extend, or interface with a data-base or if complex data structures must be constructed and manipulated, the soft-ware team may choose to create a data model as part of overall requirements modeling. A software engineer or analyst defines all data objects that are processedwithin the system, the relationships between the data objects, and other informationthat is pertinent to the relationships. The entity-relationship diagram (ERD) addresses these issues and represents all data objects that are entered, stored, transformed,and produced within an application.
6.4.1 Data Objects
A data objectis a representation of composite information that must be understoodby software. By composite information, I mean something that has a number of dif- ferent properties or attributes. Therefore, width (a single value) would not be a validdata object, but dimensions(incorporating height, width, and depth) could bedefined as an object.A data object can be an external entity (e.g., anything that produces or consumesinformation), a thing (e.g., a report or a display), an occurrence (e.g., a telephonecall) or event (e.g., an alarm), a role (e.g., salesperson), an organizational unit (e.g.,accounting department), a place (e.g., a warehouse), or a structure (e.g., a file). Forexample, a personor a carcan be viewed as a data object in the sense that eithercan be defined in terms of a set of attributes. The description of the data objectincorporates the data object and all of its attributes.A data object encapsulates data only—there is no reference within a data objectto operations that act on the data.
10Therefore, the data object can be represented asa table as shown in Figure 6.7. The headings in the table reflect attributes of the ob-ject. In this case, a car is defined in terms of make, model, ID number, body type, color,and owner. The body of the table represents specific instances of the data object. Forexample, a Chevy Corvette is an instance of the data object car.
6.4.2 Data Attributes
Data attributesdefine the properties of a data object and take on one of three differentcharacteristics. They can be used to (1) name an instance of the data object, (2) describethe instance, or (3) make reference to another instance in another table. In addition,one or more of the attributes must be defined as an identifier—that is, the identifierWebRef
Useful information ondata modeling can befound at www.datamodel.org.
How does adata objectmanifest itselfwithin the contextof an application??
A data object is arepresentation of anycomposite informationthat is processed bysoftware.
Attributes name a dataobject, describe itscharacteristics, and insome cases, makereference to anotherobject.
10 This distinction separates the data object from the class or object defined as part of the object-oriented approach (Appendix 2).pre75977_ch06.qxd  11/27/08  3:34 PM  Page 164CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 165
11 Readers who are unfamiliar with object-oriented concepts and terminology should refer to the brieftutorial presented in Appendix 2.Make Model ID# Body type Color OwnerIdentifierInstance
LexusChevyBMWFordLS400Corvette750iLTaurusAB123. . .X456. . .XZ765. . .Q12A45. . .SedanSportsCoupeSedanWhiteRedWhiteBlueRSPCCDLJLBLFTies one data object to another,in this case, ownerNamingattributesDescriptiveattributesReferentialattributesFIGURE 6.7
Tabularrepresentationof data objects
attribute becomes a “key” when we want to find an instance of the data object. In somecases, values for the identifier(s) are unique, although this is not a requirement. Refer-ring to the data object car,a reasonable identifier might be the ID number.The set of attributes that is appropriate for a given data object is determinedthrough an understanding of the problem context. The attributes for car might serve well for an application that would be used by a department of motor vehicles, butthese attributes would be useless for an automobile company that needs manufac-turing control software. In the latter case, the attributes for car might also include ID number, body type,and color,but many additional attributes (e.g., interior code, drive traintype, trim package designator, transmission type ) would have to be added to make cara meaningful object in the manufacturing control context.
A common question occurs when data objectsare discussed: Is a data object the same thingas an object-oriented
11class? The answer is “no.”A data object defines a composite data item; that is,it incorporates a collection of individual data items(attributes) and gives the collection of items a name (thename of the data object).An object-oriented class encapsulates data attributesbut also incorporates the operations (methods) thatmanipulate the data implied by those attributes.In addition, the definition of classes implies acomprehensive infrastructure that is part of the object-oriented software engineering approach. Classescommunicate with one another via messages, they canbe organized into hierarchies, and they provideinheritance characteristics for objects that are aninstance of a class.INFO
6.4.3 Relationships
Data objects are connected to one another in different ways. Consider the two dataobjects, personand car.These objects can be represented using the simple notationWebRef
A concept called“normalization” isimportant to those whointend to do thoroughdata modeling. Auseful introductioncan be found atwww.datamodel.org.
Data Objects and Object-Oriented Classes—Are They the Same Thing?pre75977_ch06.qxd  11/27/08  3:34 PM  Page 165166 PART TWOMODELING
INFOperson car
(a)  A basic connection between dataobjectsownsinsured todrive(b)  Relationships between dataobjects
personcarFIGURE 6.8
Relationshipsbetween dataobjects
illustrated in Figure 6.8a. A connection is established between person and car because the two objects are related. But what are the relationships? To determine theanswer, you should understand the role of people (owners, in this case) and carswithin the context of the software to be built. You can establish a set of object/relationship pairs that define the relevant relationships. For example,
•A person ownsa car.
•A person is insured to drivea car.The relationships ownsand insured to drivedefine the relevant connections betweenpersonand car.Figure 6.8b illustrates these object-relationship pairs graphically.The arrows noted in Figure 6.8b provide important information about the direction-ality of the relationship and often reduce ambiguity or misinterpretations.
12 Although the ERD is still used in some database design applications, UML notation (Appendix 1)can now be used for data design.13 The cardinalityof an object-relationship pair specifies “the number of occurrences of one [object]that can be related to the number of occurrences of another [object]” {Til93]. The modality of a re- lationship is 0 if there is no explicit need for the relationship to occur or the relationship is optional.The modality is 1 if an occurrence of the relationship is mandatory.Relationships indicatethe manner in whichdata objects areconnected to oneanother.
Entity-Relationship Diagrams
The object-relationship pair is the cornerstoneof the data model. These pairs can berepresented graphically using the entity-relationshipdiagram (ERD).
12The ERD was originally proposed byPeter Chen [Che77] for the design of relational databasesystems and has been extended by others. A set ofprimary components is identified for the ERD: data objects,attributes, relationships, and various type indicators. Theprimary purpose of the ERD is to represent data objectsand their relationships.Rudimentary ERD notation has already beenintroduced. Data objects are represented by a labeledrectangle. Relationships are indicated with a labeled lineconnecting objects. In some variations of the ERD, theconnecting line contains a diamond that is labeled with therelationship. Connections between data objects andrelationships are established using a variety of specialsymbols that indicate cardinality and modality.
13If you desire further information about data modeling and theentity-relationship diagram, see [Hob06] or [Sim05].pre75977_ch06.qxd  11/27/08  3:34 PM  Page 1666.5 C LASS-BASED MODELING
Class-based modeling represents the objects that the system will manipulate, theoperations (also called methods or services) that will be applied to the objects toeffect the manipulation, relationships (some hierarchical) between the objects, andthe collaborations that occur between the classes that are defined. The elementsof a class-based model include classes and objects, attributes, operations, class-responsibility-collaborator (CRC) models, collaboration diagrams, and packages.The sections that follow present a series of informal guidelines that will assist intheir identification and representation.
6.5.1 Identifying Analysis Classes
If you look around a room, there is a set of physical objects that can be easily iden-tified, classified, and defined (in terms of attributes and operations). But when you“look around” the problem space of a software application, the classes (and objects)may be more difficult to comprehend.We can begin to identify classes by examining the usage scenarios developed aspart of the requirements model and performing a “grammatical parse” [Abb83] onthe use cases developed for the system to be built. Classes are determined by un-derlining each noun or noun phrase and entering it into a simple table. Synonymsshould be noted. If the class (noun) is required to implement a solution, then it is partof the solution space; otherwise, if a class is necessary only to describe a solution, itis part of the problem space.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 167
Data Modeling
Objective:Data modeling tools provide asoftware engineer with the ability to representdata objects, their characteristics, and their relationships.Used primarily for large database applications and otherinformation systems projects, data modeling tools providean automated means for creating comprehensive entity-relation diagrams, data object dictionaries, and relatedmodels.Mechanics:Tools in this category enable the user todescribe data objects and their relationships. In some cases,the tools use ERD notation. In others, the tools model relationsusing some other mechanism. Tools in this category are oftenused as part of database design and enable the creation ofa database model by generating a database schema forcommon database management systems (DBMS).Representative Tools:14
AllFusion ERWin,developed by Computer Associates(www3.ca.com), assists in the design of data objects,proper structure, and key elements for databases.ER/Studio,developed by Embarcadero Software(www.embarcadero.com), supports entity-relationship modeling.Oracle Designer,developed by Oracle Systems(www.oracle.com), “models business processes,data entities and relationships [that] are transformedinto designs from which complete applications anddatabases are generated.”Visible Analyst,developed by Visible Systems(www.visible.com), supports a variety of analysismodeling functions including data modeling.SOFTWARE TOOLS
14 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.uote:
“The really hardproblem isdiscovering whatare the rightobjects [classes] inthe first place.”Carl Argilapre75977_ch06.qxd  11/27/08  3:34 PM  Page 167168 PART TWOMODELING
But what should we look for once all of the nouns have been isolated? Analysisclassesmanifest themselves in one of the following ways:
•External entities(e.g., other systems, devices, people) that produce orconsume information to be used by a computer-based system.
•Things(e.g., reports, displays, letters, signals) that are part of the informationdomain for the problem.
•Occurrences or events(e.g., a property transfer or the completion of a seriesof robot movements) that occur within the context of system operation.
•Roles(e.g., manager, engineer, salesperson) played by people who interactwith the system.
•Organizational units(e.g., division, group, team) that are relevant to an appli-cation.
•Places(e.g., manufacturing floor or loading dock) that establish the context ofthe problem and the overall function of the system.
•Structures(e.g., sensors, four-wheeled vehicles, or computers) that define aclass of objects or related classes of objects.This categorization is but one of many that have been proposed in the literature.
15
For example, Budd [Bud96] suggests a taxonomy of classes that includes producers (sources) and consumers(sinks) of data, data managers, viewor observer classes, and helper classes.It is also important to note what classes or objects are not. In general, a classshould never have an “imperative procedural name” [Cas89]. For example, if the de-velopers of software for a medical imaging system defined an object with the nameInvertImageor even ImageInversion,they would be making a subtle mistake. TheImageobtained from the software could, of course, be a class (it is a thing that ispart of the information domain). Inversion of the image is an operation that is ap-plied to the object. It is likely that inversion would be defined as an operation for theobject Image,but it would not be defined as a separate class to connote “imageinversion.” As Cashman [Cas89] states: “the intent of object-orientation is to encap-sulate, but still keep separate, data and operations on the data.”To illustrate how analysis classes might be defined during the early stages of mod-eling, consider a grammatical parse (nouns are underlined, verbs italicized) for aprocessing narrative
16for the SafeHomesecurity function.How doanalysisclasses manifestthemselves aselements of thesolution space??
15 Another important categorization, defining entity, boundary, and controller classes, is discussed inSection 6.5.4.16 A processing narrative is similar to the use case in style but somewhat different in purpose. Theprocessing narrative provides an overall description of the function to be developed. It is not a sce-nario written from one actor’s point of view. It is important to note, however, that a grammaticalparse can also be used for every use case developed as part of requirements gathering (elicitation).pre75977_ch06.qxd  11/27/08  3:34 PM  Page 168The SafeHome security function enablesthe homeowner to configurethe security system
when it is installed, monitorsall sensors connectedto the security system, and interacts with the homeowner through the Internet
, a PC , or a control panel . During installation
, the SafeHome PC is used to program and configurethe system . Each sensor is assigned a number
and type , a master password is programmed for arming and disarmingthe system, and telephone number(s)
are inputfor dialingwhen a sensor
event occurs.When a sensor event is recognized , the software invokesan audible alarm
attached to the system. After a delay time
that is specifiedby the homeowner during system configu- ration activities, the software dials a telephone number of a monitoring service
, provides information
about the location , reportingthe nature of the event that has been detected. The telephone number will be redialed every 20 seconds until telephone connection
is obtained.The homeowner receivessecurity information
via a control panel, the PC, or a browser, collectively called an interface
. The interface displaysprompting messages and system
status information on the control panel, the PC ,or the browser window. Homeowner in-teraction takes the following form . . . 
Extracting the nouns, we can propose a number of potential classes:
Potential ClassGeneral Classificationhomeownerrole or external entitysensorexternal entitycontrol panelexternal entityinstallationoccurrencesystem (alias security system) thingnumber, typenot objects, attributes of sensormaster passwordthingtelephone numberthingsensor eventoccurrenceaudible alarmexternal entity
monitoring serviceorganizational unit or external entity
The list would be continued until all nouns in the processing narrative have beenconsidered. Note that I call each entry in the list a potential object. You must considereach further before a final decision is made.Coad and Yourdon [Coa91] suggest six selection characteristics that should beused as you consider each potential class for inclusion in the analysis model:1.Retained information.The potential class will be useful during analysis only ifinformation about it must be remembered so that the system can function.2.Needed services.The potential class must have a set of identifiable operationsthat can change the value of its attributes in some way.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 169
The grammatical parseis not foolproof, but itcan provide you withan excellent jumpstart, if you’re strug-gling to define dataobjects and the trans-forms that operate onthem.
How do Ideterminewhether apotential classshould, in fact,become ananalysis class??pre75977_ch06.qxd  11/27/08  3:34 PM  Page 169170 PART TWOMODELING
3.Multiple attributes.During requirement analysis, the focus should be on“major” information; a class with a single attribute may, in fact, be usefulduring design, but is probably better represented as an attribute of anotherclass during the analysis activity.4.Common attributes.A set of attributes can be defined for the potential classand these attributes apply to all instances of the class.5.Common operations.A set of operations can be defined for the potential classand these operations apply to all instances of the class.6.Essential requirements.External entities that appear in the problem space andproduce or consume information essential to the operation of any solution forthe system will almost always be defined as classes in the requirements model.To be considered a legitimate class for inclusion in the requirements model, a po-tential object should satisfy all (or almost all) of these characteristics. The decisionfor inclusion of potential classes in the analysis model is somewhat subjective, andlater evaluation may cause an object to be discarded or reinstated. However, the firststep of class-based modeling is the definition of classes, and decisions (even sub-jective ones) must be made. With this in mind, you should apply the selection char-acteristics to the list of potential SafeHome classes:
Potential ClassCharacteristic Number That Applieshomeownerrejected: 1, 2 fail even though 6 appliessensoraccepted: all applycontrol panelaccepted: all applyinstallationrejectedsystem (alias security function) accepted: all applynumber, typerejected: 3 fails, attributes of sensormaster passwordrejected: 3 failstelephone numberrejected: 3 failssensor eventaccepted: all applyaudible alarmaccepted: 2, 3, 4, 5, 6 apply
monitoring servicerejected: 1, 2 fail even though 6 applies
It should be noted that (1) the preceding list is not all-inclusive, additional classeswould have to be added to complete the model; (2) some of the rejected potentialclasses will become attributes for those classes that were accepted (e.g., number and typeare attributes of Sensor,and master passwordand telephone numbermay become attributes of System); (3) different statements of the problem might cause different“accept or reject” decisions to be made (e.g., if each homeowner had an individualpassword or was identified by voice print, the Homeowner class would satisfy char- acteristics 1 and 2 and would have been accepted).uote:
“Classes struggle,some classestriumph, others areeliminated.”Mao Zedongpre75977_ch06.qxd  11/27/08  3:34 PM  Page 1706.5.2 Specifying Attributes
Attributesdescribe a class that has been selected for inclusion in the requirementsmodel. In essence, it is the attributes that define the class—that clarify what ismeant by the class in the context of the problem space. For example, if we were tobuild a system that tracks baseball statistics for professional baseball players, theattributes of the class Playerwould be quite different than the attributes of thesame class when it is used in the context of the professional baseball pension sys-tem. In the former, attributes such as name, position, batting average, fielding percentage,years played,and games playedmight be relevant. For the latter, some of these attrib-utes would be meaningful, but others would be replaced (or augmented) by attrib-utes like average salary, credit toward full vesting, pension plan options chosen, mailingaddress,and the like.To develop a meaningful set of attributes for an analysis class, you should studyeach use case and select those “things” that reasonably “belong” to the class. In ad-dition, the following question should be answered for each class: “What data items(composite and/or elementary) fully define this class in the context of the problemat hand?”To illustrate, we consider the Systemclass defined for SafeHome.A homeowner can configure the security function to reflect sensor information, alarm responseinformation, activation/deactivation information, identification information, and soforth. We can represent these composite data items in the following manner:
identification information /H11549system ID /H11545verification phone number /H11545system status alarm response information /H11549delay time /H11545telephone numberactivation/deactivation information /H11549master password /H11545number of allowable tries /H11545 temporary password
Each of the data items to the right of the equal sign could be further defined to anelementary level, but for our purposes, they constitute a reasonable list of attributesfor the Systemclass (shaded portion of Figure 6.9).Sensors are part of the overall SafeHome system, and yet they are not listed as data items or as attributes in Figure 6.9. Sensor has already been defined as a class, and multiple Sensorobjects will be associated with the System class. In general, we avoid defining an item as an attribute if more than one of the items is to be as-sociated with the class.
6.5.3 Defining Operations
Operationsdefine the behavior of an object. Although many different types of oper-ations exist, they can generally be divided into four broad categories: (1) operationsthat manipulate data in some way (e.g., adding, deleting, reformatting, selecting), (2) operations that perform a computation, (3) operations that inquire about the stateCHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 171
Attributes are the setof data objects thatfully define the classwithin the context ofthe problem.
When you defineoperations for ananalysis class, focus onproblem-orientedbehavior rather thanbehaviors required forimplementation.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 171172 PART TWOMODELING
of an object, and (4) operations that monitor an object for the occurrence of a con-trolling event. These functions are accomplished by operating on attributes and/orassociations (Section 6.5.5). Therefore, an operation must have “knowledge” of thenature of the class’ attributes and associations.As a first iteration at deriving a set of operations for an analysis class, you canagain study a processing narrative (or use case) and select those operations that rea-sonably belong to the class. To accomplish this, the grammatical parse is again stud-ied and verbs are isolated. Some of these verbs will be legitimate operations and canbe easily connected to a specific class. For example, from the SafeHome processing narrative presented earlier in this chapter, we see that “sensor is assigneda number and type” or “a master password is programmed for arming and disarmingthe system.” These phrases indicate a number of things:
•That an assign()operation is relevant for the Sensorclass.
•That a program()operation will be applied to the System class.
•That arm()and disarm()are operations that apply to Systemclass. Upon further investigation, it is likely that the operation program() will be divided into a number of more specific suboperations required to configure the system. For ex-ample, program()implies specifying phone numbers, configuring system character-istics (e.g., creating the sensor table, entering alarm characteristics), and enteringpassword(s). But for now, we specify program() as a single operation. In addition to the grammatical parse, you can gain additional insight into otheroperations by considering the communication that occurs between objects. Objectscommunicate by passing messages to one another. Before continuing with the spec-ification of operations, I explore this matter in a bit more detail.System
program( )display( ) reset( ) query( ) arm( ) disarm( ) systemIDverificationPhoneNumbersystemStatusdelayTimetelephoneNumbermasterPasswordtemporaryPasswordnumberTries       FIGURE 6.9
Class diagramfor the systemclasspre75977_ch06.qxd  11/27/08  3:34 PM  Page 172CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 173
Class Models
The scene:Ed’s cubicle, asrequirements modeling begins.The players:Jamie, Vinod, and Ed—all members ofthe SafeHomesoftware engineering team.The conversation:[Ed has been working to extract classes from the use casetemplate for ACS-DCV (presented in an earlier sidebar inthis chapter) and is presenting the classes he hasextracted to his colleagues.]Ed:So when the homeowner wants to pick a camera, heor she has to pick it from a floor plan. I’ve defined aFloorPlanclass. Here’s the diagram.(They look at Figure 6.10.)Jamie:So FloorPlanis an object that is put togetherwith walls, doors, windows, and cameras. That’s whatthose labeled lines mean, right?Ed:Yeah, they’re called “associations.” One class isassociated with another according to the associations I’veshown. [Associations are discussed in Section 6.5.5.]Vinod:So the actual floor plan is made up of walls andcontains cameras and sensors that are placed withinthose walls. How does the floor plan know where to putthose objects?Ed:It doesn’t, but the other classes do. See the attributesunder, say, WallSegment,which is used to build awall. The wall segment has start and stop coordinates andthe draw()operation does the rest.Jamie:And the same goes for windows and doors.Looks like camera has a few extra attributes.Ed:Yeah, I need them to provide pan and zoom info.Vinod:I have a question. Why does the camera havean ID but the others don’t? I notice you have an attributecalled 
nextWall. How will WallSegmentknow what the next wall will be?Ed:Good question, but as they say, that’s a designdecision, so I’m going to delay that until . . .Jamie:Give me a break. . . I’ll bet you’ve alreadyfigured it out.Ed (smiling sheepishly):True, I’m gonna use a liststructure which I’ll model when we get to design. If youget religious about separating analysis and design, thelevel of detail I have right here could be suspect.Jamie:Looks pretty good to me, but I have a few morequestions.(Jamie asks questions which result in minor modifications)Vinod:Do you have CRC cards for each of the objects?If so, we ought to role-play through them, just to makesure nothing has been omitted.Ed:I’m not quite sure how to do them.Vinod:It’s not hard and they really pay off. I’ll showyou.SAFEHOME
6.5.4 Class-Responsibility-Collaborator (CRC) Modeling
Class-responsibility-collaborator (CRC) modeling [Wir90] provides a simple means for identifying and organizing the classes that are relevant to system or productrequirements. Ambler [Amb95] describes CRC modeling in the following way:
A CRC model is really a collection of standard index cards that represent classes. Thecards are divided into three sections. Along the top of the card you write the name of theclass. In the body of the card you list the class responsibilities on the left and the collab-orators on the right.
In reality, the CRC model may make use of actual or virtual index cards. The intent isto develop an organized representation of classes. Responsibilities are the attributes and operations that are relevant for the class. Stated simply, a responsibility is“anything the class knows or does” [Amb95]. Collaboratorsare those classes that areuote:
“One purpose ofCRC cards is to failearly, to fail often,and to failinexpensively. It isa lot cheaper totear up a bunch ofcards than it wouldbe to reorganize alarge amount ofsource code.”C. Horstmannpre75977_ch06.qxd  11/27/08  3:34 PM  Page 173174 PART TWOMODELING
required to provide a class with the information needed to complete a responsibility.In general, a collaborationimplies either a request for information or a request forsome action.A simple CRC index card for the FloorPlan class is illustrated in Figure 6.11. The list of responsibilities shown on the CRC card is preliminary and subject to additionsor modification. The classes Walland Cameraare noted next to the responsibility that will require their collaboration.Classes.Basic guidelines for identifying classes and objects were presentedearlier in this chapter. The taxonomy of class types presented in Section 6.5.1 can beextended by considering the following categories:
•Entity classes, also called modelor businessclasses, are extracted directly from the statement of the problem (e.g., FloorPlan and Sensor). TheseFloorPlan
determineType( ) positionFloorplan( ) scale( ) change color( ) type name outsideDimensions 
Camera
determineType( )  translateLocation( ) displayID( ) displayView( ) displayZoom( )  type ID location fieldView panAngle ZoomSetting 
WallSegment
type startCoordinates stopCoordinates nextWallSement 
determineType( ) draw( )  Window
type startCoordinates stopCoordinates nextWindow 
determineType( ) draw( )  Is placed within
Wall
type wallDimensions  
determineType( ) computeDimensions ( )
Door
type startCoordinates stopCoordinates nextDoor
determineType( ) draw( )  Is part of
Is used to buildIs used to buildIs used to buildFIGURE 6.10
Class diagramfor FloorPlan(see sidebardiscussion)
WebRef
An excellent discussionof these class typescan be found atwww.theumlcafe.com/a0079.htm.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 174classes typically represent things that are to be stored in a database andpersist throughout the duration of the application (unless they are specificallydeleted).
•Boundary classesare used to create the interface (e.g., interactive screen orprinted reports) that the user sees and interacts with as the software is used.Entity objects contain information that is important to users, but they do notdisplay themselves. Boundary classes are designed with the responsibility ofmanaging the way entity objects are represented to users. For example, aboundary class called CameraWindow would have the responsibility of displaying surveillance camera output for the SafeHome system.
•Controller classesmanage a “unit of work” [UML03] from start to finish. Thatis, controller classes can be designed to manage (1) the creation or update ofentity objects, (2) the instantiation of boundary objects as they obtain infor-mation from entity objects, (3) complex communication between sets ofobjects, (4) validation of data communicated between objects or between theuser and the application. In general, controller classes are not considereduntil the design activity has begun.Responsibilities.Basic guidelines for identifying responsibilities (attributes andoperations) have been presented in Sections 6.5.2 and 6.5.3. Wirfs-Brock and hercolleagues [Wir90] suggest five guidelines for allocating responsibilities to classes:1.System intelligence should be distributed across classes to bestaddress the needs of the problem. Every application encompasses a certain degree of intelligence; that is, what the system knows and what itcan do. This intelligence can be distributed across classes in a number ofCHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 175
Class:
Des
Res Co llaaborat or:Class:
De
Coollaborator:Class:
D
CCollaborat or:Class: FloorPlan
Description
Responsibility:Collaborator:
Incorporates walls, doors, and windowsShows position of video camerasDefines floor plan name/typeManages floor plan positioningScales floor plan for displayScales floor plan for displayWallCameraFIGURE 6.11
A CRC modelindex card
uote:
“Objects can beclassifiedscientifically intothree majorcategories: thosethat don’t work,those that breakdown, and thosethat get lost.”Russell Baker
Whatguidelinescan be appliedfor allocatingresponsibilitiesto classes??pre75977_ch06.qxd  11/27/08  3:34 PM  Page 175176 PART TWOMODELING
different ways. “Dumb” classes (those that have few responsibilities) canbe modeled to act as servants to a few “smart” classes (those having manyresponsibilities). Although this approach makes the flow of control in asystem straightforward, it has a few disadvantages: it concentrates all intelli-gence within a few classes, making changes more difficult, and it tends torequire more classes, hence more development effort.If system intelligence is more evenly distributed across the classes in anapplication, each object knows about and does only a few things (that aregenerally well focused), the cohesiveness of the system is improved.
17 This enhances the maintainability of the software and reduces the impact of sideeffects due to change.To determine whether system intelligence is properly distributed, the re-sponsibilities noted on each CRC model index card should be evaluated todetermine if any class has an extraordinarily long list of responsibilities. Thisindicates a concentration of intelligence.
18 In addition, the responsibilities for each class should exhibit the same level of abstraction. For example, amongthe operations listed for an aggregate class called CheckingAccounta re- viewer notes two responsibilities: balance-the-accountand check-off-cleared- checks.The first operation (responsibility) implies a complex mathematicaland logical procedure. The second is a simple clerical activity. Since thesetwo operations are not at the same level of abstraction, check-off-cleared-checksshould be placed within the responsibilities of CheckEntry, a classthat is encompassed by the aggregate class CheckingAccount.2.Each responsibility should be stated as generally as possible. This guideline implies that general responsibilities (both attributes and operations)should reside high in the class hierarchy (because they are generic, they willapply to all subclasses).3.Information and the behavior related to it should reside within thesame class.This achieves the object-oriented principle called encapsulation.Data and the processes that manipulate the data should be packaged as acohesive unit.4.Information about one thing should be localized with a single class,not distributed across multiple classes. A single class should take on the responsibility for storing and manipulating a specific type of information.This responsibility should not, in general, be shared across a number ofclasses. If information is distributed, software becomes more difficult tomaintain and more challenging to test.
17 Cohesiveness is a design concept that is discussed in Chapter 8.18 In such cases, it may be necessary to spit the class into multiple classes or complete subsystems inorder to distribute intelligence more effectively.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 1765.Responsibilities should be shared among related classes, whenappropriate.There are many cases in which a variety of related objectsmust all exhibit the same behavior at the same time. As an example, considera video game that must display the following classes: Player, PlayerBody,PlayerArms, PlayerLegs, PlayerHead. Each of these classes has its own attributes (e.g., position, orientation, color, speed ) and all must be updated and displayed as the user manipulates a joystick. The responsibilities update()anddisplay()must therefore be shared by each of the objects noted. Playerknows when something has changed and update() is required. It collaborates with the other objects to achieve a new position or orientation, but eachobject controls its own display.Collaborations.Classes fulfill their responsibilities in one of two ways: (1) A classcan use its own operations to manipulate its own attributes, thereby fulfilling a par-ticular responsibility, or (2) a class can collaborate with other classes. Wirfs-Brockand her colleagues [Wir90] define collaborations in the following way:
Collaborations represent requests from a client to a server in fulfillment of a clientresponsibility. A collaboration is the embodiment of the contract between the client andthe server....W e  say that an object collaborates with another object if, to fulfill aresponsibility, it needs to send the other object any messages. A single collaborationflows in one direction—representing a request from the client to the server. From theclient’s point of view, each of its collaborations is associated with a particular responsi-bility implemented by the server.
Collaborations are identified by determining whether a class can fulfill each respon-sibility itself. If it cannot, then it needs to interact with another class. Hence, acollaboration.As an example, consider the SafeHome security function. As part of the activa- tion procedure, the ControlPanelobject must determine whether any sensorsare open. A responsibility named determine-sensor-status() is defined. If sensors are open, ControlPanelmust set a statusattribute to “not ready.” Sensor information can be acquired from each Sensorobject. Therefore, the responsibility determine-sensor-status()can be fulfilled only if ControlPanelworks in collaboration with Sensor.To help in the identification of collaborators, you can examine three differentgeneric relationships between classes [Wir90]: (1) the is-part-ofrelationship, (2) the has-knowledge-ofrelationship, and (3) the depends-upon relationship. Each of the three generic relationships is considered briefly in the paragraphs that follow.All classes that are part of an aggregate class are connected to the aggregate classvia an is-part-ofrelationship. Consider the classes defined for the video game notedearlier, the class PlayerBodyis-part-ofPlayer,as are PlayerArms, PlayerLegs, and PlayerHead.In UML, these relationships are represented as the aggregationshown in Figure 6.12.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 177pre75977_ch06.qxd  11/27/08  3:34 PM  Page 177178 PART TWOMODELING
When one class must acquire information from another class, the has-knowledge-ofrelationship is established. The determine-sensor-status() responsibility noted ear- lier is an example of a has-knowledge-of relationship.The depends-uponrelationship implies that two classes have a dependency thatis not achieved by has-knowledge-ofor is-part-of.For example, PlayerHeadmust always be connected to PlayerBody(unless the video game is particularly violent),yet each object could exist without direct knowledge of the other. An attribute of thePlayerHeadobject called center-positionis determined from the center position ofPlayerBody.This information is obtained via a third object, Player, that acquires it from PlayerBody.Hence, PlayerHeaddepends-uponPlayerBody. In all cases, the collaborator class name is recorded on the CRC model index cardnext to the responsibility that has spawned the collaboration. Therefore, the indexcard contains a list of responsibilities and the corresponding collaborations thatenable the responsibilities to be fulfilled (Figure 6.11).When a complete CRC model has been developed, stakeholders can review themodel using the following approach [Amb95]:1.All participants in the review (of the CRC model) are given a subset of theCRC model index cards. Cards that collaborate should be separated (i.e., noreviewer should have two cards that collaborate).2.All use-case scenarios (and corresponding use-case diagrams) should beorganized into categories.3.The review leader reads the use case deliberately. As the review leadercomes to a named object, she passes a token to the person holding the corre-sponding class index card. For example, a use case for SafeHome contains the following narrative:
The homeowner observes the SafeHomecontrol panel to determine if the system is ready for input. If the system is not ready, the homeowner must physically close Player
PlayerHead PlayerBody PlayerArms PlayerLegsFIGURE 6.12
A compositeaggregateclasspre75977_ch06.qxd  11/27/08  3:34 PM  Page 178windows/doors so that the ready indicator is present. [A not-ready indicator impliesthat a sensor is open, i.e., that a door or window is open.]
When the review leader comes to “control panel,” in the use case narrative,the token is passed to the person holding the ControlPanel index card. The phrase “implies that a sensor is open” requires that the index card contains aresponsibility that will validate this implication (the responsibility determine- sensor-status()accomplishes this). Next to the responsibility on the index cardis the collaborator Sensor.The token is then passed to the Sensor object. 4.When the token is passed, the holder of the Sensor card is asked to describe the responsibilities noted on the card. The group determines whether one (ormore) of the responsibilities satisfies the use-case requirement.5.If the responsibilities and collaborations noted on the index cards cannotaccommodate the use case, modifications are made to the cards. This mayinclude the definition of new classes (and corresponding CRC index cards) orthe specification of new or revised responsibilities or collaborations onexisting cards.This modus operandi continues until the use case is finished. When all use caseshave been reviewed, requirements modeling continues.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 179
CRC Models
The scene:Ed’s cubicle, asrequirements modeling begins.The players:Vinod and Ed—members of theSafeHomesoftware engineering team.The conversation:[Vinod has decided to show Ed how to develop CRC cardsby showing him an example.]Vinod:While you’ve been working on surveillance andJamie has been tied up with security, I’ve been workingon the home management function.Ed:What’s the status of that? Marketing kept changingits mind.Vinod:Here’s the first-cut use case for the wholefunction . . .  we’ve refined it a bit, but it should give youan overall view . . .Use case:SafeHomehome management function.Narrative:We want to use the home managementinterface on a PC or an Internet connection to controlelectronic devices that have wireless interface controllers. The system should allow me to turn specific lights on andoff, to control appliances that are connected to a wirelessinterface, to set my heating and air conditioning system totemperatures that I define. To do this, I want to select thedevices from a floor plan of the house. Each device mustbe identified on the floor plan. As an optional feature, Iwant to control all audiovisual devices—audio, television,DVD, digital recorders, and so forth.With a single selection, I want to be able to set theentire house for various situations. One is home,another is away,a third is overnight travel,and a fourth isextended travel.All of these situations will have settingsthat will be applied to all devices. In the overnight traveland extended travelstates, the system should turn lightson and off at random intervals (to make it look likesomeone is home) and control the heating and airconditioning system. I should be able to override thesesetting via the Internet with appropriate passwordprotection . . .Ed:The hardware guys have got all the wirelessinterfacing figured out?SAFEHOMEpre75977_ch06.qxd  11/27/08  3:34 PM  Page 179180 PART TWOMODELING
6.5.5 Associations and Dependencies
In many instances, two analysis classes are related to one another in some fashion,much like two data objects may be related to one another (Section 6.4.3). In UMLthese relationships are called associations.Referring back to Figure 6.10, the FloorPlanclass is defined by identifying a set of associations between FloorPlanand two other classes, Cameraand Wall.The class Wallis associated with three classes that allow a wall to be constructed, WallSegment, Window,andDoor.In some cases, an association may be further defined by indicating multiplicity. Re- ferring to Figure 6.10, a Wallobject is constructed from one or more WallSegmentobjects. In addition, the Wallobject may contain 0 or more Window objects and 0 or more Doorobjects. These multiplicity constraints are illustrated in Figure 6.13,where “one or more” is represented using 1. .*, and “0 or more” by 0 . .*. In UML, theasterisk indicates an unlimited upper bound on the range.
19Vinod (smiling):They’re working on it; say it’s noproblem. Anyway, I extracted a bunch of classes forhome management and we can use one as an example.Let’s use the HomeManagementInterfaceclass.Ed:Okay . . . so the responsibilities are what...t h e attributes and operations for the class and thecollaborations are the classes that the responsibilitiespoint to.Vinod:I thought you didn’t understand CRC.Ed:Maybe a little, but go ahead.Vinod:So here’s my class definition forHomeManagementInterface.Attributes:optionsPanel—contains info on buttons that enable user toselect functionality.situationPanel—contains info on buttons that enable userto select situation.floorplan—same as surveillance object but this onedisplays devices.deviceIcons—info on icons representing lights,appliances, HVAC, etc.devicePanels—simulation of appliance or device controlpanel; allows control.Operations:displayControl(), selectControl(), displaySituation(), selectsituation(), accessFloorplan(), selectDeviceIcon(),displayDevicePanel(), accessDevicePanel(), ...Class:HomeManagementInterfaceResponsibility CollaboratordisplayControl()OptionsPanel(class) selectControl()OptionsPanel(class) displaySituation()SituationPanel(class) selectSituation()SituationPanel(class) accessFloorplan()FloorPlan(class) . . . . . . Ed:So when the operation accessFloorplan()is invoked, it collaborates with the FloorPlanobject just like the onewe developed for surveillance. Wait, I have a descriptionof it here. (They look at Figure 6.10.)Vinod:Exactly. And if we wanted to review the entireclass model, we could start with this index card, then goto the collaborator’s index card, and from there to one ofthe collaborator’s collaborators, and so on.Ed:Good way to find omissions or errors.Vinod:Yep.
An association definesa relationship betweenclasses. Multiplicitydefines how many ofone class are related tohow many of anotherclass.
19 Other multiplicity relations—one to one, one to many, many to many, one to a specified range withlower and upper limits, and others—may be indicated as part of an association.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 180In many instances, a client-server relationship exists between two analysisclasses. In such cases, a client class depends on the server class in some way and adependency relationshipis established. Dependencies are defined by a stereotype. Astereotypeis an “extensibility mechanism” [Arl02] within UML that allows you todefine a special modeling element whose semantics are custom defined. In UMLstereotypes are represented in double angle brackets (e.g., <<stereotype>>).As an illustration of a simple dependency within the SafeHome surveillance sys- tem, a Cameraobject (in this case, the server class) provides a video image to aDisplayWindowobject (in this case, the client class). The relationship betweenthese two objects is not a simple association, yet a dependency association doesexist. In a use case written for surveillance (not shown), you learn that a special pass-word must be provided in order to view specific camera locations. One way toachieve this is to have Camerarequest a password and then grant permission to theDisplayWindowto produce the video display. This can be represented as shown inFigure 6.14 where <<access>> implies that the use of the camera output is controlledby a special password.CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 181
WallSegment Window DoorWall
Is used to buildIs used to buildIs used to build1..*1110..*0..*FIGURE 6.13
Multiplicity
Camera DisplayWindow
{password}<<access>>FIGURE 6.14
Dependencies
What is astereotype??pre75977_ch06.qxd  11/27/08  3:34 PM  Page 181182 PART TWOMODELING
6.5.6 Analysis Packages
An important part of analysis modeling is categorization. That is, various elementsof the analysis model (e.g., use cases, analysis classes) are categorized in a mannerthat packages them as a grouping—called an analysis package—that is given a rep- resentative name.To illustrate the use of analysis packages, consider the video game that I intro-duced earlier. As the analysis model for the video game is developed, a large num-ber of classes are derived. Some focus on the game environment—the visual scenesthat the user sees as the game is played. Classes such as Tree, Landscape, Road,Wall, Bridge, Building,and VisualEffectmight fall within this category. Others focus on the characters within the game, describing their physical features, actions,and constraints. Classes such as Player (described earlier), Protagonist, Antago-nist,and SupportingRolesmight be defined. Still others describe the rules of thegame—how a player navigates through the environment. Classes such asRulesOfMovementand ConstraintsOnActionare candidates here. Many other categories might exist. These classes can be grouped in analysis packages as shownin Figure 6.15.The plus sign preceding the analysis class name in each package indicates thatthe classes have public visibility and are therefore accessible from other packages.Although they are not shown in the figure, other symbols can precede an elementwithin a package. A minus sign indicates that an element is hidden from all otherpackages and a # symbol indicates that an element is accessible only to packagescontained within a given package.
Environment+Tree +Landscape +Road +Wall +Bridge +Building +VisualEffect +Scene 
Characters+Player +Protagonist +Antagonist +SupportingRoleRulesOfTheGame+RulesOfMovement +ConstraintsOnActionPackage nameFIGURE 6.15
PackagesA package is used toassemble a collectionof related classes.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 1826.6 S UMMARY
The objective of requirements modeling is to create a variety of representations thatdescribe what the customer requires, establish a basis for the creation of a softwaredesign, and define a set of requirements that can be validated once the software isbuilt. The requirements model bridges the gap between a system-level representationthat describes overall system and business functionality and a software design thatdescribes the software’s application architecture, user interface, and component-level structure.Scenario-based models depict software requirements from the user’s point ofview. The use case—a narrative or template-driven description of an interactionbetween an actor and the software—is the primary modeling element. Derivedduring requirements elicitation, the use case defines the keys steps for a specificfunction or interaction. The degree of use-case formality and detail varies, but theend result provides necessary input to all other analysis modeling activities. Sce-narios can also be described using an activity diagram—a flowchart-like graphicalrepresentation that depicts the processing flow within a specific scenario. Swim-lane diagrams illustrate how the processing flow is allocated to various actors orclasses.Data modeling is used to describe the information space that will be constructedor manipulated by the software. Data modeling begins by representing dataobjects—composite information that must be understood by the software. Theattributes of each data object are identified and relationships between data objectsare described.Class-based modeling uses information derived from scenario-based and datamodeling elements to identify analysis classes. A grammatical parse may be used toextract candidate classes, attributes, and operations from text-based narratives.Criteria for the definition of a class are defined. A set of class-responsibility-collaborator index cards can be used to define relationships between classes. Inaddition, a variety of UML modeling notation can be applied to define hierarchies,relationships, associations, aggregations, and dependencies among classes. Analy-sis packages are used to categorize and group classes in a manner that makes themmore manageable for large systems.
PROBLEMS AND POINTS TO PONDER
6.1.Is it possible to begin coding immediately after an analysis model has been created?Explain your answer and then argue the counterpoint.6.2.An analysis rule of thumb is that the model “should focus on requirements that are visiblewithin the problem or business domain.” What types of requirements are not visible in these do- mains? Provide a few examples.6.3.What is the purpose of domain analysis? How is it related to the concept of requirementspatterns?CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 183pre75977_ch06.qxd  11/27/08  3:34 PM  Page 183184 PART TWOMODELING
6.4.Is it possible to develop an effective analysis model without developing all four elementsshown in Figure 6.3? Explain.6.5.You have been asked to build one of the following systems:a. a network-based course registration system for your university.b. a Web-based order-processing system for a computer store.c. a simple invoicing system for a small business.d. an Internet-based cookbook that is built into an electric range or microwave.Select the system that is of interest to you and develop an entity-relationship diagram that de-scribes data objects, relationships, and attributes.6.6.The department of public works for a large city has decided to develop a Web-based pot-hole tracking and repair system (PHTRS). A description follows:Citizens can log onto a website and report the location and severity of potholes. As pot-holes are reported they are logged within a “public works department repair system” andare assigned an identifying number, stored by street address, size (on a scale of 1 to 10),location (middle, curb, etc.), district (determined from street address), and repair prior-ity (determined from the size of the pothole). Work order data are associated with eachpothole and include pothole location and size, repair crew identifying number, numberof people on crew, equipment assigned, hours applied to repair, hole status (work inprogress, repaired, temporary repair, not repaired), amount of filler material used, andcost of repair (computed from hours applied, number of people, material and equipmentused). Finally, a damage file is created to hold information about reported damage dueto the pothole and includes citizen’s name, address, phone number, type of damage, anddollar amount of damage. PHTRS is an online system; all queries are to be made inter-actively.a. Draw a UML use case diagram for the PHTRS system. You’ll have to make a number ofassumptions about the manner in which a user interacts with this system.b. Develop a class model for the PHTRS system.6.7.Write a template-based use case for the SafeHome home management system described informally in the sidebar following Section 6.5.4.6.8.Develop a complete set of CRC model index cards on the product or system you chose aspart of Problem 6.5.6.9.Conduct a review of the CRC index cards with your colleagues. How many additionalclasses, responsibilities, and collaborators were added as a consequence of the review?6.10.What is an analysis package and how might it be used?
FURTHER READINGS AND INFORMATION SOURCES
Use cases can serve as the foundation for all requirements modeling approaches. The subject isdiscussed at length by Rosenberg and Stephens (Use Case Driven Object Modeling with UML: The-ory and Practice,Apress, 2007), Denny (Succeeding with Use Cases: Working Smart to Deliver Qual-ity,Addison-Wesley, 2005), Alexander and Maiden (eds.) ( Scenarios, Stories, Use Cases: Through the Systems Development Life-Cycle, Wiley, 2004), Bittner and Spence (Use Case Modeling, Addi- son-Wesley, 2002), Cockburn [Coc01b], and other references noted in both Chapters 5 and 6.Data modeling presents a useful method for examining the information space. Books byHoberman [Hob06] and Simsion and Witt [Sim05] provide reasonably comprehensive treat-ments. In addition, Allen and Terry (Beginning Relational Data Modeling, 2d ed., Apress, 2005), Allen (Data Modeling for Everyone, Wrox Press, 2002), Teorey and his colleagues (Database Modeling and Design: Logical Design, 4th ed., Morgan Kaufmann, 2005), and Carlis and Maguire (Mastering Data Modeling, Addison-Wesley, 2000) present detailed tutorials for creatingpre75977_ch06.qxd  11/27/08  3:34 PM  Page 184CHAPTER 6REQUIREMENTS MODELING: SCENARIOS, INFORMATION, AND ANALYSIS CLASSES 185
industry-quality data models. An interesting book by Hay ( Data Modeling Patterns,Dorset House, 1995) presents typical data model patterns that are encountered in many different businesses.UML modeling techniques that can be applied for both analysis and design are discussed byO’Docherty (Object-Oriented Analysis and Design: Understanding System Development with UML2.0,Wiley, 2005), Arlow and Neustadt (UML 2 and the Unified Process, 2d ed., Addison-Wesley, 2005), Roques (UML in Practice,Wiley, 2004), Dennis and his colleagues ( Systems Analysis and Design with UML Version 2.0,Wiley, 2004), Larman (Applying UML and Patterns,2d ed., Prentice- Hall, 2001), and Rosenberg and Scott ( Use Case Driven Object Modeling with UML, Addison- Wesley, 1999).A wide variety of information sources on requirements modeling are available on theInternet. An up-to-date list of World Wide Web references that are relevant to analysismodeling can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.pre75977_ch06.qxd  11/27/08  3:34 PM  Page 185After my discussion of use cases, data modeling, and class-based modelsin Chapter 6, it’s reasonable to ask, “Aren’t those requirements modelingrepresentations enough?”The only reasonable answer is, “That depends.”For some types of software, the use case may be the only requirements mod-eling representation that is required. For others, an object-oriented approach ischosen and class-based models may be developed. But in other situations, com-plex application requirements may demand an examination of how data objectsare transformed as they move through a system; how an application behaves asa consequence of external events; whether existing domain knowledge can beadapted to the current problem; or in the case of Web-based systems and appli-cations, how content and functionality meld to provide an end user with the abil-ity to successfully navigate a WebApp to achieve usage goals.
7.1 R EQUIREMENTS MODELING STRATEGIES
One view of requirements modeling, called structured analysis, considers data and the processes that transform the data as separate entities. Data objects are mod-eled in a way that defines their attributes and relationships. Processes thatmanipulate data objects are modeled in a manner that shows how they transformdata as data objects flow through the system. A second approach to analysis 
186CHAPTER
7REQUIREMENTS MODELING : FLOW,B
EHAVIOR , PATTERNS , ANDWEBAPPS
KEY
CONCEPTS
analysis patterns . . . . . .200behavioral model  . . . . . . .195configuration model  . . . . . . .211content model . .207control flow model  . . . . . . .191data flow model  . . . . . . .188functional model  . . . . . . .210interaction model  . . . . . . .209navigation modeling  . . . . .212process specification  . . .192sequence diagrams  . . . . .197WebApps  . . . . .205
What is it? The requirements modelhas many different dimensions. Inthis chapter you’ll learn about flow-oriented models, behavioral models, and the spe-cial requirements analysis considerations thatcome into play when WebApps are developed.Each of these modeling representations supple-ments the use cases, data models, and class-based models discussed in Chapter 6.
Who does it? A software engineer (sometimescalled an “analyst”) builds the model usingrequirements elicited from various stakeholders.QUICK
LOOKWhy is it important? Your insight into softwarerequirements grows in direct proportion to thenumber of different requirements modelingdimensions. Although you may not have thetime, the resources, or the inclination to developevery representation suggested in this chapterand Chapter 6, recognize that each differentmodeling approach provides you with a differ-ent way of looking at the problem. As a conse-quence, you (and other stakeholders) will bebetter able to assess whether you’ve properlyspecified what must be accomplished.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 186modeled, called object-oriented analysis, focuses on the definition of classes and the manner in which they collaborate with one another to effect customer requirements.Although the analysis model that we propose in this book combines features ofboth approaches, software teams often choose one approach and exclude all repre-sentations from the other. The question is not which is best, but rather, what com-bination of representations will provide stakeholders with the best model of softwarerequirements and the most effective bridge to software design.
7.2 F LOW-ORIENTED MODELING
Although data flow-oriented modeling is perceived as an outdated technique bysome software engineers, it continues to be one of the most widely used require-ments analysis notations in use today.
1Although the data flow diagram(DFD) and related diagrams and information are not a formal part of UML, they can be used tocomplement UML diagrams and provide additional insight into system requirementsand flow.The DFD takes an input-process-output view of a system. That is, data objectsflow into the software, are transformed by processing elements, and resultant dataobjects flow out of the software. Data objects are represented by labeled arrows, andtransformations are represented by circles (also called bubbles). The DFD is pre-sented in a hierarchical fashion. That is, the first data flow model (sometimes calleda level 0 DFD or context diagram) represents the system as a whole. Subsequent dataflow diagrams refine the context diagram, providing increasing detail with eachsubsequent level.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 187
What are the steps? Flow-oriented modelingprovides an indication of how data objects aretransformed by processing functions. Behavioralmodeling depicts the states of the system and itsclasses and the impact of events on these states.Pattern-based modeling makes use of existingdomain knowledge to facilitate requirementsanalysis. WebApp requirements models areespecially adapted for the representation ofcontent, interaction, function, and configuration-related requirements.What is the work product? A wide array of text-based and diagrammatic forms may be chosenfor the requirements model. Each of these repre-sentations provides a view of one or more of themodel elements.
How do I ensure that I’ve done it right?
Requirements modeling work products must bereviewed for correctness, completeness, andconsistency. They must reflect the needs of allstakeholders and establish a foundation fromwhich design can be conducted.
1 Data flow modeling is a core modeling activity in structured analysis.Some will suggest thatthe DFD is old-schooland it has no place inmodern practice. That’sa view that excludes apotentially useful modeof representation at theanalysis level. If it canhelp, use the DFD.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 187188 PART TWOMODELING
7.2.1 Creating a Data Flow Model
The data flow diagram enables you to develop models of the information domain andfunctional domain. As the DFD is refined into greater levels of detail, you perform animplicit functional decomposition of the system. At the same time, the DFD refine-ment results in a corresponding refinement of data as it moves through the processesthat embody the application.A few simple guidelines can aid immeasurably during the derivation of a data flowdiagram: (1) the level 0 data flow diagram should depict the software/system as asingle bubble; (2) primary input and output should be carefully noted; (3) refinementshould begin by isolating candidate processes, data objects, and data stores to berepresented at the next level; (4) all arrows and bubbles should be labeled withmeaningful names; (5) information flow continuity must be maintained from level to level,
2 and (6) one bubble at a time should be refined. There is a natural tendency toovercomplicate the data flow diagram. This occurs when you attempt to show toomuch detail too early or represent procedural aspects of the software in lieu ofinformation flow.To illustrate the use of the DFD and related notation, we again consider theSafeHomesecurity function. A level 0 DFD for the security function is shown inFigure 7.1. The primary external entities (boxes) produce information for use by the system and consume information generated by the system. The labeled arrows rep-resent data objects or data object hierarchies. For example, user commands anddataencompasses all configuration commands, all activation/deactivation com-mands, all miscellaneous interactions, and all data that are entered to qualify orexpand a command.The level 0 DFD must now be expanded into a level 1 data flow model. But howdo we proceed? Following an approach suggested in Chapter 6, you should apply auote:
“The purpose ofdata flow diagramsis to provide asemantic bridgebetween usersand systemsdevelopers.”Kenneth Kozar
2 That is, the data objects that flow into the system or into any transformation at one level must be thesame data objects (or their constituent parts) that flow into the transformation at a more refined level.Information flowcontinuity must bemaintained as eachDFD level is refined.This means that inputand output at one levelmust be the same asinput and output at arefined level.Controlpanel User commandsand data
SensorsSensorstatusControlpaneldisplay
TelephonelineAlarmSafeHomesoftwareDisplayinformation
Telephonenumber tonesAlarmtypeFIGURE 7.1
Context-levelDFD for theSafeHomesecurityfunctionpre75977_ch07.qxd  11/27/08  3:36 PM  Page 188CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 189
“grammatical parse” [Abb83] to the use case narrative that describes the context-levelbubble. That is, we isolate all nouns (and noun phrases) and verbs (and verb phrases)in a SafeHomeprocessing narrative derived during the first requirements gatheringmeeting. Recalling the parsed processing narrative text presented in Section 6.5.1:
The SafeHome security function enablesthe homeowner to configurethe security system
when it is installed, monitorsall sensors connectedto the security system, and interacts with the homeowner through the Internet
, a PC, or a control panel . During installation
, the SafeHomePC is used to programand configurethe system . Each sensor is assigned a number
and type , a master password is programmed for arming and disarmingthe system, and telephone number(s)
are inputfor dialingwhen a sensor
event occurs.When a sensor event isrecognized, the softwareinvokesan audible
alarm attached to the system. After a delay
time that is specified by the homeowner during system configura-tion activities, the software dials a telephone number of a monitoring
service ,provides information
about the location ,reportingthe nature of the event that has been detected. The telephone number will beredialedevery 20 seconds until telephone
connection isobtained. The homeowner receivessecurity information
via a control panel, the PC, or a browser, collectively called an interface
. The interface displaysprompting messages and system
status information on the control panel, the PC, or the browser window. Homeowner in-teraction takes the following form . . .
Referring to the grammatical parse, verbs are SafeHome processes and can be rep- resented as bubbles in a subsequent DFD. Nouns are either external entities (boxes),data or control objects (arrows), or data stores (double lines). From the discussion inChapter 6, recall that nouns and verbs can be associated with one another (e.g., eachsensor is assigned a number and type; therefore number and typeare attributes of the data object sensor). Therefore, by performing a grammatical parse on the process-ing narrative for a bubble at any DFD level, you can generate much useful informa-tion about how to proceed with the refinement to the next level. Using thisinformation, a level 1 DFD is shown in Figure 7.2. The context level process shownin Figure 7.1 has been expanded into six processes derived from an examination ofthe grammatical parse. Similarly, the information flow between processes at level 1has been derived from the parse. In addition, information flow continuity is main-tained between levels 0 and 1.The processes represented at DFD level 1 can be further refined into lower levels.For example, the process monitor sensors can be refined into a level 2 DFD as shown in Figure 7.3. Note once again that information flow continuity has been maintainedbetween levels.The refinement of DFDs continues until each bubble performs a simple function.That is, until the process represented by the bubble performs a function that wouldbe easily implemented as a program component. In Chapter 8, I discuss a concept,called cohesion,that can be used to assess the processing focus of a given function.For now, we strive to refine DFDs until each bubble is “single-minded.”The grammatical parseis not foolproof, but itcan provide you with anexcellent jump start, ifyou’re struggling todefine data objects andthe transforms thatoperate on them.
Be certain that theprocessing narrativeyou intend to parse iswritten at the samelevel of abstractionthroughout.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 189190 PART TWOMODELING
Configuration information
ReadsensorsAssessagainstsetupConfigurationdata
Sensor ID,type
SensorstatusGeneratealarmsignalAlarmtype
Alarmdata
Telephonenumber
Dialphone
Telephonenumber tonesFormatfordisplaySensorinformation
Sensor IDtype,locationFIGURE 7.3
Level 2 DFDthat refinesthemonitorsensorsprocessConfiguration informationControlpanel
SensorsControlpaneldisplay
TelephonelineAlarmInteractwithuserConfiguresystem
Activate/deactivatesystem
Processpassword
MonitorsensorsDisplaymessagesand statusUser commandsand data
PasswordStartstopConfigurerequest
Configurationdata
Configurationdata
Configurationdata
Valid ID msg.A/d msg.
SensorstatusSensorinformationAlarm typeTelephonenumber tonesDisplayinformationFIGURE 7.2
Level 1 DFD forSafeHomesecurityfunctionpre75977_ch07.qxd  11/27/08  3:36 PM  Page 1907.2.2 Creating a Control Flow Model
For some types of applications, the data model and the data flow diagram are all thatis necessary to obtain meaningful insight into software requirements. As I have al-ready noted, however, a large class of applications are “driven” by events rather thandata, produce control information rather than reports or displays, and process infor-mation with heavy concern for time and performance. Such applications require theuse of control flow modelingin addition to data flow modeling.I have already noted that an event or control item is implemented as a Boolean value(e.g., true or false, on or off, 1 or 0) or a discrete list of conditions (e.g., empty, jammed,full). To select potential candidate events, the following guidelines are suggested:
•List all sensors that are “read” by the software.
•List all interrupt conditions.
•List all “switches” that are actuated by an operator.
•List all data conditions.
•Recalling the noun/verb parse that was applied to the processing narrative,review all “control items” as possible control specification inputs/outputs.
•Describe the behavior of a system by identifying its states, identify how eachstate is reached, and define the transitions between states.
•Focus on possible omissions—a very common error in specifying control; forexample, ask: “Is there any other way I can get to this state or exit from it?”Among the many events and control items that are part of SafeHomesoftware are sensor event(i.e., a sensor has been tripped), blink flag (a signal to blink the display), and start/stop switch(a signal to turn the system on or off ).
7.2.3 The Control Specification
A control specification(CSPEC) represents the behavior of the system (at the levelfrom which it has been referenced) in two different ways.
3The CSPEC contains a state diagram that is a sequential specification of behavior. It can also contain a pro-gram activation table—a combinatorial specification of behavior.Figure 7.4 depicts a preliminary state diagram
4for the level 1 control flow model for SafeHome.The diagram indicates how the system responds to events as it trav-erses the four states defined at this level. By reviewing the state diagram, you candetermine the behavior of the system and, more important, ascertain whether thereare “holes” in the specified behavior.For example, the state diagram (Figure 7.4) indicates that the transitions fromtheIdlestate can occur if the system is reset, activated, or powered off. If the system isCHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 191
How do Iselectpotential eventsfor a control flowdiagram, statediagram, orCSPEC??
3 Additional behavioral modeling notation is presented in Section 7.3.4 The state diagram notation used here conforms to UML notation. A “state transition diagram” is avail-able in structured analysis, but the UML format is superior in information content and representation.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 191192 PART TWOMODELING
activated (i.e., alarm system is turned on), a transition to the Monitoring- SystemStatusstate occurs, display messages are changed as shown, and the pro-cessmonitorAndControlSystemis invoked. Two transitions occur out of theMonitoringSystemStatusstate—(1) when the system is deactivated, a transition oc-curs back to the Idlestate; (2) when a sensor is triggered into the ActingOnAlarmstate. All transitions and the content of all states are considered during the review.A somewhat different mode of behavioral representation is the process activationtable. The PAT represents information contained in the state diagram in the context ofprocesses, not states. That is, the table indicates which processes (bubbles) in the flowmodel will be invoked when an event occurs. The PAT can be used as a guide for a de-signer who must build an executive that controls the processes represented at thislevel. A PAT for the level 1 flow model of SafeHome software is shown in Figure 7.5. The CSPEC describes the behavior of the system, but it gives us no informationabout the inner working of the processes that are activated as a result of this behavior.The modeling notation that provides this information is discussed in Section 7.2.4.
7.2.4 The Process Specification
Theprocess specification(PSPEC) is used to describe all flow model processes thatappear at the final level of refinement. The content of the process specification canResetting
Entry/set systemStatus "inactive"Entry/set displayMsg1 "Starting system"Entry/set displayMsg2 "Please wait"Entry/set displayStatus slowBlinkingDo: run diagnosticsStart/stop switchpower "on"systemOKIdle
Entry/set systemStatus "inactive"Entry/set displayMsg1 "Ready"Entry/set displayMsg2  ""Entry/set displayStatus steadyKeyHit/handleKey 
failureDetected/set displayMsg2 "contact Vendor"
MonitoringSystemStatus
Entry/set systemStatus "monitoring"Entry/set displayMsg1 "Armed"Entry/set displayMsg2   ""Entry/set displayStatus steadyDo: monitorAndControlSystemKeyHit/handleKeyActingOnAlarm
Entry/set systemStatus "monitorAndAlarm"Entry/set displayMsg1 "ALARM"Entry/set displayMsg2 triggeringSensorEntry/set displayStatus fastBlinkingDo: monitorAndControlSystemDo: soundAlarmDo: notifyAlarmRespondersKeyHit/handleKey     Reset
falseAlarmtimeOutsensorTriggered/startTimersensorTriggered/restartTimerActivatedeactivatePasswordoff/powerOffdeactivatePasswordFIGURE 7.4 State diagram for SafeHomesecurity functionpre75977_ch07.qxd  11/27/08  3:36 PM  Page 192CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 193
input events
process activation
monitor and control system         0     1     0     0     1     1activate/deactivate system         0     1     0     0     0     0display messages and status       1     0     1     1     1     1interact with user                       1     0     0     1     0     1sensor event                             0     0     0     0     1     0blink flag                                 0     0     1     1     0     0start stop switch                        0     1     0     0     0     0display action status complete     0     0     0     1     0     0in-progress                               0     0     1     0     0     0time out                                   0     0     0     0     0     1
outputalarm signal                             0     0     0     0     1     0FIGURE 7.5
Process activa-tion table forSafeHomesecurityfunction
Data Flow Modeling
The scene:Jamie’s cubicle, after thelast requirements gathering meeting has concluded.The players:Jamie, Vinod, and Ed—all members ofthe SafeHomesoftware engineering team.The conversation:(Jamie has sketched out the models shown in Figures 7.1through 7.5 and is showing them to Ed and Vinod.)Jamie:I took a software engineering course in college,and they taught us this stuff. The Prof said it’s a bit old-fashioned, but you know what, it helps me to clarifythings.Ed:That’s cool. But I don’t see any classes or objects here.Jamie:No . . . this is just a flow model with a littlebehavioral stuff thrown in.Vinod:So these DFDs represent an I-P-O view of thesoftware, right.Ed:I-P-O?Vinod:Input-process-output. The DFDs are actuallypretty intuitive . . . if you look at ‘em for a moment, theyshow how data objects flow through the system and gettransformed as they go.Ed:Looks like we could convert every bubble into anexecutable component . . . at least at the lowest level ofthe DFD.Jamie:That’s the cool part, you can. In fact, there’s away to translate the DFDs into an design architecture.Ed:Really?Jamie:Yeah, but first we’ve got to develop a completerequirements model and this isn’t it.Vinod:Well, it’s a first step, but we’re going to have toaddress class-based elements and also behavioral aspects,although the state diagram and PAT does some of that.Ed:We’ve got a lot work to do and not much time to do it.(Doug—the software engineering manager—walks into thecubical.)Doug:So the next few days will be spent developing therequirements model, huh?Jamie (looking proud):We’ve already begun.Doug:Good, we’ve got a lot of work to do and notmuch time to do it.(The three software engineers look at one another and smile.)SAFEHOMEpre75977_ch07.qxd  11/27/08  3:36 PM  Page 193194 PART TWOMODELING
include narrative text, a program design language (PDL) description5of the process algorithm, mathematical equations, tables, or UML activity diagrams. By providing aPSPEC to accompany each bubble in the flow model, you can create a “mini-spec” thatserves as a guide for design of the software component that will implement the bubble.To illustrate the use of the PSPEC, consider the process password transform repre- sented in the flow model for SafeHome(Figure 7.2). The PSPEC for this function mighttake the form:
PSPEC: process password (at control panel). Theprocess passwordtransform per- forms password validation at the control panel for the SafeHomesecurity function.Process passwordreceives a four-digit password from the interact with userfunction. The password is first compared to the master password stored within the system. If the master passwordmatches, <valid id message = true> is passed to the message and status displayfunction. If the master password does not match, the four digits are compared to a table of secondarypasswords (these may be assigned to house guests and/or workers who require entry tothe home when the owner is not present). If the password matches an entry within the table,<valid id message = true> is passed to the message and status display function. If there is no match, <valid id message = false> is passed to the message and status display function.
If additional algorithmic detail is desired at this stage, a program design languagerepresentation may also be included as part of the PSPEC. However, many believethat the PDL version should be postponed until component design commences.
5 Program design language (PDL) mixes programming language syntax with narrative text to provideprocedural design detail. PDL is discussed briefly in Chapter 10.6 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.The PSPEC is a “mini-specification” for eachtransform at the lowestrefined level of a DFD.
Structured Analysis
Objective:Structured analysis tools allow asoftware engineer to create data models, flowmodels, and behavioral models in a manner that enablesconsistency and continuity checking and easy editing andextension. Models created using these tools providethe software engineer with insight into the analysisrepresentation and help to eliminate errors before theypropagate into design, or worse, into implementation itself.Mechanics:Tools in this category use a “datadictionary” as the central database for the descriptionof all data objects. Once entries in the dictionary aredefined, entity-relationship diagrams can be createdand object hierarchies can be developed. Data flowdiagramming features allow easy creation of this graphicalmodel and also provide features for the creation of PSPECsand CSPECs. Analysis tools also enable the software engineer to create behavioral models using the statediagram as the operative notation.Representative Tools:
6
MacA&D, WinA&D, developed by Excel software(www.excelsoftware.com), provides a set ofsimple and inexpensive analysis and design tools forMacs and Windows machines.MetaCASE Workbench,developed by MetaCase Consulting(www.metacase.com), is a metatool used to definean analysis or design method (including structuredanalysis) and its concepts, rules, notations, andgenerators.System Architect,developed by Popkin Software(www.popkin.com) provides a broad range ofanalysis and design tools including tools for datamodeling and structured analysis.SOFTWARE TOOLSpre75977_ch07.qxd  11/27/08  3:36 PM  Page 194CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 195
7.3 C REATING A BEHAVIORAL MODEL
The modeling notation that I have discussed to this point represents static elementsof the requirements model. It is now time to make a transition to the dynamic be-havior of the system or product. To accomplish this, you can represent the behaviorof the system as a function of specific events and time.The behavioral modelindicates how software will respond to external events orstimuli. To create the model, you should perform the following steps:1.Evaluate all use cases to fully understand the sequence of interaction withinthe system.2.Identify events that drive the interaction sequence and understand how theseevents relate to specific objects.3.Create a sequence for each use case.4.Build a state diagram for the system.5.Review the behavioral model to verify accuracy and consistency.Each of these steps is discussed in the sections that follow.
7.3.1 Identifying Events with the Use Case
In Chapter 6 you learned that the use case represents a sequence of activities that in-volves actors and the system. In general, an event occurs whenever the system andan actor exchange information. In Section 7.2.3, I indicated that an event is notthe information that has been exchanged, but rather the fact that information has beenexchanged.A use case is examined for points of information exchange. To illustrate, we re-consider the use case for a portion of the SafeHome security function.
The homeowner uses the keypad to key in a four-digit password . The password is
compared with the valid password stored in the system . If the password is incorrect, the control panel will beep
once and reset itself for additional input. If the password iscorrect, the control panel awaits further action.
The underlined portions of the use case scenario indicate events. An actor should beidentified for each event; the information that is exchanged should be noted, and anyconditions or constraints should be listed.As an example of a typical event, consider the underlined use case phrase “home-owner uses the keypad to key in a four-digit password.” In the context of therequirements model, the object, Homeowner,
7transmits an event to the object ControlPanel.The event might be called password entered. The informationHow do Imodel thesoftware’sreaction to someexternal event??
7 In this example, we assume that each user (homeowner) that interacts with SafeHome has an identifying password and is therefore a legitimate object.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 195196 PART TWOMODELING
transferred is the four digits that constitute the password, but this is not an essentialpart of the behavioral model. It is important to note that some events have an ex-plicit impact on the flow of control of the use case, while others have no direct im-pact on the flow of control. For example, the event password entered does not explicitly change the flow of control of the use case, but the results of the eventpassword compared(derived from the interaction “password is compared with thevalid password stored in the system”) will have an explicit impact on the informationand control flow of the SafeHomesoftware.Once all events have been identified, they are allocated to the objects involved.Objects can be responsible for generating events (e.g., Homeowner generates thepassword enteredevent) or recognizing events that have occurred elsewhere(e.g., ControlPanelrecognizes the binary result of the password compared event).
7.3.2 State Representations
In the context of behavioral modeling, two different characterizations of states mustbe considered: (1) the state of each class as the system performs its function and(2) the state of the system as observed from the outside as the system performs itsfunction.
8
The state of a class takes on both passive and active characteristics [Cha93]. Apassive stateis simply the current status of all of an object’s attributes. For example,the passive state of the class Player (in the video game application discussed in Chapter 6) would include the current position and orientationattributes of Playeras well as other features of Playerthat are relevant to the game (e.g., an attribute thatindicates magic wishes remaining). The active stateof an object indicates the current sta- tus of the object as it undergoes a continuing transformation or processing. The classPlayermight have the following active states: moving, at rest, injured, being cured;trapped, lost,and so forth. An event (sometimes called a trigger) must occur to forcean object to make a transition from one active state to another.Two different behavioral representations are discussed in the paragraphs thatfollow. The first indicates how an individual class changes state based on externalevents and the second shows the behavior of the software as a function of time.State diagrams for analysis classes. One component of a behavioral model is a UML state diagram
9that represents active states for each class and the events (trig-gers) that cause changes between these active states. Figure 7.6 illustrates a state di-agram for the ControlPanelobject in the SafeHomesecurity function. Each arrow shown in Figure 7.6 represents a transition from one active state ofan object to another. The labels shown for each arrow represent the event that
8 The state diagrams presented in Chapter 6 and in Section 7.3.2 depict the state of the system. Ourdiscussion in this section will focus on the state of each class within the analysis model.9 If you are unfamiliar with UML, a brief introduction to this important modeling notation is presentedin Appendix 1.The system has statesthat represent specificexternally observablebehavior; a class hasstates that representits behavior as thesystem performs itsfunctions.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 196triggers the transition. Although the active state model provides useful insight intothe “life history” of an object, it is possible to specify additional information to pro-vide more depth in understanding the behavior of an object. In addition to specify-ing the event that causes the transition to occur, you can specify a guard and anaction [Cha93]. A guardis a Boolean condition that must be satisfied in order for thetransition to occur. For example, the guard for the transition from the “reading” stateto the “comparing” state in Figure 7.6 can be determined by examining the use case:
if (password input /H115494 digits) then compare to stored password
In general, the guard for a transition usually depends upon the value of one or moreattributes of an object. In other words, the guard depends on the passive state of theobject.An actionoccurs concurrently with the state transition or as a consequence of itand generally involves one or more operations (responsibilities) of the object. For ex-ample, the action connected to the password entered event (Figure 7.6) is an opera- tion named validatePassword()that accesses a passwordobject and performs a digit-by-digit comparison to validate the entered password.Sequence diagrams.The second type of behavioral representation, called asequence diagramin UML, indicates how events cause transitions from object toobject. Once events have been identified by examining a use case, the modelerCHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 197
ReadingLocked
SelectingPasswordentered ComparingPassword = incorrect& numberOfTries < maxTries 
Password = correct
Activation successfulKey hit
Do: validatePasswordnumberOfTries > maxTriesTimer ≤ lockedTimeTimer > lockedTimeFIGURE 7.6
State diagramfor the ControlPanelclasspre75977_ch07.qxd  11/27/08  3:36 PM  Page 197198 PART TWOMODELING
creates a sequence diagram—a representation of how events cause flow from oneobject to another as a function of time. In essence, the sequence diagram is a short-hand version of the use case. It represents key classes and the events that causebehavior to flow from class to class.Figure 7.7 illustrates a partial sequence diagram for the SafeHome security func- tion. Each of the arrows represents an event (derived from a use case) and indicateshow the event channels behavior between SafeHomeobjects. Time is measured ver- tically (downward), and the narrow vertical rectangles represent time spent in pro-cessing an activity. States may be shown along a vertical time line.The first event, system ready, is derived from the external environment and chan-nels behavior to the Homeownerobject. The homeowner enters a password. Arequest lookupevent is passed to System,which looks up the password in a simple database and returns a result(foundor not found) to ControlPanel(now in the comparingstate). A valid password results in a password=correct event to System, which activates Sensorswith a request activationevent. Ultimately, control is passed back to the homeowner with the activation successful event. Once a complete sequence diagram has been developed, all of the events thatcause transitions between system objects can be collated into a set of input eventsand output events (from an object). This information is useful in the creation of aneffective design for the system to be built.
Unlike a state diagramthat representsbehavior withoutnoting the classesinvolved, a sequencediagram representsbehavior, by describinghow classes movefrom state to state.Control panel System
System readyReadingRequest lookup
Comparing
ResultPassword enteredPassword = correct
Request activation
Activation successful Locked
SelectingTimer > lockedTimeA
A
Activation successfulHomeowner Sensors
numberOfTries > maxTriesFIGURE 7.7 Sequence diagram (partial) for the SafeHomesecurity functionpre75977_ch07.qxd  11/27/08  3:36 PM  Page 1987.4 P ATTERNS FOR REQUIREMENTS MODELING
Software patterns are a mechanism for capturing domain knowledge in a way thatallows it to be reapplied when a new problem is encountered. In some cases, thedomain knowledge is applied to a new problem within the same application domain.In other cases, the domain knowledge captured by a pattern can be applied by anal-ogy to a completely different application domain.The original author of an analysis pattern does not “create” the pattern, but,rather, discoversit as requirements engineering work is being conducted. Once thepattern has been discovered, it is documented by describing “explicitly the generalproblem to which the pattern is applicable, the prescribed solution, assumptions andconstraints of using the pattern in practice, and often some other information aboutthe pattern, such as the motivation and driving forces for using the pattern, discus-sion of the pattern’s advantages and disadvantages, and references to some knownexamples of using that pattern in practical applications” [Dev01].In Chapter 5, I introduced the concept of analysis patterns and indicated that thesepatterns represent a solution that often incorporates a class, a function, or a behaviorwithin the application domain. The pattern can be reused when performing require-ments modeling for an application within a domain.
11Analysis patterns are stored in a repository so that members of the software team can use search facilities to find andreuse them. Once an appropriate pattern is selected, it is integrated into the require-ments model by reference to the pattern name.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 199
Objective:Analysis modeling tools providethe capability to develop scenario-basedmodels, class-based models, and behavioral models usingUML notation.Mechanics:Tools in this category support the full rangeof UML diagrams required to build an analysis model(these tools also support design modeling). In additionto diagramming, tools in this category (1) performconsistency and correctness checks for all UML diagrams,(2) provide links for design and code generation,  (3) builda database that enables the management and assessmentof large UML models required for complex systems.Representative Tools:
10
The following tools support a full range of UML diagramsrequired for analysis modeling:ArgoUMLis an open source tool available atargouml.tigris.org.Enterprise Architect,developed by Sparx Systems(www.sparxsystems.com.au).PowerDesigner,developed by Sybase(www.sybase.com).Rational Rose,developed by IBM (Rational) (www01.ibm.com/software/rational/ ). System Architect,developed by Popkin Software(www.popkin.com).UML Studio,developed by Pragsoft Corporation(www.pragsoft.com).Visio,developed by Microsoft (www.microsoft.com).Visual UML,developed by Visual Object Modelers(www.visualuml.com).SOFTWARE TOOLS
10 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.11 An in-depth discussion of the use of patterns during software design is presented in Chapter 12.Generalized Analysis Modeling in UMLpre75977_ch07.qxd  11/27/08  3:36 PM  Page 199200 PART TWOMODELING
7.4.1 Discovering Analysis Patterns
The requirements model is comprised of a wide variety of elements: scenario-based(use cases), data-oriented (the data model), class-based, flow-oriented, and behav-ioral. Each of these elements examines the problem from a different perspective, andeach provides an opportunity to discover patterns that may occur throughout anapplication domain, or by analogy, across different application domains.The most basic element in the description of a requirements model is the use case.In the context of this discussion, a coherent set of use cases may serve as the basisfor discovering one or more analysis patterns. A semantic analysis pattern(SAP) “is a pattern that describes a small set of coherent use cases that together describe a basicgeneric application” [Fer00].Consider the following preliminary use case for software required to control andmonitor a real-view camera and proximity sensor for an automobile:
Use case:Monitor reverse motionDescription:When the vehicle is placed in reverse gear, the control software enables a video feed from a rear-placed video camera to the dashboard display. The control soft-ware superimposes a variety of distance and orientation lines on the dashboard displayso that the vehicle operator can maintain orientation as the vehicle moves in reverse. Thecontrol software also monitors a proximity sensor to determine whether an object isinside 10 feet of the rear of the vehicle. It will automatically break the vehicle if the prox-imity sensor indicates an object within x feet of the rear of the vehicle, where x is deter- mined based on the speed of the vehicle.
This use case implies a variety of functionality that would be refined and elaborated(into a coherent set of use cases) during requirements gathering and modeling.Regardless of how much elaboration is accomplished, the use cases suggest asimple, yet widely applicable SAP—the software-based monitoring and control ofsensors and actuators in a physical system. In this case, the “sensors” provide infor-mation about proximity and video information. The “actuator” is the breaking sys-tem of the vehicle (invoked if an object is very close to the vehicle). But in a moregeneral case, a widely applicable pattern is discovered.Software in many different application domains is required to monitor sensorsand control physical actuators. It follows that an analysis pattern that describesgeneric requirements for this capability could be used widely. The pattern, calledActuator-Sensor,would be applicable as part of the requirements model forSafeHomeand is discussed in Section 7.4.2, which follows.
7.4.2 A Requirements Pattern Example: Actuator-Sensor12
One of the requirements of the SafeHome security function is the ability to monitory security sensors (e.g., break-in sensors, fire, smoke or CO sensors, water sensors).
12 This section has been adapted from [Kon02] with the permission of the authors.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 200Internet-based extensions to SafeHomewill require the ability to control the move- ment (e.g., pan, zoom) of a security camera within a residence. The implication—SafeHomesoftware must manage various sensors and “actuators” (e.g., cameracontrol mechanisms).Konrad and Cheng [Kon02] have suggested a requirements pattern namedActuator-Sensorthat provides useful guidance for modeling this requirementwithin SafeHomesoftware. An abbreviated version of the Actuator-Sensor pattern, originally developed for automotive applications, follows.Pattern Name.Actuator-SensorIntent.Specify various kinds of sensors and actuators in an embedded system.Motivation.Embedded systems usually have various kinds of sensors and actua-tors. These sensors and actuators are all either directly or indirectly connected to acontrol unit. Although many of the sensors and actuators look quite different, theirbehavior is similar enough to structure them into a pattern. The pattern shows howto specify the sensors and actuators for a system, including attributes and opera-tions. The Actuator-Sensorpattern uses a pullmechanism (explicit request for in- formation) for PassiveSensorsand a pushmechanism (broadcast of information) for the ActiveSensors.Constraints
•Each passive sensor must have some method to read sensor input and attrib-utes that represent the sensor value.
•Each active sensor must have capabilities to broadcast update messageswhen its value changes.
•Each active sensor should send a life tick, a status message issued within aspecified time frame, to detect malfunctions.
•Each actuator must have some method to invoke the appropriate responsedetermined by the ComputingComponent.
•Each sensor and actuator should have a function implemented to check itsown operation state.
•Each sensor and actuator should be able to test the validity of the valuesreceived or sent and set its operation state if the values are outside of thespecifications.Applicability.Useful in any system in which multiple sensors and actuators arepresent.Structure.A UML class diagram for the Actuator-Sensor pattern is shown in Fig- ure 7.8. Actuator, PassiveSensor,and ActiveSensorare abstract classes and de- noted in italics. There are four different types of sensors and actuators in this pattern.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 201pre75977_ch07.qxd  11/27/08  3:36 PM  Page 201202 PART TWOMODELING
The Boolean, Integer,and Realclasses represent the most common types of sen-sors and actuators. The complex classes are sensors or actuators that use values thatcannot be easily represented in terms of primitive data types, such as a radar device.Nonetheless, these devices should still inherit the interface from the abstract classessince they should have basic functionalities such as querying the operation states.
Behavior. Figure 7.9 presents a UML sequence diagram for an example of theActuator-Sensorpattern as it might be applied for the SafeHome function that controls the positioning (e.g., pan, zoom) of a security camera. Here, theControlPanel
13queries a sensor (a passive position sensor) and an actuator (pancontrol) to check the operation state for diagnostic purposes before reading or set-ting a value. The messages Set Physical Value and Get Physical Valueare not messages between objects. Instead, they describe the interaction between the physical devicesof the system and their software counterparts. In the lower part of the diagram,below the horizontal line, the PositionSensor reports that the operation state is zero. The ComputingComponent (represented as ControlPanel) then sends theerror code for a position sensor failure to the FaultHandler that will decide how this error affects the system and what actions are required. It gets the data from thesensors and computes the required response for the actuators.Passive integersensorPassive sensorComputingcomponent
Active sensorPassive booleansensorPassive complexsensorPassive realsensor BooleanactuatorIntegeractuatorComplexactuatorRealactuatorActuator
Active booleansensorActive integersensorActive complexsensorActive realsensorFIGURE 7.8 UML sequence diagram for the Actuator-Sensor pattern. Source:Adapted from [Kon02] with permission.
13 The original pattern uses the generic phrase ComputingComponent.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 202Participants.This section of the patterns description “itemizes the classes/objects that are included in the requirements pattern” [Kon02] and describes theresponsibilities of each class/object (Figure 7.8). An abbreviated list follows:
•PassiveSensor abstract: Defines an interface for passive sensors.
•PassiveBooleanSensor:Defines passive Boolean sensors.
•PassiveIntegerSensor:Defines passive integer sensors.
•PassiveRealSensor:Defines passive real sensors.
•ActiveSensor abstract:Defines an interface for active sensors.
•ActiveBooleanSensor:Defines active Boolean sensors.
•ActiveIntegerSensor:Defines active integer sensors.
•ActiveRealSensor:Defines active real sensors.
•Actuator abstract:Defines an interface for actuators.
•BooleanActuator:Defines Boolean actuators.
•IntegerActuator:Defines integer actuators.
•RealActuator:Defines real actuators.
•ComputingComponent:The central part of the controller; it gets the datafrom the sensors and computes the required response for the actuators.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 203
FauntHandler
(PositionSensor.OpState = 1)PositionSensor ControlPanelGet operation statePanControlActuatorSenorInputDevicePositionSensorActuatorOutputDevicePanControl
Get value
Get operation stateGet operation state
Set value
Set physical value
Store errorGet physical value
(PositionSensor.OpState = 0)FIGURE 7.9 UML Class diagram for the Actuator-Sensor pattern. Source:Reprinted from [Kon02] with permission.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 203204 PART TWOMODELING
•ActiveComplexSensor:Complex active sensors have the basic functionalityof the abstract ActiveSensorclass, but additional, more elaborate, methodsand attributes need to be specified.
•PassiveComplexSensor:Complex passive sensors have the basic function-ality of the abstract PassiveSensorclass, but additional, more elaborate,methods and attributes need to be specified.
•ComplexActuator:Complex actuators also have the base functionality ofthe abstract Actuatorclass, but additional, more elaborate methods andattributes need to be specified.Collaborations.This section describes how objects and classes interact with oneanother and how each carries out its responsibilities.
•When the ComputingComponentneeds to update the value of aPassiveSensor,it queries the sensors, requesting the value by sending theappropriate message.
•ActiveSensorsare not queried. They initiate the transmission of sensorvalues to the computing unit, using the appropriate method to set the valuein the ComputingComponent.They send a life tick at least once during aspecified time frame in order to update their timestamps with the systemclock’s time.
•When the ComputingComponentneeds to set the value of an actuator, itsends the value to the actuator.
•TheComputingComponentcan query and set the operation state of thesensors and actuators using the appropriate methods. If an operation state isfound to be zero, then the error is sent to theFaultHandler,a class that contains methods for handling error messages, such as starting a more elaborate recoverymechanism or a backup device. If no recovery is possible, then the system canonly use the last known value for the sensor or the default value.
•The ActiveSensorsoffer methods to add or remove the addresses oraddress ranges of the components that want to receive the messages in caseof a value change.Consequences1.Sensor and actuator classes have a common interface.2.Class attributes can only be accessed through messages, and the classdecides whether or not to accept the message. For example, if a value of anactuator is set above a maximum value, then the actuator class may notaccept the message, or it might use a default maximum value.3.The complexity of the system is potentially reduced because of the uniformityof interfaces for actuators and sensors.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 204The requirements pattern description might also provide references to other relatedrequirements and design patterns.
7.5 R EQUIREMENTS MODELING FOR WEBAPPS14
Web developers are often skeptical when the idea of requirements analysis forWebApps is suggested. “After all,” they argue, “the Web development process mustbe agile, and analysis is time consuming. It’ll slow us down just when we need to bedesigning and building the WebApp.”Requirements analysis does take time, but solving the wrong problem takes evenmore time. The question for every WebApp developer is simple—are you sure youunderstand the requirements of the problem? If the answer is an unequivocal “yes,”then it may be possible to skip requirements modeling, but if the answer is “no,” thenrequirements modeling should be performed.
7.5.1 How Much Analysis Is Enough?
The degree to which requirements modeling for WebApps is emphasized depends onthe following factors:
•Size and complexity of WebApp increment.
•Number of stakeholders (analysis can help to identify conflicting requirementscoming from different sources).
•Size of the WebApp team.
•Degree to which members of the WebApp team have worked together before(analysis can help develop a common understanding of the project).
•Degree to which the organization’s success is directly dependent on thesuccess of the WebApp.The converse of the preceding points is that as the project becomes smaller, thenumber of stakeholders fewer, the development team more cohesive, and the appli-cation less critical, it is reasonable to apply a more lightweight analysis approach.Although it is a good idea to analyze the problem beforebeginning design, it is not true that allanalysis must precede alldesign. In fact, the design of a specific part of the WebApp only demands an analysis of those requirements that affect only thatpart of the WebApp. As an example from SafeHome, you could validly design the overall website aesthetics (layouts, color schemes, etc.) without havinganalyzed the functional requirements for e-commerce capabilities. You only need toanalyze that part of the problem that is relevant to the design work for the incre-ment to be delivered.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 205
14 This section has been adapted from Pressman and Lowe [Pre08] with permission.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 205206 PART TWOMODELING
7.5.2 Requirements Modeling Input
An agile version of the generic software process discussed in Chapter 2 can be ap-plied when WebApps are engineered. The process incorporates a communicationactivity that identifies stakeholders and user categories, the business context, de-fined informational and applicative goals, general WebApp requirements, and usagescenarios—information that becomes input to requirements modeling. This infor-mation is represented in the form of natural language descriptions, rough outlines,sketches, and other informal representations.Analysis takes this information, structures it using a formally defined representa-tion scheme (where appropriate), and then produces more rigorous models as anoutput. The requirements model provides a detailed indication of the true structureof the problem and provides insight into the shape of the solution.The SafeHomeACS-DCV(camera surveillance) function was introduced in Chap-ter 6. When it was introduced, this function seemed relatively clear and was de-scribed in some detail as part of a use case (Section 6.2.1). However, a reexaminationof the use case might uncover information that is missing, ambiguous, or unclear.Some aspects of this missing information would naturally emerge during thedesign. Examples might include the specific layout of the function buttons, their aes-thetic look and feel, the size of snapshot views, the placement of camera views andthe house floor plan, or even minutiae such as the maximum and minimum lengthof passwords. Some of these aspects are design decisions (such as the layout of thebuttons) and others are requirements (such as the length of the passwords) that don’tfundamentally influence early design work.But some missing information might actually influence the overall design itselfand relate more to an actual understanding of the requirements. For example:Q
1: What output video resolution is provided by SafeHome cameras? Q
2: What occurs if an alarm condition is encountered while the camera isbeing monitored?Q
3: How does the system handle cameras that can be panned and zoomed?Q
4: What information should be provided along with the camera view? (Forexample, location? time/date? last previous access?)None of these questions were identified or considered in the initial development ofthe use case, and yet, the answers could have a substantial effect on different aspectsof the design.Therefore, it is reasonable to conclude that although the communication activityprovides a good foundation for understanding, requirements analysis refines thisunderstanding by providing additional interpretation. As the problem structure is de-lineated as part of the requirements model, questions invariably arise. It is thesequestions that fill in the gaps—or in some cases, actually help us to find the gaps inthe first place.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 206To summarize, the inputs to the requirements model will be the information col-lected during the communication activity—anything from an informal e-mail to a de-tailed project brief complete with comprehensive usage scenarios and productspecifications.
7.5.3 Requirements Modeling Output
Requirements analysis provides a disciplined mechanism for representing and eval-uating WebApp content and function, the modes of interaction that users will en-counter, and the environment and infrastructure in which the WebApp resides.Each of these characteristics can be represented as a set of models that allow theWebApp requirements to be analyzed in a structured manner. While the specificmodels depend largely upon the nature of the WebApp, there are five main classesof models:
•Content model—identifies the full spectrum of content to be provided bythe WebApp. Content includes text, graphics and images, video, and audiodata.
•Interaction model—describes the manner in which users interact with theWebApp.
•Functional model—defines the operations that will be applied to WebAppcontent and describes other processing functions that are independent ofcontent but necessary to the end user.
•Navigation model—defines the overall navigation strategy for the WebApp.
•Configuration model—describes the environment and infrastructure inwhich the WebApp resides.You can develop each of these models using a representation scheme (oftencalled a “language”) that allows its intent and structure to be communicated andevaluated easily among members of the Web engineering team and other stake-holders. As a consequence, a list of key issues (e.g., errors, omissions, inconsisten-cies, suggestions for enhancement or modification, points of clarification) areidentified and acted upon.
7.5.4 Content Model for WebApps
The content model contains structural elements that provide an important view ofcontent requirements for a WebApp. These structural elements encompass contentobjects and all analysis classes—user-visible entities that are created or manipulatedas a user interacts with the WebApp.
15
Content can be developed prior to the implementation of the WebApp, while theWebApp is being built, or long after the WebApp is operational. In every case, it isCHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 207
15 Analysis classes were discussed in Chapter 6.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 207208 PART TWOMODELING
incorporated via navigational reference into the overall WebApp structure. A contentobjectmight be a textual description of a product, an article describing a news event,an action photograph taken at a sporting event, a user’s response on a discussionforum, an animated representation of a corporate logo, a short video of a speech, oran audio overlay for a collection of presentation slides. The content objects might bestored as separate files, embedded directly into Web pages, or obtained dynamicallyfrom a database. In other words, a content object is any item of cohesive informa-tion that is to be presented to an end user.Content objects can be determined directly from use cases by examining thescenario description for direct and indirect references to content. For example, aWebApp that supports SafeHomeis established at SafeHomeAssured.com. A use case, Purchasing Select SafeHome Components, describes the scenario required to purchase a SafeHomecomponent and contains the sentence:
I will be able to get descriptive and pricing information for each product component.
The content model must be capable of describing the content object Component.In many instances, a simple list of content objects, coupled with a brief descriptionof each object, is sufficient to define the requirements for content that must be de-signed and implemented. However, in some cases, the content model may benefitfrom a richer analysis that graphically illustrates the relationships among contentobjects and/or the hierarchy of content maintained by a WebApp.For example, consider the data tree[Sri01] created for a SafeHomeAssured.com component shown in Figure 7.10. The tree represents a hierarchy of information thatis used to describe a component. Simple or composite data items (one or more data
Marketing description
Photograph
Tech description
Schematic
Video
Wholesale pricePart number
Part name
Part type Component
Description
Price
Retail priceFIGURE 7.10
Data tree fora
SafeHome-Assured.com
componentpre75977_ch07.qxd  11/27/08  3:36 PM  Page 208values) are represented as unshaded rectangles. Content objects are represented asshaded rectangles. In the figure, description is defined by five content objects (the shaded rectangles). In some cases, one or more of these objects would be furtherrefined as the data tree expands.A data tree can be created for any content that is composed of multiple contentobjects and data items. The data tree is developed in an effort to define hierarchicalrelationships among content objects and to provide a means for reviewing contentso that omissions and inconsistencies are uncovered before design commences. Inaddition, the data tree serves as the basis for content design.
7.5.5 Interaction Model for WebApps
The vast majority of WebApps enable a “conversation” between an end user and ap-plication functionality, content, and behavior. This conversation can be describedusing an interactionmodel that can be composed of one or more of the followingelements: (1) use cases, (2) sequence diagrams, (3) state diagrams,
16and/or (4) user interface prototypes.In many instances, a set of use cases is sufficient to describe the interaction at ananalysis level (further refinement and detail will be introduced during design). How-ever, when the sequence of interaction is complex and involves multiple analysisclasses or many tasks, it is sometimes worthwhile to depict it using a more rigorousdiagrammatic form.The layout of the user interface, the content it presents, the interaction mecha-nisms it implements, and the overall aesthetic of the user-WebApp connections havemuch to do with user satisfaction and the overall success of the WebApp. Althoughit can be argued that the creation of a user interface prototype is a design activity, itis a good idea to perform it during the creation of the analysis model. The sooner thata physical representation of a user interface can be reviewed, the higher the likeli-hood that end users will get what they want. The design of user interfaces is dis-cussed in detail in Chapter 11.Because WebApp construction tools are plentiful, relatively inexpensive, andfunctionally powerful, it is best to create the interface prototype using such tools.The prototype should implement the major navigational links and represent theoverall screen layout in much the same way that it will be constructed. For exam-ple, if five major system functions are to be provided to the end user, the prototypeshould represent them as the user will see them upon first entering the WebApp.Will graphical links be provided? Where will the navigation menu be displayed?What other information will the user see? Questions like these should be answeredby the prototype.CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 209
16 Sequence diagrams and state diagrams are modeled using UML notation. State diagrams aredescribed in Section 7.3. See Appendix 1 for additional detail.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 209210 PART TWOMODELING
7.5.6 Functional Model for WebApps
Many WebApps deliver a broad array of computational and manipulative functionsthat can be associated directly with content (either using it or producing it) and thatare often a major goal of user-WebApp interaction. For this reason, functional re-quirements must be analyzed, and when necessary, modeled.The functional modeladdresses two processing elements of the WebApp, eachrepresenting a different level of procedural abstraction: (1) user-observable func-tionality that is delivered by the WebApp to end users, and (2) the operations con-tained within analysis classes that implement behaviors associated with the class.User-observable functionality encompasses any processing functions that are ini-tiated directly by the user. For example, a financial WebApp might implement a va-riety of financial functions (e.g., a college tuition savings calculator or a retirementsavings calculator). These functions may actually be implemented using operationswithin analysis classes, but from the point of view of the end user, the function (morecorrectly, the data provided by the function) is the visible outcome.At a lower level of procedural abstraction, the requirements model describes theprocessing to be performed by analysis class operations. These operations manipu-late class attributes and are involved as classes collaborate with one another toaccomplish some required behavior.Regardless of the level of procedural abstraction, the UML activity diagram canbe used to represent processing details. At the analysis level, activity diagramsshould be used only where the functionality is relatively complex. Much of the com-plexity of many WebApps occurs not in the functionality provided, but rather withthe nature of the information that can be accessed and the ways in which this canbe manipulated.An example of relatively complex functionality for SafeHomeAssured.com is addressed by a use case entitled Get recommendations for sensor layout for my space.The user has already developed a layout for the space to be monitored, and in thisuse case, selects that layout and requests recommended locations for sensors withinthe layout. SafeHomeAssured.comresponds with a graphical representation of thelayout with additional information on the recommended locations for sensors. Theinteraction is quite simple, the content is somewhat more complex, but the underly-ing functionality it very sophisticated. The system must undertake a relatively com-plex analysis of the floor layout in order to determine the optimal set of sensors. Itmust examine room dimensions, the location of doors and windows, and coordinatethese with sensor capabilities and specifications. No small task! A set of activitydiagrams can be used to describe processing for this use case.The second example is the use case Control cameras. In this use case, the inter- action is relatively simple, but there is the potential for complex functionality, giventhat this “simple” operation requires complex communication with devices locatedremotely and accessible across the Internet. A further possible complication relatespre75977_ch07.qxd  11/27/08  3:36 PM  Page 210to negotiation of control when multiple authorized people attempt to monitorand/or control a single sensor at the same time.Figure 7.11 depicts an activity diagram for the takeControlOfCamera()operation that is part of the Cameraanalysis class used within the Control cameras use case. It should be noted that two additional operations are invoked with the proceduralflow: requestCameraLock(),which tries to lock the camera for this user, andgetCurrentCameraUser(),which retrieves the name of the user who is currently con-trolling the camera. The construction details indicating how these operations are in-voked and the interface details for each operation are not considered until WebAppdesign commences.
7.5.7 Configuration Models for WebApps
In some cases, the configuration model is nothing more than a list of server-sideand client-side attributes. However, for more complex WebApps, a variety of con-figuration complexities (e.g., distributing load among multiple servers, cachingarchitectures, remote databases, multiple servers serving various objects on thesame Web page) may have an impact on analysis and design. The UML deployment diagramcan be used in situations in which complex configuration architecturesmust be considered.For SafeHomeAssured.comthe public content and functionality should bespecified to be accessible across all major Web clients (i.e., those with more thanCHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 211
getCurrentCameraUser()
Report Camerain use and nameof current userLock available Lock unavailableCamera not in useCamera in use
requestCameraLock()
Report Cameranow locked foruserReport CameraunavailableFIGURE 7.11
Activitydiagramfor thetakeControlOf-Camera()operationpre75977_ch07.qxd  11/27/08  3:36 PM  Page 211212 PART TWOMODELING
1 percent market share or greater17). Conversely, it may be acceptable to restrict themore complex control and monitoring functionality (which is only accessible toHomeownerusers) to a smaller set of clients. The configuration model forSafeHomeAssured.comwill also specify interoperability with existing productdatabases and monitoring applications.
7.5.8 Navigation Modeling
Navigation modeling considers how each user category will navigate from oneWebApp element (e.g., content object) to another. The mechanics of navigation aredefined as part of design. At this stage, you should focus on overall navigationrequirements. The following questions should be considered:
•Should certain elements be easier to reach (require fewer navigation steps)than others? What is the priority for presentation?
•Should certain elements be emphasized to force users to navigate in theirdirection?
•How should navigation errors be handled?
•Should navigation to related groups of elements be given priority overnavigation to a specific element?
•Should navigation be accomplished via links, via search-based access, or bysome other means?
•Should certain elements be presented to users based on the context ofprevious navigation actions?
•Should a navigation log be maintained for users?
•Should a full navigation map or menu (as opposed to a single “back” link ordirected pointer) be available at every point in a user’s interaction?
•Should navigation design be driven by the most commonly expected userbehaviors or by the perceived importance of the defined WebApp elements?
•Can a user “store” his previous navigation through the WebApp to expeditefuture usage?
•For which user category should optimal navigation be designed?
•How should links external to the WebApp be handled? Overlaying theexisting browser window? As a new browser window? As a separate frame?These and many other questions should be asked and answered as part of navigationanalysis.
17 Determining market share for browsers is notoriously problematic and varies depending on whichsurvey is used. Nevertheless, at the time of writing, Internet Explorer and Firefox are the onlybrowsers that were reported in excess of 30 percent, and Mozilla, Opera, and Safari the only otherones consistently above 1 percent.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 212You and other stakeholders must also determine overall requirements for navi-gation. For example, will a “site map” be provided to give users an overview of theentire WebApp structure? Can a user take a “guided tour” that will highlight the mostimportant elements (content objects and functions) that are available? Will a user beable to access content objects or functions based on defined attributes of those ele-ments (e.g., a user might want to access all photographs of a specific building or allfunctions that allow computation of weight)?
7.6 S UMMARY
Flow-oriented models focus on the flow of data objects as they are transformed byprocessing functions. Derived from structured analysis, flow-oriented models usethe data flow diagram, a modeling notation that depicts how input is transformedinto output as data objects move through a system. Each software function thattransforms data is described by a process specification or narrative. In addition todata flow, this modeling element also depicts control flow—a representation thatillustrates how events affect the behavior of a system.Behavioral modeling depicts dynamic behavior. The behavioral model uses inputfrom scenario-based, flow-oriented, and class-based elements to represent thestates of analysis classes and the system as a whole. To accomplish this, states areidentified, the events that cause a class (or the system) to make a transition from onestate to another are defined, and the actions that occur as transition is accomplishedare also identified. State diagrams and sequence diagrams are the notation used forbehavioral modeling.Analysis patterns enable a software engineer to use existing domain knowledge tofacilitate the creation of a requirements model. An analysis pattern describes a spe-cific software feature or function that can be described by a coherent set of use cases.It specifies the intent of the pattern, the motivation for its use, constraints that limitits use, its applicability in various problem domains, the overall structure of the pat-tern, its behavior and collaborations, and other supplementary information.Requirements modeling for WebApps can use most, if not all, of the modeling el-ements discussed in this book. However, these elements are applied within a set ofspecialized models that address content, interaction, function, navigation, and theclient-server configuration in which the WebApp resides.
PROBLEMS AND POINTS TO PONDER
7.1.What is the fundamental difference between the structured analysis and object-orientedstrategies for requirements analysis?7.2.In a data flow diagram, does an arrow represent a flow of control or something else?7.3.What is “information flow continuity” and how is it applied as a data flow diagram isrefined?CHAPTER 7REQUIREMENTS MODELING: FLOW, BEHAVIOR, PATTERNS, AND WEBAPPS 213pre75977_ch07.qxd  11/27/08  3:36 PM  Page 213214 PART TWOMODELING
7.4.How is a grammatical parse used in the creation of a DFD?7.5.What is a control specification?7.6.Are a PSPEC and a use case the same thing? If not, explain the differences.7.7.There are two different types of “states” that behavioral models can represent. What arethey?7.8.How does a sequence diagram differ from a state diagram. How are they similar?7.9.Suggest three requirements patterns for a modern mobile phone and write a briefdescription of each. Could these patterns be used for other devices. Provide an example.7.10.Select one of the patterns you developed in Problem 7.9 and develop a reasonably com-plete pattern description similar in content and style to the one presented in Section 7.4.2.7.11.How much analysis modeling do you think would be required for SafeHomeAssured.com?Would each of the model types described in Section 7.5.3 be required?7.12.What is the purpose of the interaction model for a WebApp?7.13.It could be argued that a WebApp functional model should be delayed until design.Present pros and cons for this argument.7.14.What is the purpose of a configuration model?7.15.How does the navigation model differ from the interaction model?
FURTHER READINGS AND INFORMATION SOURCES
Dozens of books have been published on structured analysis. All cover the subject adequately,but only a few do a truly excellent job. DeMarco and Plauger ( Structured Analysis and System Specification,Pearson, 1985) is a classic that remains a good introduction to the basic notation.Books by Kendall and Kendall (Systems Analysis and Design, 5th ed., Prentice-Hall, 2002), Hofferet al. (Modern Systems Analysis and Design, Addison-Wesley, 3d ed., 2001), Davis and Yen (The Information System Consultant’s Handbook: Systems Analysis and Design, CRC Press, 1998), and Modell (A Professional’s Guide to Systems Analysis, 2d ed., McGraw-Hill, 1996) are worthwhile references. Yourdon’s book (Modern Structured Analysis, Yourdon-Press, 1989) on the subjectremains among the most comprehensive coverage published to date.Behavioral modeling presents an important dynamic view of system behavior. Books byWagner and his colleagues (Modeling Software with Finite State Machines: A Practical Approach,Auerbach, 2006) and Boerger and Staerk ( Abstract State Machines,Springer, 2003) present thor- ough discussion of state diagrams and other behavioral representations.The majority of books written about software patterns focus on software design. However,books by Evans (Domain-Driven Design, Addison-Wesley, 2003) and Fowler ([Fow03] and [Fow97]) address analysis patterns specifically.An in-depth treatment of analysis modeling for WebApps is presented by Pressman andLowe [Pre08]. Papers contained within an anthology edited by Murugesan and Desphande ( Web Engineering: Managing Diversity and Complexity of Web Application Development, Springer, 2001) treat various aspects of WebApp requirements. In addition, the annual Proceedings of the Inter-national Conference on Web Engineering regularly addresses requirements modeling issues. A wide variety of information sources on requirements modeling are available on theInternet. An up-to-date list of World Wide Web references that are relevant to analysismodeling can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.pre75977_ch07.qxd  11/27/08  3:36 PM  Page 214Software design encompasses the set of principles, concepts, and practicesthat lead to the development of a high-quality system or product. Designprinciples establish an overriding philosophy that guides you in the designwork you must perform. Design concepts must be understood before the me-chanics of design practice are applied, and design practice itself leads to the cre-ation of various representations of the software that serve as a guide for theconstruction activity that follows.Design is pivotal to successful software engineering. In the early 1990s MitchKapor, the creator of Lotus 1-2-3, presented a “software design manifesto” inDr. Dobbs Journal.He said:
What is design? It’s where you stand with a foot in two worlds—the world of technol-ogy and the world of people and human purposes—and you try to bring the twotogether....
215CHAPTER
8DESIGN
CONCEPTS
What is it? Design is what almostevery engineer wants to do. It is theplace where creativity rules—wherestakeholder requirements, businessneeds, and technical considerations all cometogether in the formulation of a product or sys-tem. Design creates a representation or modelof the software, but unlike the requirementsmodel (that focuses on describing requireddata, function, and behavior), the design modelprovides detail about software architecture,data structures, interfaces, and components thatare necessary to implement the system.
Who does it? Software engineers conduct each ofthe design tasks.
Why is it important? Design allows you to modelthe system or product that is to be built. Thismodel can be assessed for quality andimproved before code is generated, tests areconducted, and end users become involved inlarge numbers. Design is the place where soft-ware quality is established.
What are the steps? Design depicts the soft-ware in a number of different ways. First, theQUICK
LOOKarchitecture of the system or product must berepresented. Then, the interfaces that connectthe software to end users, to other systems anddevices, and to its own constituent componentsare modeled. Finally, the software componentsthat are used to construct the system aredesigned. Each of these views represents a dif-ferent design action, but all must conform to aset of basic design concepts that guide softwaredesign work.
What is the work product? A design model thatencompasses architectural, interface, component-level, and deployment representations is theprimary work product that is produced duringsoftware design.
How do I ensure that I’ve done it right? Thedesign model is assessed by the software teamin an effort to determine whether it containserrors, inconsistencies, or omissions; whetherbetter alternatives exist; and whether themodel can be implemented within the con-straints, schedule, and cost that have beenestablished.KEY
CONCEPTS
abstraction . . . .223architecture  . . .223aspects  . . . . . .228cohesion . . . . . .227data design  . . .234design process  .219functionalindependence  . .227good design  . . .219information hiding  . . . . . . .226pre75977_ch08.qxd  11/27/08  3:38 PM  Page 215The Roman architecture critic Vitruvius advanced the notion that well-designed build-ings were those which exhibited firmness, commodity, and delight. The same might besaid of good software. Firmness:A program should not have any bugs that inhibit its func-tion. Commodity:A program should be suitable for the purposes for which it was in-tended. Delight:The experience of using the program should be a pleasurable one. Herewe have the beginnings of a theory of design for software.
The goal of design is to produce a model or representation that exhibits firmness,commodity, and delight. To accomplish this, you must practice diversification andthen convergence. Belady [Bel81] states that “diversification is the acquisition of arepertoire of alternatives, the raw material of design: components, component solu-tions, and knowledge, all contained in catalogs, textbooks, and the mind.” Once thisdiverse set of information is assembled, you must pick and choose elements from therepertoire that meet the requirements defined by requirements engineering and theanalysis model (Chapters 5 through 7). As this occurs, alternatives are consideredand rejected and you converge on “one particular configuration of components, andthus the creation of the final product” [Bel81].Diversification and convergence combine intuition and judgment based on expe-rience in building similar entities, a set of principles and/or heuristics that guide theway in which the model evolves, a set of criteria that enables quality to be judged,and a process of iteration that ultimately leads to a final design representation.Software design changes continually as new methods, better analysis, and broaderunderstanding evolve.
1Even today, most software design methodologies lack thedepth, flexibility, and quantitative nature that are normally associated with more clas-sical engineering design disciplines. However, methods for software design do exist,criteria for design quality are available, and design notation can be applied. In thischapter, I explore the fundamental concepts and principles that are applicable to allsoftware design, the elements of the design model, and the impact of patterns onthe design process. In Chapters 9 through 13 I’ll present a variety of software design methods as they are applied to architectural, interface, and component-level design as well as pattern-based and Web-oriented design approaches.
8.1 D ESIGN WITHIN THE CONTEXT OF SOFTWARE ENGINEERING
Software design sits at the technical kernel of software engineering and is appliedregardless of the software process model that is used. Beginning once software re-quirements have been analyzed and modeled, software design is the last softwareengineering action within the modeling activity and sets the stage for construction(code generation and testing).216 PART TWOMODELING
modularity  . . . .225object-orienteddesign  . . . . . . .230patterns . . . . . .224quality attributes . . . . .220quality guidelines . . . . .219refactoring  . . . .229separation ofconcerns . . . . . .225software design  . . . . . . .221stepwise refinement  . . . .228
1 Those readers with further interest in the philosophy of software design might have interest inPhilippe Kruchen’s intriguing discussion of “post-modern” design [Kru05a].uote:
“The most commonmiracle of softwareengineering is thetransition fromanalysis to designand design to code.”Richard Due’pre75977_ch08.qxd  11/27/08  3:38 PM  Page 216Each of the elements of the requirements model (Chapters 6 and 7) provides in-formation that is necessary to create the four design models required for a completespecification of design. The flow of information during software design is illustratedin Figure 8.1. The requirements model, manifested by scenario-based, class-based,flow-oriented, and behavioral elements, feed the design task. Using design notationand design methods discussed in later chapters, design produces a data/class de-sign, an architectural design, an interface design, and a component design.The data/class design transforms class models (Chapter 6) into design class real-izations and the requisite data structures required to implement the software. Theobjects and relationships defined in the CRC diagram and the detailed data contentdepicted by class attributes and other notation provide the basis for the data designaction. Part of class design may occur in conjunction with the design of softwarearchitecture. More detailed class design occurs as each software component isdesigned.The architectural design defines the relationship between major structural ele-ments of the software, the architectural styles and design patterns that can be usedto achieve the requirements defined for the system, and the constraints that affectthe way in which architecture can be implemented [Sha96]. The architectural designrepresentation—the framework of a computer-based system—is derived from therequirements model.CHAPTER 8DESIGN CONCEPTS 217
Software designshould always beginwith a consideration ofdata—the foundationfor all other elementsof the design. After thefoundation is laid, thearchitecture must bederived. Only thenshould you performother design tasks.Analysis ModelUse cases - text Use-case diagrams Activity diagrams Swimlane diagramsData flow diagrams Control-flow diagrams Processing narrativesFlow-orientedelements
Behavioralelements Class-basedelementsScenerio-basedelements
Class diagrams Analysis packages CRC models Collaboration diagrams  State diagrams Sequence diagramsData/Class DesignInterface DesignArchitectural DesignComponent-Level Design
Design ModelFIGURE 8.1 Translating the requirements model into the design modelpre75977_ch08.qxd  11/27/08  3:38 PM  Page 217The interface design describes how the software communicates with systems thatinteroperate with it, and with humans who use it. An interface implies a flow ofinformation (e.g., data and/or control) and a specific type of behavior. Therefore,usage scenarios and behavioral models provide much of the information requiredfor interface design.The component-level design transforms structural elements of the software ar-chitecture into a procedural description of software components. Information ob-tained from the class-based models, flow models, and behavioral models serve asthe basis for component design.During design you make decisions that will ultimately affect the success of soft-ware construction and, as important, the ease with which software can be main-tained. But why is design so important?The importance of software design can be stated with a single word—quality.Design is the place where quality is fostered in software engineering. Design providesyou with representations of software that can be assessed for quality. Design is theonly way that you can accurately translate stakeholder’s requirements into a finishedsoftware product or system. Software design serves as the foundation for all the soft-ware engineering and software support activities that follow. Without design, you riskbuilding an unstable system—one that will fail when small changes are made; onethat may be difficult to test; one whose quality cannot be assessed until late in thesoftware process, when time is short and many dollars have already been spent.218 PART TWOMODELING
uote:
“There are twoways ofconstructing asoftware design.One way is tomake it so simplethat there areobviously nodeficiencies, andthe other way is tomake it socomplicated thatthere are noobviousdeficiencies. Thefirst method is farmore difficult.”C. A. R. Hoare
Design versus Coding
The scene:Jamie’s cubicle, as theteam prepares to translate requirements into design.The players:Jamie, Vinod, and Ed—all members ofthe SafeHomesoftware engineering team.The conversation:Jamie:You know, Doug [the team manager] is obsessedwith design. I gotta be honest, what I really love doing iscoding. Give me C++ or Java, and I’m happy.Ed:Nah . . . you like to design.Jamie:You’re not listening; coding is where it’s at.Vinod:I think what Ed means is you don’t really likecoding; you like to design and express it in code. Code isthe language you use to represent the design.Jamie:And what’s wrong with that?Vinod:Level of abstraction.Jamie:Huh?Ed:A programming language is good for representingdetails like data structures and algorithms, but it’s not sogood for representing architecture or component-to-component collaboration . . . stuff like that.Vinod:And a screwed-up architecture can ruin even thebest code.Jamie (thinking for a minute):So, you’re sayingthat I can’t represent architecture in code . . . that’s not true.Vinod:You can certainly imply architecture in code, butin most programming languages, it’s pretty difficult to geta quick, big-picture read on architecture by examiningthe code.Ed:And that’s what we want before we begin coding.Jamie:Okay, maybe design and coding are different,but I still like coding better.SAFEHOMEpre75977_ch08.qxd  11/27/08  3:38 PM  Page 2188.2 T HEDESIGN PROCESS
Software design is an iterative process through which requirements are translatedinto a “blueprint” for constructing the software. Initially, the blueprint depicts a holis-tic view of software. That is, the design is represented at a high level of abstraction—a level that can be directly traced to the specific system objective and more detaileddata, functional, and behavioral requirements. As design iterations occur, subse-quent refinement leads to design representations at much lower levels of abstraction.These can still be traced to requirements, but the connection is more subtle.
8.2.1 Software Quality Guidelines and Attributes
Throughout the design process, the quality of the evolving design is assessed with aseries of technical reviews discussed in Chapter 15. McGlaughlin [McG91] suggeststhree characteristics that serve as a guide for the evaluation of a good design:
•The design must implement all of the explicit requirements contained in therequirements model, and it must accommodate all of the implicit require-ments desired by stakeholders.
•The design must be a readable, understandable guide for those who generatecode and for those who test and subsequently support the software.
•The design should provide a complete picture of the software, addressing thedata, functional, and behavioral domains from an implementation perspective.Each of these characteristics is actually a goal of the design process. But how is eachof these goals achieved?Quality Guidelines.In order to evaluate the quality of a design representation,you and other members of the software team must establish technical criteria forgood design. In Section 8.3, I discuss design concepts that also serve as softwarequality criteria. For the time being, consider the following guidelines:1.A design should exhibit an architecture that (1) has been created using rec-ognizable architectural styles or patterns, (2) is composed of componentsthat exhibit good design characteristics (these are discussed later in thischapter), and (3) can be implemented in an evolutionary fashion,
2thereby facilitating implementation and testing.2.A design should be modular; that is, the software should be logically parti-tioned into elements or subsystems.3.A design should contain distinct representations of data, architecture,interfaces, and components.CHAPTER 8DESIGN CONCEPTS 219
uote:
“. . . writing aclever piece of codethat works is onething; designingsomething that cansupport a long-lasting business isquite another.”C. Ferguson
What are thecharacteris-tics of a gooddesign??
2 For smaller systems, design can sometimes be developed linearly.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 2194.A design should lead to data structures that are appropriate for the classes tobe implemented and are drawn from recognizable data patterns.5.A design should lead to components that exhibit independent functionalcharacteristics.6.A design should lead to interfaces that reduce the complexity of connectionsbetween components and with the external environment.7.A design should be derived using a repeatable method that is driven by infor-mation obtained during software requirements analysis.8.A design should be represented using a notation that effectively communi-cates its meaning.These design guidelines are not achieved by chance. They are achieved through theapplication of fundamental design principles, systematic methodology, and thoroughreview.220 PART TWOMODELING
Design is important because it allows asoftware team to assess the quality
3of the software before it is implemented—at a time when errors,omissions, or inconsistencies are easy and inexpensive tocorrect. But how do we assess quality during design? Thesoftware can’t be tested, because there is no executablesoftware to test. What to do?During design, quality is assessed by conducting a seriesof technical reviews (TRs). TRs are discussed in detail inChapter 15,
4but it’s worth providing a summary of thetechnique at this point. A technical review is a meetingconducted by members of the software team. Usually two,three, or four people participate depending on the scope ofthe design information to be reviewed. Each person playsa role: thereview leaderplans the meeting, sets an agenda,and runs the meeting; therecordertakes notes so thatnothing is missed; theproduceris the person whose workproduct (e.g., the design of a software component) is beingreviewed. Prior to the meeting, each person on the reviewteam is given a copy of the design work product and is askedto read it, looking for errors, omissions, or ambiguity. Whenthe meeting commences, the intent is to note all problemswith the work product so that they can be corrected beforeimplementation begins. The TR typically lasts between 90minutes and 2 hours. At the conclusion of the TR, the reviewteam determines whether further actions are required on thepart of the producer before the design work product can beapproved as part of the final design model.INFO
3 The quality factors discussed in Chapter 23 can assist the review team as it assesses quality.4 You might consider reviewing Chapter 15 at this time. Technical reviews are a critical part of thedesign process and are an important mechanism for achieving design quality.Quality Attributes.Hewlett-Packard [Gra87] developed a set of software qualityattributes that has been given the acronym FURPS—functionality, usability, reliabil-ity, performance, and supportability. The FURPS quality attributes represent a targetfor all software design:
•Functionalityis assessed by evaluating the feature set and capabilities of theprogram, the generality of the functions that are delivered, and the security ofthe overall system.uote:
“Quality isn’tsomething you layon top of subjectsand objects liketinsel on aChristmas tree.”Robert PirsigAssessing Design Quality—The Technical Reviewpre75977_ch08.qxd  11/27/08  3:38 PM  Page 220•Usabilityis assessed by considering human factors (Chapter 11), overallaesthetics, consistency, and documentation.
•Reliabilityis evaluated by measuring the frequency and severity of failure, theaccuracy of output results, the mean-time-to-failure (MTTF), the ability torecover from failure, and the predictability of the program.
•Performanceis measured by considering processing speed, response time,resource consumption, throughput, and efficiency.
•Supportabilitycombines the ability to extend the program (extensibility),adaptability, serviceability—these three attributes represent a more commonterm, maintainability—and in addition, testability, compatibility, configura-bility (the ability to organize and control elements of the software configura-tion, Chapter 22), the ease with which a system can be installed, and the easewith which problems can be localized.Not every software quality attribute is weighted equally as the software design is de-veloped. One application may stress functionality with a special emphasis on secu-rity. Another may demand performance with particular emphasis on processingspeed. A third might focus on reliability. Regardless of the weighting, it is importantto note that these quality attributes must be considered as design commences, notafter the design is complete and construction has begun.
8.2.2 The Evolution of Software Design
The evolution of software design is a continuing process that has now spanned al-most six decades. Early design work concentrated on criteria for the development ofmodular programs [Den73] and methods for refining software structures in a top-down manner [Wir71]. Procedural aspects of design definition evolved into a philos-ophy called structured programming[Dah72], [Mil72]. Later work proposed methodsfor the translation of data flow [Ste74] or data structure (e.g., [Jac75], [War74]) intoa design definition. Newer design approaches (e.g., [Jac92], [Gam95]) proposed anobject-oriented approach to design derivation. More recent emphasis in software de-sign has been on software architecture [Kru06] and the design patterns that can beused to implement software architectures and lower levels of design abstractions(e.g., [Hol06] [Sha05]). Growing emphasis on aspect-oriented methods (e.g., [Cla05],[Jac04]), model-driven development [Sch06], and test-driven development [Ast04]emphasize techniques for achieving more effective modularity and architecturalstructure in the designs that are created.A number of design methods, growing out of the work just noted, are being ap-plied throughout the industry. Like the analysis methods presented in Chapters 6 and7, each software design method introduces unique heuristics and notation, as wellas a somewhat parochial view of what characterizes design quality. Yet, all of thesemethods have a number of common characteristics: (1) a mechanism for the trans-lation of the requirements model into a design representation, (2) a notation forCHAPTER 8DESIGN CONCEPTS 221
Software designerstend to focus on theproblem to be solved.Just don’t forget thatthe FURPS attributesare always part of theproblem. They must beconsidered.
uote:
“A designer knowsthat he hasachieved perfectionnot when there isnothing left to add,but when there isnothing left to takeaway.”Antoine deSt-Expurey
Whatcharacter-istics are commonto all designmethods??pre75977_ch08.qxd  11/27/08  3:38 PM  Page 221representing functional components and their interfaces, (3) heuristics for refine-ment and partitioning, and (4) guidelines for quality assessment.Regardless of the design method that is used, you should apply a set of basic con-cepts to data, architectural, interface, and component-level design. These conceptsare considered in the sections that follow.222 PART TWOMODELING
Generic Task Set for Design
1. Examine the information domainmodel, and design appropriate datastructures for data objects and their attributes.2. Using the analysis model, select an architectural stylethat is appropriate for the software.3. Partition the analysis model into design subsystemsand allocate these subsystems within the architecture:Be certain that each subsystem is functionallycohesive.Design subsystem interfaces.Allocate analysis classes or functions to eachsubsystem.4. Create a set of design classes or components:Translate analysis class description into a designclass.Check each design class against design criteria;consider inheritance issues.Define methods and messages associated with eachdesign class.Evaluate and select design patterns for a designclass or a subsystem.Review design classes and revise as required.5. Design any interface required with external systemsor devices.6. Design the user interface:Review results of task analysis.Specify action sequence based on user scenarios.Create behavioral model of the interface.Define interface objects, control mechanisms.Review the interface design and revise as required.7. Conduct component-level design.Specify all algorithms at a relatively low level ofabstraction.Refine the interface of each component.Define component-level data structures.Review each component and correct all errorsuncovered.8. Develop a deployment model.TASKSET
8.3 D ESIGN CONCEPTS
A set of fundamental software design concepts has evolved over the history of soft-ware engineering. Although the degree of interest in each concept has varied overthe years, each has stood the test of time. Each provides the software designer witha foundation from which more sophisticated design methods can be applied. Eachhelps you answer the following questions:
•What criteria can be used to partition software into individual components?
•How is function or data structure detail separated from a conceptual repre-sentation of the software?
•What uniform criteria define the technical quality of a software design?M. A. Jackson [Jac75] once said: “The beginning of wisdom for a [software engi-neer] is to recognize the difference between getting a program to work, and gettingit right.” Fundamental software design concepts provide the necessary frameworkfor “getting it right.”pre75977_ch08.qxd  11/27/08  3:38 PM  Page 222In the sections that follow, I present a brief overview of important software designconcepts that span both traditional and object-oriented software development.
8.3.1 Abstraction
When you consider a modular solution to any problem, many levels of abstractioncan be posed. At the highest level of abstraction, a solution is stated in broad termsusing the language of the problem environment. At lower levels of abstraction, amore detailed description of the solution is provided. Problem-oriented terminologyis coupled with implementation-oriented terminology in an effort to state a solution.Finally, at the lowest level of abstraction, the solution is stated in a manner that canbe directly implemented.As different levels of abstraction are developed, you work to create both proce-dural and data abstractions. A procedural abstractionrefers to a sequence of instruc- tions that have a specific and limited function. The name of a procedural abstractionimplies these functions, but specific details are suppressed. An example of a proce-dural abstraction would be the word open for a door. Openimplies a long sequence of procedural steps (e.g., walk to the door, reach out and grasp knob, turn knob andpull door, step away from moving door, etc.).
5
A data abstractionis a named collection of data that describes a data object. Inthe context of the procedural abstraction open, we can define a data abstraction called door.Like any data object, the data abstraction for doorwould encompass a set of attributes that describe the door (e.g., door type, swing direction, openingmechanism, weight, dimensions). It follows that the procedural abstraction openwould make use of information contained in the attributes of the data abstractiondoor.
8.3.2 Architecture
Software architecturealludes to “the overall structure of the software and the waysin which that structure provides conceptual integrity for a system” [Sha95a]. In itssimplest form, architecture is the structure or organization of program components(modules), the manner in which these components interact, and the structure of datathat are used by the components. In a broader sense, however, components can begeneralized to represent major system elements and their interactions.One goal of software design is to derive an architectural rendering of a system.This rendering serves as a framework from which more detailed design activities areconducted. A set of architectural patterns enables a software engineer to solvecommon design problems.CHAPTER 8DESIGN CONCEPTS 223
uote:
“Abstraction is oneof the fundamentalways that we ashumans cope withcomplexity.”Grady Booch
5 It should be noted, however, that one set of operations can be replaced with another, as long as thefunction implied by the procedural abstraction remains the same. Therefore, the steps required toimplement openwould change dramatically if the door were automatic and attached to a sensor.As a designer, workhard to derive bothprocedural and dataabstractions that servethe problem at hand.If they can serve anentire domain ofproblems, that’s evenbetter.
WebRef
An in-depth discussionof software architecturecan be found atwww.sei.cmu.edu/ata/ata_init.html.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 223Shaw and Garlan [Sha95a] describe a set of properties that should be specified aspart of an architectural design:
Structural properties.This aspect of the architectural design representation definesthe components of a system (e.g., modules, objects, filters) and the manner in whichthose components are packaged and interact with one another. For example, objects arepackaged to encapsulate both data and the processing that manipulates the data and in-teract via the invocation of methods.Extra-functional properties.The architectural design description should address how the design architecture achieves requirements for performance, capacity, reliability,security, adaptability, and other system characteristics.Families of related systems.The architectural design should draw upon repeatable patterns that are commonly encountered in the design of families of similar systems. Inessence, the design should have the ability to reuse architectural building blocks.
Given the specification of these properties, the architectural design can be repre-sented using one or more of a number of different models [Gar95]. Structural models represent architecture as an organized collection of program components.Framework modelsincrease the level of design abstraction by attempting to identifyrepeatable architectural design frameworks that are encountered in similar types ofapplications. Dynamic modelsaddress the behavioral aspects of the program archi-tecture, indicating how the structure or system configuration may change as a func-tion of external events. Process models focus on the design of the business or technical process that the system must accommodate. Finally, functional modelscan be used to represent the functional hierarchy of a system.A number of different architectural description languages (ADLs) have been devel- oped to represent these models [Sha95b]. Although many different ADLs have beenproposed, the majority provide mechanisms for describing system components andthe manner in which they are connected to one another.You should note that there is some debate about the role of architecture in design.Some researchers argue that the derivation of software architecture should be sep-arated from design and occurs between requirements engineering actions and moreconventional design actions. Others believe that the derivation of architecture is anintegral part of the design process. The manner in which software architecture ischaracterized and its role in design are discussed in Chapter 9.
8.3.3 Patterns
Brad Appleton defines a design pattern in the following manner: “A pattern is a named nugget of insight which conveys the essence of a proven solution to a recur-ring problem within a certain context amidst competing concerns” [App00]. Statedin another way, a design pattern describes a design structure that solves a particulardesign problem within a specific context and amid “forces” that may have an impacton the manner in which the pattern is applied and used.224 PART TWOMODELING
uote:
“A softwarearchitecture is thedevelopment workproduct that givesthe highest returnon investment withrespect to quality,schedule, andcost.”Len Bass et al.
Don’t just let architec-ture happen. If you do,you’ll spend the rest ofthe project trying toforce fit the design.Design architectureexplicitly.
uote:
“Each patterndescribes aproblem whichoccurs over andover again in ourenvironment, andthen describes thecore of the solutionto that problem, insuch a way thatyou can use thissolution a milliontimes over, withoutever doing it thesame way twice.”ChristopherAlexanderpre75977_ch08.qxd  11/27/08  3:38 PM  Page 224The intent of each design pattern is to provide a description that enables adesigner to determine (1) whether the pattern is applicable to the current work,(2) whether the pattern can be reused (hence, saving design time), and (3) whetherthe pattern can serve as a guide for developing a similar, but functionally or struc-turally different pattern. Design patterns are discussed in detail in Chapter 12.
8.3.4 Separation of Concerns
Separation of concernsis a design concept [Dij82] that suggests that any complexproblem can be more easily handled if it is subdivided into pieces that can each besolved and/or optimized independently. A concern is a feature or behavior that is specified as part of the requirements model for the software. By separating concernsinto smaller, and therefore more manageable pieces, a problem takes less effort andtime to solve.For two problems, p
1and p2, if the perceived complexity of p1is greater than the perceived complexity of p
2, it follows that the effort required to solve p1is greater than the effort required to solve p
2. As a general case, this result is intuitively obvi-ous. It does take more time to solve a difficult problem.It also follows that the perceived complexity of two problems when they are com-bined is often greater than the sum of the perceived complexity when each is takenseparately. This leads to a divide-and-conquer strategy—it’s easier to solve a com-plex problem when you break it into manageable pieces. This has important impli-cations with regard to software modularity.Separation of concerns is manifested in other related design concepts: modular-ity, aspects, functional independence, and refinement. Each will be discussed in thesubsections that follow.
8.3.5 Modularity
Modularity is the most common manifestation of separation of concerns. Softwareis divided into separately named and addressable components, sometimes calledmodules,that are integrated to satisfy problem requirements.It has been stated that “modularity is the single attribute of software that allows aprogram to be intellectually manageable” [Mye78]. Monolithic software (i.e., a largeprogram composed of a single module) cannot be easily grasped by a software engi-neer. The number of control paths, span of reference, number of variables, and over-all complexity would make understanding close to impossible. In almost allinstances, you should break the design into many modules, hoping to make under-standing easier and, as a consequence, reduce the cost required to build the software.Recalling my discussion of separation of concerns, it is possible to conclude thatif you subdivide software indefinitely the effort required to develop it will becomenegligibly small! Unfortunately, other forces come into play, causing this conclusionto be (sadly) invalid. Referring to Figure 8.2, the effort (cost) to develop an individualsoftware module does decrease as the total number of modules increases. Given theCHAPTER 8DESIGN CONCEPTS 225
The argument for sepa-ration of concerns canbe taken too far. Ifyou divide a probleminto an inordinatenumber of verysmall problems,solving each will beeasy, but putting thesolution together—integration—may be very difficult.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 225same set of requirements, more modules means smaller individual size. However, asthe number of modules grows, the effort (cost) associated with integrating the mod-ules also grows. These characteristics lead to a total cost or effort curve shown in thefigure. There is a number, M,of modules that would result in minimum developmentcost, but we do not have the necessary sophistication to predict M with assurance. The curves shown in Figure 8.2 do provide useful qualitative guidance when mod-ularity is considered. You should modularize, but care should be taken to stay in thevicinity of M.Undermodularity or overmodularity should be avoided. But how do youknow the vicinity of M? How modular should you make software? The answers tothese questions require an understanding of other design concepts considered laterin this chapter.You modularize a design (and the resulting program) so that development can bemore easily planned; software increments can be defined and delivered; changes canbe more easily accommodated; testing and debugging can be conducted more effi-ciently, and long-term maintenance can be conducted without serious side effects.
8.3.6 Information Hiding
The concept of modularity leads you to a fundamental question: “How do I decom-pose a software solution to obtain the best set of modules?” The principle of infor-mation hiding [Par72] suggests that modules be “characterized by design decisionsthat (each) hides from all others.” In other words, modules should be specified anddesigned so that information (algorithms and data) contained within a module is in-accessible to other modules that have no need for such information.Hiding implies that effective modularity can be achieved by defining a set of inde-pendent modules that communicate with one another only that information neces-sary to achieve software function. Abstraction helps to define the procedural (orinformational) entities that make up the software. Hiding defines and enforces accessconstraints to both procedural detail within a module and any local data structureused by the module [Ros75].226 PART TWOMODELING
MRegion of minimumcost
Number of modulesCost or effort
Cost/moduleCost to integrateTotal software costFIGURE 8.2
Modularityand softwarecost
What is theright numberof modules for agiven system??
The intent of informationhiding is to hide thedetails of data structuresand procedural processingbehind a module inter-face. Knowledge of thedetails need not beknown by users of themodule.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 226The use of information hiding as a design criterion for modular systems providesthe greatest benefits when modifications are required during testing and later dur-ing software maintenance. Because most data and procedural detail are hidden fromother parts of the software, inadvertent errors introduced during modification areless likely to propagate to other locations within the software.
8.3.7 Functional Independence
The concept of functional independence is a direct outgrowth of separation of con-cerns, modularity, and the concepts of abstraction and information hiding. In land-mark papers on software design, Wirth [Wir71] and Parnas [Par72] allude torefinement techniques that enhance module independence. Later work by Stevens,Myers, and Constantine [Ste74] solidified the concept.Functional independence is achieved by developing modules with “single-minded” function and an “aversion” to excessive interaction with other modules.Stated another way, you should design software so that each module addresses aspecific subset of requirements and has a simple interface when viewed from otherparts of the program structure. It is fair to ask why independence is important.Software with effective modularity, that is, independent modules, is easier to de-velop because function can be compartmentalized and interfaces are simplified(consider the ramifications when development is conducted by a team). Independentmodules are easier to maintain (and test) because secondary effects caused by de-sign or code modification are limited, error propagation is reduced, and reusablemodules are possible. To summarize, functional independence is a key to good de-sign, and design is the key to software quality.Independence is assessed using two qualitative criteria: cohesion and coupling.Cohesionis an indication of the relative functional strength of a module. Coupling is an indication of the relative interdependence among modules.Cohesion is a natural extension of the information-hiding concept described inSection 8.3.6. A cohesive module performs a single task, requiring little interactionwith other components in other parts of a program. Stated simply, a cohesive mod-ule should (ideally) do just one thing. Although you should always strive for high co-hesion (i.e., single-mindedness), it is often necessary and advisable to have asoftware component perform multiple functions. However, “schizophrenic” compo-nents (modules that perform many unrelated functions) are to be avoided if a gooddesign is to be achieved.Coupling is an indication of interconnection among modules in a software struc-ture. Coupling depends on the interface complexity between modules, the point atwhich entry or reference is made to a module, and what data pass across the inter-face. In software design, you should strive for the lowest possible coupling. Simpleconnectivity among modules results in software that is easier to understand and lessprone to a “ripple effect” [Ste74], caused when errors occur at one location and prop-agate throughout a system.CHAPTER 8DESIGN CONCEPTS 227
Why shouldyou striveto createindependentmodules??
Cohesion is aqualitative indicationof the degree to whicha module focuses onjust one thing.
Coupling is aqualitative indication ofthe degree to which amodule is connected toother modules and tothe outside world.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 2278.3.8 Refinement
Stepwise refinement is a top-down design strategy originally proposed by NiklausWirth [Wir71]. A program is developed by successively refining levels of proceduraldetail. A hierarchy is developed by decomposing a macroscopic statement of func-tion (a procedural abstraction) in a stepwise fashion until programming languagestatements are reached.Refinement is actually a process of elaboration. You begin with a statement of function (or description of information) that is defined at a high level of abstraction.That is, the statement describes function or information conceptually but providesno information about the internal workings of the function or the internal structureof the information. You then elaborate on the original statement, providing more andmore detail as each successive refinement (elaboration) occurs.Abstraction and refinement are complementary concepts. Abstraction enablesyou to specify procedure and data internally but suppress the need for “outsiders” tohave knowledge of low-level details. Refinement helps you to reveal low-level de-tails as design progresses. Both concepts allow you to create a complete designmodel as the design evolves.
8.3.9 Aspects
As requirements analysis occurs, a set of “concerns” is uncovered. These concerns“include requirements, use cases, features, data structures, quality-of-service issues,variants, intellectual property boundaries, collaborations, patterns and contracts”[AOS07]. Ideally, a requirements model can be organized in a way that allows you toisolate each concern (requirement) so that it can be considered independently. Inpractice, however, some of these concerns span the entire system and cannot beeasily compartmentalized.As design begins, requirements are refined into a modular design representation.Consider two requirements, Aand B.Requirement A crosscutsrequirement B“if a software decomposition [refinement] has been chosen in which B cannot be satis- fied without taking Ainto account” [Ros04].For example, consider two requirements for the SafeHomeAssured.comWebApp. Requirement Ais described via the ACS-DCVuse case discussed in Chapter 6. A design refinement would focus on those modules that would enable a registered userto access video from cameras placed throughout a space. Requirement B is a generic security requirement that states that a registered user must be validated prior to usingSafeHomeAssured.com.This requirement is applicable for all functions that areavailable to registered SafeHomeusers. As design refinement occurs, A* is a design representation for requirement Aand B*is a design representation for requirement B . Therefore, A*and B*are representations of concerns, and B* crosscuts A*. An aspectis a representation of a crosscutting concern. Therefore, the design rep-resentation, B*, of the requirement a registered user must be validated prior to usingSafeHomeAssured.com,is an aspect of the SafeHomeWebApp. It is important to228 PART TWOMODELING
There is a tendency tomove immediately tofull detail, skippingrefinement steps. Thisleads to errors andomissions and makesthe design much moredifficult to review.Perform stepwiserefinement.
uote:
“It’s hard to readthrough a book onthe principles ofmagic withoutglancing at thecover periodicallyto make sure itisn’t a book onsoftware design.”Bruce Tognazzini
A crosscutting concernis some characteristicof the system thatapplies across manydifferent requirements.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 228identify aspects so that the design can properly accommodate them as refinementand modularization occur. In an ideal context, an aspect is implemented as a sepa-rate module (component) rather than as software fragments that are “scattered” or“tangled” throughout many components [Ban06]. To accomplish this, the design ar-chitecture should support a mechanism for defining an aspect—a module that en-ables the concern to be implemented across all other concerns that it crosscuts.
8.3.10 Refactoring
An important design activity suggested for many agile methods (Chapter 3),refactoringis a reorganization technique that simplifies the design (or code) of acomponent without changing its function or behavior. Fowler [Fow00] defines refac-toring in the following manner: “Refactoring is the process of changing a softwaresystem in such a way that it does not alter the external behavior of the code [design]yet improves its internal structure.”When software is refactored, the existing design is examined for redundancy, un-used design elements, inefficient or unnecessary algorithms, poorly constructed orinappropriate data structures, or any other design failure that can be corrected to yielda better design. For example, a first design iteration might yield a component thatexhibits low cohesion (i.e., it performs three functions that have only limited relation-ship to one another). After careful consideration, you may decide that the componentshould be refactored into three separate components, each exhibiting high cohesion.CHAPTER 8DESIGN CONCEPTS 229
WebRef
Excellent resources forrefactoring can befound at www.refactoring.com.
WebRef
A variety of refactoringpatterns can be found athttp:/ /c2.com/cgi/wiki?RefactoringPatterns.
Design Concepts
The scene:Vinod’s cubicle, asdesign modeling begins.The players:Vinod, Jamie, and Ed—members of theSafeHomesoftware engineering team. Also, Shakira, anew member of the team.The conversation:[All four team members have just returned from a morningseminar entitiled “Applying Basic Design Concepts,”offered by a local computer science professor.]Vinod:Did you get anything out of the seminar?Ed:Knew most of the stuff, but it’s not a bad idea to hearit again, I suppose.Jamie:When I was an undergrad CS major, I neverreally understood why information hiding was asimportant as they say it is.Vinod:Because . . . bottom line . . . it’s a technique forreducing error propagation in a program. Actually,functional independence also accomplishes the same thing.Shakira:I wasn’t a CS grad, so a lot of the stuff theinstructor mentioned is new to me. I can generategood code and fast. I don’t see why this stuff is soimportant.Jamie:I’ve seen your work, Shak, and you know what,you do a lot of this stuff naturally. . . that’s why yourdesigns and code work.Shakira (smiling):Well, I always do try to partitionthe code, keep it focused on one thing, keep interfacessimple and constrained, reuse code whenever I can . . .that sort of thing.Ed:Modularity, functional independence, hiding, patterns. . . see.Jamie:I still remember the very first programmingcourse I took. . . they taught us to refine the codeiteratively.Vinod:Same thing can be applied to design, you know.Vinod:The only concepts I hadn’t heard of before were“aspects” and “refactoring.”SAFEHOMEpre75977_ch08.qxd  11/27/08  3:38 PM  Page 229The result will be software that is easier to integrate, easier to test, and easier tomaintain.
8.3.11 Object-Oriented Design Concepts
The object-oriented (OO) paradigm is widely used in modern software engineering.Appendix 2 has been provided for those readers who may be unfamiliar with OOdesign concepts such as classes and objects, inheritance, messages, and polymor-phism, among others.
8.3.12 Design Classes
The requirements model defines a set of analysis classes (Chapter 6). Each describessome element of the problem domain, focusing on aspects of the problem that areuser visible. The level of abstraction of an analysis class is relatively high.As the design model evolves, you will define a set of design classes that refine the analysis classes by providing design detail that will enable the classes to be imple-mented, and implement a software infrastructure that supports the business solu-tion. Five different types of design classes, each representing a different layer of thedesign architecture, can be developed [Amb01]:
•User interface classesdefine all abstractions that are necessary for human-computer interaction (HCI). In many cases, HCI occurs within the context of a metaphor(e.g., a checkbook, an order form, a fax machine), and the designclasses for the interface may be visual representations of the elements of themetaphor.
•Business domain classesare often refinements of the analysis classes definedearlier. The classes identify the attributes and services (methods) that arerequired to implement some element of the business domain.
•Process classesimplement lower-level business abstractions required to fullymanage the business domain classes.
•Persistent classesrepresent data stores (e.g., a database) that will persistbeyond the execution of the software.
•System classesimplement software management and control functions thatenable the system to operate and communicate within its computing envi-ronment and with the outside world.230 PART TWOMODELING
Shakira:That’s used in Extreme Programming, I thinkshe said.Ed:Yep. It’s not a whole lot different than refinement, onlyyou do it after the design or code is completed. Kind of anoptimization pass through the software, if you ask me.Jamie:Let’s get back to SafeHomedesign. I think weshould put these concepts on our review checklist as wedevelop the design model for SafeHome.Vinod:I agree. But as important, let’s all commit to thinkabout them as we develop the design.
What typesof classesdoes the designercreate??pre75977_ch08.qxd  11/27/08  3:38 PM  Page 230As the architecture forms, the level of abstraction is reduced as each analysis classis transformed into a design representation. That is, analysis classes represent dataobjects (and associated services that are applied to them) using the jargon of thebusiness domain. Design classes present significantly more technical detail as aguide for implementation.Arlow and Neustadt [Arl02] suggest that each design class be reviewed to ensurethat it is “well-formed.” They define four characteristics of a well-formed designclass:Complete and sufficient.A design class should be the complete encapsu-lation of all attributes and methods that can reasonably be expected (basedon a knowledgeable interpretation of the class name) to exist for the class.For example, the class Scenedefined for video-editing software is completeonly if it contains all attributes and methods that can reasonably be associ-ated with the creation of a video scene. Sufficiency ensures that the designclass contains only those methods that are sufficient to achieve the intent ofthe class, no more and no less.Primitiveness.Methods associated with a design class should be focusedon accomplishing one service for the class. Once the service has been imple-mented with a method, the class should not provide another way to accom-plish the same thing. For example, the class VideoClip for video-editing software might have attributes start-point andend-pointto indicate the start and end points of the clip (note that the raw video loaded into the systemmay be longer than the clip that is used). The methods, setStartPoint() and setEndPoint(),provide the only means for establishing start and end pointsfor the clip.High cohesion.A cohesive design class has a small, focused set of responsi-bilities and single-mindedly applies attributes and methods to implementthose responsibilities. For example, the classVideoClipmight contain a set of methods for editing the video clip. As long as each method focuses solely onattributes associated with the video clip, cohesion is maintained.Low coupling.Within the design model, it is necessary for design classes tocollaborate with one another. However, collaboration should be kept to anacceptable minimum. If a design model is highly coupled (all design classescollaborate with all other design classes), the system is difficult to implement,to test, and to maintain over time. In general, design classes within a subsys-tem should have only limited knowledge of other classes. This restriction,called the Law of Demeter[Lie03], suggests that a method should only sendmessages to methods in neighboring classes.
6CHAPTER 8DESIGN CONCEPTS 231
What is a“well-formed” designclass??
6 A less formal way of stating the Law of Demeter is “Each unit should only talk to its friends; Don’ttalk to strangers.”pre75977_ch08.qxd  11/27/08  3:38 PM  Page 231232 PART TWOMODELING
The scene:Ed’s cubicle, as designmodeling begins.The players:Vinod and Ed—members of theSafeHomesoftware engineering team.The conversation:[Ed is working on the FloorPlanclass (see sidebar dis-cussion in Section 6.5.3 and Figure 6.10) and has refinedit for the design model.]Ed:So you remember the FloorPlanclass, right? It’sused as part of the surveillance and home managementfunctions.Vinod (nodding):Yeah, I seem to recall that we usedit as part of our CRC discussions for home management.Ed:We did. Anyway, I’m refining it for design. Want toshow how we’ll actually implement theFloorPlanclass. My idea is to implement it as a set of linked lists [aspecific data structure] So...Ih a dt orefine the analysisclassFloorPlan(Figure 6.10) and actually, sort ofsimplify it.Vinod:The analysis class showed only things in theproblem domain, well, actually on the computer screen,that were visible to the end user, right?Ed:Yep, but for the FloorPlandesign class, I’ve gotto add some things that are implementation specific. Ineeded to show that FloorPlanis an aggregation ofsegments—hence the Segmentclass—and that theSegmentclass is composed of lists for wall segments,windows, doors, and so on. The class Cameracollaborates with FloorPlan,and obviously, there canbe many cameras in the floor plan.Vinod:Phew, let’s see a picture of this new FloorPlan design class.[Ed shows Vinod the drawing shown in Figure 8.3.]Vinod:Okay, I see what you’re trying to do. This allowsyou to modify the floor plan easily because new items canbe added to or deleted from the list—the aggregation—without any problems.Ed (nodding):Yeah, I think it’ll work.Vinod:So do I.SAFEHOME
FloorPlanaddCamera( ) addWall( ) addWindow( ) deleteSegment( ) draw( )  type outsideDimensions  
WallSegmentSegmentstartCoordinate endCoordinate getType( ) draw( )
WindowCameratype id fieldView panAnglezoomSetting  
1*
1*FIGURE 8.3
Design classfor FloorPlanand compositeaggregationfor the class(see sidebardiscussion)Refining an Analysis Class into a Design Classpre75977_ch08.qxd  11/27/08  3:38 PM  Page 2328.4 T HEDESIGN MODEL
The design model can be viewed in two different dimensions as illustrated inFigure 8.4. Theprocess dimensionindicates the evolution of the design model as de-sign tasks are executed as part of the software process. The abstraction dimension represents the level of detail as each element of the analysis model is transformedinto a design equivalent and then refined iteratively. Referring to Figure 8.4, thedashed line indicates the boundary between the analysis and design models. In somecases, a clear distinction between the analysis and design models is possible. In othercases, the analysis model slowly blends into the design and a clear distinction is lessobvious.The elements of the design model use many of the same UML diagrams
7that were used in the analysis model. The difference is that these diagrams are refinedand elaborated as part of design; more implementation-specific detail is provided,and architectural structure and style, components that reside within the architec-ture, and interfaces between the components and with the outside world are allemphasized.CHAPTER 8DESIGN CONCEPTS 233
Process dimensionAbstraction dimension
Architecture elementsInterface elementsComponent-level elementsDeployment-level elementsLowHighClass diagrams Analysis packages CRC models Collaboration    diagrams Data flow diagrams Control-flow diagrams Processing narrativesUse cases - text Use-case diagrams Activity diagrams Swimlane diagrams Collaboration    diagramsState diagramsSequence diagramsDesign class    realizationsSubsystems Collaboration    diagrams Refinements to:
Deployment diagramsClass diagramsAnalysis packagesCRC modelsCollaboration diagramsData flow diagramsControl-flow diagramsProcessing narrativesState diagramsSequence diagrams
Component diagramsDesign classes Activity diagrams Sequence diagrams Refinements to:
Component diagramsDesign classes Activity diagrams Sequence diagrams Design class realizations Subsystems Collaboration diagrams Component diagrams Design classes Activity diagrams Sequence diagramsAnalysis model
Design modelRequirements:  Constraints  Interoperability  Targets and      configuration
Technical interface design  Navigation design GUI design     Design class       realizations    Subsystems    Collaboration       diagrams FIGURE 8.4 Dimensions of the design modelThe design model hasfour major elements:data, architecture,components, and interface.
7 Appendix 1 provides a tutorial on basic UML concepts and notation.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 233You should note, however, that model elements indicated along the horizontal axisare not always developed in a sequential fashion. In most cases preliminary architec-tural design sets the stage and is followed by interface design and component-leveldesign, which often occur in parallel. The deployment model is usually delayed untilthe design has been fully developed.You can apply design patterns (Chapter 12) at any point during design. These pat-terns enable you to apply design knowledge to domain-specific problems that havebeen encountered and solved by others.
8.4.1 Data Design Elements
Like other software engineering activities, data design (sometimes referred to as dataarchitecting) creates a model of data and/or information that is represented at a highlevel of abstraction (the customer/user’s view of data). This data model is then re-fined into progressively more implementation-specific representations that can beprocessed by the computer-based system. In many software applications, the archi-tecture of the data will have a profound influence on the architecture of the softwarethat must process it.The structure of data has always been an important part of software design. Atthe program component level, the design of data structures and the associatedalgorithms required to manipulate them is essential to the creation of high-qualityapplications. At the application level, the translation of a data model (derived as partof requirements engineering) into a database is pivotal to achieving the businessobjectives of a system. At the business level, the collection of information stored indisparate databases and reorganized into a “data warehouse” enables data miningor knowledge discovery that can have an impact on the success of the business itself.In every case, data design plays an important role. Data design is discussed in moredetail in Chapter 9.
8.4.2 Architectural Design Elements
The architectural designfor software is the equivalent to the floor plan of a house. Thefloor plan depicts the overall layout of the rooms; their size, shape, and relationshipto one another; and the doors and windows that allow movement into and out of therooms. The floor plan gives us an overall view of the house. Architectural design el-ements give us an overall view of the software.The architectural model [Sha96] is derived from three sources: (1) informationabout the application domain for the software to be built; (2) specific requirementsmodel elements such as data flow diagrams or analysis classes, their relationshipsand collaborations for the problem at hand; and (3) the availability of architecturalstyles (Chapter 9) and patterns (Chapter 12).The architectural design element is usually depicted as a set of interconnectedsubsystems, often derived from analysis packages within the requirements model.Each subsystem may have it’s own architecture (e.g., a graphical user interface might234 PART TWOMODELING
uote:
“Questions aboutwhether designis necessary oraffordable arequite beside thepoint: design isinevitable. Thealternative to good design is baddesign, not nodesign at all.”Douglas Martin
At the architectural(application) level,data design focuses onfiles or databases; atthe component level,data design considersthe data structures thatare required toimplement local dataobjects.
uote:
“You can use aneraser on thedrafting table or asledge hammer onthe constructionsite.”Frank LloydWrightpre75977_ch08.qxd  11/27/08  3:38 PM  Page 234be structured according to a preexisting architectural style for user interfaces). Tech-niques for deriving specific elements of the architectural model are presented inChapter 9.
8.4.3 Interface Design Elements
The interface design for software is analogous to a set of detailed drawings (andspecifications) for the doors, windows, and external utilities of a house. Thesedrawings depict the size and shape of doors and windows, the manner in which theyoperate, the way in which utility connections (e.g., water, electrical, gas, telephone)come into the house and are distributed among the rooms depicted in the floor plan.They tell us where the doorbell is located, whether an intercom is to be used to an-nounce a visitor’s presence, and how a security system is to be installed. In essence,the detailed drawings (and specifications) for the doors, windows, and external util-ities tell us how things and information flow into and out of the house and within therooms that are part of the floor plan. The interface design elements for software de-pict information flows into and out of the system and how it is communicated amongthe components defined as part of the architecture.There are three important elements of interface design: (1) the user interface (UI);(2) external interfaces to other systems, devices, networks, or other producers orconsumers of information; and (3) internal interfaces between various design com-ponents. These interface design elements allow the software to communicate exter-nally and enable internal communication and collaboration among the componentsthat populate the software architecture.UI design (increasingly called usability design) is a major software engineering ac-tion and is considered in detail in Chapter 11. Usability design incorporates aestheticelements (e.g., layout, color, graphics, interaction mechanisms), ergonomic ele-ments (e.g., information layout and placement, metaphors, UI navigation), and tech-nical elements (e.g., UI patterns, reusable components). In general, the UI is a uniquesubsystem within the overall application architecture.The design of external interfaces requires definitive information about the entityto which information is sent or received. In every case, this information should becollected during requirements engineering (Chapter 5) and verified once the inter-face design commences.
8The design of external interfaces should incorporate errorchecking and (when necessary) appropriate security features.The design of internal interfaces is closely aligned with component-level design(Chapter 10). Design realizations of analysis classes represent all operations and themessaging schemes required to enable communication and collaboration betweenoperations in various classes. Each message must be designed to accommodatethe requisite information transfer and the specific functional requirements of theCHAPTER 8DESIGN CONCEPTS 235
uote:
“The public is morefamiliar with baddesign than gooddesign. It is, ineffect, conditionedto prefer baddesign, becausethat is what it liveswith. The newbecomesthreatening, theold reassuring.”Paul Rand
There are three partsto the interface designelement: the userinterface, interfaces tosystem external to theapplication, and inter-faces to componentswithin the application.
uote:
“Every now andthen go away, havea little relaxation,for when you comeback to your workyour judgment willbe surer. Go somedistance awaybecause then thework appearssmaller and moreof it can be taken inat a glance and alack of harmonyand proportion ismore readily seen.”LeonardoDaVinci
8 Interface characteristics can change with time. Therefore, a designer should ensure that the spec-ification for the interface is accurate and complete.pre75977_ch08.qxd  11/27/08  3:38 PM  Page 235operation that has been requested. If the classic input-process-output approach todesign is chosen, the interface of each software component is designed based on dataflow representations and the functionality described in a processing narrative.In some cases, an interface is modeled in much the same way as a class. In UML,an interface is defined in the following manner [OMG03a]: “An interface is a speci-fier for the externally-visible [public] operations of a class, component, or other clas-sifier (including subsystems) without specification of internal structure.” Stated moresimply, an interface is a set of operations that describes some part of the behavior ofa class and provides access to these operations.For example, the SafeHomesecurity function makes use of a control panel that al-lows a homeowner to control certain aspects of the security function. In an advancedversion of the system, control panel functions may be implemented via a wirelessPDA or mobile phone.The ControlPanelclass (Figure 8.5) provides the behavior associated with a key-pad, and therefore, it must implement the operations readKeyStroke () and decodeKey (). If these operations are to be provided to other classes (in this case, WirelessPDAandMobilePhone), it is useful to define an interface as shown in the figure. Theinterface, named KeyPad, is shown as an <<interface>> stereotype or as a small,labeled circle connected to the class with a line. The interface is defined with noattributes and the set of operations that are necessary to achieve the behavior ofa keypad.The dashed line with an open triangle at its end (Figure 8.5) indicates that theControlPanelclass provides KeyPadoperations as part of its behavior. In UML, this236 PART TWOMODELING
ControlPanel
LCDdisplay LEDindicators keyPadCharacteristics speaker wirelessInterface readKeyStroke( ) decodeKey( ) displayStatus( ) lightLEDs( ) sendControlMsg( )
KeyPad
readKeystroke( ) decodeKey( ) <<Interface>>WirelessPDAMobilePhone
KeyPadFIGURE 8.5
Interfacerepresentationfor Control-PanelWebRef
Extremely valuableinformation on UIdesign can be found atwww.useit.com.
uote:
“A commonmistake thatpeople make whentrying to designsomethingcompletelyfoolproof was tounderestimate theingenuity ofcomplete fools.”Douglas Adamspre75977_ch08.qxd  11/27/08  3:39 PM  Page 236is characterized as a realization.That is, part of the behavior of ControlPanel will be implemented by realizing KeyPadoperations. These operations will be providedto other classes that access the interface.
8.4.4 Component-Level Design Elements
The component-level design for software is the equivalent to a set of detailed draw-ings (and specifications) for each room in a house. These drawings depict wiring andplumbing within each room, the location of electrical receptacles and wall switches,faucets, sinks, showers, tubs, drains, cabinets, and closets. They also describe theflooring to be used, the moldings to be applied, and every other detail associatedwith a room. The component-level design for software fully describes the internaldetail of each software component. To accomplish this, the component-level designdefines data structures for all local data objects and algorithmic detail for all pro-cessing that occurs within a component and an interface that allows access to allcomponent operations (behaviors).Within the context of object-oriented software engineering, a component is rep-resented in UML diagrammatic form as shown in Figure 8.6. In this figure, a compo-nent named SensorManagement(part of the SafeHomesecurity function) is represented. A dashed arrow connects the component to a class named Sensorthat is assigned to it. The SensorManagement component performs all functions asso- ciated with SafeHomesensors including monitoring and configuring them. Furtherdiscussion of component diagrams is presented in Chapter 10.The design details of a component can be modeled at many different levels ofabstraction. A UML activity diagram can be used to represent processing logic.Detailed procedural flow for a component can be represented using eitherpseudocode (a programming language-like representation described in Chapter 10)or some other diagrammatic form (e.g., flowchart or box diagram). Algorithmicstructure follows the rules established for structured programming (i.e., a set of con-strained procedural constructs). Data structures, selected based on the nature of thedata objects to be processed, are usually modeled using pseudocode or the pro-gramming language to be used for implementation.
8.4.5 Deployment-Level Design Elements
Deployment-level design elements indicate how software functionality and subsys-tems will be allocated within the physical computing environment that will supportCHAPTER 8DESIGN CONCEPTS 237
uote:
“The details arenot the details.They make thedesign.”Charles Eames
SensorManagement SensorFIGURE 8.6
A UMLcomponentdiagrampre75977_ch08.qxd  11/27/08  3:39 PM  Page 237the software. For example, the elements of the SafeHome product are configured to operate within three primary computing environments—a home-based PC, theSafeHomecontrol panel, and a server housed at CPI Corp. (providing Internet-basedaccess to the system).During design, a UML deployment diagram is developed and then refined asshown in Figure 8.7. In the figure, three computing environments are shown (inactuality, there would be more including sensors, cameras, and others). The sub-systems (functionality) housed within each computing element are indicated. Forexample, the personal computer houses subsystems that implement security, sur-veillance, home management, and communications features. In addition, an exter-nal access subsystem has been designed to manage all attempts to access theSafeHomesystem from an external source. Each subsystem would be elaborated toindicate the components that it implements.The diagram shown in Figure 8.7 is in descriptor form. This means that the de- ployment diagram shows the computing environment but does not explicitly indicateconfiguration details. For example, the “personal computer” is not further identified.It could be a Mac or a Windows-based PC, a Sun workstation, or a Linux-box. Thesedetails are provided when the deployment diagram is revisited in instance form during the latter stages of design or as construction begins. Each instance of thedeployment (a specific, named hardware configuration) is identified.238 PART TWOMODELING
CPI server Control panel
Personal computer
Security
HomeManagementSurveillance
CommunicationSecurity HomeownerAccess
ExternalAccessFIGURE 8.7
A UMLdeploymentdiagram
Deployment diagramsbegin in descriptorform, where thedeployment environ-ment is described ingeneral terms. Later,instance form is usedand elements of theconfiguration areexplicitly described.pre75977_ch08.qxd  11/27/08  3:39 PM  Page 2388.5 S UMMARY
Software design commences as the first iteration of requirements engineeringcomes to a conclusion. The intent of software design is to apply a set of principles,concepts, and practices that lead to the development of a high-quality system orproduct. The goal of design is to create a model of software that will implement allcustomer requirements correctly and bring delight to those who use it. Software de-signers must sift through many design alternatives and converge on a solution thatbest suits the needs of project stakeholders.The design process moves from a “big picture” view of software to a more narrowview that defines the detail required to implement a system. The process begins byfocusing on architecture. Subsystems are defined; communication mechanismsamong subsystems are established; components are identified, and a detailed de-scription of each component is developed. In addition, external, internal, and userinterfaces are designed.Design concepts have evolved over the first 60 years of software engineeringwork. They describe attributes of computer software that should be present regard-less of the software engineering process that is chosen, the design methods that areapplied, or the programming languages that are used. In essence, design conceptsemphasize the need for abstraction as a mechanism for creating reusable softwarecomponents; the importance of architecture as a way to better understand the over-all structure of a system; the benefits of pattern-based engineering as a technique fordesigning software with proven capabilities; the value of separation of concerns andeffective modularity as a way to make software more understandable, more testable,and more maintainable; the consequences of information hiding as a mechanismfor reducing the propagation of side effects when errors do occur; the impact offunctional independence as a criterion for building effective modules; the use ofrefinement as a design mechanism; a consideration of aspects that crosscut systemrequirements; the application of refactoring for optimizing the design that is derived;and the importance of object-oriented classes and the characteristics that are relatedto them.The design model encompasses four different elements. As each of these ele-ments is developed, a more complete view of the design evolves. The architecturalelement uses information derived from the application domain, the requirementsmodel, and available catalogs for patterns and styles to derive a complete structuralrepresentation of the software, its subsystems, and components. Interface design el-ements model external and internal interfaces and the user interface. Component-level elements define each of the modules (components) that populate thearchitecture. Finally, deployment-level design elements allocate the architecture, itscomponents, and the interfaces to the physical configuration that will house thesoftware.CHAPTER 8DESIGN CONCEPTS 239pre75977_ch08.qxd  11/27/08  3:39 PM  Page 239PROBLEMS AND POINTS TO PONDER
8.1.Do you design software when you “write” a program? What makes software design differ-ent from coding?8.2.If a software design is not a program (and it isn’t), then what is it?8.3.How do we assess the quality of a software design?8.4.Examine the task set presented for design. Where is quality assessed within the task set?How is this accomplished? How are the quality attributes discussed in Section 8.2.1 achieved?8.5.Provide examples of three data abstractions and the procedural abstractions that can beused to manipulate them.8.6.Describe software architecture in your own words.8.7.Suggest a design pattern that you encounter in a category of everyday things (e.g.,consumer electronics, automobiles, appliances). Briefly describe the pattern.8.8.Describe separation of concerns in your own words. Is there a case when a divide-and-conquer strategy may not be appropriate? How might such a case affect the argument formodularity?8.9.When should a modular design be implemented as monolithic software? How can this beaccomplished? Is performance the only justification for implementation of monolithic software?8.10.Discuss the relationship between the concept of information hiding as an attribute ofeffective modularity and the concept of module independence.8.11.How are the concepts of coupling and software portability related? Provide examples tosupport your discussion.8.12.Apply a “stepwise refinement approach” to develop three different levels of proceduralabstractions for one or more of the following programs: (a) Develop a check writer that, given anumeric dollar amount, will print the amount in words normally required on a check. (b) Itera-tively solve for the roots of a transcendental equation. (c) Develop a simple task schedulingalgorithm for an operating system.8.13.Consider the software required to implement a full navigation capability (using GPS) in amobile, handheld communication device. Describe two or three crosscutting concerns thatwould be present. Discuss how you would represent one of these concerns as an aspect.8.14.Does “refactoring” mean that you modify the entire design iteratively? If not, what doesit mean?8.15.Briefly describe each of the four elements of the design model.
FURTHER READINGS AND INFORMATION SOURCES
Donald Norman has written two books ( The Design of Everyday Things,Doubleday, 1990, and The Psychology of Everyday Things,Harpercollins, 1988) that have become classics in the designliterature and “must” reading for anyone who designs anything that humans use. Adams(Conceptual Blockbusting,3d ed., Addison-Wesley, 1986) has written a book that is essentialreading for designers who want to broaden their way of thinking. Finally, a classic text by Polya(How to Solve It,2d ed., Princeton University Press, 1988) provides a generic problem-solvingprocess that can help software designers when they are faced with complex problems.Following in the same tradition, Winograd et al. (Bringing Design to Software, Addison- Wesley, 1996) discusses software designs that work, those that don’t, and why. A fascinatingbook edited by Wixon and Ramsey (Field Methods Casebook for Software Design, Wiley, 1996)240 PART TWOMODELINGpre75977_ch08.qxd  11/27/08  3:39 PM  Page 240suggests field research methods (much like those used by anthropologists) to understand howend users do the work they do and then design software that meets their needs. Beyer andHoltzblatt (Contextual Design: A Customer-Centered Approach to Systems Designs, Academic Press, 1997) offer another view of software design that integrates the customer/user into everyaspect of the software design process. Bain (Emergent Design, Addison-Wesley, 2008) couples patterns, refactoring, and test-driven development into an effective design approach.Comprehensive treatment of design in the context of software engineering is presentedby Fox (Introduction to Software Engineering Design, Addison-Wesley, 2006) and Zhu (Software Design Methodology,Butterworth-Heinemann, 2005). McConnell ( Code Complete,2d ed., Mi- crosoft Press, 2004) presents an excellent discussion of the practical aspects of designing high-quality computer software. Robertson ( Simple Program Design,3d ed., Boyd and Fraser Publishing, 1999) presents an introductory discussion of software design that is useful for thosebeginning their study of the subject. Budgen (Software Design, 2d ed., Addison-Wesley, 2004) in- troduces a variety of popular design methods, comparing and contrasting each. Fowler and hiscolleagues (Refactoring: Improving the Design of Existing Code, Addison-Wesley, 1999) discusses techniques for the incremental optimization of software designs. Rosenberg and Stevens (UseCase Driven Object Modeling with UML, Apress, 2007) discuss the development of object-oriented designs using use cases as a foundation.An excellent historical survey of software design is contained in an anthology edited by Free-man and Wasserman (Software Design Techniques, 4th ed., IEEE, 1983). This tutorial reprints many of the classic papers that have formed the basis for current trends in software design.Measures of design quality, presented from both the technical and management perspectives,are considered by Card and Glass (Measuring Software Design Quality, Prentice-Hall, 1990). A wide variety of information sources on software design are available on the Internet. Anup-to-date list of World Wide Web references that are relevant to software design and designengineering can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 8DESIGN CONCEPTS 241pre75977_ch08.qxd  11/27/08  3:39 PM  Page 241Design has been described as a multistep process in which representationsof data and program structure, interface characteristics, and proceduraldetail are synthesized from information requirements. This description isextended by Freeman [Fre80]:
[D]esign is an activity concerned with making major decisions, often of a structuralnature. It shares with programming a concern for abstracting information represen-tation and processing sequences, but the level of detail is quite different at theextremes. Design builds coherent, well-planned representations of programs thatconcentrate on the interrelationships of parts at the higher level and the logical oper-ations involved at the lower levels.
As I noted in Chapter 8, design is information driven. Software design methodsare derived from consideration of each of the three domains of the analysis model.The data, functional, and behavioral domains serve as a guide for the creation ofthe software design.Methods required to create “coherent, well-planned representations” of thedata and architectural layers of the design model are presented in this chapter.The objective is to provide a systematic approach for the derivation of thearchitectural design—the preliminary blueprint from which software isconstructed.
242CHAPTER
9ARCHITECTURAL
DESIGN
KEY
CONCEPTSarchetypes  . . . . .257architecturaldescription language  . . . . . .264architecture  . . . .243alternatives  . . .261components  . . .258complexity  . . . .263data centered  . .250data flow . . . . .251design  . . . . . . .255genres  . . . . . . .247layered  . . . . . .253object oriented . .252patterns . . . . . .253refinement  . . . .258styles  . . . . . . .249template  . . . . .247ATAM . . . . . . . . .262factoring  . . . . . .268instantiation . . . .260mapping . . . . . . .265
What is it? Architectural designrepresents the structure of data andprogram components that are re-quired to build a computer-basedsystem. It considers the architectural style that thesystem will take, the structure and properties ofthe components that constitute the system, andthe interrelationships that occur among all ar-chitectural components of a system.
Who does it? Although a software engineer candesign both data and architecture, the job is of-ten allocated to specialists when large, complexsystems are to be built. A database or dataQUICK
LOOKwarehouse designer creates the data architec-ture for a system. The “system architect” selectsan appropriate architectural style from the re-quirements derived during software require-ments analysis.
Why is it important? You wouldn’t attempt to builda house without a blueprint, would you? You alsowouldn’t begin drawing blueprints by sketchingthe plumbing layout for the house. You’d need tolook at the big picture—the house itself—beforeyou worry about details. That’s what architecturaldesign does—it provides you with the big pictureand ensures that you’ve got it right.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 2429.1 S OFTWARE ARCHITECTURE
In their landmark book on the subject, Shaw and Garlan [Sha96] discuss softwarearchitecture in the following manner:
Ever since the first program was divided into modules, software systems have had archi-tectures, and programmers have been responsible for the interactions among the mod-ules and the global properties of the assemblage. Historically, architectures have beenimplicit—accidents of implementation, or legacy systems of the past. Good softwaredevelopers have often adopted one or several architectural patterns as strategies forsystem organization, but they use these patterns informally and have no means to makethem explicit in the resulting system.
Today, effective software architecture and its explicit representation and design havebecome dominant themes in software engineering.
9.1.1 What Is Architecture?
When you consider the architecture of a building, many different attributes come tomind. At the most simplistic level, you think about the overall shape of the physicalstructure. But in reality, architecture is much more. It is the manner in which the var-ious components of the building are integrated to form a cohesive whole. It is theway in which the building fits into its environment and meshes with other buildingsin its vicinity. It is the degree to which the building meets its stated purpose and sat-isfies the needs of its owner. It is the aesthetic feel of the structure—the visual im-pact of the building—and the way textures, colors, and materials are combined tocreate the external facade and the internal “living environment.” It is small details—the design of lighting fixtures, the type of flooring, the placement of wall hangings,the list is almost endless. And finally, it is art.But architecture is also something else. It is “thousands of decisions, both big andsmall” [Tyr05]. Some of these decisions are made early in design and can have aprofound impact on all other design actions. Others are delayed until later, therebyCHAPTER 9ARCHITECTURAL DESIGN 243
What are the steps? Architectural design beginswith data design and then proceeds to the deri-vation of one or more representations of the ar-chitectural structure of the system. Alternativearchitectural styles or patterns are analyzed toderive the structure that is best suited to customerrequirements and quality attributes. Once an al-ternative has been selected, the architecture iselaborated using an architectural designmethod.What is the work product? An architecturemodel encompassing data architecture and pro-gram structure is created during architecturaldesign. In addition, component properties andrelationships (interactions) are described.
How do I ensure that I’ve done it right? Ateach stage, software design work products arereviewed for clarity, correctness, completeness,and consistency with requirements and with oneanother.
uote:
“The architectureof a system is acomprehensiveframework thatdescribes its formand structure—itscomponents andhow they fittogether.”Jerrold Grochowpre75977_ch09.qxd  11/27/08  3:42 PM  Page 243eliminating overly restrictive constraints that would lead to a poor implementationof the architectural style.But what about software architecture? Bass, Clements, and Kazman [Bas03]define this elusive term in the following way:
The software architecture of a program or computing system is the structure or structuresof the system, which comprise software components, the externally visible properties ofthose components, and the relationships among them.
The architecture is not the operational software. Rather, it is a representation thatenables you to (1) analyze the effectiveness of the design in meeting its stated re-quirements, (2) consider architectural alternatives at a stage when making designchanges is still relatively easy, and (3) reduce the risks associated with the construc-tion of the software.This definition emphasizes the role of “software components” in any architecturalrepresentation. In the context of architectural design, a software component can besomething as simple as a program module or an object-oriented class, but it can alsobe extended to include databases and “middleware” that enable the configuration ofa network of clients and servers. The properties of components are those character-istics that are necessary for an understanding of how the components interact withother components. At the architectural level, internal properties (e.g., details of an al-gorithm) are not specified. The relationships between components can be as simpleas a procedure call from one module to another or as complex as a database accessprotocol.Some members of the software engineering community (e.g., [Kaz03]) make adistinction between the actions associated with the derivation of a software archi-tecture (what I call “architectural design”) and the actions that are applied to derivethe software design. As one reviewer of this edition noted:
There is a distinct difference between the terms architecture and design. A design is an instance of an architecturesimilar to an object being an instance of a class. For example,consider the client-server architecture. I can design a network-centric software system inmany different ways from this architecture using either the Java platform (Java EE) orMicrosoft platform (.NET framework). So, there is one architecture, but many designs canbe created based on that architecture. Therefore, you cannot mix “architecture” and“design” with each other.
Although I agree that a software design is an instance of a specific softwarearchitecture, the elements and structures that are defined as part of an architec-ture are the root of every design that evolves from them. Design begins with aconsideration of architecture.In this book the design of software architecture considers two levels of the designpyramid (Figure 8.1)—data design and architectural design. In the context of the pre-ceding discussion, data design enables you to represent the data component of thearchitecture in conventional systems and class definitions (encompassing attributes244 PART TWOMODELING
Software architecturemust model thestructure of a systemand the manner inwhich data andprocedural componentscollaborate with oneanother.
uote:
“Marry yourarchitecture inhaste, repent atyour leisure.”Barry Boehm
WebRef
Useful pointers tomany softwarearchitecture sites canbe obtained at www2.umassd.edu/SECenter/SAResources.html.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 244and operations) in object-oriented systems. Architectural design focuses on therepresentation of the structure of software components, their properties, and inter-actions.
9.1.2 Why Is Architecture Important?
In a book dedicated to software architecture, Bass and his colleagues [Bas03] iden-tify three key reasons that software architecture is important:
•Representations of software architecture are an enabler for communicationbetween all parties (stakeholders) interested in the development of acomputer-based system.
•The architecture highlights early design decisions that will have a profoundimpact on all software engineering work that follows and, as important, onthe ultimate success of the system as an operational entity.
•Architecture “constitutes a relatively small, intellectually graspable model ofhow the system is structured and how its components work together” [Bas03].The architectural design model and the architectural patterns contained within itare transferable. That is, architecture genres, styles, and patterns (Sections 9.2through 9.4) can be applied to the design of other systems and represent a set ofabstractions that enable software engineers to describe architecture in predictableways.
9.1.3 Architectural Descriptions
Each of us has a mental image of what the word architecture means. In reality, how- ever, it means different things to different people. The implication is that differentstakeholders will see an architecture from different viewpoints that are driven by dif-ferent sets of concerns. This implies that an architectural description is actually a setof work products that reflect different views of the system.For example, the architect of a major office building must work with a variety ofdifferent stakeholders. The primary concern of the owner of the building (one stake-holder) is to ensure that it is aesthetically pleasing and that it provides sufficient of-fice space and infrastructure to ensure its profitability. Therefore, the architect mustdevelop a description using views of the building that address the owner’s concerns.The viewpoints used are a three-dimensional drawings of the building (to illustratethe aesthetic view) and a set of two-dimensional floor plans to address this stake-holder’s concern for office space and infrastructure.But the office building has many other stakeholders, including the structuralsteel fabricator who will provide steel for the building skeleton. The structural steelfabricator needs detailed architectural information about the structural steel that willsupport the building, including types of I-beams, their dimensions, connectivity,materials, and many other details. These concerns are addressed by different workproducts that represent different views of the architecture. Specialized drawingsCHAPTER 9ARCHITECTURAL DESIGN 245
uote:
“Architecture is fartoo important toleave in the handsof a single person,no matter howbright they are.”Scott Ambler
The architectural modelprovides a Gestalt viewof the system,allowing the softwareengineer to examine itas a whole.
Your effort shouldfocus on architecturalrepresentations thatwill guide all otheraspects of design.Spend the time tocarefully review thearchitecture. A mistakehere will have a long-term negative impact.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 245(another viewpoint) of the structural steel skeleton of the building focus on only oneof many of the fabricator’s concerns.An architectural description of a software-based system must exhibit character-istics that are analogous to those noted for the office building. Tyree and Akerman[Tyr05] note this when they write: “Developers want clear, decisive guidance on howto proceed with design. Customers want a clear understanding on the environmen-tal changes that must occur and assurances that the architecture will meet their busi-ness needs. Other architects want a clear, salient understanding of the architecture’skey aspects.” Each of these “wants” is reflected in a different view represented usinga different viewpoint.The IEEE Computer Society has proposed IEEE-Std-1471-2000, Recommended Practice for Architectural Description of Software-Intensive Systems, [IEE00], with the following objectives: (1) to establish a conceptual framework and vocabulary for useduring the design of software architecture, (2) to provide detailed guidelines for rep-resenting an architectural description, and (3) to encourage sound architecturaldesign practices.The IEEE standard defines an architectural description (AD) as “a collection of prod- ucts to document an architecture.” The description itself is represented using multipleviews, where each viewis “a representation of a whole system from the perpective ofa related set of [stakeholder] concerns.” A viewis created according to rules and con- ventions defined in a viewpoint—“a specification of the conventions for constructingand using a view” [IEE00]. A number of different work products that are used to de-velop different views of the software architecture are discussed later in this chapter.
9.1.4 Architectural Decisions
Each view developed as part of an architectural description addresses a specificstakeholder concern. To develop each view (and the architectural description as awhole) the system architect considers a variety of alternatives and ultimately decideson the specific architectural features that best meet the concern. Therefore, archi-tectural decisions themselves can be considered to be one view of the architecture.The reasons that decisions were made provide insight into the structure of a systemand its conformance to stakeholder concerns.As a system architect, you can use the template suggested in the sidebar to docu-ment each major decision. By doing this, you provide a rationale for your work andestablish an historical record that can be useful when design modifications mustbe made.246 PART TWOMODELING
9.2 A RCHITECTURAL GENRES
Although the underlying principles of architectural design apply to all types of archi-tecture, the architectural genrewill often dictate the specific architectural approach tothe structure that must be built. In the context of architectural design, genreimplies apre75977_ch09.qxd  11/27/08  3:42 PM  Page 246CHAPTER 9ARCHITECTURAL DESIGN 247
Architecture Decision Description Template
Each major architectural decision can bedocumented for later review by stakeholders whowant to understand the architecture description that hasbeen proposed. The template presented in this sidebar isan adapted and abbreviated version of a templateproposed by Tyree and Ackerman [Tyr05].Design issue:Describe the architectural designissues that are to be addressed.Resolution:State the approach you’ve chosento address the design issue.Category:Specify the design category thatthe issue and resolution address(e.g., data design, contentstructure, component structure,integration, presentation).Assumptions:Indicate any assumptions thathelped shape the decision.Constraints:Specify any environmentalconstraints that helped shape thedecision (e.g., technologystandards, available patterns,project-related issues).Alternatives:Briefly describe the architecturaldesign alternatives that wereconsidered and why they wererejected.Argument:State why you chose theresolution over other alternatives.Implications:Indicate the design consequencesof making the decision. How willthe resolution affect otherarchitectural design issues? Willthe resolution constrain the designin any way?Related decisions:What other documented decisionsare related to this decision?Related concerns:What other requirements arerelated to this decision?Work products:Indicate where this decision willbe reflected in the architecturedescription.Notes:Reference any team notes or otherdocumentation that was used tomake the decision.INFO
A number of differentarchitectural stylesmay be applicable to aspecific genre (alsocalled an applicationdomain).specific category within the overall software domain. Within each category, you en-counter a number of subcategories. For example, within the genre of buildings, youwould encounter the following general styles: houses, condos, apartment buildings,office buildings, industrial building, warehouses, and so on. Within each general style,more specific styles might apply (Section 9.3). Each style would have a structure thatcan be described using a set of predictable patterns.In his evolving Handbook of Software Architecture [Boo08], Grady Booch suggests the following architectural genres for software-based systems:
•Artificial intelligence—Systems that simulate or augment human cognition,locomotion, or other organic processes.
•Commercial and nonprofit—Systems that are fundamental to theoperation of a business enterprise.
•Communications—Systems that provide the infrastructure for transferringand managing data, for connecting users of that data, or for presenting dataat the edge of an infrastructure.
•Content authoring—Systems that are used to create or manipulate textualor multimedia artifacts.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 247248 PART TWOMODELING
•Devices—Systems that interact with the physical world to provide somepoint service for an individual.
•Entertainment and sports—Systems that manage public events or thatprovide a large group entertainment experience.
•Financial—Systems that provide the infrastructure for transferring andmanaging money and other securities.
•Games—Systems that provide an entertainment experience for individualsor groups.
•Government—Systems that support the conduct and operations of a local,state, federal, global, or other political entity.
•Industrial—Systems that simulate or control physical processes.
•Legal—Systems that support the legal industry.
•Medical—Systems that diagnose or heal or that contribute to medicalresearch.
•Military—Systems for consultation, communications, command, control,and intelligence (C4I) as well as offensive and defensive weapons.
•Operating systems—Systems that sit just above hardware to provide basicsoftware services.
•Platforms—Systems that sit just above operating systems to provideadvanced services.
•Scientific—Systems that are used for scientific research and applications.
•Tools—Systems that are used to develop other systems.
•Transportation—Systems that control water, ground, air, or space vehicles.
•Utilities—Systems that interact with other software to provide some pointservice.From the standpoint of architectural design, each genre represents a unique chal-lenge. As an example, consider the software architecture for a game system. Gamesystems, sometimes called immersive interactive applications, require the computa- tion of intensive algorithms, sophisticated computer graphics, streaming multimediadata sources, real-time interactivity via conventional and unconventional inputs,and a variety of other specialized concerns.Alexandre Francois [Fra03] suggests a software architecture for Immersipresence
1
that can be applied for a gaming environment. He describes the architecture in thefollowing manner:
SAI (Software Architecture for Immersipresence) is a new software architecture modelfor designing, analyzing and implementing applications performing distributed,uote:
“Programmingwithout an overallarchitecture ordesign in mind islike exploring acave with only aflashlight: Youdon’t know whereyou’ve been, youdon’t know whereyou’re going, andyou don’t knowquite where youare.”Danny Thorpe
1 Francois uses the term immersipresencefor immersive, interactive applications.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 248asynchronous parallel processing of generic data streams. The goal of SAI is to provide auniversal framework for the distributed implementation of algorithms and their easyintegration into complex systems. . . . The underlying extensible data model and hybrid(shared repository and message-passing) distributed asynchronous parallel processingmodel allow natural and efficient manipulation of generic data streams, using existinglibraries or native code alike. The modularity of the style facilitates distributed code de-velopment, testing, and reuse, as well as fast system design and integration, maintenanceand evolution.
A detailed discussion of SAI is beyond the scope of this book. However, it is impor-tant to recognize that the gaming system genre can be addressed with an architec-tural style (Section 9.3) that has been specifically designed to address gaming systemconcerns. If you have further interest, see [Fra03].
9.3 A RCHITECTURAL STYLES
When a builder uses the phrase “center hall colonial” to describe a house, most peo-ple familiar with houses in the United States will be able to conjure a general imageof what the house will look like and what the floor plan is likely to be. The builderhas used an architectural styleas a descriptive mechanism to differentiate the housefrom other styles (e.g., A-frame, raised ranch, Cape Cod). But more important, thearchitectural style is also a template for construction. Further details of the housemust be defined, its final dimensions must be specified, customized features maybe added, building materials are to be determined, but the style—a “center hallcolonial”—guides the builder in his work.The software that is built for computer-based systems also exhibits one of manyarchitectural styles. Each style describes a system category that encompasses (1) aset of components (e.g., a database, computational modules) that perform a functionrequired by a system; (2) a set of connectors that enable “communication, coordina-tion and cooperation” among components; (3) constraints that define how compo-nents can be integrated to form the system; and (4) semantic models that enable adesigner to understand the overall properties of a system by analyzing the knownproperties of its constituent parts [Bas03].An architectural style is a transformation that is imposed on the design of an en-tire system. The intent is to establish a structure for all components of the system.In the case where an existing architecture is to be reengineered (Chapter 29), theimposition of an architectural style will result in fundamental changes to the struc-ture of the software including a reassignment of the functionality of components[Bos00].An architectural pattern, like an architectural style, imposes a transformation onthe design of an architecture. However, a pattern differs from a style in a number offundamental ways: (1) the scope of a pattern is less broad, focusing on one aspectof the architecture rather than the architecture in its entirety; (2) a pattern imposes aCHAPTER 9ARCHITECTURAL DESIGN 249
uote:
“There is at theback of everyartist’s mind, apattern or type ofarchitecture.”G. K. Chesterton
What is anarchitecturalstyle??
WebRef
Attribute-basedarchitectural styles(ABAS) can be used asbuilding blocks forsoftware architectures.Information can beobtained at www.sei.cmu.edu/architecture/abas.html.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 249rule on the architecture, describing how the software will handle some aspect of itsfunctionality at the infrastructure level (e.g., concurrency) [Bos00]; (3) architecturalpatterns (Section 9.4) tend to address specific behavioral issues within the context ofthe architecture (e.g., how real-time applications handle synchronization or inter-rupts). Patterns can be used in conjunction with an architectural style to shape theoverall structure of a system. In Section 9.3.1, I consider commonly used architec-tural styles and patterns for software.250 PART TWOMODELING
Canonical Architectural Structures
In essence, software architecture represents astructure in which some collection of entities (oftencalled components) is connected by a set of definedrelationships (often called connectors). Both componentsand connectors are associated with a set of propertiesthat allow the designer to differentiate the types of componentsand connectors that can be used. But what kinds ofstructures (components, connectors, and properties) can beused to describe an architecture? Bass and Kazman[Bas03] suggest five canonical or foundation architecturalstructures:Functional structure.Components represent functionor processing entities. Connectors represent interfaces thatprovide the ability to “use” or “pass data to” a component.Properties describe the nature of the components and theorganization of the interfaces.Implementation structure.“Components can bepackages, classes, objects, procedures, functions,methods, etc., all of which are vehicles for packagingfunctionality at various levels of abstraction” [Bas03].Connectors include the ability to pass data and control,share data, “use”, and “is-an-instance-of.” Propertiesfocus on quality characteristics (e.g., maintainability,reusability) that result when the structure is implemented.Concurrency structure.Components represent “unitsof concurrency” that are organized as parallel tasks orthreads. “Relations [connectors] include synchronizes-with,is-higher-priority-than, sends-data-to, can’t-run-without, andcan’t-run-with. Properties relevant to this structure includepriority, preemptability, and execution time” [Bas03].Physical structure.This structure is similar to thedeployment model developed as part of design. Thecomponents are the physical hardware on which softwareresides. Connectors are the interfaces between hardwarecomponents, and properties address capacity, bandwidth,performance, and other attributes.Developmental structure.This structure defines thecomponents, work products, and other information sourcesthat are required as software engineering proceeds.Connectors represent the relationships among work prod-ucts, and properties identify the characteristics of each item.Each of these structures presents a different view ofsoftware architecture, exposing information that is useful tothe software team as modeling and construction proceed.INFO
9.3.1 A Brief Taxonomy of Architectural Styles
Although millions of computer-based systems have been created over the past60 years, the vast majority can be categorized into one of a relatively small numberof architectural styles:Data-centered architectures.A data store (e.g., a file or database) resides atthe center of this architecture and is accessed frequently by other components thatupdate, add, delete, or otherwise modify data within the store. Figure 9.1 illus-trates a typical data-centered style. Client software accesses a central repository.In some cases the data repository is passive. That is, client software accesses thedata independent of any changes to the data or the actions of other client soft-ware. A variation on this approach transforms the repository into a “blackboard”uote:
“The use ofpatterns and stylesof design ispervasive inengineeringdisciplines.”Mary Shaw andDavid Garlanpre75977_ch09.qxd  11/27/08  3:42 PM  Page 250CHAPTER 9ARCHITECTURAL DESIGN 251
Clientsoftware
Clientsoftware
Clientsoftware ClientsoftwareClientsoftwareClientsoftwareClientsoftware Clientsoftware
Data store(repository orblackboard)FIGURE 9.1
Data-centeredarchitecture
that sends notifications to client software when data of interest to the clientchanges.Data-centered architectures promote integrability[Bas03]. That is, existing components can be changed and new client components added to the architecturewithout concern about other clients (because the client components operateindependently). In addition, data can be passed among clients using the black-board mechanism (i.e., the blackboard component serves to coordinate the trans-fer of information between clients). Client components independently executeprocesses.Data-flow architectures.This architecture is applied when input data are to betransformed through a series of computational or manipulative components intooutput data. A pipe-and-filter pattern (Figure 9.2) has a set of components, calledfilters, connected by pipesthat transmit data from one component to the next. Eachfilter works independently of those components upstream and downstream, is de-signed to expect data input of a certain form, and produces data output (to the nextfilter) of a specified form. However, the filter does not require knowledge of theworkings of its neighboring filters.If the data flow degenerates into a single line of transforms, it is termed batch se-quential. This structure accepts a batch of data and then applies a series of sequen-tial components (filters) to transform it.Call and return architectures.This architectural style enables you to achieve aprogram structure that is relatively easy to modify and scale. A number of substyles[Bas03] exist within this category:
•Main program/subprogram architectures. This classic program structure decomposes function into a control hierarchy where a “main” programpre75977_ch09.qxd  11/27/08  3:42 PM  Page 251252 PART TWOMODELING
invokes a number of program components that in turn may invoke still othercomponents. Figure 9.3 illustrates an architecture of this type.
•Remote procedure call architectures.The components of a mainprogram/subprogram architecture are distributed across multiple computerson a network.Object-oriented architectures.The components of a system encapsulate dataand the operations that must be applied to manipulate the data. Communication andcoordination between components are accomplished via message passing.Main program
Controller subprogram Controller subprogramController subprogram
Application subprogram Application subprogramApplication subprogramApplication subprogramApplication subprogramApplication subprogram Application subprogramFIGURE 9.3 Main program/subprogram architectureFilterPipesFilterFilter
Filter Filter
Filter Filter
FilterPipes and filtersFilter
FilterFIGURE 9.2
Data-flowarchitecturepre75977_ch09.qxd  11/27/08  3:42 PM  Page 252CHAPTER 9ARCHITECTURAL DESIGN 253
Layered architectures.The basic structure of a layered architecture is illustratedin Figure 9.4. A number of different layers are defined, each accomplishing opera-tions that progressively become closer to the machine instruction set. At the outerlayer, components service user interface operations. At the inner layer, componentsperform operating system interfacing. Intermediate layers provide utility servicesand application software functions.These architectural styles are only a small subset of those available.
2Once requirements engineering uncovers the characteristics and constraints of the sys-tem to be built, the architectural style and/or combination of patterns that bestfits those characteristics and constraints can be chosen. In many cases, morethan one pattern might be appropriate and alternative architectural styles can bedesigned and evaluated. For example, a layered style (appropriate for most sys-tems) can be combined with a data-centered architecture in many databaseapplications.
9.3.2 Architectural Patterns
As the requirements model is developed, you’ll notice that the software must addressa number of broad problems that span the entire application. For example, therequirements model for virtually every e-commerce application is faced with thefollowing problem: How do we offer a broad array of goods to a broad array ofcustomers and allow those customers to purchase our goods online?Core layerComponentsUser interface layerApplication layerUtility layerFIGURE 9.4
Layeredarchitecture
2 See [Bus07], [Gor06], [Roz05], [Bas03], [Bos00], or [Hof00] for a detailed discussion of architecturalstyles and patterns.uote:
“Maybe it’s in thebasement. Let mego upstairs andcheck.”M. C. Escherpre75977_ch09.qxd  11/27/08  3:42 PM  Page 253254 PART TWOMODELING
The scene:Jamie’s cubicle, as designmodeling begins.The players:Jamie and Ed—members of theSafeHomesoftware engineering team.The conversation:Ed (frowning):We’ve been modeling the securityfunction using UML . . . you know classes, relationships,that sort of stuff. So I guess the object-orientedarchitecture
3is the right way to go.Jamie:But . . .?Ed:But . . . I have trouble visualizing what an object-oriented architecture is. I get the call and returnarchitecture, sort of a conventional process hierarchy, butOO . . . I don’t know, it seems sort of amorphous.Jamie (smiling):Amorphous, huh?Ed:Yeah . . . what I mean is I can’t visualize a realstructure, just design classes floating in space.Jamie:Well, that’s not true. There are class hierarchies. . . think of the hierarchy (aggregation) we did for theFloorPlanobject [Figure 8.3]. An OO architecture is acombination of that structure and the interconnections—you know, collaborations—between the classes. We canshow it by fully describing the attributes and operations,the messaging that goes on, and the structure of theclasses.Ed:I’m going to spend an hour mapping out a call andreturn architecture; then I’ll go back and consider an OOarchitecture.Jamie:Doug’ll have no problem with that. He said thatwe should consider architectural alternatives. By theway, there’s absolutely no reason why both of thesearchitectures couldn’t be used in combination with oneanother.Ed:Good. I’m on it.SAFEHOME
3 It can be argued that the SafeHome architecture should be considered at a higher level than the architecture noted. SafeHomehas a variety of subsystems—home monitoring functionality, thecompany’s monitoring site, and the subsystem running on the owner’s PC. Within subsystems,concurrent processes (e.g., those monitoring sensors) and event handling are prevalent. Somearchitectural decisions at this level are made during product engineering, but architectural designwithin software engineering may very well have to consider these issues.Choosing an Architectural Style
The requirements model also defines a context in which this question must beanswered. For example, an e-commerce business that sells golf equipment toconsumers will operate in a different context than an e-commerce business that sellshigh-priced industrial equipment to medium and large corporations. In addition, aset of limitations and constraints may affect the way in which you address the prob-lem to be solved.Architectural patterns address an application-specific problem within a specificcontext and under a set of limitations and constraints. The pattern proposes anarchitectural solution that can serve as the basis for architectural design.Earlier in this chapter, I noted that most applications fit within a specific domainor genre and that one or more architectural styles may be appropriate for that genre.For example, the overall architectural style for an application might be call-and-return or object-oriented. But within that style, you will encounter a set of commonproblems that might best be addressed with specific architectural patterns. Someof these problems and a more complete discussion of architectural patterns arepresented in Chapter 12.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 254CHAPTER 9ARCHITECTURAL DESIGN 255
9.3.3 Organization and Refinement
Because the design process often leaves you with a number of architectural alterna-tives, it is important to establish a set of design criteria that can be used to assess anarchitectural design that is derived. The following questions [Bas03] provide insightinto an architectural style:Control.How is control managed within the architecture? Does a distinctcontrol hierarchy exist, and if so, what is the role of components within thiscontrol hierarchy? How do components transfer control within the system?How is control shared among components? What is the control topology(i.e., the geometric form that the control takes)? Is control synchronized ordo components operate asynchronously?Data.How are data communicated between components? Is the flow of datacontinuous, or are data objects passed to the system sporadically? What is themode of data transfer (i.e., are data passed from one component to anotheror are data available globally to be shared among system components)? Dodata components (e.g., a blackboard or repository) exist, and if so, what istheir role? How do functional components interact with data components?Are data components passive or active (i.e., does the data componentactively interact with other components in the system)? How do data andcontrol interact within the system?These questions provide the designer with an early assessment of design quality andlay the foundation for more detailed analysis of the architecture.
9.4 A RCHITECTURAL DESIGN
As architectural design begins, the software to be developed must be put intocontext—that is, the design should define the external entities (other systems, de-vices, people) that the software interacts with and the nature of the interaction. Thisinformation can generally be acquired from the requirements model and all otherinformation gathered during requirements engineering. Once context is modeledand all external software interfaces have been described, you can identify a set ofarchitectural archetypes. Anarchetypeis an abstraction (similar to a class) that rep- resents one element of system behavior. The set of archetypes provides a collectionof abstractions that must be modeled architecturally if the system is to be con-structed, but the archetypes themselves do not provide enough implementation de-tail. Therefore, the designer specifies the structure of the system by defining andrefining software components that implement each archetype. This process contin-ues iteratively until a complete architectural structure has been derived. In thesections that follow we examine each of these architectural design tasks in a bitmore detail.How do Iassess anarchitectural stylethat has beenderived??
uote:
“A doctor can buryhis mistakes, butan architect canonly advise hisclient to plantvines.”Frank LloydWrightpre75977_ch09.qxd  11/27/08  3:42 PM  Page 2559.4.1 Representing the System in Context
At the architectural design level, a software architect uses an architectural context di-agram(ACD) to model the manner in which software interacts with entities externalto its boundaries. The generic structure of the architectural context diagram is illus-trated in Figure 9.5.Referring to the figure, systems that interoperate with the target system (the system for which an architectural design is to be developed) are represented as
•Superordinate systems—those systems that use the target system as part ofsome higher-level processing scheme.
•Subordinate systems—those systems that are used by the target system andprovide data or processing that are necessary to complete target systemfunctionality.
•Peer-level systems—those systems that interact on a peer-to-peer basis (i.e.,information is either produced or consumed by the peers and the targetsystem.
•Actors—entities (people, devices) that interact with the target system byproducing or consuming information that is necessary for requisite processing.Each of these external entities communicates with the target system through an in-terface (the small shaded rectangles).To illustrate the use of the ACD, consider the home security function of theSafeHomeproduct. The overall SafeHomeproduct controller and the Internet-based system are both superordinate to the security function and are shown above the256 PART TWOMODELING
Superordinate systems
Subordinate systemsDepends onUses Uses Used by
Peers Actors
Target systemFIGURE 9.5
ArchitecturalcontextdiagramSource:Adapted from[Bos00].Architectural contextrepresents how thesoftware interacts withentities external to itsboundaries.
How dosystemsinteroperate withone another??pre75977_ch09.qxd  11/27/08  3:42 PM  Page 256function in Figure 9.6. The surveillance function is a peer system and uses (is used by) the home security function in later versions of the product. The homeowner and con-trol panels are actors that are both producers and consumers of informationused/produced by the security software. Finally, sensors are used by the securitysoftware and are shown as subordinate to it.As part of the architectural design, the details of each interface shown in Fig-ure 9.6 would have to be specified. All data that flow into and out of the target sys-tem must be identified at this stage.
9.4.2 Defining Archetypes
An archetypeis a class or pattern that represents a core abstraction that is critical tothe design of an architecture for the target system. In general, a relatively small setof archetypes is required to design even relatively complex systems. The target sys-tem architecture is composed of these archetypes, which represent stable elementsof the architecture but may be instantiated many different ways based on thebehavior of the system.In many cases, archetypes can be derived by examining the analysis classes de-fined as part of the requirements model. Continuing the discussion of the SafeHomehome security function, you might define the following archetypes:
•Node.Represents a cohesive collection of input and output elements ofthe home security function. For example a node might be comprised of(1) various sensors and (2) a variety of alarm (output) indicators.
•Detector.An abstraction that encompasses all sensing equipment that feedsinformation into the target system.CHAPTER 9ARCHITECTURAL DESIGN 257
Archetypes are theabstract building blocksof an architecturaldesign.Target system: security function
Uses Uses Peers HomeownerSafeHomeproductInternet-basedsystem
Surveillancefunction
SensorsControl panel
Sensors UsesFIGURE 9.6
Architecturalcontextdiagram forthe SafeHomesecurityfunctionpre75977_ch09.qxd  11/27/08  3:42 PM  Page 257•Indicator.An abstraction that represents all mechanisms (e.g., alarm siren,flashing lights, bell) for indicating that an alarm condition is occurring.
•Controller.An abstraction that depicts the mechanism that allows thearming or disarming of a node. If controllers reside on a network, they havethe ability to communicate with one another.Each of these archetypes is depicted using UML notation as shown in Figure 9.7.Recall that the archetypes form the basis for the architecture but are abstractions thatmust be further refined as architectural design proceeds. For example, Detectormight be refined into a class hierarchy of sensors.
9.4.3 Refining the Architecture into Components
As the software architecture is refined into components, the structure of the systembegins to emerge. But how are these components chosen? In order to answer thisquestion, you begin with the classes that were described as part of the require-ments model.
4These analysis classes represent entities within the application(business) domain that must be addressed within the software architecture. Hence,the application domain is one source for the derivation and refinement of compo-nents. Another source is the infrastructure domain. The architecture must accom-modate many infrastructure components that enable application componentsbut have no business connection to the application domain. For example, mem-ory management components, communication components, database compo-nents, and task management components are often integrated into the softwarearchitecture.258 PART TWOMODELING
Controller
Node
Communicates with
DetectorIndicatorFIGURE 9.7
UML relation-ships forSafeHomesecurityfunctionarchetypesSource:Adapted from[Bos00].
4 If a conventional (non-object-oriented) approach is chosen, components are derived from the dataflow model. I discuss this approach briefly in Section 9.6.uote:
“The structure of asoftware systemprovides theecology in whichcode is born,matures, and dies.A well-designedhabitat allows forthe successfulevolution of all thecomponentsneeded in asoftware system.”R. Pattispre75977_ch09.qxd  11/27/08  3:42 PM  Page 258The interfaces depicted in the architecture context diagram (Section 9.4.1) implyone or more specialized components that process the data that flows across theinterface. In some cases (e.g., a graphical user interface), a complete subsystemarchitecture with many components must be designed.Continuing the SafeHomehome security function example, you might define theset of top-level components that address the following functionality:
•External communication management—coordinates communication of thesecurity function with external entities such as other Internet-based systemsand external alarm notification.
•Control panel processing—manages all control panel functionality.
•Detector management—coordinates access to all detectors attached to thesystem.
•Alarm processing—verifies and acts on all alarm conditions.Each of these top-level components would have to be elaborated iteratively and thenpositioned within the overall SafeHome architecture. Design classes (with appro- priate attributes and operations) would be defined for each. It is important to note,however, that the design details of all attributes and operations would not be speci-fied until component-level design (Chapter 10).The overall architectural structure (represented as a UML component diagram) isillustrated in Figure 9.8. Transactions are acquired by external communication man- agementas they move in from components that process the SafeHome GUI and theCHAPTER 9ARCHITECTURAL DESIGN 259
SafeHome executiveExternal communicationmanagement 
GUI InternetinterfaceFunction selection
Security Surveillance Homemanagement
Control panel processing Detectormanagement Alarmprocessing-FIGURE 9.8 Overall architectural structure for SafeHomewith top-level componentspre75977_ch09.qxd  11/27/08  3:42 PM  Page 259Internet interface. This information is managed by a SafeHome executive compo- nent that selects the appropriate product function (in this case security). The control panel processingcomponent interacts with the homeowner to arm/disarm the se-curity function. The detector management component polls sensors to detect an alarm condition, and the alarm processing component produces output when an alarm is detected.
9.4.4 Describing Instantiations of the System
The architectural design that has been modeled to this point is still relatively highlevel. The context of the system has been represented, archetypes that indicate theimportant abstractions within the problem domain have been defined, the overallstructure of the system is apparent, and the major software components havebeen identified. However, further refinement (recall that all design is iterative) isstill necessary.To accomplish this, an actual instantiation of the architecture is developed. By thisI mean that the architecture is applied to a specific problem with the intent of demon-strating that the structure and components are appropriate.Figure 9.9 illustrates an instantiation of the SafeHome architecture for the security system. Components shown in Figure 9.8 are elaborated to show additional detail.For example, the detector management component interacts with a scheduler infra- structure component that implements polling of each sensor object used by the se- curity system. Similar elaboration is performed for each of the componentsrepresented in Figure 9.8.260 PART TWOMODELING
Architectural Design
Objective:Architectural design tools modelthe overall software structure by representingcomponent interface, dependencies and relationships, andinteractions.Mechanics:Tool mechanics vary. In most cases, architectural design capability is part of the functionalityprovided by automated tools for analysis and designmodeling.Representative Tools:
5
Adalon,developed by Synthis Corp. (www.synthis.com), is a specialized design tool for the design andconstruction of specific Web-based componentarchitectures.ObjectiF ,developed by microTOOL GmbH(www.microtool.de/objectiF/en/), is a UML-based design tool that leads to architectures (e.g., Coldfusion, J2EE, Fusebox) amenable tocomponent-based software engineering (Chapter 29).Rational Rose,developed by Rational (www-306.ibm.com/software/rational/ ), is a UML-based design tool that supports all aspects of architectural design.SOFTWARE TOOLS
5 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 260CHAPTER 9ARCHITECTURAL DESIGN 261
Externalcommunicationmanagement
GUI InternetinterfaceSecurity
Controlpanel processingDetectormanagement Alarmprocessing
Keypadprocessing
CP displayfunctionsSchedulerPhonecommunication
AlarmSafeHomeexecutive
SensorFIGURE 9.9 An instantiation of the security function with component elaboration
9.5 A SSESSING ALTERNATIVE ARCHITECTURAL DESIGNS
In their book on the evaluation of software architectures, Clements and hiscolleagues [Cle03] state:
To put it bluntly, an architecture is a bet, a wager on the success of a system. Wouldn’t itbe nice to know in advance if you’ve placed your bet on a winner, as opposed to waitinguntil the system is mostly completed before knowing whether it will meet its requirementsor not? If you’re buying a system or paying for its development, wouldn’t you like to havesome assurance that it’s started off down the right path? If you’re the architect yourself,wouldn’t you like to have a good way to validate your intuitions and experience, so thatyou can sleep at night knowing that the trust placed in your design is well founded?
Indeed, answers to these questions would have value. Design results in a number ofarchitectural alternatives that are each assessed to determine which is the mostappropriate for the problem to be solved. In the sections that follow, I present twodifferent approaches for the assessment of alternative architectural designs. The firstmethod uses an iterative method to assess design trade-offs. The second approachapplies a pseudo-quantitative technique for assessing design quality.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 261262 PART TWOMODELING
WebRef
In-depth information on ATAM can beobtained at: www.sei.cmu.edu/activities/architecture/ata_method.html.9.5.1 An Architecture Trade-Off Analysis Method
The Software Engineering Institute (SEI) has developed an architecture trade-off analy-sis method(ATAM) [Kaz98] that establishes an iterative evaluation process for softwarearchitectures. The design analysis activities that follow are performed iteratively:1.Collect scenarios.A set of use cases (Chapters 5 and 6) is developed torepresent the system from the user’s point of view.2.Elicit requirements, constraints, and environment description. This information is determined as part of requirements engineering and is used to be certainthat all stakeholder concerns have been addressed.3.Describe the architectural styles/patterns that have been chosen to address thescenarios and requirements.The architectural style(s) should be describedusing one of the following architectural views:
•Module viewfor analysis of work assignments with components and thedegree to which information hiding has been achieved.
•Process viewfor analysis of system performance.
•Data flow viewfor analysis of the degree to which the architecture meetsfunctional requirements.4.Evaluate quality attributes by considering each attribute in isolation. The num- ber of quality attributes chosen for analysis is a function of the time availablefor review and the degree to which quality attributes are relevant to the sys-tem at hand. Quality attributes for architectural design assessment includereliability, performance, security, maintainability, flexibility, testability, porta-bility, reusability, and interoperability.5.Identify the sensitivity of quality attributes to various architectural attributes for aspecific architectural style.This can be accomplished by making small changes inthe architecture and determining how sensitive a quality attribute, say perform-ance, is to the change. Any attributes that are significantly affected by variationin the architecture are termed sensitivity points.6.Critique candidate architectures (developed in step 3) using the sensitivity analy-sis conducted in step 5.The SEI describes this approach in the followingmanner [Kaz98]:
Once the architectural sensitivity points have been determined, finding trade-offpoints is simply the identification of architectural elements to which multiple attrib-utes are sensitive. For example, the performance of a client-server architecture mightbe highly sensitive to the number of servers (performance increases, within somerange, by increasing the number of servers). . . . The number of servers, then, is atrade-off point with respect to this architecture.
These six steps represent the first ATAM iteration. Based on the results of steps 5 and6, some architecture alternatives may be eliminated, one or more of the remainingpre75977_ch09.qxd  11/27/08  3:42 PM  Page 262architectures may be modified and represented in more detail, and then the ATAMsteps are reapplied.
6CHAPTER 9ARCHITECTURAL DESIGN 263
Architecture Assessment
The scene:Doug Miller’s office asarchitectural design modeling proceeds.The players:Vinod, Jamie, and Ed—members of theSafeHomesoftware engineering team and Doug Miller,manager of the software engineering group.The conversation:Doug:I know you guys are deriving a couple ofdifferent architectures for the SafeHomeproduct, andthat’s a good thing. I guess my question is, how are wegoing to choose the one that’s best?Ed:I’m working on a call and return style and theneither Jamie or I are going to derive an OO architecture.Doug:Okay, and how do we choose?Jamie:I took a CS course in design in my senior year, andI remember that there are a number of ways to do it.Vinod:There are, but they’re a bit academic. Look, Ithink we can do our assessment and choose the right oneusing use cases and scenarios.Doug:Isn’t that the same thing?Vinod:Not when you’re talking about architecturalassessment. We already have a complete set of use cases.So we apply each to both architectures and see how the system reacts, how components and connectors work inthe use case context.Ed:That’s a good idea. Makes sure we didn’t leaveanything out.Vinod:True, but it also tells us whether the architecturaldesign is convoluted, whether the system has to twist itselfinto a pretzel to get the job done.Jamie:Scenarios aren’t just another name for use cases.Vinod:No, in this case a scenario implies somethingdifferent.Doug:You’re talking about a quality scenario or achange scenario, right?Vinod:Yes. What we do is go back to the stakeholdersand ask them how SafeHomeis likely to change over thenext, say, three years. You know, new versions, features,that sort of thing. We build a set of change scenarios.We also develop a set of quality scenarios that definethe attributes we’d like to see in the softwarearchitecture.Jamie:And we apply them to the alternatives.Vinod:Exactly. The style that handles the use cases andscenarios best is the one we choose.SAFEHOME
9.5.2 Architectural Complexity
A useful technique for assessing the overall complexity of a proposed architecture isto consider dependencies between components within the architecture. These de-pendencies are driven by information/control flow within the system. Zhao [Zha98]suggests three types of dependencies:
Sharing dependenciesrepresent dependence relationships among consumers who use thesame resource or producers who produce for the same consumers. For example, for twocomponents uand v, if uand vrefer to the same global data, then there exists a shareddependence relationship between u and v.Flow dependenciesrepresent dependence relationships between producers and con-sumers of resources. For example, for two components uand v,if umust complete before
6 The Software Architecture Analysis Method (SAAM) is an alternative to ATAM and is well-worth examining by those readers interested in architectural analysis. A paper on SAAM can be down-loaded from www.sei.cmu.edu/publications/articles/saam-metho-propert-sas.html.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 263264 PART TWOMODELING
control flows into v(prerequisite), or if ucommunicates with vby parameters, then there exists a flow dependence relationship between uand v. Constrained dependenciesrepresent constraints on the relative flow of control amonga set of activities. For example, for two components u and v, uand vcannot execute at the same time (mutual exclusion), then there exists a constrained dependence relation-ship between uand v.
The sharing and flow dependencies noted by Zhao are similar to the concept of cou-pling discussed in Chapter 8. Coupling is an important design concept that is appli-cable at the architectural level and at the component level. Simple metrics forevaluating coupling are discussed in Chapter 23.
9.5.3 Architectural Description Languages
The architect of a house has a set of standardized tools and notation that allow thedesign to be represented in an unambiguous, understandable fashion. Although thesoftware architect can draw on UML notation, other diagrammatic forms, and a fewrelated tools, there is a need for a more formal approach to the specification of anarchitectural design.Architectural description language(ADL) provides a semantics and syntax for describ-ing a software architecture. Hofmann and his colleagues [Hof01] suggest that an ADLshould provide the designer with the ability to decompose architectural components,compose individual components into larger architectural blocks, and represent inter-faces (connection mechanisms) between components. Once descriptive, language-based techniques for architectural design have been established, it is more likely thateffective assessment methods for architectures will be established as the design evolves.
The following summary of a number of importantADLs was prepared by Rickard Land [Lan02]and is reprinted with the author’s permission. It should benoted that the first five ADLs listed have been developed forresearch purposes and are not commercial products.Rapide(http://poset.stanford.edu/rapide/ ) builds on the notion of partial ordered sets, and thusintroduces quite new (but seemingly powerful)programming constructs.UniCon(www.cs.cmu.edu/~UniCon) is “anarchitectural description language intended to aiddesigners in defining software architectures in terms ofabstractions that they find useful.”Aesop(www.cs.cmu.edu/~able/aesop/)addresses the problem of style reuse. With Aesop, it ispossible to define styles and use them when constructingan actual system.Wright(www.cs.cmu.edu/~able/wright/ ) is a formal language including the following elements:componentswith ports, connectorswith roles, and glueto attach roles to ports. Architectural styles can beformalized in the language with predicates, thusallowing for static checks to determine the consistencyand completeness of an architecture.Acme(www.cs.cmu.edu/~acme/) can be seen asa second-generation ADL, in that its intention is toidentify a kind of least common denominator forADLs.UML(www.uml.org/) includes many of the artifactsneeded for architectural descriptions—processes,nodes, views, etc. For informal descriptions, UML iswell suited just because it is a widely understoodstandard. It, however, lacks the full strength needed foran adequate architectural description.SOFTWARE TOOLS
Architectural Description Languagespre75977_ch09.qxd  11/27/08  3:42 PM  Page 264CHAPTER 9ARCHITECTURAL DESIGN 265
9.6 A RCHITECTURAL MAPPING USING DATAFLOW
The architectural styles discussed in Section 9.3.1 represent radically different archi-tectures. So it should come as no surprise that a comprehensive mapping thataccomplishes the transition from the requirements model to a variety of architecturalstyles does not exist. In fact, there is no practical mapping for some architecturalstyles, and the designer must approach the translation of requirements to design forthese styles in using the techniques discussed in Section 9.4.To illustrate one approach to architectural mapping, consider the call and returnarchitecture—an extremely common structure for many types of systems. The calland return architecture can reside within other more sophisticated architecturesdiscussed earlier in this chapter. For example, the architecture of one or morecomponents of a client-server architecture might be call and return.A mapping technique, called structured design [You79], is often characterized as a data flow-oriented design method because it provides a convenient transition from adata flow diagram (Chapter 7) to software architecture.
7The transition from informa- tion flow (represented as a DFD) to program structure is accomplished as part of a six-step process: (1) the type of information flow is established, (2) flow boundaries areindicated, (3) the DFD is mapped into the program structure, (4) control hierarchy isdefined, (5) the resultant structure is refined using design measures and heuristics, and(6) the architectural description is refined and elaborated.As a brief example of data flow mapping, I present a step-by-step “transform”mapping for a small part of theSafeHomesecurity function.
8In order to perform the mapping, the type of information flow must be determined. One type of informationflow is calledtransform flowand exhibits a linear quality. Data flows into the systemalong anincoming flow pathwhere it is transformed from an external worldrepresentation into internalized form. Once it has been internalized, it is processedat atransform center.Finally, it flows out of the system along an outgoing flow path that transforms the data into external world form.
9
9.6.1 Transform Mapping
Transform mapping is a set of design steps that allows a DFD with transform flowcharacteristics to be mapped into a specific architectural style. To illustrate thisapproach, we again consider the SafeHome security function.
10One element of the analysis model is a set of data flow diagrams that describe information flow within
7 It should be noted that other elements of the requirements model are also used during the mappingmethod.8 A more detailed discussion of structured design is presented within the website that accompaniesthis book.9 Another important type of information flow, transaction flow,is not considered in this example, but is addressed in the structured design example presented within the website that accompanies this book.10 We consider only the portion of the SafeHome security function that uses the control panel. Other features discussed throughout this book are not considered here.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 265266 PART TWOMODELING
the security function. To map these data flow diagrams into a software architecture,you would initiate the following design steps:Step 1. Review the fundamental system model. The fundamental system model or context diagram depicts the security function as a single transformation, repre-senting the external producers and consumers of data that flow into and out of thefunction. Figure 9.10 depicts a level 0 context model, and Figure 9.11 shows refineddata flow for the security function.
Controlpanel User commandsand data
SensorsSensorstatusControlpaneldisplay
TelephonelineAlarmSafeHomesoftwareDisplayinformation
Telephonenumber tonesAlarmtypeFIGURE 9.10
Context-levelDFD for theSafeHomesecurityfunction
telephonelineConfiguration informationControlpanel
SensorsControlpaneldisplay
TelephonelineAlarmInteractwithuserConfiguresystemActivate/deactivatesystemProcesspasswordMonitorsensorsDisplaymessagesand statusUser commandsand data
PasswordStartstopConfigurerequest
Configurationdata
ConfigurationdataConfigurationdata
Valid ID msg.A/D msg.
SensorstatusSensorinformationAlarm typeTelephonenumber tonesDisplayinformationFIGURE 9.11
Level 1 DFD forthe SafeHomesecurityfunctionpre75977_ch09.qxd  11/27/08  3:42 PM  Page 266Step 2. Review and refine data flow diagrams for the software. Information obtained from the requirements model is refined to produce greater detail. Forexample, the level 2 DFD for monitor sensors (Figure 9.12) is examined, and a level 3 data flow diagram is derived as shown in Figure 9.13. At level 3, each transform inCHAPTER 9ARCHITECTURAL DESIGN 267
If the DFD is refinedfurther at this time, striveto derive bubbles thatexhibit high cohesion.
Configuration information
ReadsensorsAssessagainstsetupConfigurationdata
Sensor ID,type
SensorstatusGeneratealarmsignalAlarmtype
Alarmdata
Telephonenumber
Dialphone
Telephonenumber tonesFormatfordisplaySensorinformation
Sensor IDtype,locationFIGURE 9.12
Level 2 DFDthat refines themonitorsensorstransform
Generatepulses toline
Telephonenumber tonesSet upconnectionto phonenetSelectphonenumberEstablishalarmconditionsAcquireresponseinfoReadsensors
GeneratealarmsignalFormatdisplayGeneratedisplayConfiguration information
Configuration data
SensorstatusSensorID, settingAlarmcondition code,sensor ID, timinginformation
List ofnumbersTelephonenumber
TonereadytelephonenumberAlarmdataSensorID type,locationFormatedID, type,location
AlarmtypeSensorinformationFIGURE 9.13 Level 3 DFD for monitor sensorswith flow boundariespre75977_ch09.qxd  11/27/08  3:42 PM  Page 267the data flow diagram exhibits relatively high cohesion (Chapter 8). That is, theprocess implied by a transform performs a single, distinct function that can beimplemented as a component in the SafeHome software. Therefore, the DFD in Figure 9.13 contains sufficient detail for a “first cut” at the design of architecture forthe monitor sensorssubsystem, and we proceed without further refinement.Step 3. Determine whether the DFD has transform or transaction flow
11
characteristics.Evaluating the DFD (Figure 9.13), we see data entering the soft-ware along one incoming path and exiting along three outgoing paths. Therefore, anoverall transform characteristic will be assumed for information flow.Step 4. Isolate the transform center by specifying incoming and outgoingflow boundaries.Incoming data flows along a path in which information isconverted from external to internal form; outgoing flow converts internalized datato external form. Incoming and outgoing flow boundaries are open to interpretation.That is, different designers may select slightly different points in the flow as bound-ary locations. In fact, alternative design solutions can be derived by varying theplacement of flow boundaries. Although care should be taken when boundaries areselected, a variance of one bubble along a flow path will generally have little impacton the final program structure.Flow boundaries for the example are illustrated as shaded curves running verti-cally through the flow in Figure 9.13. The transforms (bubbles) that constitute thetransform center lie within the two shaded boundaries that run from top to bottomin the figure. An argument can be made to readjust a boundary (e.g., an incomingflow boundary separating read sensors and acquire response infocould be proposed). The emphasis in this design step should be on selecting reasonable boundaries,rather than lengthy iteration on placement of divisions.Step 5. Perform “first-level factoring.” The program architecture derived using this mapping results in a top-down distribution of control. Factoring leads to a program structure in which top-level components perform decision making and low-level components perform most input, computation, and output work. Middle-levelcomponents perform some control and do moderate amounts of work.When transform flow is encountered, a DFD is mapped to a specific structure(a call and return architecture) that provides control for incoming, transform, andoutgoing information processing. This first-level factoring for the monitor sensorssubsystem is illustrated in Figure 9.14. A main controller (called monitor sensors executive) resides at the top of the program structure and coordinates the followingsubordinate control functions:
•An incoming information processing controller, called sensor input controller,coordinates receipt of all incoming data.268 PART TWOMODELING
You will oftenencounter both othertypes of data flowwithin the same flow-oriented model. Theflows are partitioned,and program structureis derived using theappropriate mapping.
Vary the location offlow boundaries in aneffort to explore alter-native program struc-tures. This takes verylittle time and providesimportant insight.
11 In transaction flow, a single data item, called a transaction,causes the data flow to branch along one of a number of flow paths defined by the nature of the transaction.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 268CHAPTER 9ARCHITECTURAL DESIGN 269
•A transform flow controller, called alarm conditions controller, supervises all operations on data in internalized form (e.g., a module that invokes variousdata transformation procedures).
•An outgoing information processing controller, called alarm output controller,coordinates production of output information.Although a three-pronged structure is implied by Figure 9.14, complex flows inlarge systems may dictate two or more control modules for each of the genericcontrol functions described previously. The number of modules at the first levelshould be limited to the minimum that can accomplish control functions and stillmaintain good functional independence characteristics.Step 6. Perform “second-level factoring.” Second-level factoring is accom- plished by mapping individual transforms (bubbles) of a DFD into appropriatemodules within the architecture. Beginning at the transform center boundary andmoving outward along incoming and then outgoing paths, transforms are mappedinto subordinate levels of the software structure. The general approach to second-level factoring is illustrated in Figure 9.15.Although Figure 9.15 illustrates a one-to-one mapping between DFD transformsand software modules, different mappings frequently occur. Two or even three bub-bles can be combined and represented as one component, or a single bubble maybe expanded to two or more components. Practical considerations and measuresMonitorsensorsexecutive
Alarmconditionscontroller Alarmoutputcontroller SensorinputcontrollerFIGURE 9.14
First-levelfactoring formonitorsensors
Don’t becomedogmatic at this stage.It may be necessary toestablish two or morecontrollers for inputprocessing or computa-tion, based on thecomplexity of thesystem to be built. Ifcommon sense dictatesthis approach, do it!
Eliminate redundantcontrol modules. That is,if a control module doesnothing except controlone other module, itscontrol function shouldbe imploded to a higher-level module.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 269of design quality dictate the outcome of second-level factoring. Review and refine-ment may lead to changes in this structure, but it can serve as a “first-iteration”design.Second-level factoring for incoming flow follows in the same manner. Factoringis again accomplished by moving outward from the transform center boundary onthe incoming flow side. The transform center of monitor sensorssubsystem soft- ware is mapped somewhat differently. Each of the data conversion or calculationtransforms of the transform portion of the DFD is mapped into a module subordi-nate to the transform controller. A completed first-iteration architecture is shownin Figure 9.16.The components mapped in the preceding manner and shown in Figure 9.16represent an initial design of software architecture. Although components arenamed in a manner that implies function, a brief processing narrative (adapted fromthe process specification developed for a data transformation created duringrequirements modeling) should be written for each. The narrative describes the270 PART TWOMODELING
MonitorsensorsexecutiveAlarmconditionscontrollerAlarmoutputcontrollerSensorinputcontrollerGeneratealarmsignalFormatdisplayGeneratedisplay
Set upconnectionto phonenetGeneratepulses toline
Transformflow boundary
GeneratealarmsignalSet upconnectionto phone netFormatdisplay
Generatepulses to lineGeneratedisplayFIGURE 9.15
Second-levelfactoring formonitorsensors
Keep “worker” moduleslow in the programstructure. This will leadto an architecture that iseasier to maintain.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 270CHAPTER 9ARCHITECTURAL DESIGN 271
component interface, internal data structures, a functional narrative, and a briefdiscussion of restrictions and special features (e.g., file input-output, hardware-dependent characteristics, special timing requirements).Step 7. Refine the first-iteration architecture using design heuristics forimproved software quality.A first-iteration architecture can always be refined byapplying concepts of functional independence (Chapter 8). Components are explodedor imploded to produce sensible factoring, separation of concerns, good cohesion,minimal coupling, and most important, a structure that can be implemented withoutdifficulty, tested without confusion, and maintained without grief.Refinements are dictated by the analysis and assessment methods describedbriefly in Section 9.5, as well as practical considerations and common sense. Thereare times, for example, when the controller for incoming data flow is totally unnec-essary, when some input processing is required in a component that is subordi-nate to the transform controller, when high coupling due to global data cannot beavoided, or when optimal structural characteristics cannot be achieved. Softwarerequirements coupled with human judgment is the final arbiter.The objective of the preceding seven steps is to develop an architectural repre-sentation of software. That is, once structure is defined, we can evaluate and refinesoftware architecture by viewing it as a whole. Modifications made at this timerequire little additional work, yet can have a profound impact on software quality.You should pause for a moment and consider the difference between the designapproach described and the process of “writing programs.” If code is the only repre-sentation of software, you and your colleagues will have great difficulty evaluatingor refining at a global or holistic level and will, in fact, have difficulty “seeing theforest for the trees.”Alarmoutputcontroller
GeneratealarmsignalSet upconnectionto phone netFormatdisplay
Generatepulses to lineGeneratedisplayAlarmconditionscontroller
SelectphonenumberEstablishalarmconditionsMonitorsensorsexecutive
Sensorinputcontroller
Acquireresponseinfo
ReadsensorsFIGURE 9.16
First-iterationstructure formonitorsensors
uote:
“Make it as simpleas possible. But nosimpler.”Albert Einsteinpre75977_ch09.qxd  11/27/08  3:42 PM  Page 271272 PART TWOMODELING
The scene:Jamie’s cubicle, asdesign modeling begins.The players:Jamie and Ed—members of theSafeHomesoftware engineering team.The conversation:[Ed has just completed a first-cut design of the monitorsensors subsystem. He stops in to ask Jamie her opinion.]Ed:So here’s the architecture that I derived.[Ed shows Jamie Figure 9.16, which she studies for a fewmoments.]Jamie:That’s cool, but I think we can do a few things tomake it simpler . . . and better.Ed:Such as?Jamie:Well, why did you use the sensor input controllercomponent?Ed:Because you need a controller for the mapping.Jamie:Not really. The controller doesn’t do much, sincewe’re managing a single flow path for incoming data.We can eliminate the controller with no ill effects.Ed:I can live with that. I’ll make the change and . . .Jamie (smiling):Hold up! We can also implode thecomponents establish alarm conditionsand select phonenumber. The transform controller you show isn’t reallynecessary, and the small decrease in cohesion is tolerable.Ed:Simplification, huh?Jamie:Yep. And while we’re making refinements, itwould be a good idea to implode the components format displayand generate display. Display formatting for thecontrol panel is simple. We can define a new modulecalled produce display.Ed (sketching):So this is what you think we should do?”[Shows Jamie Figure 9.17.]Jamie:It’s a good start.SAFEHOME
Alarmoutputcontroller
GeneratealarmsignalSet upconnectionto phone netProducedisplay
Generatepulses to lineEstablishalarmconditionsMonitorsensorsexecutive
Acquireresponseinfo
ReadsensorsFIGURE 9.17
Refinedprogramstructure formonitorsensorsRefining a First-Cut Architecture
9.6.2 Refining the Architectural Design
Any discussion of design refinement should be prefaced with the following com-ment: “Remember that an ‘optimal design’ that doesn’t work has questionablemerit.” You should be concerned with developing a representation of software thatwill meet all functional and performance requirements and merit acceptance basedon design measures and heuristics.Whathappensafter thearchitecture hasbeen created??pre75977_ch09.qxd  11/27/08  3:42 PM  Page 272CHAPTER 9ARCHITECTURAL DESIGN 273
Refinement of software architecture during early stages of design is to be en-couraged. As I discussed earlier in this chapter, alternative architectural styles maybe derived, refined, and evaluated for the “best” approach. This approach to opti-mization is one of the true benefits derived by developing a representation of soft-ware architecture.It is important to note that structural simplicity often reflects both elegance andefficiency. Design refinement should strive for the smallest number of componentsthat is consistent with effective modularity and the least complex data structure thatadequately serves information requirements.
9.7 S UMMARY
Software architecture provides a holistic view of the system to be built. It depicts thestructure and organization of software components, their properties, and the con-nections between them. Software components include program modules and thevarious data representations that are manipulated by the program. Therefore, datadesign is an integral part of the derivation of the software architecture. Architecturehighlights early design decisions and provides a mechanism for considering the ben-efits of alternative system structures.A number of different architectural styles and patterns are available to the soft-ware engineer and may be applied within a given architectural genre. Each style de-scribes a system category that encompasses a set of components that perform afunction required by a system; a set of connectors that enable communication, co-ordination, and cooperation among components; constraints that define how com-ponents can be integrated to form the system; and semantic models that enable adesigner to understand the overall properties of a system.In a general sense, architectural design is accomplished using four distinct steps.First, the system must be represented in context. That is, the designer should definethe external entities that the software interacts with and the nature of the interac-tion. Once context has been specified, the designer should identify a set of top-levelabstractions, called archetypes, that represent pivotal elements of the system’s be-havior or function. After abstractions have been defined, the design begins to movecloser to the implementation domain. Components are identified and representedwithin the context of an architecture that supports them. Finally, specific instantia-tions of the architecture are developed to “prove” the design in a real-world context.As a simple example of architectural design, the mapping method presented inthis chapter uses data flow characteristics to derive a commonly used architecturalstyle. A data flow diagram is mapped into program structure using a transform map-ping approach. Transform mapping is applied to an information flow that exhibitsdistinct boundaries between incoming and outgoing data. The DFD is mapped into astructure that allocates control to input, processing, and output along three sepa-rately factored module hierarchies. Once an architecture has been derived, it is elab-orated and then analyzed using quality criteria.pre75977_ch09.qxd  11/27/08  3:42 PM  Page 273PROBLEMS AND POINTS TO PONDER
9.1.Using the architecture of a house or building as a metaphor, draw comparisons withsoftware architecture. How are the disciplines of classical architecture and the software archi-tecture similar? How do they differ?9.2.Present two or three examples of applications for each of the architectural styles noted inSection 9.3.1.9.3.Some of the architectural styles noted in Section 9.3.1 are hierarchical in nature and oth-ers are not. Make a list of each type. How would the architectural styles that are not hierarchi-cal be implemented?9.4.The terms architectural style, architectural pattern, and framework(not discussed in this book) are often encountered in discussions of software architecture. Do some research anddescribe how each of these terms differs from its counterparts.9.5.Select an application with which you are familiar. Answer each of the questions posed forcontrol and data in Section 9.3.3.9.6.Research the ATAM (using [Kaz98]) and present a detailed discussion of the six stepspresented in Section 9.5.1.9.7.If you haven’t done so, complete Problem 6.6. Use the design methods described in thischapter to develop a software architecture for the PHTRS.9.8.Using a data flow diagram and a processing narrative, describe a computer-based systemthat has distinct transform flow characteristics. Define flow boundaries and map the DFD into asoftware architecture using the technique described in Section 9.6.1.
FURTHER READINGS AND INFORMATION SOURCES
The literature on software architecture has exploded over the past decade. Books by Gorton(Essential Software Architecture,Springer, 2006), Reekie and McAdam (A Software ArchitecturePrimer,Angophora Press, 2006), Albin (The Art of Software Architecture,Wiley, 2003), and Bass and his colleagues (Software Architecture in Practice, 2d ed., Addison-Wesley, 2002) present worthwhile introductions to an intellectually challenging topic area.Buschman and his colleagues (Pattern-Oriented Software Architecture, Wiley, 2007) and Kuchana (Software Architecture Design Patterns in Java, Auerbach, 2004) discuss pattern-oriented aspects of architectural design. Rozanski and Woods ( Software Systems Architecture,Addison- Wesley, 2005), Fowler (Patterns of Enterprise Application Architecture, Addison-Wesley, 2003), Clements and his colleagues (Documenting Software Architecture: View and Beyond, Addison- Wesley, 2002), Bosch [Bos00], and Hofmeister and his colleagues [Hof00] provide in-depth treat-ments of software architecture.Hennesey and Patterson (Computer Architecture,4th ed., Morgan-Kaufmann, 2007) take a distinctly quantitative view of software architectural design issues. Clements and his colleagues(Evaluating Software Architectures, Addison-Wesley, 2002) consider the issues associated with the assessment of architectural alternatives and the selection of the best architecture for a givenproblem domain.Implementation-specific books on architecture address architectural design within a specificdevelopment environment or technology. Marks and Bell (Service-Oriented Architecture, Wiley, 2006) discuss a design approach that links business and computational resources with the re-quirements defined by customers. Stahl and his colleagues (Model-Driven Software Development,Wiley, 2006) discuss architecture within the context of domain-specific modeling approaches.Radaideh and Al-ameed (Architecture of Reliable Web Applications Software, GI Global, 2007) con- sider architectures that are appropriate for WebApps. Clements and Northrop (Software ProductLines: Practices and Patterns,Addison-Wesley, 2001) address the design of architectures that274 PART TWOMODELINGpre75977_ch09.qxd  12/3/08  1:58 PM  Page 274CHAPTER 9ARCHITECTURAL DESIGN 275
support software product lines. Shanley (Protected Mode Software Architecture, Addison-Wesley, 1996) provides architectural design guidance for anyone designing PC-based real-time operatingsystems, multitask operating systems, or device drivers.Current software architecture research is documented yearly in the Proceedings of the Inter-national Workshop on Software Architecture, sponsored by the ACM and other computing organ- izations, and the Proceedings of the International Conference on Software Engineering.A wide variety of information sources on architectural design are available on the Internet.An up-to-date list of World Wide Web references that are relevant to architectural design can befound at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.pre75977_ch09.qxd  12/3/08  1:58 PM  Page 275Component-level design occurs after the first iteration of architecturaldesign has been completed. At this stage, the overall data and programstructure of the software has been established. The intent is to translatethe design model into operational software. But the level of abstraction of theexisting design model is relatively high, and the abstraction level of the opera-tional program is low. The translation can be challenging, opening the door to theintroduction of subtle errors that are difficult to find and correct in later stages ofthe software process. In a famous lecture, Edsgar Dijkstra, a major contributor toour understanding of software design, stated [Dij72]:
Software seems to be different from many other products, where as a rule higher qual-ity implies a higher price. Those who want really reliable software will discover thatthey must find a means of avoiding the majority of bugs to start with, and as a result,
276CHAPTER
10COMPONENT -LEVEL
DESIGN
KEY
CONCEPTScohesion . . . . . . .286componentsclassifying  . . . .307adaptation  . . . .305composition  . . .305object-oriented  . . . . . .277qualification  . . .304traditional  . . . .298WebApp . . . . . .296component-baseddevelopment . . . .303content design . . .297coupling  . . . . . . .288
What is it? A complete set of soft-ware components is defined duringarchitectural design. But the internaldata structures and processingdetails of each component are not representedat a level of abstraction that is close to code.Component-level design defines the data struc-tures, algorithms, interface characteristics, andcommunication mechanisms allocated to eachsoftware component.
Who does it? A software engineer performs component-level design.
Why is it important? You have to be able to de-termine whether the software will work beforeyou build it. The component-level design repre-sents the software in a way that allows you to re-view the details of the design for correctness andconsistency with other design representations(i.e., the data, architectural, and interface de-signs). It provides a means for assessing whetherdata structures, interfaces, and algorithms willwork.
What are the steps? Design representationsof data, architecture, and interfaces form theQUICK
LOOKfoundation for component-level design. Theclass definition or processing narrative for eachcomponent is translated into a detailed designthat makes use of diagrammatic or text-basedforms that specify internal data structures, localinterface detail, and processing logic. Designnotation encompasses UML diagrams and sup-plementary forms. Procedural design is specifiedusing a set of structured programming con-structs. It is often possible to acquire existingreusable software components rather than build-ing new ones.
What is the work product? The design for eachcomponent, represented in graphical, tabular,or text-based notation, is the primary workproduct produced during component-leveldesign.
How do I ensure that I’ve done it right? A designreview is conducted. The design is examined todetermine whether data structures, interfaces, pro-cessing sequences, and logical conditions are cor-rect and will produce the appropriate data orcontrol transformation allocated to the componentduring earlier design steps.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 276CHAPTER 10COMPONENT-LEVEL DESIGN 277
designguidelines . . . . . .285domainengineering  . . . .303tabular design notation  . . . . . . .300the programming process will become cheaper . . . effective programmers . . . should notwaste their time debugging—they should not introduce bugs to start with.
Although these words were spoken many years ago, they remain true today. As youtranslate the design model into source code, you should follow a set of designprinciples that not only perform the translation but also do not “introduce bugs tostart with.”It is possible to represent the component-level design using a programming lan-guage. In essence, the program is created using the architectural design model as aguide. An alternative approach is to represent the component-level design usingsome intermediate (e.g., graphical, tabular, or text-based) representation that can betranslated easily into source code. Regardless of the mechanism that is used torepresent the component-level design, the data structures, interfaces, and algo-rithms defined should conform to a variety of well-established design guidelines thathelp you to avoid errors as the procedural design evolves. In this chapter, I examinethese design guidelines and the methods available for achieving them.
uote:
“The details arenot the details.They make thedesign.”Charles Eames10.1 W HATISACOMPONENT ?
A componentis a modular building block for computer software. More formally, theOMG Unified Modeling Language Specification [OMG03a] defines a component as “. . . a modular, deployable, and replaceable part of a system that encapsulatesimplementation and exposes a set of interfaces.”As we discussed in Chapter 9, components populate the software architectureand, as a consequence, play a role in achieving the objectives and requirements ofthe system to be built. Because components reside within the software architec-ture, they must communicate and collaborate with other components and withentities (e.g., other systems, devices, people) that exist outside the boundaries ofthe software.The true meaning of the term component will differ depending on the point of view of the software engineer who uses it. In the sections that follow, I examine three im-portant views of what a component is and how it is used as design modeling proceeds.
10.1.1 An Object-Oriented View
In the context of object-oriented software engineering, a component contains a setof collaborating classes.
1Each class within a component has been fully elaboratedto include all attributes and operations that are relevant to its implementation. Aspart of the design elaboration, all interfaces that enable the classes to communicateand collaborate with other design classes must also be defined. To accomplish this,you begin with the requirements model and elaborate analysis classes (for compo-nents that relate to the problem domain) and infrastructure classes (for componentsthat provide support services for the problem domain).
From an object-oriented viewpoint, acomponent is a set ofcollaborating classes.
1 In some cases, a component may contain a single class.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 277278 PART TWOMODELING
PrintJobcomputeJob
initiateJob
numberOfPagesnumberOfSidespaperType   paperWeight   paperSize   paperColormagnificationcolorRequirementsproductionFeatures   collationOptions   bindingOptions   coverStock   bleed   prioritytotalJobCostWOnumber PrintJob
computePageCost( ) computePaperCost( ) computeProdCost( ) computeTotalJobCost( ) buildWorkOrder( ) checkPriority( ) passJobto Production( ) Elaborated design class <<interface>> computeJob
computePageCost( ) computePaperCost( ) computeProdCost( ) computeTotalJobCost( )
<<interface>> initiateJob
buildWorkOrder( ) checkPriority( ) passJobto Production( )DesigncomponentnumberOfPages numberOfSides paperType magnification productionFeaturesPrintJob
computeJobCost( ) passJobtoPrinter( ) Analysis classFIGURE 10.1
Elaboration ofa designcomponent
To illustrate this process of design elaboration, consider software to be built for asophisticated print shop. The overall intent of the software is to collect the cus-tomer’s requirements at the front counter, cost a print job, and then pass the job onto an automated production facility. During requirements engineering, an analysisclass called PrintJobwas derived. The attributes and operations defined duringanalysis are noted at the top of Figure 10.1. During architectural design, PrintJobis defined as a component within the software architecture and is represented usingthe shorthand UML notation
2shown in the middle right of the figure. Note thatPrintJobhas two interfaces, computeJob,which provides job costing capability, and initiateJob,which passes the job along to the production facility. These are repre-sented using the “lollipop” symbols shown to the left of the component box.
2 Readers who are unfamiliar with UML notation should refer to Appendix 1.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 278Component-level design begins at this point. The details of the component PrintJobmust be elaborated to provide sufficient information to guide implementation. The orig-inal analysis class is elaborated to flesh out all attributes and operations required to im-plement the class as the component PrintJob. Referring to the lower right portion of Figure 10.1, the elaborated design class PrintJob contains more detailed attribute information as well as an expanded description of operations required to implementthe component. The interfaces computeJob and initiateJobimply communication and collaboration with other components (not shown here). For example, the operationcomputePageCost()(part of the computeJobinterface) might collaborate with a PricingTablecomponent that contains job pricing information. The checkPriority() operation (part of the initiateJobinterface) might collaborate with a JobQueuecompo- nent to determine the types and priorities of jobs currently awaiting production.This elaboration activity is applied to every component defined as part of thearchitectural design. Once it is completed, further elaboration is applied to eachattribute, operation, and interface. The data structures appropriate for each attributemust be specified. In addition, the algorithmic detail required to implement the pro-cessing logic associated with each operation is designed. This procedural designactivity is discussed later in this chapter. Finally, the mechanisms required to imple-ment the interface are designed. For object-oriented software, this may encompassthe description of all messaging that is required to effect communication betweenobjects within the system.
10.1.2 The Traditional View
In the context of traditional software engineering, a component is a functional elementof a program that incorporates processing logic, the internal data structures that are re-quired to implement the processing logic, and an interface that enables the componentto be invoked and data to be passed to it. A traditional component, also called a module, resides within the software architecture and serves one of three important roles: (1) acontrol componentthat coordinates the invocation of all other problem domain com-ponents, (2) a problem domain component that implements a complete or partial func- tion that is required by the customer, or (3) an infrastructure componentthat is responsible for functions that support the processing required in the problem domain.Like object-oriented components, traditional software components are derivedfrom the analysis model. In this case, however, the data flow-oriented element of theanalysis model serves as the basis for the derivation. Each transform (bubble) repre-sented at the lowest levels of the data flow diagram is mapped (Section 9.6) into amodule hierarchy. Control components (modules) reside near the top of the hierar-chy (program architecture), and problem domain components tend to reside towardthe bottom of the hierarchy. To achieve effective modularity, design concepts likefunctional independence (Chapter 8) are applied as components are elaborated.To illustrate this process of design elaboration for traditional components, againconsider software to be built for a sophisticated print shop. A set of data flow diagramsCHAPTER 10COMPONENT-LEVEL DESIGN 279
Recall that analysismodeling and designmodeling are bothiterative actions. Elabo-rating the originalanalysis class mayrequire additionalanalysis steps, whichare then followed withdesign modeling stepsto represent theelaborated design class(the details of thecomponent).
uote:
“A complex systemthat works isinvariably found tohave evolved froma simple systemthat worked.”John Gallpre75977_ch10.qxd  11/27/08  3:46 PM  Page 279280 PART TWOMODELING
As the design for eachsoftware component iselaborated, the focusshifts to the design ofspecific data structuresand procedural designto manipulate the datastructures. However,don’t forget thearchitecture that musthouse the componentsor the global datastructures thatmay serve manycomponents.would be derived during requirements modeling. Assume that these are mapped intoan architecture shown in Figure 10.2. Each box represents a software component.Note that the shaded boxes are equivalent in function to the operations defined for thePrintJobclass discussed in Section 10.1.1. In this case, however, each operation isrepresented as a separate module that is invoked as shown in the figure. Other mod-ules are used to control processing and are therefore control components.During component-level design, each module in Figure 10.2 is elaborated. Themodule interface is defined explicitly. That is, each data or control object that flowsacross the interface is represented. The data structures that are used internal to themodule are defined. The algorithm that allows the module to accomplish its intendedfunction is designed using the stepwise refinement approach discussed in Chapter 8.The behavior of the module is sometimes represented using a state diagram.To illustrate this process, consider the module ComputePageCost.The intent of this module is to compute the printing cost per page based on specifications provided bythe customer. Data required to perform this function are: number of pages in the docu-ment, total number of documents to be produced, one- or two-side printing, color requirements,and size requirements.These data are passed to ComputePageCost via the module’s in- terface. ComputePageCostuses these data to determine a page cost that is based onthe size and complexity of the job—a function of all data passed to the module viathe interface. Page cost is inversely proportional to the size of the job and directlyproportional to the complexity of the job.Readprint jobdataJobmanagementsystemSelectjobmgmtfunction
Developjob costBuildwork orderSend jobtoproduction
Computepage cost Computepaper cost Computeprod cost Checkpriority Pass job toproductionFIGURE 10.2
Structure chartfor a tradi-tional systempre75977_ch10.qxd  11/27/08  3:46 PM  Page 280Figure 10.3 represents the component-level design using a modified UMLnotation. The ComputePageCostmodule accesses data by invoking the modulegetJobData,which allows all relevant data to be passed to the component, and adatabase interface, accessCostsDB,which enables the module to access a databasethat contains all printing costs. As design continues, the ComputePageCost module is elaborated to provide algorithm detail and interface detail (Figure 10.3). Algorithmdetail can be represented using the pseudocode text shown in the figure or witha UML activity diagram. The interfaces are represented as a collection of input andoutput data objects or items. Design elaboration continues until sufficient detail isprovided to guide construction of the component.
10.1.3 A Process-Related View
The object-oriented and traditional views of component-level design presented inSections 10.1.1 and 10.1.2 assume that the component is being designed fromscratch. That is, you have to create a new component based on specificationsderived from the requirements model. There is, of course, another approach.CHAPTER 10COMPONENT-LEVEL DESIGN 281
ComputePageCostDesign component
accessCostsDBgetJobData
Elaborated module
PageCost
in: numberPages in: numberDocs in: sides= 1, 2 in: color=1, 2, 3, 4 in: page size = A, B, C, D out: page cost in:  job size in:  color=1, 2, 3, 4 in:  pageSize = A, B, C, D out:  BPC out:  SF 
 job size (JS) =    numberPages * numberDocs; lookup base page cost (BPC) -->    accessCostsDB (JS, color); lookup size factor (SF) -->    accessCostDB (JS, color, size) job complexity factor (JCF) =    1 + [(sides-1)*sideCost + SF] pagecost = BPC * JCF  getJobData (numberPages, numberDocs, sides, color, pageSize, pageCost) accessCostsDB(jobSize, color, pageSize, BPC, SF) computePageCost( )FIGURE 10.3 Component-level design for ComputePageCostpre75977_ch10.qxd  11/27/08  3:46 PM  Page 281282 PART TWOMODELING
Over the past two decades, the software engineering community has emphasized theneed to build systems that make use of existing software components or design patterns.In essence, a catalog of proven design or code-level components is made available toyou as design work proceeds. As the software architecture is developed, you choosecomponents or design patterns from the catalog and use them to populate the architec-ture. Because these components have been created with reusability in mind, a completedescription of their interface, the function(s) they perform, and the communication andcollaboration they require are all available to you. I discuss some of the importantaspects of component-based software engineering (CBSE) later in Section 10.6.
Component-Based Standards and Frameworks
One of the key elements that lead to thesuccess or failure of CBSE is the availabilityof component-based standards, sometimes calledmiddleware. Middlewareis a collection of infrastructurecomponents that enable problem domain components tocommunicate with one another across a network orwithin a complex system. Software engineers who wantto use component-based development as their softwareprocess can choose from among the followingstandards:OMG CORBA—www.corba.org/Microsoft COM—www.microsoft.com/com/tech/complus.aspMicrosoft .NET—http:/ /msdn2.microsoft.com/en-us/netframework/default.aspxSun JavaBeans—http:/ /java.sun.com/products/ejb/The websites noted present a wide array of tutorials, whitepapers, tools, and general resources on these importantmiddleware standards.INFO
10.2 D ESIGNING CLASS-BASED COMPONENTS
As I have already noted, component-level design draws on information developedas part of the requirements model (Chapters 6 and 7) and represented as part ofthe architectural model (Chapter 9). When an object-oriented software engineeringapproach is chosen, component-level design focuses on the elaboration of problemdomain specific classes and the definition and refinement of infrastructure classescontained in the requirements model. The detailed description of the attributes,operations, and interfaces used by these classes is the design detail required as aprecursor to the construction activity.
10.2.1 Basic Design Principles
Four basic design principles are applicable to component-level design and have beenwidely adopted when object-oriented software engineering is applied. The underlyingmotivation for the application of these principles is to create designs that are moreamenable to change and to reduce the propagation of side effects when changes dooccur. You can use these principles as a guide as each software component is developed.The Open-Closed Principle (OCP). “A module [component] should be open for extension but closed for modification” [Mar00]. This statement seems to be apre75977_ch10.qxd  11/27/08  3:46 PM  Page 282CHAPTER 10COMPONENT-LEVEL DESIGN 283
contradiction, but it represents one of the most important characteristics of a goodcomponent-level design. Stated simply, you should specify the component in a waythat allows it to be extended (within the functional domain that it addresses) with-out the need to make internal (code or logic-level) modifications to the componentitself. To accomplish this, you create abstractions that serve as a buffer between thefunctionality that is likely to be extended and the design class itself.For example, assume that the SafeHome security function makes use of a Detector class that must check the status of each type of security sensor. It is likely that as timepasses, the number and types of security sensors will grow. If internal processing logicis implemented as a sequence of if-then-else constructs, each addressing a differentsensor type, the addition of a new sensor type will require additional internal pro-cessing logic (still another if-then-else). This is a violation of OCP.One way to accomplish OCP for the Detector class is illustrated in Figure 10.4. The sensorinterface presents a consistent view of sensors to the detector compo-nent. If a new type of sensor is added no change is required for the Detector class (component). The OCP is preserved.Detector<<interface>>Sensorread( ) enable( ) disable( ) test( )
Window/ doorSensorSmokeSensor MotionDetector HeatSensor CO2SensorFIGURE 10.4
Following theOCP
The OCP in Action
The scene:Vinod’s cubicle.The players:Vinod and Shakira—members of theSafeHomesoftware engineering team.The conversation:Vinod:I just got a call from Doug [the team manager].He says marketing wants to add a new sensor.Shakira (smirking):Not again, jeez!Vinod:Yeah . . . and you’re not going to believe whatthese guys have come up with.Shakira:Amaze me.Vinod (laughing):They call it a doggie angst sensor.Shakira:Say what?Vinod:It’s for people who leave their pets home inapartments or condos or houses that are close to oneSAFEHOMEpre75977_ch10.qxd  11/27/08  3:46 PM  Page 283284 PART TWOMODELING
The Liskov Substitution Principle (LSP). “Subclasses should be substitutable for their base classes”[Mar00]. This design principle, originally proposed by Barbara Liskov[Lis88], suggests that a component that uses a base class should continue to functionproperly if a class derived from the base class is passed to the component instead. LSPdemands that any class derived from a base class must honor any implied contract be-tween the base class and the components that use it. In the context of this discussion,a “contract” is a preconditionthat must be true before the component uses a base classand a postconditionthat should be true after the component uses a base class. Whenyou create derived classes, be sure they conform to the pre- and postconditions.Dependency Inversion Principle (DIP). “Depend on abstractions. Do not depend on concretions”[Mar00]. As we have seen in the discussion of the OCP, abstractionsare the place where a design can be extended without great complication. The morea component depends on other concrete components (rather than on abstractionssuch as an interface), the more difficult it will be to extend.The Interface Segregation Principle (ISP). “Many client-specific interfaces are better than one general purpose interface” [Mar00]. There are many instances in which multiple client components use the operations provided by a server class. ISPsuggests that you should create a specialized interface to serve each major categoryof clients. Only those operations that are relevant to a particular category of clientsshould be specified in the interface for that client. If multiple clients require the sameoperations, it should be specified in each of the specialized interfaces.As an example, consider the FloorPlan class that is used for the SafeHomesecu- rity and surveillance functions (Chapter 6). For the security functions, FloorPlan is used only during configuration activities and uses the operations placeDevice(),showDevice(), groupDevice(),and removeDevice()to place, show, group, and remove sensors from the floor plan. The SafeHome surveillance function uses the four
If you dispense withdesign and hack outcode, just rememberthat code is theultimate “concretion.”You’re violating DIP .another. The dog starts to bark. The neighbor gets angryand complains. With this sensor, if the dog barks formore than, say, a minute, the sensor sets a special alarmmode that calls the owner on his or her cell phone.Shakira:You’re kidding me, right?Vinod:Nope. Doug wants to know how much time it’sgoing to take to add it to the security function.Shakira (thinking a moment):Not much . . . look.[She shows Vinod Figure 10.4] We’ve isolated the actualsensor classes behind the sensorinterface. As long aswe have specs for the doggie sensor, adding it should bea piece of cake. Only thing I’ll have to do is create anappropriate component . . . uh, class, for it. No changeto the Detectorcomponent at all.Vinod:So I’ll tell Doug it’s no big deal.Shakira:Knowing Doug, he’ll keep us focused and notdeliver the doggie thing until the next release.Vinod:That’s not a bad thing, but you can implementnow if he wants you to?Shakira:Yeah, the way we designed the interface letsme do it with no hassle.Vinod (thinking a moment):Have you ever heardof the open-closed principle?Shakira (shrugging):Never heard of it.Vinod (smiling):Not a problem.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 284operations noted for security, but also requires special operations to managecameras: showFOV()and showDeviceID().Hence, the ISP suggests that client compo- nents from the two SafeHomefunctions have specialized interfaces defined forthem. The interface for security would encompass only the operations placeDevice(),showDevice(), groupDevice(),and removeDevice().The interface for surveillance would incorporate the operations placeDevice(), showDevice(), groupDevice(), and removeDevice(),along with showFOV()and showDeviceID().Although component-level design principles provide useful guidance, compo-nents themselves do not exist in a vacuum. In many cases, individual componentsor classes are organized into subsystems or packages. It is reasonable to ask howthis packaging activity should occur. Exactly how should components be organizedas the design proceeds? Martin [Mar00] suggests additional packaging principlesthat are applicable to component-level design:The Release Reuse Equivalency Principle (REP). “The granule of reuse is the granule of release”[Mar00]. When classes or components are designed for reuse, thereis an implicit contract that is established between the developer of the reusable entityand the people who will use it. The developer commits to establish a release controlsystem that supports and maintains older versions of the entity while the users slowlyupgrade to the most current version. Rather than addressing each class individually,it is often advisable to group reusable classes into packages that can be managed andcontrolled as newer versions evolve.The Common Closure Principle (CCP). “Classes that change together belong together.”[Mar00]. Classes should be packaged cohesively. That is, when classes arepackaged as part of a design, they should address the same functional or behavioralarea. When some characteristic of that area must change, it is likely that only thoseclasses within the package will require modification. This leads to more effectivechange control and release management.The Common Reuse Principle (CRP). “Classes that aren’t reused together should not be grouped together”[Mar00]. When one or more classes within a packagechanges, the release number of the package changes. All other classes or packagesthat rely on the package that has been changed must now update to the most recentrelease of the package and be tested to ensure that the new release operates withoutincident. If classes are not grouped cohesively, it is possible that a class with no rela-tionship to other classes within a package is changed. This will precipitate unneces-sary integration and testing. For this reason, only classes that are reused togethershould be included within a package.
10.2.2 Component-Level Design Guidelines
In addition to the principles discussed in Section 10.2.1, a set of pragmatic designguidelines can be applied as component-level design proceeds. These guidelinesapply to components, their interfaces, and the dependencies and inheritanceCHAPTER 10COMPONENT-LEVEL DESIGN 285
Designing componentsfor reuse requires morethan good technicaldesign. It also requireseffective configurationcontrol mechanisms(Chapter 22).pre75977_ch10.qxd  11/27/08  3:46 PM  Page 285286 PART TWOMODELING
characteristics that have an impact on the resultant design. Ambler [Amb02b] sug-gests the following guidelines:Components.Naming conventions should be established for components that arespecified as part of the architectural model and then refined and elaborated as partof the component-level model. Architectural component names should be drawnfrom the problem domain and should have meaning to all stakeholders who view thearchitectural model. For example, the class name FloorPlan is meaningful to every- one reading it regardless of technical background. On the other hand, infrastructurecomponents or elaborated component-level classes should be named to reflectimplementation-specific meaning. If a linked list is to be managed as part of theFloorPlanimplementation, the operation manageList() is appropriate, even if a non- technical person might misinterpret it.
3
You can choose to use stereotypes to help identify the nature of components atthe detailed design level. For example, < <infrastructure> > might be used to identify an infrastructure component, <<database>>could be used to identify a database that services one or more design classes or the entire system; <<table>>can be used to identify a table within a database.Interfaces.Interfaces provide important information about communication andcollaboration (as well as helping us to achieve the OCP). However, unfettered repre-sentation of interfaces tends to complicate component diagrams. Ambler [Amb02c]recommends that (1) lollipop representation of an interface should be used in lieu ofthe more formal UML box and dashed arrow approach, when diagrams grow complex;(2) for consistency, interfaces should flow from the left-hand side of the componentbox; (3) only those interfaces that are relevant to the component under considerationshould be shown, even if other interfaces are available. These recommendations areintended to simplify the visual nature of UML component diagrams.Dependencies and Inheritance.For improved readability, it is a good ideato model dependencies from left to right and inheritance from bottom (derivedclasses) to top (base classes). In addition, component interdependencies shouldbe represented via interfaces, rather than by representation of a component-to-component dependency. Following the philosophy of the OCP, this will help tomake the system more maintainable.
10.2.3 Cohesion
In Chapter 8, I described cohesion as the “single-mindedness” of a component.Within the context of component-level design for object-oriented systems, cohesionWhat shouldwe considerwhen we namecomponents??
3 It is unlikely that someone from marketing or the customer organization (a nontechnical type)would examine detailed design information.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 286implies that a component or class encapsulates only attributes and operations thatare closely related to one another and to the class or component itself. Lethbridgeand Laganiére [Let01] define a number of different types of cohesion (listed in orderof the level of the cohesion
4):
Functional.Exhibited primarily by operations, this level of cohesion occurswhen a component performs a targeted computation and then returns aresult.Layer.Exhibited by packages, components, and classes, this type of cohe-sion occurs when a higher layer accesses the services of a lower layer,but lower layers do not access higher layers. Consider, for example, theSafeHomesecurity function requirement to make an outgoing phone call if analarm is sensed. It might be possible to define a set of layered packages asshown in Figure 10.5. The shaded packages contain infrastructure compo-nents. Access is from the control panel package downward.Communicational.All operations that access the same data are definedwithin one class. In general, such classes focus solely on the data in ques-tion, accessing and storing it.Classes and components that exhibit functional, layer, and communicationalcohesion are relatively easy to implement, test, and maintain. You should strive toachieve these levels of cohesion whenever possible. It is important to note, however,that pragmatic design and implementation issues sometimes force you to opt forlower levels of cohesion.CHAPTER 10COMPONENT-LEVEL DESIGN 287
4 In general, the higher the level of cohesion, the easier the component is to implement, test, andmaintain.)DetectorControl panel
Phone
Modem
T-comFIGURE 10.5
Layer cohesion
Although an under-standing of the variouslevels of cohesion isinstructive, it is moreimportant to be awareof the general conceptas you designcomponents. Keepcohesion as high as ispossible.pre75977_ch10.qxd  11/27/08  3:46 PM  Page 287288 PART TWOMODELING
Cohesion in Action
The scene:Jamie’s cubicle.The players:Jamie and Ed—members of theSafeHomesoftware engineering team who are workingon the surveillance function.The conversation:Ed:I have a first-cut design of the cameracomponent.Jamie:Wanna do a quick review?Ed:I guess . . . but really, I’d like your input onsomething.(Jamie gestures for him to continue.)Ed:We originally defined five operations for camera. Look . . .determineType()tells me the type of camera.translateLocation()allows me to move the cameraaround the floor plan.displayID()gets the camera ID and displays it near thecamera icon.displayView()shows me the field of view of the cameragraphically.displayZoom()shows me the magnification of the cam-era graphically.Ed:I’ve designed each separately, and they’re prettysimple operations. So I thought it might be a good idea tocombine all of the display operations into just one that’scalled displayCamera()—it’ll show the ID, the view, andthe zoom. Whaddaya think?Jamie (grimacing):Not sure that’s such a good idea.Ed (frowning):Why, all of these little ops can causeheadaches.Jamie:The problem with combining them is we losecohesion, you know, the displayCamera()op won’t be single-minded.Ed (mildly exasperated):So what? The whole thingwill be less than 100 source lines, max. It’ll be easier toimplement, I think.Jamie:And what if marketing decides to change theway that we represent the view field?Ed:I just jump into the displayCamera()op and make themod.Jamie:What about side effects?Ed:Whaddaya mean?Jamie:Well, say you make the change butinadvertently create a problem with the ID display.Ed:I wouldn’t be that sloppy.Jamie:Maybe not, but what if some support person two years from now has to make the mod. He might notunderstand the op as well as you do, and, who knows, hemight be sloppy.Ed:So you’re against it?Jamie:You’re the designer . . . it’s your decision . . . justbe sure you understand the consequences of lowcohesion.Ed (thinking a moment):Maybe we’ll go withseparate display ops.Jamie:Good decision.SAFEHOME
10.2.4 Coupling
In earlier discussions of analysis and design, I noted that communication andcollaboration are essential elements of any object-oriented system. There is, however,a darker side to this important (and necessary) characteristic. As the amount of com-munication and collaboration increases (i.e., as the degree of “connectedness” betweenclasses increases), the complexity of the system also increases. And as complexityincreases, the difficulty of implementing, testing, and maintaining software grows.Couplingis a qualitative measure of the degree to which classes are connected toone another. As classes (and components) become more interdependent, couplingincreases. An important objective in component-level design is to keep coupling aslow as is possible.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 288Class coupling can manifest itself in a variety of ways. Lethbridge and Laganiére[Let01] define the following coupling categories:Content coupling.Occurs when one component “surreptitiously modifiesdata that is internal to another component” [Let01]. This violates informationhiding—a basic design concept.Common coupling.Occurs when a number of components all make use ofa global variable. Although this is sometimes necessary (e.g., for establishingdefault values that are applicable throughout an application), common cou-pling can lead to uncontrolled error propagation and unforeseen side effectswhen changes are made.Control coupling.Occurs when operation A()invokes operation B()and passes a control flag to B.The control flag then “directs” logical flow withinB.The problem with this form of coupling is that an unrelated change in B can result in the necessity to change the meaning of the control flag that A passes. If this is overlooked, an error will result.Stamp coupling.Occurs when ClassBis declared as a type for an argu- ment of an operation of ClassA. Because ClassB is now a part of the defini- tion of ClassA, modifying the system becomes more complex.Data coupling.Occurs when operations pass long strings of data argu-ments. The “bandwidth” of communication between classes and componentsgrows and the complexity of the interface increases. Testing and mainte-nance are more difficult.Routine call coupling.Occurs when one operation invokes another. Thislevel of coupling is common and is often quite necessary. However, it doesincrease the connectedness of a system.Type use coupling.Occurs when component Auses a data type defined in component B(e.g., this occurs whenever “a class declares an instance vari-able or a local variable as having another class for its type” [Let01]). If the typedefinition changes, every component that uses the definition must alsochange.Inclusion or import coupling.Occurs when component Aimports or in- cludes a package or the content of component B.External coupling.Occurs when a component communicates or collabo-rates with infrastructure components (e.g., operating system functions,database capability, telecommunication functions). Although this type of cou-pling is necessary, it should be limited to a small number of components orclasses within a system.Software must communicate internally and externally. Therefore, coupling is a factof life. However, the designer should work to reduce coupling whenever possible andunderstand the ramifications of high coupling when it cannot be avoided.CHAPTER 10COMPONENT-LEVEL DESIGN 289
As the design for eachsoftware component iselaborated, the focusshifts to the design ofspecific data structuresand procedural designto manipulate the datastructures. However,don’t forget thearchitecture that musthouse the componentsor the global datastructures thatmay serve manycomponents.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 289290 PART TWOMODELING
If you’re working in anon-OO environment,the first three stepsfocus on refinement ofdata objects andprocessing functions(transforms) identifiedas part of the require-ments model.Coupling in Action
The scene:Shakira’s cubicle.The players:Vinod and Shakira—members of theSafeHomesoftware team who are working on the securityfunction.The conversation:Shakira:I had what I thought was a great idea . . .then I thought about it a little, and it seemed like a not sogreat idea. I finally rejected it, but I just thought I’d run itby you.Vinod:Sure. What’s the idea?Shakira:Well, each of the sensors recognizes an alarmcondition of some kind, right?Vinod (smiling):That’s why we call them sensors,Shakira.Shakira (exasperated):Sarcasm, Vinod, you’ve gotto work on your interpersonal skills.Vinod:You were saying?Shakira:Okay, anyway, I figured . . . why not create anoperation within each sensor object called makeCall()thatwould collaborate directly with the OutgoingCallcomponent, well, with an interface to the OutgoingCall component.Vinod (pensive):You mean rather than havingthat collaboration occur out of a component likeControlPanelor something?Shakira:Yeah . . . but then I said to myself, thatmeans that every sensor object will be connected to theOutgoingCallcomponent, and that means that itsindirectly coupled to the outside world and . . . well, I justthought it made things complicated.Vinod:I agree. In this case, it’s a better idea to let thesensor interface pass info to the ControlPaneland let it initiate the outgoing call. Besides, different sensorsmight result in different phone numbers. You don’twant the senor to store that information because if itchanges . . .Shakira:It just didn’t feel right.Vinod:Design heuristics for coupling tell us it’s not right.Shakira:Whatever . . .SAFEHOME
10.3 C ONDUCTING COMPONENT -LEVEL DESIGN
Earlier in this chapter I noted that component-level design is elaborative in nature.You must transform information from requirements and architectural models intoa design representation that provides sufficient detail to guide the construction(coding and testing) activity. The following steps represent a typical task set forcomponent-level design, when it is applied for an object-oriented system.Step 1. Identify all design classes that correspond to the problem domain.Using the requirements and architectural model, each analysis class and architec-tural component is elaborated as described in Section 10.1.1.Step 2. Identify all design classes that correspond to the infrastructuredomain.These classes are not described in the requirements model and are oftenmissing from the architecture model, but they must be described at this point. As wehave noted earlier, classes and components in this category include GUI components(often available as reusable components), operating system components, and objectand data management components.Step 3. Elaborate all design classes that are not acquired as reusablecomponents.Elaboration requires that all interfaces, attributes, and operationsuote:
“If I had moretime, I would havewritten a shorterletter.”Blaise Pascalpre75977_ch10.qxd  11/27/08  3:47 PM  Page 290necessary to implement the class be described in detail. Design heuristics (e.g., com-ponent cohesion and coupling) must be considered as this task is conducted.Step 3a. Specify message details when classes or components collaborate.The requirements model makes use of a collaboration diagram to show how analy-sis classes collaborate with one another. As component-level design proceeds, it issometimes useful to show the details of these collaborations by specifying the struc-ture of messages that are passed between objects within a system. Although this de-sign activity is optional, it can be used as a precursor to the specification of interfacesthat show how components within the system communicate and collaborate.Figure 10.6 illustrates a simple collaboration diagram for the printing system dis-cussed earlier. Three objects, ProductionJob, WorkOrder, and JobQueue,collab- orate to prepare a print job for submission to the production stream. Messages arepassed between objects as illustrated by the arrows in the figure. During require-ments modeling the messages are specified as shown in the figure. However, as de-sign proceeds, each message is elaborated by expanding its syntax in the followingmanner [Ben02]:
[guard condition] sequence expression (return value) : /H11005 message name (argument list)
where a [guard condition]is written in Object Constraint Language (OCL)5and speci- fies any set of conditions that must be met before the message can be sent; sequenceexpressionis an integer value (or other ordering indicator, e.g., 3.1.2) that indicatesthe sequential order in which a message is sent; (return value) is the name of the information that is returned by the operation invoked by the message; message nameidentifies the operation that is to be invoked, and (argument list) is the list of attributes that are passed to the operation.CHAPTER 10COMPONENT-LEVEL DESIGN 291
:ProductionJob
:WorkOrder:JobQueue
1: buildJob(WOnumber)2: submitJob(WOnumber)FIGURE 10.6
Collaborationdiagram withmessaging
5 OCL is discussed briefly in Appendix 1.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 291292 PART TWOMODELING
PrintJobcomputeJobinitiateJob
ProductionJobbuildJobsubmitJobWorkOrder
appropriate attributes
buildWorkOrder ( )getJobDescription
JobQueue
appropriate attributes
checkPriority ( )<<interface>> initiateJob
passJobToProduction( )FIGURE 10.7 Refactoring interfaces and class definitions for PrintJobStep 3b. Identify appropriate interfaces for each component. Within the context of component-level design, a UML interface is “a group of externally visible(i.e., public) operations. The interface contains no internal structure, it has no attrib-utes, no associations . . .” [Ben02]. Stated more formally, an interface is the equiva-lent of an abstract class that provides a controlled connection between designclasses. The elaboration of interfaces is illustrated in Figure 10.1. In essence, opera-tions defined for the design class are categorized into one or more abstract classes.Every operation within the abstract class (the interface) should be cohesive; that is,it should exhibit processing that focuses on one limited function or subfunction.Referring to Figure 10.1, it can be argued that the interface initiateJob does not exhibit sufficient cohesion. In actuality, it performs three different subfunctions—building a work order, checking job priority, and passing a job to production. Theinterface design should be refactored. One approach might be to reexamine the de-sign classes and define a new class WorkOrder that would take care of all activities associated with the assembly of a work order. The operation buildWorkOrder() be- comes a part of that class. Similarly, we might define a class JobQueuethat would incorporate the operation checkPriority(). A class ProductionJob would encompass all information associated with a production job to be passed to the productionfacility. The interface initiateJobwould then take the form shown in Figure 10.7.The interface initiateJobis now cohesive, focusing on one function. The interfacesassociated with ProductionJob, WorkOrder, and JobQueueare similarly single-minded.Step 3c. Elaborate attributes and define data types and data structuresrequired to implement them.In general, data structures and types used to defineattributes are defined within the context of the programming language that is to bepre75977_ch10.qxd  11/27/08  3:47 PM  Page 292used for implementation. UML defines an attribute’s data type using the followingsyntax:
name : type-expression /H11005initial-value {property string}
where nameis the attribute name, type expressionis the data type, initial valueis the value that the attribute takes when an object is created, and property-string defines a prop- erty or characteristic of the attribute.During the first component-level design iteration, attributes are normally de-scribed by name. Referring once again to Figure 10.1, the attribute list for PrintJoblists only the names of the attributes. However, as design elaboration proceeds, eachattribute is defined using the UML attribute format noted. For example, paperType- weightis defined in the following manner:
paperType-weight: string /H11005“A” { contains 1 of 4 values - A, B, C, or D}
which defines paperType-weightas a string variable initialized to the value A that cantake on one of four values from the set {A,B,C, D}.If an attribute appears repeatedly across a number of design classes, and it has arelatively complex structure, it is best to create a separate class to accommodate theattribute.Step 3d. Describe processing flow within each operation in detail. This may be accomplished using a programming language-based pseudocode or with a UMLactivity diagram. Each software component is elaborated through a number of iter-ations that apply the stepwise refinement concept (Chapter 8).The first iteration defines each operation as part of the design class. In every case,the operation should be characterized in a way that ensures high cohesion; that is,the operation should perform a single targeted function or subfunction. The nextiteration does little more than expand the operation name. For example, the operationcomputePaperCost()noted in Figure 10.1 can be expanded in the following manner:
computePaperCost (weight, size, color): numeric
This indicates that computePaperCost() requires the attributes weight, size,and coloras input and returns a value that is numeric (actually a dollar value) as output.If the algorithm required to implement computePaperCost()is simple and widely understood, no further design elaboration may be necessary. The softwareengineer who does the coding will provide the detail necessary to implement theoperation. However, if the algorithm is more complex or arcane, further designelaboration is required at this stage. Figure 10.8 depicts a UML activity diagram forcomputePaperCost().When activity diagrams are used for component-level designspecification, they are generally represented at a level of abstraction that is some-what higher than source code. An alternative approach—the use of pseudocode fordesign specification—is discussed in Section 10.5.3.CHAPTER 10COMPONENT-LEVEL DESIGN 293
Use stepwiseelaboration as yourefine the componentdesign. Always ask, “Is there a way thiscan be simplified andyet still accomplish thesame result?”pre75977_ch10.qxd  11/27/08  3:47 PM  Page 293294 PART TWOMODELING
Step 4. Describe persistent data sources (databases and files) and identifythe classes required to manage them. Databases and files normally transcend the design description of an individual component. In most cases, these persistentdata stores are initially specified as part of architectural design. However, as designelaboration proceeds, it is often useful to provide additional detail about the struc-ture and organization of these persistent data sources.Step 5. Develop and elaborate behavioral representations for a class orcomponent.UML state diagrams were used as part of the requirements model torepresent the externally observable behavior of the system and the more localizedbehavior of individual analysis classes. During component-level design, it is some-times necessary to model the behavior of a design class.The dynamic behavior of an object (an instantiation of a design class as theprogram executes) is affected by events that are external to it and the current stateValidate attributesinputaccessPaperDB(weight)returns baseCostperPage
Size = BpaperCostperPage =paperCostperPage*1.2
Size = CpaperCostperPage = paperCostperPage*1.4
Size = DpaperCostperPage = paperCostperPage*1.6
Color is custompaperCostperPage =   paperCostperPage*1.14Color is standardpaperCostperPage =    baseCostperPage
Returns (paperCostperPage)FIGURE 10.8
UML activitydiagram forcompute-PaperCost()pre75977_ch10.qxd  11/27/08  3:47 PM  Page 294(mode of behavior) of the object. To understand the dynamic behavior of an object,you should examine all use cases that are relevant to the design class throughout itslife. These use cases provide information that helps you to delineate the events thataffect the object and the states in which the object resides as time passes and eventsoccur. The transitions between states (driven by events) are represented using a UMLstatechart [Ben02] as illustrated in Figure 10.9.The transition from one state (represented by a rectangle with rounded corners)to another occurs as a consequence of an event that takes the form:
Event-name (parameter-list) [guard-condition] / action expression
where event-nameidentifies the event, parameter-listincorporates data that are associated with the event, guard-condition is written in Object Constraint Language (OCL) and specifies a condition that must be met before the event can occur, andaction expressiondefines an action that occurs as the transition takes place.Referring to Figure 10.9, each state may define entry/and exit/actions that occur as transition into the state occurs and as transition out of the state occurs, respectively. Inmost cases, these actions correspond to operations that are relevant to the class that isbeing modeled. The do/indicator provides a mechanism for indicating activities thatCHAPTER 10COMPONENT-LEVEL DESIGN 295
buildingJobDataentry/readJobData( )exit/displayJobData( ) do/checkConsistency( ) include/dataInput
entry/computeJob exit/save totalJobCost  
formingJobentry/buildJob exit/save WOnumber do/ computingJobCost
submittingJobentry/submitJob exit/initiateJob do/place on JobQueue Behavior within the state buildingJobData
dataInputCompleted [all data items consistent]/displayUserOptions dataInputIncomplete  
deliveryDateAccepted [customer is authorized]/ printJobEstimate jobCostAccepted [customer is authorized]/ getElectronicSignature 
jobSubmitted [all authorizations acquired]/printWorkOrder FIGURE 10.9
Statechartfragment forPrintJob classpre75977_ch10.qxd  11/27/08  3:47 PM  Page 295296 PART TWOMODELING
occur while in the state, and the include/ indicator provides a means for elaborating the behavior by embedding more statechart detail within the definition of a state.It is important to note that the behavioral model often contains information thatis not immediately obvious in other design models. For example, careful examina-tion of the statechart in Figure 10.9 indicates that the dynamic behavior of thePrintJobclass is contingent upon two customer approvals as costs and scheduledata for the print job are derived. Without approvals (the guard condition ensuresthat the customer is authorized to approve) the print job cannot be submittedbecause there is no way to reach the submittingJob state. Step 6. Elaborate deployment diagrams to provide additional implementa-tion detail.Deployment diagrams (Chapter 8) are used as part of architecturaldesign and are represented in descriptor form. In this form, major system functions(often represented as subsystems) are represented within the context of the com-puting environment that will house them.During component-level design, deployment diagrams can be elaborated to rep-resent the location of key packages of components. However, components generallyare not represented individually within a component diagram. The reason for this isto avoid diagrammatic complexity. In some cases, deployment diagrams are elabo-rated into instance form at this time. This means that the specific hardware andoperating system environment(s) that will be used is (are) specified and the locationof component packages within this environment is indicated.Step 7. Refactor every component-level design representation and alwaysconsider alternatives.Throughout this book, I have emphasized that designis an iterative process. The first component-level model you create will not be ascomplete, consistent, or accurate as the nth iteration you apply to the model. It isessential to refactor as design work is conducted.In addition, you should not suffer from tunnel vision. There are always alterna-tive design solutions, and the best designers consider all (or most) of them beforesettling on the final design model. Develop alternatives and consider each care-fully, using the design principles and concepts presented in Chapter 8 and in thischapter.
10.4 C OMPONENT -LEVEL DESIGN FOR WEBAPPS
The boundary between content and function is often blurred when Web-basedsystems and applications (WebApps) are considered. Therefore, it is reasonable toask: What is a WebApp component?In the context of this chapter, a WebApp component is (1) a well-defined cohesivefunction that manipulates content or provides computational or data processing foran end user or (2) a cohesive package of content and functionality that provides thepre75977_ch10.qxd  11/27/08  3:47 PM  Page 296end user with some required capability. Therefore, component-level design forWebApps often incorporates elements of content design and functional design.
10.4.1 Content Design at the Component Level
Content design at the component level focuses on content objects and the manner in which they may be packaged for presentation to a WebApp end user.As an example, consider a Web-based video surveillance capability withinSafeHomeAssured.com. Among many capabilities, the user can select and controlany of the cameras represented as part of a floor plan, require video-capture thumb-nail images from all the cameras, and display streaming video from any one camera.In addition, the user can control pan and zoom for a camera using appropriatecontrol icons.A number of potential content components can be defined for the video surveil-lance capability: (1) the content objects that represent the space layout (the floorplan) with additional icons representing the location of sensors and video cameras,(2) the collection of thumbnail video captures (each a separate data object), and(3) the streaming video window for a specific camera. Each of these components canbe separately named and manipulated as a package.Consider a floor plan that depicts four cameras placed strategically throughout ahouse. Upon user request, a video frame is captured from each camera and is iden-tified as a dynamically generated content object, VideoCaptureN, where Nidenti- fies cameras 1 to 4. A content component, named Thumbnail-Images, combines all four VideoCaptureNcontent objects and displays them on the video surveillancepage.The formality of content design at the component level should be tuned to thecharacteristics of the WebApp to be built. In many cases, content objects need notbe organized as components and can be manipulated individually. However, as thesize and complexity (of the WebApp, content objects, and their interrelationships)grows, it may be necessary to organize content in a way that allows easier referenceand design manipulation.
6In addition, if content is highly dynamic (e.g., the contentfor an online auction site), it becomes important to establish a clear structural modelthat incorporates content components.
10.4.2 Functional Design at the Component Level
Modern Web applications deliver increasingly sophisticated processing functionsthat (1) perform localized processing to generate content and navigation capabilityin a dynamic fashion, (2) provide computation or data processing capability that isappropriate for the WebApp’s business domain, (3) provide sophisticated databasequery and access, or (4) establish data interfaces with external corporate systems. ToCHAPTER 10COMPONENT-LEVEL DESIGN 297
6 Content components can also be reused in other WebApps.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 297298 PART TWOMODELING
achieve these (and many other) capabilities, you will design and construct WebAppfunctional components that are similar in form to software components forconventional software.WebApp functionality is delivered as a series of components developed in paral-lel with the information architecture to ensure that they are consistent. In essenceyou begin by considering both the requirements model and the initial informationarchitecture and then examining how functionality affects the user’s interaction withthe application, the information that is presented, and the user tasks that areconducted.During architectural design, WebApp content and functionality are combined tocreate a functional architecture. A functional architecture is a representation of the functional domain of the WebApp and describes the key functional components inthe WebApp and how these components interact with each other.For example, the pan and zoom functions for the SafeHomeAssured.comvideo surveillance capability are implemented as part of a CameraControlcomponent. Alternatively, pan and zoom can be implemented as the operations, pan()andzoom(), which are part of aCameraclass. In either case, the functionality implied by pan andzoom must be implemented as modules within SafeHomeAssured.com.
10.5 D ESIGNING TRADITIONAL COMPONENTS
The foundations of component-level design for traditional software components7
were formed in the early 1960s and were solidified with the work of Edsger Dijkstraand his colleagues ([Boh66], [Dij65], [Dij76b]). In the late 1960s, Dijkstra and othersproposed the use of a set of constrained logical constructs from which any programcould be formed. The constructs emphasized “maintenance of functional domain.”That is, each construct had a predictable logical structure and was entered at thetop and exited at the bottom, enabling a reader to follow procedural flow moreeasily.The constructs are sequence, condition, and repetition. Sequence implements processing steps that are essential in the specification of any algorithm. Conditionprovides the facility for selected processing based on some logical occurrence, andrepetitionallows for looping. These three constructs are fundamental to structuredprogramming—an important component-level design technique.The structured constructs were proposed to limit the procedural design ofsoftware to a small number of predictable logical structures. Complexity metrics(Chapter 23) indicate that the use of the structured constructs reduces program com-plexity and thereby enhances readability, testability, and maintainability. The use of
7 A traditional software component implements an element of processing that addresses a functionor subfunction in the problem domain or some capability in the infrastructure domain. Often calledmodules, procedures, or subroutines, traditional components do not encapsulate data in the sameway that object-oriented components do.Structuredprogramming is adesign technique thatconstrains logic flowto three constructs:sequence, condition,and repetition.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 298a limited number of logical constructs also contributes to a human understandingprocess that psychologists call chunking. To understand this process, consider the way in which you are reading this page. You do not read individual letters but ratherrecognize patterns or chunks of letters that form words or phrases. The structuredconstructs are logical chunks that allow a reader to recognize procedural elementsof a module, rather than reading the design or code line by line. Understanding isenhanced when readily recognizable logical patterns are encountered.Any program, regardless of application area or technical complexity, can bedesigned and implemented using only the three structured constructs. It should benoted, however, that dogmatic use of only these constructs can sometimes causepractical difficulties. Section 10.5.1 considers this issue in further detail.
10.5.1 Graphical Design Notation
”A picture is worth a thousand words,” but it’s rather important to know whichpicture and which 1000 words. There is no question that graphical tools, such as theUML activity diagram or the flowchart, provide useful pictorial patterns that readilydepict procedural detail. However, if graphical tools are misused, the wrong picturemay lead to the wrong software.The activity diagram allows you to represent sequence, condition, and repetition—all elements of structured programming—and is a descendent of an earlier picto-rial design representation (still used widely) called a flowchart.A flowchart, like an activity diagram, is quite simple pictorially. A box is used to indicate a process-ing step. A diamond represents a logical condition, and arrows show the flowof control. Figure 10.10 illustrates three structured constructs. The sequenceisCHAPTER 10COMPONENT-LEVEL DESIGN 299
Firsttask
Nexttask
Sequence
SelectionConditionTF
If-then-else
RepetitionElse-part Then-par t
CaseconditionCase  partT
TTFT
TFF FF
Do   whileRepeat  untilFIGURE 10.10
Flowchartconstructspre75977_ch10.qxd  11/27/08  3:47 PM  Page 299300 PART TWOMODELING
How do Ibuild adecision table??represented as two processing boxes connected by a line (arrow) of control.Condition,also calledif-then-else,is depicted as a decision diamond that, if true,causesthen-partprocessing to occur, and if false, invokes else-partprocessing. Repetitionis represented using two slightly different forms. The do whiletests a con- dition and executes a loop task repetitively as long as the condition holds true. Arepeat untilexecutes the loop task first and then tests a condition and repeats thetask until the condition fails. Theselection(orselect-case) construct shown in the fig- ure is actually an extension of theif-then-else.A parameter is tested by successive decisions until a true condition occurs and a case partprocessing path is executed. In general, the dogmatic use of only the structured constructs can introduce inef-ficiency when an escape from a set of nested loops or nested conditions is required.More important, additional complication of all logical tests along the path of escapecan cloud software control flow, increase the possibility of error, and have a nega-tive impact on readability and maintainability. What can you do?You’re left with two options: (1) The procedural representation is redesigned sothat the “escape branch” is not required at a nested location in the flow of control or(2) the structured constructs are violated in a controlled manner; that is, a con-strained branch out of the nested flow is designed. Option 1 is obviously the idealapproach, but option 2 can be accommodated without violating the spirit of struc-tured programming.
10.5.2 Tabular Design Notation
In many software applications, a module may be required to evaluate a complexcombination of conditions and select appropriate actions based on these conditions.Decision tables[Hur83] provide a notation that translates actions and conditions(described in a processing narrative or a use case) into a tabular form. The table isdifficult to misinterpret and may even be used as a machine-readable input to atable-driven algorithm.Decision table organization is illustrated in Figure 10.11. Referring to the figure,the table is divided into four sections. The upper left-hand quadrant contains a listof all conditions. The lower left-hand quadrant contains a list of all actions that arepossible based on combinations of conditions. The right-hand quadrants form amatrix that indicates condition combinations and the corresponding actions thatwill occur for a specific combination. Therefore, each column of the matrix may beinterpreted as a processing rule.The following steps are applied to develop a deci-sion table:1.List all actions that can be associated with a specific procedure (or component).2.List all conditions (or decisions made) during execution of the procedure.3.Associate specific sets of conditions with specific actions, eliminating impos-sible combinations of conditions; alternatively, develop every possible per-mutation of conditions.4.Define rules by indicating what actions occur for a set of conditions.Use a decision tablewhen a complex set ofconditions and actionsare encountered withina component.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 300To illustrate the use of a decision table, consider the following excerpt from aninformal use case that has just been proposed for the print shop system:
Three types of customers are defined: a regular customer, a silver customer, and a goldcustomer (these types are assigned by the amount of business the customer does with theprint shop over a 12 month period). A regular customer receives normal print rates anddelivery. A silver customer gets an 8 percent discount on all quotes and is placed aheadof all regular customers in the job queue. A gold customer gets a 15 percent reduction inquoted prices and is placed ahead of both regular and silver customers in the job queue.A special discount of xpercent in addition to other discounts can be applied to anycustomer’s quote at the discretion of management.
Figure 10.11 illustrates a decision table representation of the preceding informal usecase. Each of the six rules indicates one of six viable conditions. As a general rule, thedecision table can be used effectively to supplement other procedural design notation.
10.5.3 Program Design Language
Program design language(PDL), also called structured Englishor pseudocode,incorpo- rates the logical structure of a programming language with the free-form expressiveability of a natural language (e.g., English). Narrative text (e.g., English) is embeddedwithin a programming language-like syntax. Automated tools (e.g., [Cai03]) can beused to enhance the application of PDL.A basic PDL syntax should include constructs for component definition, interfacedescription, data declaration, block structuring, condition constructs, repetition con-structs, and input-output (I/O) constructs. It should be noted that PDL can beextended to include keywords for multitasking and/or concurrent processing, inter-rupt handling, interprocess synchronization, and many other features. The applica-tion design for which PDL is to be used should dictate the final form for the designlanguage. The format and semantics for some of these PDL constructs are presentedin the example that follows.CHAPTER 10COMPONENT-LEVEL DESIGN 301
Conditions
Regular customer Silver customer  Gold customer Special discount
ActionsNo discount Apply 8 percent discount  Apply 15 percent discount  Apply additional x percentdiscountTFTTTTTF135 64
FTTT2RulesFIGURE 10.11
Decision tablenomenclaturepre75977_ch10.qxd  11/27/08  3:47 PM  Page 301302 PART TWOMODELING
To illustrate the use of PDL, consider a procedural design for the SafeHome secu- rity function discussed in earlier chapters. The system monitors alarms for fire,smoke, burglar, water, and temperature (e.g., the heating system fails while thehomeowner is away during winter) and produces an alarm bell and calls a monitor-ing service, generating a voice-synthesized message.Recall that PDL is nota programming language. You can adapt as required with-out worry about syntax errors. However, the design for the monitoring softwarewould have to be reviewed (do you see any problems?) and further refined beforecode could be written. The following PDL
8provides an elaboration of the procedural design for an early version of an alarm management component.
component alarmManagement;The intent of this component is to manage control panel switches and input from sensors bytype and to act on any alarm condition that is encountered.set default values for systemStatus (returned value), all data itemsinitialize all system ports and reset all hardwarecheck controlPanelSwitches (cps)if cps = “test” then invoke alarm set to “on”if cps = “alarmOff” then invoke alarm set to “off”if cps = “newBoundingValue” then invoke keyboardInputif cps = “burglarAlarmOff” invoke deactivateAlarm;•••default for cps = nonereset all signalValues and switchesdo for all sensorsinvoke checkSensor procedure returning signalValueif signalValue > bound [alarmType]then phoneMessage = message [alarmType]set alarmBell to “on” for alarmTimeSecondsset system status = “alarmCondition”parbegininvoke alarm procedure with “on”, alarmTimeSeconds;invoke phone procedure set to alarmType, phoneNumberendparelse skipendifenddoforend alarmManagement
8 The level of detail represented by the PDL is defined locally. Some people prefer a more naturallanguage-oriented description, while others prefer something that is close to code.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 302Note that the designer for the alarmManagement component has used the con- struct parbegin … parendthat specifies a parallel block. All tasks specified within theparbeginblock are executed in parallel. In this case, implementation details are notconsidered.
10.6 C OMPONENT -BASED DEVELOPMENT
In the software engineering context, reuse is an idea both old and new. Programmershave reused ideas, abstractions, and processes since the earliest days of computing,but the early approach to reuse was ad hoc. Today, complex, high-quality computer-based systems must be built in very short time periods and demand a more organ-ized approach to reuse.Component-based software engineering (CBSE) is a process that emphasizes the design and construction of computer-based systems using reusable software“components.” Clements [Cle95] describes CBSE in the following way:
[CBSE] embodies the “buy, don’t build” philosophy espoused by Fred Brooks and others.In the same way that early subroutines liberated the programmer from thinking aboutdetails, [CBSE] shifts the emphasis from programming software to composing softwaresystems. Implementation has given way to integration as the focus.
But a number of questions arise. Is it possible to construct complex systems byassembling them from a catalog of reusable software components? Can this beaccomplished in a cost- and time-effective manner? Can appropriate incentives beestablished to encourage software engineers to reuse rather than reinvent? Ismanagement willing to incur the added expense associated with creating reusablesoftware components? Can the library of components necessary to accomplish reusebe created in a way that makes it accessible to those who need it? Can componentsthat do exist be found by those who need them?Increasingly, the answer to each of these questions is “yes.” In the rest of thissection, I examine some of the issues that must be considered to make CBSEsuccessful within a software engineering organization.
10.6.1 Domain Engineering
The intent of domain engineeringis to identify, construct, catalog, and disseminate aset of software components that have applicability to existing and future software ina particular application domain.
9The overall goal is to establish mechanisms thatenable software engineers to share these components—to reuse them—during workon new and existing systems. Domain engineering includes three major activities—analysis, construction, and dissemination.CHAPTER 10COMPONENT-LEVEL DESIGN 303
uote:
“Domainengineering isabout findingcommonalitiesamong systems toidentifycomponents thatcan be applied tomany systems . . .”Paul Clements
9 In Chapter 9 we referred to architectural genres that identify specific application domains.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 303304 PART TWOMODELING
The overall approach to domain analysis is often characterized within the context of object-oriented software engineering. The steps in the process are defined as:1.Define the domain to be investigated.2.Categorize the items extracted from the domain.3.Collect a representative sample of applications in the domain.4.Analyze each application in the sample and define analysis classes.5.Develop a requirements model for the classes.It is important to note that domain analysis is applicable to any software engineer-ing paradigm and may be applied for conventional as well as object-orienteddevelopment.
10.6.2 Component Qualification, Adaptation, and Composition
Domain engineering provides the library of reusable components that are requiredfor component-based software engineering. Some of these reusable components aredeveloped in-house, others can be extracted from existing applications, and stillothers may be acquired from third parties.Unfortunately, the existence of reusable components does not guarantee thatthese components can be integrated easily or effectively into the architecture chosenfor a new application. It is for this reason that a sequence of component-baseddevelopment actions is applied when a component is proposed for use.Component Qualification.Component qualification ensures that a candidatecomponent will perform the function required, will properly “fit” into the architecturalstyle (Chapter 9) specified for the system, and will exhibit the quality characteristics(e.g., performance, reliability, usability) that are required for the application.An interface description provides useful information about the operation and use ofa software component, but it does not provide all of the information required to deter-mine if a proposed component can, in fact, be reused effectively in a new application.Among the many factors considered during component qualification are [Bro96]:
•Application programming interface (API).
•Development and integration tools required by the component.
•Run-time requirements, including resource usage (e.g., memory or storage),timing or speed, and network protocol.
•Service requirements, including operating system interfaces and supportfrom other components.
•Security features, including access controls and authentication protocol.
•Embedded design assumptions, including the use of specific numerical ornonnumerical algorithms.
•Exception handling.The analysis processwe discuss in thissection focuses onreusable components.However, the analysisof complete COTSsystems (e.g., e-commerce Apps,sales force automationApps) can also be apart of domainanalysis.
What factors areconsidered duringcomponentqualification??pre75977_ch10.qxd  11/27/08  3:47 PM  Page 304Each of these factors is relatively easy to assess when reusable components thathave been developed in-house are proposed. If good software engineering practiceswere applied during the development of a component, answers to the questionsimplied by the list can be developed. However, it is much more difficult to determinethe internal workings of commercial off-the-shelf (COTS) or third-party componentsbecause the only available information may be the interface specification itself.Component Adaptation.In an ideal setting, domain engineering creates a libraryof components that can be easily integrated into an application architecture. Theimplication of “easy integration” is that (1) consistent methods of resource manage-ment have been implemented for all components in the library, (2) common activi-ties such as data management exist for all components, and (3) interfaces within thearchitecture and with the external environment have been implemented in a consis-tent manner.In reality, even after a component has been qualified for use within an applicationarchitecture, conflicts may occur in one or more of the areas just noted. To avoidthese conflicts, an adaptation technique called component wrapping [Bro96] is some- times used. When a software team has full access to the internal design and code fora component (often not the case unless open-source COTS components are used),white-box wrappingis applied. Like its counterpart in software testing (Chapter 18),white-box wrapping examines the internal processing details of the component andmakes code-level modifications to remove any conflict. Gray-box wrappingis applied when the component library provides a component extension language or API thatenables conflicts to be removed or masked. Black-box wrapping requires the intro- duction of pre- and postprocessing at the component interface to remove or maskconflicts. You must determine whether the effort required to adequately wrap a com-ponent is justified or whether a custom component (designed to eliminate theconflicts encountered) should be engineered instead.Component Composition.The component composition task assembles quali-fied, adapted, and engineered components to populate the architecture establishedfor an application. To accomplish this, an infrastructure must be established to bindthe components into an operational system. The infrastructure (usually a library ofspecialized components) provides a model for the coordination of components andspecific services that enable components to coordinate with one another andperform common tasks.Because the potential impact of reuse and CBSE on the software industry isenormous, a number of major companies and industry consortia have proposedstandards for component software.
10CHAPTER 10COMPONENT-LEVEL DESIGN 305
In addition to assessingwhether the cost ofadaptation for reuse isjustified, you shouldalso assess whetherachieving requiredfunctionality andperformance can bedone cost effectively.
10 Greg Olsen [Ols06] provides an excellent discussion of past and present industry efforts to makeCBSE a reality.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 305306 PART TWOMODELING
OMG/CORBA.The Object Management Group has published a commonobject request broker architecture(OMG/CORBA). An object request broker(ORB) provides a variety of services that enable reusable components(objects) to communicate with other components, regardless of their locationwithin a system.Microsoft COM and .NET.Microsoft has developed a component objectmodel(COM) that provides a specification for using components produced byvarious vendors within a single application running under the Windows op-erating system. From the point of view of the application, “the focus is not onhow [COM objects are] implemented, only on the fact that the object has aninterface that it registers with the system, and that it uses the componentsystem to communicate with other COM objects” [Har98a]. The Microsoft.NET framework encompasses COM and provides a reusable class library thatcovers a wide array of application domains.Sun JavaBeans Components.The JavaBeans component system is aportable, platform-independent CBSE infrastructure developed using the Javaprogramming language. The JavaBeans component system encompasses aset of tools, called the Bean Development Kit (BDK), that allows developers to (1) analyze how existing Beans (components) work, (2) customize theirbehavior and appearance, (3) establish mechanisms for coordination andcommunication, (4) develop custom Beans for use in a specific application,and (5) test and evaluate Bean behavior.None of these standards dominate the industry. Although many developershave standardized on one, it is likely that large software organizations maychoose to use a standard based on the application categories and platforms thatare chosen.
10.6.3 Analysis and Design for Reuse
Although the CBSE process encourages the use of existing software components,there are times when new software components must be developed and integratedwith existing COTS and in-house components. Because these new componentsbecome members of the in-house library of reusable components, they should beengineered for reuse.Design concepts such as abstraction, hiding, functional independence, refine-ment, and structured programming, along with object-oriented methods, testing,software quality assurance (SQA), and correctness verification methods (Chapter 21),all contribute to the creation of software components that are reusable. In this sub-section, I consider the reuse-specific issues that are complementary to solid softwareengineering practices.The requirements model is analyzed to determine those elements that point toexisting reusable components. Elements of the requirements model are compared toWebRef
The latest informationon JavaBeans can be obtained atjava.sun.com/products/javabeans/docs/.WebRef
The latest informationon COM and .NET canbe obtained at www.microsoft.com/COMandmsdn2.microsoft.com/en-us/netframeworkdefault.aspx.WebRef
The latest informationon CORBA can beobtained atwww.omg.org.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 306descriptions of reusable components in a process that is sometimes referred to as“specification matching” [Bel95]. If specification matching points to an existing com-ponent that fits the needs of the current application, you can extract the componentfrom a reuse library (repository) and use it in the design of a new system. If compo-nents cannot be found (i.e., there is no match), a new component is created. It is atthis point—when you begin to create a new component—that design for reuse (DFR) should be considered.As we have already noted, DFR requires that you apply solid software design con-cepts and principles (Chapter 8). But the characteristics of the application domainmust also be considered. Binder [Bin93] suggests a number of key issues
11that form a basis for design for reuse:Standard data.The application domain should be investigated and standardglobal data structures (e.g., file structures or a complete database) should beidentified. All design components can then be characterized to make use ofthese standard data structures.Standard interface protocols.Three levels of interface protocol should beestablished: the nature of intramodular interfaces, the design of externaltechnical (nonhuman) interfaces, and the human-computer interface.Program templates.An architectural style (Chapter 9) is chosen and canserve as a template for the architectural design of a new software.Once standard data, interfaces, and program templates have been established, youhave a framework in which to create the design. New components that conform tothis framework have a higher probability for subsequent reuse.
10.6.4 Classifying and Retrieving Components
Consider a large university library. Hundreds of thousands of books, periodicals, andother information resources are available for use. But to access these resources,a categorization scheme must be developed. To navigate this large volume ofinformation, librarians have defined a classification scheme that includes a Libraryof Congress classification code, keywords, author names, and other index entries. Allenable the user to find the needed resource quickly and easily.Now, consider a large component repository. Tens of thousands of reusable soft-ware components reside in it. But how do you find the one that you need? To answerthis question, another question arises: How do we describe software components inunambiguous, classifiable terms? These are difficult questions, and no definitiveanswer has yet been developed. In this section I explore current directions that willenable future software engineers to navigate reuse libraries.CHAPTER 10COMPONENT-LEVEL DESIGN 307
DFR can be quitedifficult when compo-nents must be inter-faced or integratedwith legacy systems orwith multiple systemswhose architecture andinterfacing protocolsare inconsistent.
11 In general, DFR preparations should be undertaken as part of domain engineering.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 307308 PART TWOMODELING
A reusable software component can be described in many ways, but an idealdescription encompasses what Tracz [Tra95] has called the 3C model—concept,content, and context. The conceptof a software component is “a description of whatthe component does” [Whi95]. The interface to the component is fully described andthe semantics—represented within the context of pre- and postconditions—is iden-tified. The concept should communicate the intent of the component. The content of a component describes how the concept is realized. In essence, the content is infor-mation that is hidden from casual users and need be known only to those who intendto modify or test the component. The context places a reusable software component within its domain of applicability. That is, by specifying conceptual, operational, andimplementation features, the context enables a software engineer to find the appro-priate component to meet application requirements.To be of use in a pragmatic setting, concept, content, and context must be trans-lated into a concrete specification scheme. Dozens of papers and articles have beenwritten about classification schemes for reusable software components (e.g., see[Cec06] for an overview of current trends).Classification enables you to find and retrieve candidate reusable components,but a reuse environment must exist to integrate these components effectively. Areuse environment exhibits the following characteristics:
•A component database capable of storing software components and the clas-sification information necessary to retrieve them.
•A library management system that provides access to the database.
•A software component retrieval system (e.g., an object request broker) thatenables a client application to retrieve components and services from thelibrary server.
•CBSE tools that support the integration of reused components into a newdesign or implementation.Each of these functions interact with or is embodied within the confines of a reuselibrary.The reuse libraryis one element of a larger software repository (Chapter 22) andprovides facilities for the storage of software components and a wide variety ofreusable work products (e.g., specifications, designs, patterns, frameworks, codefragments, test cases, user guides). The library encompasses a database and thetools that are necessary to query the database and retrieve components from it. Thecomponent classification scheme serves as the basis for library queries.Queries are often characterized using the context element of the 3C model de-scribed earlier in this section. If an initial query results in a voluminous list of candi-date components, the query is refined to narrow the list. Concept and contentinformation are then extracted (after candidate components are found) to assist youin selecting the proper component.What arethe keycharacteristics ofa componentreuseenvironment??
WebRef
A comprehensivecollection of resourceson CBSE can be foundat www.cbd-hq.com/.pre75977_ch10.qxd  11/27/08  3:47 PM  Page 308CHAPTER 10COMPONENT-LEVEL DESIGN 309
CBSE
Objective:To aid in modeling, design,review, and integration of software componentsas part of a larger system.Mechanics:Tools mechanics vary. In general, CBSE toolsassist in one or more of the following capabilities:specification and modeling of the software architecture,browsing and selection of available software components;integration of components.Representative Tools
12
ComponentSource(www.componentsource.com) provides a wide array of COTS software components(and tools) supported within many differentcomponent standards.Component Manager,developed by Flashline(www.flashline.com), “is an application thatenables, promotes, and measures software componentreuse.”Select Component Factory,developed by Select BusinessSolutions (www.selectbs.com), “is an integratedset of products for software design, design review,service/component management, requirementsmanagement and code generation.”Software Through Pictures-ACD,distributed by Aonix(www.aonix.com), enables comprehensivemodeling using UML for the OMG model drivenarchitecture—an open, vendor-neutral approachfor CBSE.SOFTWARE TOOLS
12 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.10.7 S UMMARY
The component-level design process encompasses a sequence of activities thatslowly reduces the level of abstraction with which software is represented.Component-level design ultimately depicts the software at a level of abstraction thatis close to code.Three different views of component-level design may be taken, depending onthe nature of the software to be developed. The object-oriented view focuses on theelaboration of design classes that come from both the problem and infrastructuredomain. The traditional view refines three different types of components or modules:control modules, problem domain modules, and infrastructure modules. In bothcases, basic design principles and concepts that lead to high-quality software are ap-plied. When considered from a process viewpoint, component-level design draws onreusable software components and design patterns that are pivotal elements ofcomponent-based software engineering.A number of important principles and concepts guide the designer as classes areelaborated. Ideas encompassed in the Open-Closed Principle and the DependencyInversion Principle and concepts such as coupling and cohesion guide the softwareengineer in building testable, implementable, and maintainable software compo-nents. To conduct component-level design in this context, classes are elaborated byspecifying messaging details, identifying appropriate interfaces, elaborating attrib-utes and defining data structures to implement them, describing processing flowpre75977_ch10.qxd  11/27/08  3:47 PM  Page 309310 PART TWOMODELING
within each operation, and representing behavior at a class or component level. Inevery case, design iteration (refactoring) is an essential activity.Traditional component-level design requires the representation of data struc-tures, interfaces, and algorithms for a program module in sufficient detail to guidein the generation of programming language source code. To accomplish this, thedesigner uses one of a number of design notations that represent component-leveldetail in either graphical, tabular, or text-based formats.Component-level design for WebApps considers both content and functionality asit is delivered by a Web-based system. Content design at the component level focuseson content objects and the manner in which they may be packaged for presentationto a WebApp end user. Functional design for WebApps focuses on processing func-tions that manipulate content, perform computations, query and access a database,and establish interfaces with other systems. All component-level design principlesand guidelines apply.Structured programming is a procedural design philosophy that constrains thenumber and type of logical constructs used to represent algorithmic detail. The in-tent of structured programming is to assist the designer in defining algorithms thatare less complex and therefore easier to read, test, and maintain.Component-based software engineering identifies, constructs, catalogs, and dis-seminates a set of software components in a particular application domain. Thesecomponents are then qualified, adapted, and integrated for use in a new system.Reusable components should be designed within an environment that establishesstandard data structures, interface protocols, and program architectures for eachapplication domain.
PROBLEMS AND POINTS TO PONDER
10.1.The term componentis sometimes a difficult one to define. First provide a generic defini-tion, and then provide more explicit definitions for object-oriented and traditional software.Finally, pick three programming languages with which you are familiar and illustrate how eachdefines a component.10.2.Why are control components necessary in traditional software and generally not requiredin object-oriented software?10.3.Describe the OCP in your own words. Why is it important to create abstractions that serveas an interface between components?10.4.Describe the DIP in your own words. What might happen if a designer depends too heav-ily on concretions?10.5.Select three components that you have developed recently and assess the types of cohesionthat each exhibits. If you had to define the primary benefit of high cohesion, what would it be?10.6.Select three components that you have developed recently and assess the types of cou-pling that each exhibits. If you had to define the primary benefit of low coupling, what wouldit be?10.7.Is it reasonable to say that problem domain components should never exhibit externalcoupling? If you agree, what types of component would exhibit external coupling?pre75977_ch10.qxd  11/27/08  3:47 PM  Page 31010.8.Develop (1) an elaborated design class, (2) interface descriptions, (3) an activity diagramfor one of the operations within the class, and (4) a detailed statechart diagram for one of theSafeHomeclasses that we have discussed in earlier chapters.10.9.Are stepwise refinement and refactoring the same thing? If not, how do they differ?10.10.What is a WebApp component?10.11.Select a small portion of an existing program (approximately 50 to 75 source lines).Isolate the structured programming constructs by drawing boxes around them in the sourcecode. Does the program excerpt have constructs that violate the structured programmingphilosophy? If so, redesign the code to make it conform to structured programming constructs.If not, what do you notice about the boxes that you’ve drawn?10.12.All modern programming languages implement the structured programming con-structs. Provide examples from three programming languages.10.13.Select a small coded component and represent it using (1) an activity diagram, (2) aflowchart, (3) a decision table, and (4) PDL.10.14.Why is “chunking” important during the component-level design review process?
FURTHER READINGS AND INFORMATION SOURCES
Many books on component-based development and component reuse have been publishedin recent years. Apperly and his colleagues ( Service- and Component-Based Development, Addison-Wesley, 2003), Heineman and Councill ( Component Based Software Engineering, Addison-Wesley, 2001), Brown (Large Scale Component-Based Development, Prentice-Hall, 2000), Allen (Realizing e-Business with Components, Addison-Wesley, 2000), Herzum and Sims (Business Component Factory,Wiley, 1999), Allen, Frost, and Yourdon (Component-Based Devel-opment for Enterprise Systems: Applying the Select Perspective, Cambridge University Press, 1998) cover all important aspects of the CBSE process. Cheesman and Daniels (UML Components,Addison-Wesley, 2000) discuss CBSE with a UML emphasis.Gao and his colleagues (Testing and Quality Assurance for Component-Based Software, Artech House, 2006) and Gross (Component-Based Software Testing with UML, Springer, 2005) discuss testing and SQA issues for component-based systems.Dozens of books describing the industry’s component-based standards have been publishedin recent years. These address the inner workings of the standards themselves but also considermany important CBSE topics.The work of Linger, Mills, and Witt (Structured Programming—Theory and Practice, Addison- Wesley, 1979) remains a definitive treatment of the subject. The text contains a good PDL as wellas detailed discussions of the ramifications of structured programming. Other books that focuson procedural design issues for traditional systems include those by Robertson (Simple ProgramDesign,3d ed., Course Technology, 2000), Farrell (A Guide to Programming Logic and Design,Course Technology, 1999), Bentley (Programming Pearls, 2d ed., Addison-Wesley, 1999), and Dahl (Structured Programming,Academic Press, 1997).Relatively few recent books have been dedicated solely to component-level design. In gen-eral, programming language books address procedural design in some detail but always in thecontext of the language that is introduced by the book. Hundreds of titles are available.A wide variety of information sources on component-level design are available on theInternet. An up-to-date list of World Wide Web references that are relevant to component-leveldesign can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.CHAPTER 10COMPONENT-LEVEL DESIGN 311pre75977_ch10.qxd  11/27/08  3:47 PM  Page 311We live in a world of high-technology products, and virtually all ofthem—consumer electronics, industrial equipment, corporate systems,military systems, personal computer software, and WebApps—requirehuman interaction. If a product is to be successful, it must exhibit good usability— a qualitative measure of the ease and efficiency with which a human can employthe functions and features offered by the high-technology product.Whether an interface has been designed for a digital music player or theweapons control system for a fighter aircraft, usability matters. If interface mech-anisms have been well designed, the user glides through the interaction using asmooth rhythm that allows work to be accomplished effortlessly. But if the inter-face is poorly conceived, the user moves in fits and starts, and the end result isfrustration and poor work efficiency.For the first three decades of the computing era, usability was not a dominantconcern among those who built software. In his classic book on design, DonaldNorman [Nor88] argued that it was time for a change in attitude:
To make technology that fits human beings, it is necessary to study human beings. Butnow we tend to study only the technology. As a result, people are required to conformto technology. It is time to reverse this trend, time to make technology that conformsto people.
312CHAPTER
11USERINTERFACE
DESIGN
KEY
CONCEPTS
accessibility  . . .334commandlabeling  . . . . . .333control  . . . . . . .313designevaluation  . . . . .342error handling . .333golden rules  . . .313help facilities  . .332interfaceanalysis  . . . . .320consistent  . . .316design  . . . . . .328models . . . . . .317internationali-zation  . . . . . . .334memory load  . .314
What is it? User interface designcreates an effective communicationmedium between a human and acomputer. Following a set of interfacedesign principles, design identifies interface ob-jects and actions and then creates a screen layoutthat forms the basis for a user interface prototype.
Who does it? A software engineer designs theuser interface by applying an iterative processthat draws on predefined design principles.
Why is it important? If software is difficult to use,if it forces you into mistakes, or if it frustratesyour efforts to accomplish your goals, you won’tlike it, regardless of the computational power itexhibits, the content it delivers, or the functional-ity it offers. The interface has to be right becauseit molds a user’s perception of the software.
What are the steps? User interface design beginswith the identification of user, task, and environ-QUICK
LOOKmental requirements. Once user tasks have beenidentified, user scenarios are created and ana-lyzed to define a set of interface objects andactions. These form the basis for the creation ofscreen layout that depicts graphical design andplacement of icons, definition of descriptivescreen text, specification and titling for windows,and specification of major and minor menuitems. Tools are used to prototype and ultimatelyimplement the design model, and the result isevaluated for quality.
What is the work product? User scenarios arecreated and screen layouts are generated. Aninterface prototype is developed and modified inan iterative fashion.
How do I ensure that I’ve done it right? An in-terface prototype is “test driven” by the users,and feedback from the test drive is used for thenext iterative modification of the prototype.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 312CHAPTER 11USER INTERFACE DESIGN 313
As technologists studied human interaction, two dominant issues arose. First, a setof golden rules(discussed in Section 11.1) were identified. These applied to all hu-man interaction with technology products. Second, a set of interaction mechanismswere defined to enable software designers to build systems that properly imple-mented the golden rules. These interaction mechanisms, collectively called thegraphical user interface (GUI), have eliminated some of the most egregious problemsassociated with human interfaces. But even in a “Windows world,” we all haveencountered user interfaces that are difficult to learn, difficult to use, confusing,counterintuitive, unforgiving, and in many cases, totally frustrating. Yet, someonespent time and energy building each of these interfaces, and it is not likely that thebuilder created these problems purposely.
11.1 T HEGOLDEN RULES
In his book on interface design, Theo Mandel [Man97] coins three golden rules:1.Place the user in control.2.Reduce the user’s memory load.3.Make the interface consistent.These golden rules actually form the basis for a set of user interface design princi-ples that guide this important aspect of software design.
11.1.1 Place the User in Control
During a requirements-gathering session for a major new information system, a keyuser was asked about the attributes of the window-oriented graphical interface.“What I really would like,” said the user solemnly, “is a system that reads my mind.It knows what I want to do before I need to do it and makes it very easy for me to getit done. That’s all, just that.”My first reaction was to shake my head and smile, but I paused for a moment.There was absolutely nothing wrong with the user’s request. She wanted a systemthat reacted to her needs and helped her get things done. She wanted to control thecomputer, not have the computer control her.Most interface constraints and restrictions that are imposed by a designer areintended to simplify the mode of interaction. But for whom?As a designer, you may be tempted to introduce constraints and limitations tosimplify the implementation of the interface. The result may be an interface that iseasy to build, but frustrating to use. Mandel [Man97] defines a number of designprinciples that allow the user to maintain control:Define interaction modes in a way that does not force a user into unneces-sary or undesired actions.An interaction mode is the current state of the inter-face. For example, if spell checkis selected in a word-processor menu, the softwareprinciples andguidelines . . . . .336process  . . . . . .319response time . .332task analysis  . .322taskelaboration . . . .324usability . . . . . .317user analysis  . .321WebApp interfacedesign  . . . . . . .335
uote:
“It’s better todesign the userexperience thanrectify it.”Jon Meadspre75977_ch11.qxd  11/27/08  3:55 PM  Page 313314 PART TWOMODELING
moves to a spell-checking mode. There is no reason to force the user to remain inspell-checking mode if the user desires to make a small text edit along the way. Theuser should be able to enter and exit the mode with little or no effort.Provide for flexible interaction.Because different users have different interac-tion preferences, choices should be provided. For example, software might allow auser to interact via keyboard commands, mouse movement, a digitizer pen, a mul-titouch screen, or voice recognition commands. But every action is not amenable toevery interaction mechanism. Consider, for example, the difficulty of using keyboardcommand (or voice input) to draw a complex shape.Allow user interaction to be interruptible and undoable. Even when involved in a sequence of actions, the user should be able to interrupt the sequence to dosomething else (without losing the work that had been done). The user should alsobe able to “undo” any action.Streamline interaction as skill levels advance and allow the interaction tobe customized.Users often find that they perform the same sequence of interac-tions repeatedly. It is worthwhile to design a “macro” mechanism that enables anadvanced user to customize the interface to facilitate interaction.Hide technical internals from the casual user. The user interface should move the user into the virtual world of the application. The user should not be aware of theoperating system, file management functions, or other arcane computing technol-ogy. In essence, the interface should never require that the user interact at a levelthat is “inside” the machine (e.g., a user should never be required to type operatingsystem commands from within application software).Design for direct interaction with objects that appear on the screen. The user feels a sense of control when able to manipulate the objects that are necessaryto perform a task in a manner similar to what would occur if the object were a phys-ical thing. For example, an application interface that allows a user to “stretch” anobject (scale it in size) is an implementation of direct manipulation.
11.1.2 Reduce the User’s Memory Load
The more a user has to remember, the more error-prone the interaction with thesystem will be. It is for this reason that a well-designed user interface does not taxthe user’s memory. Whenever possible, the system should “remember” pertinent in-formation and assist the user with an interaction scenario that assists recall. Man-del [Man97] defines design principles that enable an interface to reduce the user’smemory load:Reduce demand on short-term memory. When users are involved in complex tasks, the demand on short-term memory can be significant. The interface should bedesigned to reduce the requirement to remember past actions, inputs, and results.uote:
“I have alwayswished that mycomputer would beas easy to use asmy telephone. Mywish has cometrue. I no longerknow how to usemy telephone.”BjarneStronstrup(originator ofC/H11545/H11545)pre75977_ch11.qxd  11/27/08  3:55 PM  Page 314CHAPTER 11USER INTERFACE DESIGN 315
This can be accomplished by providing visual cues that enable a user to recognizepast actions, rather than having to recall them.Establish meaningful defaults.The initial set of defaults should make sense forthe average user, but a user should be able to specify individual preferences. How-ever, a “reset” option should be available, enabling the redefinition of original defaultvalues.Define shortcuts that are intuitive. When mnemonics are used to accomplish a system function (e.g., alt-P to invoke the print function), the mnemonic should betied to the action in a way that is easy to remember (e.g., first letter of the task to beinvoked).The visual layout of the interface should be based on a real-worldmetaphor.For example, a bill payment system should use a checkbook and checkregister metaphor to guide the user through the bill paying process. This enables theuser to rely on well-understood visual cues, rather than memorizing an arcaneinteraction sequence.Disclose information in a progressive fashion. The interface should be or- ganized hierarchically. That is, information about a task, an object, or some be-havior should be presented first at a high level of abstraction. More detail shouldbe presented after the user indicates interest with a mouse pick. An example, com-mon to many word-processing applications, is the underlining function. The func-tion itself is one of a number of functions under a text style menu. However, every underlining capability is not listed. The user must pick underlining; then all un-derlining options (e.g., single underline, double underline, dashed underline) arepresented.
Violating a UI Golden Rule
The scene:Vinod’s cubicle, as userinterface design begins.The players:Vinod and Jamie, members of theSafeHomesoftware engineering team.The conversation:Jamie:I’ve been thinking about the surveillance functioninterface.Vinod (smiling):Thinking is good.Jamie:I think maybe we can simplify matters some.Vinod:Meaning?Jamie:Well, what if we eliminate the floor plan entirely.It’s flashy, but it’s going to take serious development effort.Instead we just ask the user to specify the camera hewants to see and then display the video in a videowindow.Vinod:How does the homeowner remember how manycameras are set up and where they are?Jamie (mildly irritated):He’s the homeowner; heshould know.Vinod:But what if he doesn’t?Jamie:He should.SAFEHOMEpre75977_ch11.qxd  11/27/08  3:55 PM  Page 315316 PART TWOMODELING
11.1.3 Make the Interface Consistent
The interface should present and acquire information in a consistent fashion. Thisimplies that (1) all visual information is organized according to design rules that aremaintained throughout all screen displays, (2) input mechanisms are constrainedto a limited set that is used consistently throughout the application, and (3) mecha-nisms for navigating from task to task are consistently defined and implemented.Mandel [Man97] defines a set of design principles that help make the interfaceconsistent:Allow the user to put the current task into a meaningful context. Many in- terfaces implement complex layers of interactions with dozens of screen images. Itis important to provide indicators (e.g., window titles, graphical icons, consistentcolor coding) that enable the user to know the context of the work at hand. Inaddition, the user should be able to determine where he has come from and whatalternatives exist for a transition to a new task.Maintain consistency across a family of applications. A set of applications (or products) should all implement the same design rules so that consistency is main-tained for all interaction.If past interactive models have created user expectations, do not makechanges unless there is a compelling reason to do so. Once a particular in- teractive sequence has become a de facto standard (e.g., the use of alt-S to save afile), the user expects this in every application he encounters. A change (e.g., usingalt-S to invoke scaling) will cause confusion.The interface design principles discussed in this and the preceding sectionsprovide you with basic guidance. In the sections that follow, you’ll learn about theinterface design process itself.Vinod:That’s not the point . . . what if he forgets?Jamie:Uh, we could provide a list of operationalcameras and their locations.Vinod:That’s possible, but why should he have to askfor a list?Jamie:Okay, we provide the list whether he asks or not.Vinod:Better. At least he doesn’t have to remember stuffthat we can give him.Jamie (thinking for a moment):But you like thefloor plan, don’t you?Vinod:Uh huh.Jamie:Which one will marketing like, do you think?Vinod:You’re kidding, right?Jamie:No.Vinod:Duh . . . the one with the flash . . . they lovesexy product features . . . they’re not interested in whichis easier to build.Jamie (sighing):Okay, maybe I’ll prototype both.Vinod:Good idea . . . then we let the customer decide.
uote:
“Things that lookdifferent should actdifferent. Thingsthat look the sameshould act thesame.”Larry Marinepre75977_ch11.qxd  11/27/08  3:55 PM  Page 316CHAPTER 11USER INTERFACE DESIGN 317
11.2 U SERINTERFACE ANALYSIS AND DESIGN
The overall process for analyzing and designing a user interface begins with thecreation of different models of system function (as perceived from the outside). Youbegin by delineating the human- and computer-oriented tasks that are required toachieve system function and then considering the design issues that apply to allinterface designs. Tools are used to prototype and ultimately implement the designmodel, and the result is evaluated by end users for quality.
11.2.1 Interface Analysis and Design Models
Four different models come into play when a user interface is to be analyzed and de-signed. A human engineer (or the software engineer) establishes a user model, the software engineer creates a design model, the end user develops a mental image that is often called the user’s mental modelor the system perception,and the implementersUsability
In an insightful paper on usability, LarryConstantine [Con95] asks a question that hassignificant bearing on the subject: “What do users want,anyway?” He answers this way:What users really want are good tools. All softwaresystems, from operating systems and languages todata entry and decision support applications, arejust tools. End users want from the tools weengineer for them much the same as we expect fromthe tools we use. They want systems that are easy tolearn and that help them do their work. They wantsoftware that doesn’t slow them down, that doesn’ttrick or confuse them, that doesn’t make it easier tomake mistakes or harder to finish the job.Constantine argues that usability is not derived fromaesthetics, state-of-the-art interaction mechanisms, or built-in interface intelligence. Rather, it occurs when thearchitecture of the interface fits the needs of the peoplewho will be using it.A formal definition of usability is somewhat illusive.Donahue and his colleagues [Don99] define it in thefollowing manner: “Usability is a measure of how wella computer system . . . facilitates learning; helps learnersremember what they’ve learned; reduces the likelihoodof errors; enables them to be efficient, and makes themsatisfied with the system.”The only way to determine whether “usability” existswithin a system you are building is to conduct usabilityassessment or testing. Watch users interact with the systemand answer the following questions [Con95]:
•Is the system usable without continual help or instruction?
•Do the rules of interaction help a knowledgeable userto work efficiently?
•Do interaction mechanisms become more flexible asusers become more knowledgeable?
•Has the system been tuned to the physical and socialenvironment in which it will be used?
•Is the user aware of the state of the system? Does theuser know where she is at all times?
•Is the interface structured in a logical and consistentmanner?
•Are interaction mechanisms, icons, and proceduresconsistent across the interface?
•Does the interaction anticipate errors and help the usercorrect them?
•Is the interface tolerant of errors that are made?
•Is the interaction simple?If each of these questions is answered “yes,” it is likely thatusability has been achieved.Among the many measurable benefits derived from ausable system are [Don99]: increased sales and customersatisfaction, competitive advantage, better reviews in themedia, better word of mouth, reduced support costs,improved end-user productivity, reduced training costs,reduced documentation costs, reduced likelihood oflitigation from unhappy customers.INFO
WebRef
An excellent source ofUI design informationcan be found at www.useit.com.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 317318 PART TWOMODELING
of the system create an implementation model . Unfortunately, each of these models may differ significantly. Your role, as an interface designer, is to reconcile these dif-ferences and derive a consistent representation of the interface.The user model establishes the profile of end users of the system. In his introduc-tory column on “user-centric design,” Jeff Patton [Pat07] notes:
The truth is, designers and developers—myself included—often think about users. How-ever, in the absence of a strong mental model of specific users, we self-substitute. Self-substitution isn’t user centric—it’s self-centric.
To build an effective user interface, “all design should begin with an understandingof the intended users, including profiles of their age, gender, physical abilities, edu-cation, cultural or ethnic background, motivation, goals and personality” [Shn04]. Inaddition, users can be categorized as:Novices.No syntactic knowledge
1 of the system and little semantic knowledge2
of the application or computer usage in general.Knowledgeable, intermittent users.Reasonable semantic knowledge of the appli-cation but relatively low recall of syntactic information necessary to use theinterface.Knowledgeable, frequent users.Good semantic and syntactic knowledge that of-ten leads to the “power-user syndrome”; that is, individuals who look for short-cuts and abbreviated modes of interaction.The user’s mental model(system perception) is the image of the system that endusers carry in their heads. For example, if the user of a particular word processorwere asked to describe its operation, the system perception would guide the re-sponse. The accuracy of the description will depend upon the user’s profile (e.g.,novices would provide a sketchy response at best) and overall familiarity with soft-ware in the application domain. A user who understands word processors fully buthas worked with the specific word processor only once might actually be able to pro-vide a more complete description of its function than the novice who has spentweeks trying to learn the system.The implementation modelcombines the outward manifestation of the computer-based system (the look and feel of the interface), coupled with all supporting infor-mation (books, manuals, videotapes, help files) that describes interface syntax andsemantics. When the implementation model and the user’s mental model are coin-cident, users generally feel comfortable with the software and use it effectively. Toaccomplish this “melding” of the models, the design model must have beenuote:
“If there’s a ’trick’to it, the UI isbroken.”DouglasAnderson
Even a novice userwants shortcuts; evenknowledgeable,frequent userssometimes needguidance. Give themwhat they need.
1 In this context, syntactic knowledge refers to the mechanics of interaction that are required to use the interface effectively.2 Semantic knowledgerefers to the underlying sense of the application—an understanding of thefunctions that are performed, the meaning of input and output, and the goals and objectives of thesystem.The user’s mentalmodel shapes how theuser perceives theinterface and whetherthe UI meets the user’sneeds.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 318CHAPTER 11USER INTERFACE DESIGN 319
developed to accommodate the information contained in the user model, and theimplementation model must accurately reflect syntactic and semantic informationabout the interface.The models described in this section are “abstractions of what the user is doingor thinks he is doing or what somebody else thinks he ought to be doing when heuses an interactive system” [Mon84]. In essence, these models enable the interfacedesigner to satisfy a key element of the most important principle of user interfacedesign: “Know the user, know the tasks.”
11.2.2 The Process
The analysis and design process for user interfaces is iterative and can be repre-sented using a spiral model similar to the one discussed in Chapter 2. Referring toFigure 11.1, the user interface analysis and design process begins at the interior ofthe spiral and encompasses four distinct framework activities [Man97]: (1) interfaceanalysis and modeling, (2) interface design, (3) interface construction, and (4) inter-face validation. The spiral shown in Figure 11.1 implies that each of these tasks willoccur more than once, with each pass around the spiral representing additionalelaboration of requirements and the resultant design. In most cases, the construc-tion activity involves prototyping—the only practical way to validate what has beendesigned.Interface analysisfocuses on the profile of the users who will interact with thesystem. Skill level, business understanding, and general receptiveness to the newsystem are recorded; and different user categories are defined. For each user cate-gory, requirements are elicited. In essence, you work to understand the systemperception (Section 11.2.1) for each class of users.Once general requirements have been defined, a more detailed task analysis is conducted. Those tasks that the user performs to accomplish the goals of the systemuote:
“… pay attentionto what users do,not what they say.”Jakob Nielsen
Interface design Interface constructionInterface analysis and modelingInterface validationFIGURE 11.1
The userinterfacedesign processuote:
“It’s better todesign the userexperience thanrectify it.”Jon Meadspre75977_ch11.qxd  11/27/08  3:55 PM  Page 319320 PART TWOMODELING
are identified, described, and elaborated (over a number of iterative passes throughthe spiral). Task analysis is discussed in more detail in Section 11.3. Finally, analysisof the user environment focuses on the physical work environment. Among thequestions to be asked are
•Where will the interface be located physically?
•Will the user be sitting, standing, or performing other tasks unrelated to theinterface?
•Does the interface hardware accommodate space, light, or noise constraints?
•Are there special human factors considerations driven by environmentalfactors?The information gathered as part of the analysis action is used to create an analysismodel for the interface. Using this model as a basis, the design action commences.The goal of interface designis to define a set of interface objects and actions (andtheir screen representations) that enable a user to perform all defined tasks in amanner that meets every usability goal defined for the system. Interface design isdiscussed in more detail in Section 11.4.Interface constructionnormally begins with the creation of a prototype that en-ables usage scenarios to be evaluated. As the iterative design process continues, auser interface tool kit (Section 11.5) may be used to complete the construction of theinterface.Interface validationfocuses on (1) the ability of the interface to implement everyuser task correctly, to accommodate all task variations, and to achieve all generaluser requirements; (2) the degree to which the interface is easy to use and easyto learn, and (3) the users’ acceptance of the interface as a useful tool in theirwork.As I have already noted, the activities described in this section occur iteratively.Therefore, there is no need to attempt to specify every detail (for the analysis or de-sign model) on the first pass. Subsequent passes through the process elaborate taskdetail, design information, and the operational features of the interface.
11.3 I NTERFACE ANALYSIS3
A key tenet of all software engineering process models is this: understand the prob-lem before you attempt to design a solution. In the case of user interface design, un- derstanding the problem means understanding (1) the people (end users) who willinteract with the system through the interface, (2) the tasks that end users mustWhat do weneed toknow about theenvironment aswe begin UIdesign??
3 It is reasonable to argue that this section should be placed in Chapter 5, 6, or 7, since requirementsanalysis issues are discussed there. It has been positioned here because interface analysis and de-sign are intimately connected to one another, and the boundary between the two is often fuzzy.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 320CHAPTER 11USER INTERFACE DESIGN 321
perform to do their work, (3) the content that is presented as part of the interface,and (4) the environment in which these tasks will be conducted. In the sections thatfollow, I examine each of these elements of interface analysis with the intent ofestablishing a solid foundation for the design tasks that follow.
11.3.1 User Analysis
The phrase “user interface” is probably all the justification needed to spend sometime understanding the user before worrying about technical matters. Earlier I notedthat each user has a mental image of the software that may be different from themental image developed by other users. In addition, the user’s mental image may bevastly different from the software engineer’s design model. The only way that youcan get the mental image and the design model to converge is to work to understandthe users themselves as well as how these people will use the system. Informationfrom a broad array of sources can be used to accomplish this:User Interviews.The most direct approach, members of the software teammeet with end users to better understand their needs, motivations, work cul-ture, and a myriad of other issues. This can be accomplished in one-on-onemeetings or through focus groups.Sales input.Sales people meet with users on a regular basis and can gatherinformation that will help the software team to categorize users and betterunderstand their requirements.Marketing input.Market analysis can be invaluable in the definition ofmarket segments and an understanding of how each segment might use thesoftware in subtly different ways.Support input.Support staff talks with users on a daily basis. They are themost likely source of information on what works and what doesn’t, whatusers like and what they dislike, what features generate questions and whatfeatures are easy to use.The following set of questions (adapted from [Hac98]) will help you to betterunderstand the users of a system:
•Are users trained professionals, technicians, clerical, or manufacturingworkers?
•What level of formal education does the average user have?
•Are the users capable of learning from written materials or have theyexpressed a desire for classroom training?
•Are users expert typists or keyboard phobic?
•What is the age range of the user community?
•Will the users be represented predominately by one gender?
•How are users compensated for the work they perform?How do welearn whatthe user wantsfrom the UI??
Above all, spend timetalking to actual users,but be careful. Onestrong opinion doesn’tnecessarily mean thatthe majority of userswill agree.
How do we learnabout thedemographics andcharacteristics of endusers?pre75977_ch11.qxd  11/27/08  3:55 PM  Page 321322 PART TWOMODELING
•Do users work normal office hours or do they work until the job is done?
•Is the software to be an integral part of the work users do or will it be usedonly occasionally?
•What is the primary spoken language among users?
•What are the consequences if a user makes a mistake using the system?
•Are users experts in the subject matter that is addressed by the system?
•Do users want to know about the technology that sits behind the interface?Once these questions are answered, you’ll know who the end users are, what is likelyto motivate and please them, how they can be grouped into different user classes orprofiles, what their mental models of the system are, and how the user interface mustbe characterized to meet their needs.
11.3.2 Task Analysis and Modeling
The goal of task analysis is to answer the following questions:
•What work will the user perform in specific circumstances?
•What tasks and subtasks will be performed as the user does the work?
•What specific problem domain objects will the user manipulate as work isperformed?
•What is the sequence of work tasks—the workflow?
•What is the hierarchy of tasks?To answer these questions, you must draw upon techniques that I have discussedearlier in this book, but in this instance, these techniques are applied to the userinterface.Use cases.In earlier chapters you learned that the use case describes the mannerin which an actor (in the context of user interface design, an actor is always a person)interacts with a system. When used as part of task analysis, the use case is devel-oped to show how an end user performs some specific work-related task. In mostinstances, the use case is written in an informal style (a simple paragraph) in thefirst-person. For example, assume that a small software company wants to builda computer-aided design system explicitly for interior designers. To get a betterunderstanding of how they do their work, actual interior designers are asked todescribe a specific design function. When asked: “How do you decide where to putfurniture in a room?” an interior designer writes the following informal use case:
I begin by sketching the floor plan of the room, the dimensions and the location of win-dows and doors. I’m very concerned about light as it enters the room, about the view outof the windows (if it’s beautiful, I want to draw attention to it), about the running lengthof an unobstructed wall, about the flow of movement through the room. I then look at thelist of furniture my customer and I have chosen—tables, chairs, sofa, cabinets, the list ofThe user’s goal is toaccomplish one ormore tasks via the UI.To accomplish this, the UI must providemechanisms that allowthe user to achieve her goal.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 322CHAPTER 11USER INTERFACE DESIGN 323
accents—lamps, rugs, paintings, sculpture, plants, smaller pieces, and my notes on anydesires my customer has for placement. I then draw each item from my lists using a tem-plate that is scaled to the floor plan. I label each item I draw and use pencil because I al-ways move things. I consider a number of alternative placements and decide on the oneI like best. Then, I draw a rendering (a 3-D picture) of the room to give my customer a feelfor what it’ll look like.
This use case provides a basic description of one important work task for thecomputer-aided design system. From it, you can extract tasks, objects, and theoverall flow of the interaction. In addition, other features of the system that wouldplease the interior designer might also be conceived. For example, a digital photocould be taken looking out each window in a room. When the room is rendered, theactual outside view could be represented through each window.
Use Cases for UI Design
The scene:Vinod’s cubicle, as userinterface design continues.The players:Vinod and Jamie, members of theSafeHomesoftware engineering team.The conversation:Jamie:I pinned down our marketing contact and hadher write a use case for the surveillance interface.Vinod:From whose point of view?Jamie:The homeowner, who else is there?Vinod:There’s also the system administrator role, evenif it’s the homeowner playing the role, it’s a different pointof view. The “administrator” sets the system up, configuresstuff, lays out the floor plan, places the cameras . . .Jamie:All I had her do was play the role of thehomeowner when he wants to see video.Vinod:That’s okay. It’s one of the major behaviors of thesurveillance function interface. But we’re going to have toexamine the system administration behavior as well.Jamie (irritated):You’re right.[Jamie leaves to find the marketing person. She returns afew hours later.]Jamie:I was lucky, I found her and we worked throughthe administrator use case together. Basically, we’re goingto define “administration” as one function that’s applicableto all other SafeHomefunctions. Here’s what we came up with.[Jamie shows the informal use case to Vinod.]Informal use case:I want to be able to set or editthe system layout at any time. When I set up the system,I select an administration function. It asks me whether I want to do a new setup or whether I want to edit an existing setup. If I select a new setup, the systemdisplays a drawing screen that will enable me to drawthe floor plan onto a grid. There will be icons for walls,windows, and doors so that drawing is easy. I juststretch the icons to their appropriate lengths. The systemwill display the lengths in feet or meters (I can select the measurement system). I can select from a libraryof sensors and cameras and place them on the floorplan. I get to label each, or the system will do automaticlabeling. I can establish settings for sensors and camerasfrom appropriate menus. If I select edit, I can movesensors or cameras, add new ones or delete existingones, edit the floor plan, and edit the settings forcameras and sensors. In every case, I expect the systemto do consistency checking and to help me avoidmistakes.Vinod (after reading the scenario): Okay, there are probably some useful design patterns [Chapter 12] orreusable components for GUIs for drawing programs. I’llbetcha 50 bucks we can implement some or most of theadministrator interface using them.Jamie:Agreed. I’ll check it out.SAFEHOMEpre75977_ch11.qxd  11/27/08  3:55 PM  Page 323324 PART TWOMODELING
Task elaboration.In Chapter 8, I discussed stepwise elaboration (also called func-tional decomposition or stepwise refinement) as a mechanism for refining the pro-cessing tasks that are required for software to accomplish some desired function.Task analysis for interface design uses an elaborative approach to assist in under-standing the human activities the user interface must accommodate.Task analysis can be applied in two ways. As I have already noted, an interactive,computer-based system is often used to replace a manual or semimanual activity. Tounderstand the tasks that must be performed to accomplish the goal of the activity, youmust understand the tasks that people currently perform (when using a manual ap-proach) and then map these into a similar (but not necessarily identical) set of tasks thatare implemented in the context of the user interface. Alternatively, you can study anexisting specification for a computer-based solution and derive a set of user tasks thatwill accommodate the user model, the design model, and the system perception.Regardless of the overall approach to task analysis, you must first define and clas-sify tasks. I have already noted that one approach is stepwise elaboration. Forexample, let’s reconsider the computer-aided design system for interior designers dis-cussed earlier. By observing an interior designer at work, you notice that interiordesign comprises a number of major activities: furniture layout (note the use case dis-cussed earlier), fabric and material selection, wall and window coverings selection,presentation (to the customer), costing, and shopping. Each of these major tasks canbe elaborated into subtasks. For example, using information contained in the use case,furniture layout can be refined into the following tasks: (1) draw a floor plan based onroom dimensions, (2) place windows and doors at appropriate locations, (3a) use fur-niture templates to draw scaled furniture outlines on the floor plan, (3b) use accentstemplates to draw scaled accents on the floor plan, (4) move furniture outlines andaccent outlines to get the best placement, (5) label all furniture and accent outlines,(6) draw dimensions to show location, and (7) draw a perspective-rendering view forthe customer. A similar approach could be used for each of the other major tasks.Subtasks 1 to 7 can each be refined further. Subtasks 1 to 6 will be performed bymanipulating information and performing actions within the user interface. On theother hand, subtask 7 can be performed automatically in software and will result inlittle direct user interaction.
4The design model of the interface should accommodateeach of these tasks in a way that is consistent with the user model (the profile of a“typical” interior designer) and system perception (what the interior designer expectsfrom an automated system).Object elaboration.Rather than focusing on the tasks that a user must perform,you can examine the use case and other information obtained from the user andextract the physical objects that are used by the interior designer. These objects canTask elaboration isquite useful, but it canalso be dangerous.Just because you haveelaborated a task, donot assume that thereisn’t another way todo it, and that theother way will betried when the UI isimplemented.
4 However, this may not be the case. The interior designer might want to specify the perspective to bedrawn, the scaling, the use of color, and other information. The use case related to drawing per-spective renderings would provide the information you need to address this task.pre75977_ch11.qxd  11/27/08  3:55 PM  Page 324CHAPTER 11USER INTERFACE DESIGN 325
be categorized into classes. Attributes of each class are defined, and an evaluationof the actions applied to each object provide a list of operations. For example, thefurniture template might translate into a class called Furniturewith attributes that might include size, shape, location,and others. The interior designer would select the object from the Furnitureclass, moveit to a position on the floor plan (another ob- ject in this context), drawthe furniture outline, and so forth. The tasks select, move,and draware operations. The user interface analysis model would not provide a lit-eral implementation for each of these operations. However, as the design is elabo-rated, the details of each operation are defined.Workflow analysis.When a number of different users, each playing differentroles, makes use of a user interface, it is sometimes necessary to go beyond taskanalysis and object elaboration and apply workflow analysis.This technique allows you to understand how a work process is completed when several people (and roles)are involved. Consider a company that intends to fully automate the process of pre-scribing and delivering prescription drugs. The entire process
5will revolve around a Web-based application that is accessible by physicians (or their assistants), pharma-cists, and patients. Workflow can be represented effectively with a UML swimlanediagram (a variation on the activity diagram).We consider only a small part of the work process: the situation that occurs whena patient asks for a refill. Figure 11.2 presents a swimlane diagram that indicates thetasks and decisions for each of the three roles noted earlier. This information mayhave been elicited via interview or from use cases written by each actor. Regardless,the flow of events (shown in the figure) enables you to recognize a number of keyinterface characteristics:1.Each user implements different tasks via the interface; therefore, the look andfeel of the interface designed for the patient will be different than the onedefined for pharmacists or physicians.2.The interface design for pharmacists and physicians must accommodateaccess to and display of information from secondary information sources(e.g., access to inventory for the pharmacist and access to information aboutalternative medications for the physician).3.Many of the activities noted in the swimlane diagram can be further elabo-rated using task analysis and/or object elaboration (e.g., Fills prescription could imply a mail-order delivery, a visit to a pharmacy, or a visit to a specialdrug distribution center).Hierarchical representation.A process of elaboration occurs as you begin toanalyze the interface. Once workflow has been established, a task hierarchy can bedefined for each user type. The hierarchy is derived by a stepwise elaboration ofAlthough objectelaboration is useful,it should not be used as a stand-aloneapproach. The user’svoice mustbe consid-ered during taskanalysis.
5 This example has been adapted from [Hac98].uote:
“It is far better to adapt thetechnology to theuser than to forcethe user to adaptto the technology.”Larry Marinepre75977_ch11.qxd  11/27/08  3:55 PM  Page 325326 PART TWOMODELING
PatientPharmacistPhysician
Requests that a prescription be refilled
No refills remainingChecks patientrecordsDetermines status of prescription
Refills remaining
Refill not allowedApproves refill 
Evaluates alternativemedication
None
Receives request tocontact physicianAlternativeavailableChecks inventory forrefill or alternativeOut of stockReceives out of stocknotificationReceives time/dateto pick upIn stock
Picks upprescription
FillsprescriptionFIGURE 11.2 Swimlane diagram for prescription refill functionpre75977_ch11.qxd  11/27/08  3:56 PM  Page 326CHAPTER 11USER INTERFACE DESIGN 327
each task identified for the user. For example, consider the following user task andsubtask hierarchy.User task:Requests that a prescription be refilled
•Provide identifying information.
•Specify name.
•Specify userid.
•Specify PIN and password.
•Specify prescription number.
•Specify date refill is required.To complete the task, three subtasks are defined. One of these subtasks, provide iden-tifying information,is further elaborated in three additional sub-subtasks.
11.3.3 Analysis of Display Content
The user tasks identified in Section 11.3.2 lead to the presentation of a variety ofdifferent types of content. For modern applications, display content can range fromcharacter-based reports (e.g., a spreadsheet), graphical displays (e.g., a histogram,a 3-D model, a picture of a person), or specialized information (e.g., audio or videofiles). The analysis modeling techniques discussed in Chapters 6 and 7 identify theoutput data objects that are produced by an application. These data objects may be(1) generated by components (unrelated to the interface) in other parts of anapplication, (2) acquired from data stored in a database that is accessible from theapplication, or (3) transmitted from systems external to the application in question.During this interface analysis step, the format and aesthetics of the content (as itis displayed by the interface) are considered. Among the questions that are askedand answered are:
•Are different types of data assigned to consistent geographic locations onthe screen (e.g., photos always appear in the upper right-hand corner)?
•Can the user customize the screen location for content?
•Is proper on-screen identification assigned to all content?
•If a large report is to be presented, how should it be partitioned for ease ofunderstanding?
•Will mechanisms be available for moving directly to summary information forlarge collections of data?
•Will graphical output be scaled to fit within the bounds of the display devicethat is used?
•How will color be used to enhance understanding?
•How will error messages and warnings be presented to the user?The answers to these (and other) questions will help you to establish requirementsfor content presentation.How do wedeterminethe format andaesthetics ofcontent displayedas part of the UI??pre75977_ch11.qxd  11/27/08  3:56 PM  Page 327328 PART TWOMODELING
11.3.4 Analysis of the Work Environment
Hackos and Redish [Hac98] discuss the importance of work environment analysiswhen they state:
People do not perform their work in isolation. They are influenced by the activity aroundthem, the physical characteristics of the workplace, the type of equipment they are using,and the work relationships they have with other people. If the products you design do notfit into the environment, they may be difficult or frustrating to use.
In some applications the user interface for a computer-based system is placed in a“user-friendly location” (e.g., proper lighting, good display height, easy keyboardaccess), but in others (e.g., a factory floor or an airplane cockpit), lighting may besuboptimal, noise may be a factor, a keyboard or mouse may not be an option, dis-play placement may be less than ideal. The interface designer may be constrained byfactors that mitigate against ease of use.In addition to physical environmental factors, the workplace culture also comesinto play. Will system interaction be measured in some manner (e.g., time per trans-action or accuracy of a transaction)? Will two or more people have to share infor-mation before an input can be provided? How will support be provided to users ofthe system? These and many related questions should be answered before the inter-face design commences.
11.4 I NTERFACE DESIGN STEPS
Once interface analysis has been completed, all tasks (or objects and actions)required by the end user have been identified in detail and the interface designactivity commences. Interface design, like all software engineering design, is an it-erative process. Each user interface design step occurs a number of times, elaborat-ing and refining information developed in the preceding step.Although many different user interface design models (e.g., [Nor86], [Nie00]) havebeen proposed, all suggest some combination of the following steps:1.Using information developed during interface analysis (Section 11.3), defineinterface objects and actions (operations).2.Define events (user actions) that will cause the state of the user interface tochange. Model this behavior.3.Depict each interface state as it will actually look to the end user.4.Indicate how the user interprets the state of the system from information pro-vided through the interface.In some cases, you can begin with sketches of each interface state (i.e., what theuser interface looks like under various circumstances) and then work backward todefine objects, actions, and other important design information. Regardless of thesequence of design tasks, you should (1) always follow the golden rules discusseduote:
“Interactive design[is] a seamlessblend of graphicarts, technology,and psychology.”Brad Wienerspre75977_ch11.qxd  11/27/08  3:56 PM  Page 328CHAPTER 11USER INTERFACE DESIGN 329
in Section 11.1, (2) model how the interface will be implemented, and (3) considerthe environment (e.g., display technology, operating system, development tools)that will be used.
11.4.1 Applying Interface Design Steps
The definition of interface objects and the actions that are applied to them is animportant step in interface design. To accomplish this, user scenarios are parsedin much the same way as described in Chapter 6. That is, a use case is written.Nouns (objects) and verbs (actions) are isolated to create a list of objects andactions.Once the objects and actions have been defined and elaborated iteratively, theyare categorized by type. Target, source, and application objects are identified. Asource object(e.g., a report icon) is dragged and dropped onto a target object (e.g., a printer icon). The implication of this action is to create a hard-copy report. Anapplication objectrepresents application-specific data that are not directly manipu-lated as part of screen interaction. For example, a mailing list is used to store namesfor a mailing. The list itself might be sorted, merged, or purged (menu-based ac-tions), but it is not dragged and dropped via user interaction.When you are satisfied that all important objects and actions have been de-fined (for one design iteration), screen layout is performed. Like other interfacedesign activities, screen layout is an interactive process in which graphical de-sign and placement of icons, definition of descriptive screen text, specificationand titling for windows, and definition of major and minor menu items are con-ducted. If a real-world metaphor is appropriate for the application, it is specifiedat this time, and the layout is organized in a manner that complements themetaphor.To provide a brief illustration of the design steps noted previously, consider a userscenario for the SafeHomesystem (discussed in earlier chapters). A preliminary usecase (written by the homeowner) for the interface follows:
Preliminary use case:I want to gain access to my SafeHome system from any remote location via the Internet. Using browser software operating on my notebook computer(while I’m at work or traveling), I can determine the status of the alarm system, arm ordisarm the system, reconfigure security zones, and view different rooms within the housevia preinstalled video cameras.To access SafeHomefrom a remote location, I provide an identifier and a password.These define levels of access (e.g., all users may not be able to reconfigure the system) andprovide security. Once validated, I can check the status of the system and change the sta-tus by arming or disarming SafeHome. I can reconfigure the system by displaying a floor plan of the house, viewing each of the security sensors, displaying each currently config-ured zone, and modifying zones as required. I can view the interior of the house via strate-gically placed video cameras. I can pan and zoom each camera to provide different viewsof the interior.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 329330 PART TWOMODELING
Based on this use case, the following homeowner tasks, objects, and data items areidentified:
•accessesthe SafeHomesystem
•entersan IDand passwordto allow remote access
•checkssystem status
•armsor disarms SafeHomesystem
•displaysfloor planand sensor locations
•displayszoneson floor plan
•changeszoneson floor plan
•displaysvideo camera locationson floor plan
•selectsvideo camerafor viewing
•viewsvideo images(four frames per second)
•pansor zoomsthe video cameraObjects (boldface) and actions (italics) are extracted from this list of homeownertasks. The majority of objects noted are application objects. However, videocamera location(a source object) is dragged and dropped onto video camera(a target object) to create a video image(a window with video display). A preliminary sketch of the screen layout for video monitoring is created (Fig-ure 11.3).
6To invoke the video image, a video camera location icon, C, located in thefloor plan displayed in the monitoring window is selected. In this case a camera lo-cation in the living room (LR) is then dragged and dropped onto the video cameraicon in the upper left-hand portion of the screen. The video image window appears,displaying streaming video from the camera located in the LR. The zoom and pancontrol slides are used to control the magnification and direction of the video image.To select a view from another camera, the user simply drags and drops a differentcamera location icon into the camera icon in the upper left-hand corner of thescreen.The layout sketch shown would have to be supplemented with an expansion ofeach menu item within the menu bar, indicating what actions are available for thevideo monitoring mode (state). A complete set of sketches for each homeowner tasknoted in the user scenario would be created during the interface design.
11.4.2 User Interface Design Patterns
Graphical user interfaces have become so common that a wide variety of user inter-face design patterns has emerged. As I noted earlier in this book, a design pattern isAlthough automatedtools can be useful indeveloping layoutprototypes, sometimesa pencil and paper areall that are needed.
6 Note that this differs somewhat from the implementation of these features in earlier chapters. Thismight be considered a first draft design and represents one alternative that might be considered.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 330CHAPTER 11USER INTERFACE DESIGN 331
an abstraction that prescribes a design solution to a specific, well-bounded designproblem.As an example of a commonly encountered interface design problem, consider asituation in which a user must enter one or more calendar dates, sometimes monthsin advance. There are many possible solutions to this simple problem, and a num-ber of different patterns that might be proposed. Laakso [Laa00] suggests a patterncalled CalendarStripthat produces a continuous, scrollable calendar in which thecurrent date is highlighted and future dates may be selected by picking them fromthe calendar. The calendar metaphor is well known to every user and provides aneffective mechanism for placing a future date in context.A vast array of interface design patterns has been proposed over the pastdecade. A more detailed discussion of user interface design patterns is presentedin Chapter 12. In addition, Erickson [Eri08] provides pointers to many Web-basedcollections.
11.4.3 Design Issues
As the design of a user interface evolves, four common design issues almost alwayssurface: system response time, user help facilities, error information handling, andAccess   Configure  System Status   View   Monitoring
Monitoring
First FloorSSSS
SSSSM
M
Video Image—LRLRDRKIT
CCCSafeHome
Connect
Status
Video Camera
InOutRLSMCdoor/window sensormotion detector (beam shown)video camera locationFIGURE 11.3
Preliminaryscreen layout
WebRef
A wide variety of UIdesign patterns hasbeen proposed. Forpointers to a variety ofpatterns sites, visit www.hcipatterns.org.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 331332 PART TWOMODELING
command labeling. Unfortunately, many designers do not address these issues untilrelatively late in the design process (sometimes the first inkling of a problem doesn’toccur until an operational prototype is available). Unnecessary iteration, projectdelays, and end-user frustration often result. It is far better to establish each as adesign issue to be considered at the beginning of software design, when changes areeasy and costs are low.Response time.System response time is the primary complaint for many interac-tive applications. In general, system response time is measured from the point atwhich the user performs some control action (e.g., hits the return key or clicks amouse) until the software responds with desired output or action.System response time has two important characteristics: length and variability.If system response is too long, user frustration and stress are inevitable. Variability refers to the deviation from average response time, and in many ways, it is themost important response time characteristic. Low variability enables the user toestablish an interaction rhythm, even if response time is relatively long. For ex-ample, a 1-second response to a command will often be preferable to a responsethat varies from 0.1 to 2.5 seconds. When variability is significant, the user is al-ways off balance, always wondering whether something “different” has occurredbehind the scenes.Help facilities.Almost every user of an interactive, computer-based system re-quires help now and then. In some cases, a simple question addressed to a knowl-edgeable colleague can do the trick. In others, detailed research in a multivolume setof “user manuals” may be the only option. In most cases, however, modern softwareprovides online help facilities that enable a user to get a question answered orresolve a problem without leaving the interface.A number of design issues [Rub88] must be addressed when a help facility is con-sidered:
•Will help be available for all system functions and at all times during systeminteraction? Options include help for only a subset of all functions andactions or help for all functions.
•How will the user request help? Options include a help menu, a specialfunction key, or a HELP command.
•How will help be represented? Options include a separate window, areference to a printed document (less than ideal), or a one- or two-linesuggestion produced in a fixed screen location.
•How will the user return to normal interaction? Options include areturn button displayed on the screen, a function key, or control sequence.uote:
“A commonmistake thatpeople make whentrying to designsomethingcompletelyfoolproof is tounderestimate theingenuity ofcomplete fools.”Douglas Adamspre75977_ch11.qxd  11/27/08  3:56 PM  Page 332CHAPTER 11USER INTERFACE DESIGN 333
•How will help information be structured? Options include a “flat” structure inwhich all information is accessed through a keyword, a layered hierarchy ofinformation that provides increasing detail as the user proceeds into thestructure, or the use of hypertext.Error handling.Error messages and warnings are “bad news” delivered to usersof interactive systems when something has gone awry. At their worst, errormessages and warnings impart useless or misleading information and serve only toincrease user frustration. There are few computer users who have not encounteredan error of the form: “Application XXX has been forced to quit because an error of type1023 has been encountered.”Somewhere, an explanation for error 1023 must exist;otherwise, why would the designers have added the identification? Yet, the errormessage provides no real indication of what went wrong or where to look to getadditional information. An error message presented in this manner does nothing toassuage user anxiety or to help correct the problem.In general, every error message or warning produced by an interactive systemshould have the following characteristics:
•The message should describe the problem in jargon that the user canunderstand.
•The message should provide constructive advice for recovering from theerror.
•The message should indicate any negative consequences of the error (e.g.,potentially corrupted data files) so that the user can check to ensure that theyhave not occurred (or correct them if they have).
•The message should be accompanied by an audible or visual cue. That is, abeep might be generated to accompany the display of the message, or themessage might flash momentarily or be displayed in a color that is easilyrecognizable as the “error color.”
•The message should be “nonjudgmental.” That is, the wording should neverplace blame on the user.Because no one really likes bad news, few users will like an error message no mat-ter how well designed. But an effective error message philosophy can do much toimprove the quality of an interactive system and will significantly reduce user frus-tration when problems do occur.Menu and command labeling.The typed command was once the most com-mon mode of interaction between user and system software and was commonlyused for applications of every type. Today, the use of window-oriented, point-and-pick interfaces has reduced reliance on typed commands, but some power-userscontinue to prefer a command-oriented mode of interaction. A number of designWhatcharacter-istics should a“good’” errormessage have??uote:
“The interface fromhell—’to correctthis error andcontinue, enter any11-digit primenumber …’”Author unknownpre75977_ch11.qxd  11/27/08  3:56 PM  Page 333334 PART TWOMODELING
issues arise when typed commands or menu labels are provided as a mode ofinteraction:
•Will every menu option have a corresponding command?
•What form will commands take? Options include a control sequence (e.g.,alt-P), function keys, or a typed word.
•How difficult will it be to learn and remember the commands? What can bedone if a command is forgotten?
•Can commands be customized or abbreviated by the user?
•Are menu labels self-explanatory within the context of the interface?
•Are submenus consistent with the function implied by a master menu item?As I noted earlier in this chapter, conventions for command usage should be es-tablished across all applications. It is confusing and often error-prone for a userto type alt-D when a graphics object is to be duplicated in one application and alt-D when a graphics object is to be deleted in another. The potential for error isobvious.Application accessibility.As computing applications become ubiquitous, soft-ware engineers must ensure that interface design encompasses mechanisms thatenable easy access for those with special needs. Accessibility for users (and software engineers) who may be physically challenged is an imperative for ethical, legal, andbusiness reasons. A variety of accessibility guidelines (e.g., [W3C03])—many de-signed for Web applications but often applicable to all types of software—provide de-tailed suggestions for designing interfaces that achieve varying levels of accessibility.Others (e.g., [App08], [Mic08]) provide specific guidelines for “assistive technology”that addresses the needs of those with visual, hearing, mobility, speech, and learn-ing impairments.Internationalization.Software engineers and their managers invariably underes-timate the effort and skills required to create user interfaces that accommodate theneeds of different locales and languages. Too often, interfaces are designed for onelocale and language and then jury-rigged to work in other countries. The challengefor interface designers is to create “globalized” software. That is, user interfacesshould be designed to accommodate a generic core of functionality that can be de-livered to all who use the software. Localization features enable the interface to be customized for a specific market.A variety of internationalization guidelines (e.g., [IBM03]) are available to soft-ware engineers. These guidelines address broad design issues (e.g., screen layoutsmay differ in various markets) and discrete implementation issues (e.g., differentalphabets may create specialized labeling and spacing requirements). The Unicodestandard [Uni03] has been developed to address the daunting challenge of manag-ing dozens of natural languages with hundreds of characters and symbols.
WebRef
Guidelines fordeveloping accessiblesoftware can befound at www3.ibm.com/able/guidelines/software/accesssoftware.html.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 334CHAPTER 11USER INTERFACE DESIGN 335
User Interface Development
Objective:These tools enable a softwareengineer to create a sophisticated GUI withrelatively little custom software development. The toolsprovide access to reusable components and make thecreation of an interface a matter of selecting frompredefined capabilities that are assembled using the tool.Mechanics:Modern user interfaces are constructedusing a set of reusable components that are coupled withsome custom components developed to providespecialized features. Most user interface development toolsenable a software engineer to create an interface using“drag and drop” capability. That is, the developer selectsfrom many predefined capabilities (e.g., forms builders,interaction mechanisms, command processing capability)and places these capabilities within the content of theinterface to be created.Representative Tools:7
LegaSuite GUI, developed by Seagull Software(www.seagullsoftware.com), enabled thecreation of browser-based GUIs and provide facilitiesfor reengineering antiquated interfaces.Motif Common Desktop Environment,developed by TheOpen Group (www.osf.org/tech/desktop/cde/), is an integrated graphical user interface for opensystems desktop computing. It delivers a single,standard graphical interface for the management ofdata and files (the graphical desktop) andapplications.Altia Design 8.0,developed by Altia (www.altia.com),is a tool for creating GUIs on a variety of differentplatforms (e.g., automotive, handheld, industrial).SOFTWARE TOOLS
7 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.8 Each of us has bookmarked a Web page, only to revisit it later and have no indication of the web-site or the context for the page (as well as no way to move to another location within the site).11.5 W EBAPPINTERFACE DESIGN
Every user interface—whether it is designed for a WebApp, a traditional softwareapplication, a consumer product, or an industrial device—should exhibit the usabil-ity characteristics that were discussed earlier in this chapter. Dix [Dix99] argues thatyou should design a WebApp interface so that it answers three primary questions forthe end user:Where am I?The interface should (1) provide an indication of the WebApp that hasbeen accessed
8and (2) inform the user of her location in the content hierarchy.What can I do now?The interface should always help the user understand hiscurrent options—what functions are available, what links are live, what contentis relevant?Where have I been, where am I going?The interface must facilitate navigation.Hence, it must provide a “map” (implemented in a way that is easy to under-stand) of where the user has been and what paths may be taken to move else-where within the WebApp.An effective WebApp interface must provide answers for each of these questions asthe end user navigates through content and functionality.If it is likely that usersmay enter yourWebApp at variouslocations and levels inthe content hierarchy,be sure to design everypage with navigationfeatures that will leadthe user to other pointsof interest.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 335336 PART TWOMODELING
11.5.1 Interface Design Principles and Guidelines
The user interface of a WebApp is its “first impression.” Regardless of the value of itscontent, the sophistication of its processing capabilities and services, and the over-all benefit of the WebApp itself, a poorly designed interface will disappoint thepotential user and may, in fact, cause the user to go elsewhere. Because of the sheervolume of competing WebApps in virtually every subject area, the interface must“grab” a potential user immediately.Bruce Tognozzi [Tog01] defines a set of fundamental characteristics that allinterfaces should exhibit and in doing so, establishes a philosophy that should befollowed by every WebApp interface designer:
Effective interfaces are visually apparent and forgiving, instilling in their users a sense ofcontrol. Users quickly see the breadth of their options, grasp how to achieve their goals,and do their work.Effective interfaces do not concern the user with the inner workings of the system.Work is carefully and continuously saved, with full option for the user to undo any activ-ity at any time.Effective applications and services perform a maximum of work, while requiring aminimum of information from users.
In order to design WebApp interfaces that exhibit these characteristics, Tognozzi[Tog01] identifies a set of overriding design principles:
9
Anticipation.A WebApp should be designed so that it anticipates the user’s nextmove.For example, consider a customer support WebApp developed by a manufac-turer of computer printers. A user has requested a content object that presentsinformation about a printer driver for a newly released operating system. Thedesigner of the WebApp should anticipate that the user might request a downloadof the driver and should provide navigation facilities that allow this to happenwithout requiring the user to search for this capability.Communication.The interface should communicate the status of any activity initi-ated by the user.Communication can be obvious (e.g., a text message) or subtle (e.g.,an image of a sheet of paper moving through a printer to indicate that printing isunder way). The interface should also communicate user status (e.g., the user’s iden-tification) and her location within the WebApp content hierarchy.Consistency.The use of navigation controls, menus, icons, and aesthetics (e.g., color,shape, layout) should be consistent throughout the WebApp. For example, if underlined blue text implies a navigation link, content should never incorporate blue underlinedtext that does not imply a link. In addition, an object, say a yellow triangle, used toA good WebAppinterface isunderstandable andforgiving, providing theuser with a sense ofcontrol.
Is there a setof basic prin-ciples that can beapplied as youdesign a GUI??
9 Tognozzi’s original principles have been adapted and extended for use this book. See [Tog01] forfurther discussion of these principles.uote:
“If a site isperfectly usablebut it lacks anelegant andappropriate designstyle, it will fail.”Curt Cloningerpre75977_ch11.qxd  11/27/08  3:56 PM  Page 336CHAPTER 11USER INTERFACE DESIGN 337
indicate a caution message before the user invokes a particular function or action,should not be used for other purposes elsewhere in the WebApp. Finally, everyfeature of the interface should respond in a manner that is consistent with userexpectations.
10
Controlled autonomy.The interface should facilitate user movement throughoutthe WebApp, but it should do so in a manner that enforces navigation conventions thathave been established for the application. For example, navigation to secure portions of the WebApp should be controlled by userID and password, and there should be nonavigation mechanism that enables a user to circumvent these controls.Efficiency.The design of the WebApp and its interface should optimize the user’swork efficiency, not the efficiency of the developer who designs and builds it or the client-server environment that executes it.Tognozzi [Tog01] discusses this when he writes:“This simple truth is why it is so important for everyone involved in a software proj-ect to appreciate the importance of making user productivity goal one and to under-stand the vital difference between building an efficient system and empoweringan efficient user.”Flexibility.The interface should be flexible enough to enable some users to accomplishtasks directly and others to explore the WebApp in a somewhat random fashion. In every case, it should enable the user to understand where he is and provide the user withfunctionality that can undo mistakes and retrace poorly chosen navigation paths.Focus.The WebApp interface (and the content it presents) should stay focused on theuser task(s) at hand.In all hypermedia there is a tendency to route the user to looselyrelated content. Why? Because it’s very easy to do! The problem is that the user canrapidly become lost in many layers of supporting information and lose sight of theoriginal content that she wanted in the first place.Fitt’s law.“The time to acquire a target is a function of the distance to and size of thetarget”[Tog01]. Based on a study conducted in the 1950s [Fit54], Fitt’s law “is aneffective method of modeling rapid, aimed movements, where one appendage (like ahand) starts at rest at a specific start position, and moves to rest within a target area”[Zha02]. If a sequence of selections or standardized inputs (with many differentoptions within the sequence) is defined by a user task, the first selection (e.g., mousepick) should be physically close to the next selection. For example, consider a WebApphome page interface at an e-commerce site that sells consumer electronics.Each user option implies a set of follow-on user choices or actions. For example,the “buy a product” option requires that the user enter a product category followedby the product name. The product category (e.g., audio equipment, televisions, DVD
10 Tognozzi [Tog01] notes that the only way to be sure that user expectations are properly understoodis through comprehensive user testing (Chapter 20).WebRef
A search on the Webwill uncover manyavailable libraries, e.g.,Java API packages,interfaces, and classesat java.sun.comorCOM, DCOM, andType Libraries at msdn.Microsoft.com.uote:
“The best journeyis the one with thefewest steps.Shorten thedistance betweenthe user and theirgoal.”Author unknownpre75977_ch11.qxd  11/27/08  3:56 PM  Page 337338 PART TWOMODELING
players) appears as a pull-down menu as soon as “buy a product” is picked. There-fore, the next choice is immediately obvious (it is nearby) and the time to acquire itis negligible. If, on the other hand, the choice appeared on a menu that was locatedon the other side of the screen, the time for the user to acquire it (and then make thechoice) would be far too long.Human interface objects.A vast library of reusable human interface objects hasbeen developed for WebApps. Use them. Any interface object that can be “seen, heard, touched or otherwise perceived” [Tog01] by an end user can be acquired from anyone of a number of object libraries.Latency reduction.Rather than making the user wait for some internal operation tocomplete (e.g., downloading a complex graphical image), the WebApp should use mul-titasking in a way that lets the user proceed with work as if the operation has been com-pleted.In addition to reducing latency, delays must be acknowledged so that the userunderstands what is happening. This includes (1) providing audio feedback when aselection does not result in an immediate action by the WebApp, (2) displaying ananimated clock or progress bar to indicate that processing is under way, and (3) pro-viding some entertainment (e.g., an animation or text presentation) while lengthyprocessing occurs.Learnability.A WebApp interface should be designed to minimize learning time, andonce learned, to minimize relearning required when the WebApp is revisited. In general the interface should emphasize a simple, intuitive design that organizes content andfunctionality into categories that are obvious to the user.Metaphors.An interface that uses an interaction metaphor is easier to learn andeasier to use, as long as the metaphor is appropriate for the application and the user. A metaphor should call on images and concepts from the user’s experience, but it doesnot need to be an exact reproduction of a real-world experience. For example, an e-commerce site that implements automated bill paying for a financial institution,uses a checkbook metaphor (not surprisingly) to assist the user in specifying andscheduling bill payments. However, when a user “writes” a check, he need not enterthe complete payee name but can pick from a list of payees or have the system selectbased on the first few typed letters. The metaphor remains intact, but the user getsan assist from the WebApp.Maintain work product integrity. A work product (e.g., a form completed by the user, a user-specified list) must be automatically saved so that it will not be lost if an erroroccurs.Each of us has experienced the frustration associated with completing alengthy WebApp form only to have the content lost because of an error (made by us,by the WebApp, or in transmission from client to server). To avoid this, a WebAppshould be designed to autosave all user-specified data. The interface should supportthis function and provide the user with an easy mechanism for recovering “lost”information.
Metaphors are anexcellent idea becausethey mirror real-worldexperience. Just besure that the metaphoryou choose is wellknown to end users.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 338CHAPTER 11USER INTERFACE DESIGN 339
Readability.All information presented through the interface should be readable byyoung and old.The interface designer should emphasize readable type styles, fontsizes, and color background choices that enhance contrast.Track state.When appropriate, the state of the user interaction should be tracked andstored so that a user can logoff and return later to pick up where she left off. In general, cookies can be designed to store state information. However, cookies are a contro-versial technology, and other design solutions may be more palatable for some users.Visible navigation.A well-designed WebApp interface provides “the illusion that usersare in the same place, with the work brought to them” [Tog01]. When this approach is used, navigation is not a user concern. Rather, the user retrieves content objectsand selects functions that are displayed and executed through the interface.
Interface Design Review
The scene:Doug Miller’s office.The players:Doug Miller (manager of the SafeHomesoftware engineering group) and Vinod Raman, a memberof the SafeHomeproduct software engineering team.The conversation:Doug:Vinod, have you and the team had a chance toreview the SafeHomeAssured.come-commerceinterface prototype?Vinod:Yeah . . . we all went through it from a technicalpoint of view, and I have a bunch of notes. I e-mailed‘em to Sharon [manager of the WebApp team for theoutsourcing vendor for the SafeHomee-commercewebsite] yesterday.Doug:You and Sharon can get together and discuss thesmall stuff . . . give me a summary of the important issues.Vinod:Overall, they’ve done a good job, nothingground breaking, but it’s a typical e-commerce interface,decent aesthetics, reasonable layout, they’ve hit all theimportant functions . . .Doug (smiling ruefully):But?Vinod:Well, there are a few things . . . .Doug:Such as . . .Vinod (showing Doug a sequence of story-boards for the interface prototype): Here’s the major functions menu that’s displayed on the home page:Learn aboutSafeHome.Describe your home.GetSafeHomecomponent recommendations.Purchase aSafeHomesystem.Get technical support.The problem isn’t with these functions. They’re all okay,but the level of abstraction isn’t right.Doug:They’re all major functions, aren’t they?Vinod:They are, but here’s the thing . . . you canpurchase a system by inputting a list of components . . .no real need to describe the house if you don’t want to.I’d suggest only four menu options on the home page:Learn aboutSafeHome.Specify theSafeHomesystem you need.Purchase aSafeHomesystem.Get technical support.When you select Specify theSafeHomesystemyou need, you’ll then have the following options:SelectSafeHomecomponents.GetSafeHomecomponent recommendations.If you’re a knowledgeable user, you’ll select componentsfrom a set of categorized pull-down menus for sensors,cameras, control panels, etc. If you need help, you’ll askfor a recommendation and that will require that youdescribe your house. I think it’s a bit more logical.Doug:I agree. Have you talked with Sharon about this?Vinod:No, I want to discuss this with marketing first;then I’ll give her a call.SAFEHOMEpre75977_ch11.qxd  11/27/08  3:56 PM  Page 339340 PART TWOMODELING
Nielsen and Wagner [Nie96] suggest a few pragmatic interface design guidelines(based on their redesign of a major WebApp) that provide a nice complement to theprinciples suggested earlier in this section:
•Reading speed on a computer monitor is approximately 25 percent slowerthan reading speed for hardcopy. Therefore, do not force the user to readvoluminous amounts of text, particularly when the text explains theoperation of the WebApp or assists in navigation.
•Avoid “under construction” signs—an unnecessary link is sure to disappoint.
•Users prefer not to scroll. Important information should be placed within thedimensions of a typical browser window.
•Navigation menus and head bars should be designed consistently and shouldbe available on all pages that are available to the user. The design should notrely on browser functions to assist in navigation.
•Aesthetics should never supersede functionality. For example, a simplebutton might be a better navigation option than an aesthetically pleasing, butvague image or icon whose intent is unclear.
•Navigation options should be obvious, even to the casual user. The usershould not have to search the screen to determine how to link to othercontent or services.A well-designed interface improves the user’s perception of the content or servicesprovided by the site. It need not necessarily be flashy, but it should always be wellstructured and ergonomically sound.
11.5.2 Interface Design Workflow for WebApps
Earlier in this chapter I noted that user interface design begins with the identificationof user, task, and environmental requirements. Once user tasks have been identified,user scenarios (use cases) are created and analyzed to define a set of interfaceobjects and actions.Information contained within the requirements model forms the basis for thecreation of a screen layout that depicts graphical design and placement of icons, def-inition of descriptive screen text, specification and titling for windows, and specifi-cation of major and minor menu items. Tools are then used to prototype andultimately implement the interface design model. The following tasks represent arudimentary workflow for WebApp interface design:1.Review information contained in the requirements model and refineas required.2.Develop a rough sketch of the WebApp interface layout. An interface prototype (including the layout) may have been developed as part of therequirements modeling activity. If the layout already exists, it should bereviewed and refined as required. If the interface layout has not beenuote:
“People have verylittle patience forpoorly designedWWW sites.”Jakob NielsenandAnnette Wagnerpre75977_ch11.qxd  11/27/08  3:56 PM  Page 340CHAPTER 11USER INTERFACE DESIGN 341
developed, you should work with stakeholders to develop it at this time. Aschematic first-cut layout sketch is shown in Figure 11.4.3.Map user objectives into specific interface actions. For the vast major- ity of WebApps, the user will have a relatively small set of primary objectives.These should be mapped into specific interface actions as shown in Figure 11.4.In essence, you must answer the following question: “How does the interfaceenable the user to accomplish each objective?”4.Define a set of user tasks that are associated with each action. Each interface action (e.g., “buy a product”) is associated with a set of user tasks.These tasks have been identified during requirements modeling. During de-sign, they must be mapped into specific interactions that encompass naviga-tion issues, content objects, and WebApp functions.5.Storyboard screen images for each interface action. As each action is considered, a sequence of storyboard images (screen images) should be createdto depict how the interface responds to user interaction. Content objects shouldbe identified (even if they have not yet been designed and developed), WebAppfunctionality should be shown, and navigation links should be indicated.6.Refine interface layout and storyboards using input from aestheticdesign.In most cases, you’ll be responsible for rough layout and story-boarding, but the aesthetic look and feel for a major commercial site isoften developed by artistic, rather than technical, professionals. Aestheticdesign (Chapter 13) is integrated with the work performed by the interfacedesigner.List of user objectivesObjective #1Objective #2Objective #3Objective #4Objective #5Objective #nNavigationmenuMenu barmajor functionsGraphic, logo, and company name
Graphic
Home page text copyFIGURE 11.4
Mapping userobjectives intointerfaceactionspre75977_ch11.qxd  11/27/08  3:56 PM  Page 341342 PART TWOMODELING
7.Identify user interface objects that are required to implement theinterface.This task may require a search through an existing object libraryto find those reusable objects (classes) that are appropriate for the WebAppinterface. In addition, any custom classes are specified at this time.8.Develop a procedural representation of the user’s interaction withthe interface.This optional task uses UML sequence diagrams and/oractivity diagrams (Appendix 1) to depict the flow of activities (and decisions)that occur as the user interacts with the WebApp.9.Develop a behavioral representation of the interface. This optional task makes use of UML state diagrams (Appendix 1) to represent statetransitions and the events that cause them. Control mechanisms (i.e., theobjects and actions available to the user to alter a WebApp state) aredefined.10.Describe the interface layout for each state. Using design information developed in Tasks 2 and 5, associate a specific layout or screen image witheach WebApp state described in Task 8.11.Refine and review the interface design model. Review of the interface should focus on usability.It is important to note that the final task set you choose should be adapted to thespecial requirements of the application that is to be built.
11.6 D ESIGN EVALUATION
Once you create an operational user interface prototype, it must be evaluatedto determine whether it meets the needs of the user. Evaluation can span a formal-ity spectrum that ranges from an informal “test drive,” in which a user providesimpromptu feedback to a formally designed study that uses statistical methods forthe evaluation of questionnaires completed by a population of end users.The user interface evaluation cycle takes the form shown in Figure 11.5. After thedesign model has been completed, a first-level prototype is created. The prototype isevaluated by the user,
11who provides you with direct comments about the efficacyof the interface. In addition, if formal evaluation techniques are used (e.g., ques-tionnaires, rating sheets), you can extract information from these data (e.g., 80 percent of all users did not like the mechanism for saving data files). Design mod-ifications are made based on user input, and the next level prototype is created. Theevaluation cycle continues until no further modifications to the interface design arenecessary.
11 It is important to note that experts in ergonomics and interface design may also conduct reviewsof the interface. These reviews are called heuristic evaluationsor cognitive walkthroughs.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 342CHAPTER 11USER INTERFACE DESIGN 343
The prototyping approach is effective, but is it possible to evaluate the quality ofa user interface before a prototype is built? If you identify and correct potentialproblems early, the number of loops through the evaluation cycle will be reducedand development time will shorten. If a design model of the interface has beencreated, a number of evaluation criteria [Mor81] can be applied during early designreviews:1.The length and complexity of the requirements model or written specificationof the system and its interface provide an indication of the amount of learn-ing required by users of the system.2.The number of user tasks specified and the average number of actions pertask provide an indication of interaction time and the overall efficiency of thesystem.3.The number of actions, tasks, and system states indicated by the design modelimply the memory load on users of the system.4.Interface style, help facilities, and error handling protocol provide a generalindication of the complexity of the interface and the degree to which it will beaccepted by the user.Once the first prototype is built, you can collect a variety of qualitative and quanti-tative data that will assist in evaluating the interface. To collect qualitative data, ques-tionnaires can be distributed to users of the prototype. Questions can be: (1) simpleyes/no response, (2) numeric response, (3) scaled (subjective) response, (4) LikertBuildprototype #ninterface
Evaluationis studied bydesignerUserevaluatesinterfaceDesignmodificationsare madeBuildprototype #1interfacePreliminarydesign
Interface designis completeFIGURE 11.5
The interfacedesign evalua-tion cyclepre75977_ch11.qxd  11/27/08  3:56 PM  Page 343344 PART TWOMODELING
scales (e.g., strongly agree, somewhat agree), (5) percentage (subjective) response,or (6) open-ended.If quantitative data are desired, a form of time-study analysis can be conducted.Users are observed during interaction, and data—such as number of tasks correctlycompleted over a standard time period, frequency of actions, sequence of actions,time spent “looking” at the display, number and types of errors, error recovery time,time spent using help, and number of help references per standard time period—arecollected and used as a guide for interface modification.A complete discussion of user interface evaluation methods is beyond the scopeof this book. For further information, see [Hac98] and [Sto05].
11.7 S UMMARY
The user interface is arguably the most important element of a computer-based sys-tem or product. If the interface is poorly designed, the user’s ability to tap the com-putational power and informational content of an application may be severelyhindered. In fact, a weak interface may cause an otherwise well-designed and solidlyimplemented application to fail.Three important principles guide the design of effective user interfaces: (1) placethe user in control, (2) reduce the user’s memory load, and (3) make the interface con-sistent. To achieve an interface that abides by these principles, an organized designprocess must be conducted.The development of a user interface begins with a series of analysis tasks. Useranalysis defines the profiles of various end users and is gathered from a variety ofbusiness and technical sources. Task analysis defines user tasks and actions usingeither an elaborative or object-oriented approach, applying use cases, task and ob-ject elaboration, workflow analysis, and hierarchical task representations to fullyunderstand the human-computer interaction. Environmental analysis identifies thephysical and social structures in which the interface must operate.Once tasks have been identified, user scenarios are created and analyzed to definea set of interface objects and actions. This provides a basis for the creation of a screenlayout that depicts graphical design and placement of icons, definition of descriptivescreen text, specification and titling for windows, and specification of major and minormenu items. Design issues such as response time, command and action structure, er-ror handling, and help facilities are considered as the design model is refined. A varietyof implementation tools are used to build a prototype for evaluation by the user.Like interface design for conventional software, the design of WebApp interfacesdescribes the structure and organization of the user interface and includes a repre-sentation of screen layout, a definition of the modes of interaction, and a descriptionof navigation mechanisms. A set of interface design principles and an interface de-sign workflow guide a WebApp designer when layout and interface control mecha-nisms are designed.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 344CHAPTER 11USER INTERFACE DESIGN 345
The user interface is the window into the software. In many cases, the interfacemolds a user’s perception of the quality of the system. If the “window” is smudged,wavy, or broken, the user may reject an otherwise powerful computer-based system.
PROBLEMS AND POINTS TO PONDER
11.1.Describe the worst interface that you have ever worked with and critique it relative to theconcepts introduced in this chapter. Describe the best interface that you have ever worked withand critique it relative to the concepts introduced in this chapter.11.2.Develop two additional design principles that “place the user in control.”11.3.Develop two additional design principles that “reduce the user’s memory load.”11.4.Develop two additional design principles that “make the interface consistent.”11.5.Consider one of the following interactive applications (or an application assigned by yourinstructor):a. A desktop publishing systemb. A computer-aided design systemc. An interior design system (as described in Section 11.3.2)d. An automated course registration system for a universitye. A library management systemf. An Internet-based polling booth for public electionsg. A home banking systemh. An interactive application assigned by your instructorDevelop a user model, design model, mental model, and an implementation model, for any oneof these systems.11.6.Perform a detailed task analysis for any one of the systems listed in Problem 11.5 Useeither an elaborative or object-oriented approach.11.7.Add at least five additional questions to the list developed for content analysis inSection 11.3.3.11.8.Continuing Problem 11.5, define interface objects and actions for the application youhave chosen. Identify each object type.11.9.Develop a set of screen layouts with a definition of major and minor menu items for thesystem you chose in Problem 11.5.11.10.Develop a set of screen layouts with a definition of major and minor menu items for theSafeHomesystem. You may elect to take a different approach than the one shown for the screenlayout in Figure 11.3.11.11.Describe your approach to user help facilities for the task analysis design model andtask analysis you have performed as part of Problems 11.5 through 11.8.11.12.Provide a few examples that illustrate why response time variability can be an issue.11.13.Develop an approach that would automatically integrate error messages and a userhelp facility. That is, the system would automatically recognize the error type and provide a helpwindow with suggestions for correcting it. Perform a reasonably complete software design thatconsiders appropriate data structures and algorithms.11.14.Develop an interface evaluation questionnaire that contains 20 generic questions thatwould apply to most interfaces. Have 10 classmates complete the questionnaire for an interac-tive system that you all use. Summarize the results and report them to your class.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 345346 PART TWOMODELING
FURTHER READINGS AND INFORMATION SOURCES
Although his book is not specifically about human-computer interfaces, much of what DonaldNorman (The Design of Everyday Things, reissue edition, Currency/Doubleday, 1990) has to say about the psychology of effective design applies to the user interface. It is recommended read-ing for anyone who is serious about doing high-quality interface design.Graphical user interfaces are ubiquitous in the modern world of computing. Whether it’s anATM, a mobile phone, an electronic dashboard in an automobile, a website, or a business appli-cation, the user interface provides a window into the software. It is for this reason that booksaddressing interface design abound. Butow (User Interface Design for Mere Mortals, Addison- Wesley, 2007), Galitz (The Essential Guide to User Interface Design, 3d ed., Wiley, 2007), Lehikonen and his colleagues (Personal Content Experience: Managing Digital Life in the Mobile Age, Wiley- Interscience, 2007), Cooper and his colleagues (About Face 3: The Essentials of Interaction Design,3d ed., Wiley, 2007), Ballard (Designing the Mobile User Experience, Wiley, 2007), Nielsen (Coordinating User Interfaces for Consistency, Morgan-Kaufmann, 2006), Lauesen ( User Interface Design: A Software Engineering Perspective, Addison-Wesley, 2005), Barfield (The User Interface: Concepts and Design,Bosko Books, 2004) all discuss usability, user interface concepts, principles,and design techniques and contain many useful examples.Older books by Beyer and Holtzblatt ( Contextual Design: A Customer Centered Approach to Sys- tems Design,Morgan-Kaufmann, 2002), Raskin ( The Humane Interface,Addison-Wesley, 2000), Constantine and Lockwood (Software for Use,ACM Press, 1999), and Mayhew (The Usability En- gineering Lifecycle,Morgan-Kaufmann, 1999) present treatments that provide additional designguidelines and principles as well as suggestions for interface requirements elicitation, designmodeling, implementation, and testing.Johnson (GUI Bloopers: Don’ts and Do’s for Software Developers and Web Designers, Morgan- Kaufmann, 2000) provides useful guidance for those that learn more effectively by examiningcounterexamples. An enjoyable book by Cooper (The Inmates Are Running the Asylum, Sams Publishing, 1999) discusses why high-tech products drive us crazy and how to design ones thatdon’t.A wide variety of information sources on user interface design are available on the Internet.An up-to-date list of World Wide Web references that are relevant to user interface design canbe found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.pre75977_ch11.qxd  11/27/08  3:56 PM  Page 346Each of us has encountered a design problem and silently thought: I wonder if anyone has developed a solution for this? The answer is almost always— yes!The problem is finding the solution; ensuring that it does, in fact, fitthe problem you’ve encountered; understanding the constraints that may restrictthe manner in which the solution is applied; and finally, translating the proposedsolution into your design environment.But what if the solution were codified in some manner? What if there was a stan-dard way of describing a problem (so you could look it up), and an organizedmethod for representing the solution to the problem? It turns out that softwareproblems have been codified and described using a standardized template, and so-lutions to them (along with constraints) have been proposed. Called design patterns,
347CHAPTER
12PATTERN -BASED
DESIGN
What is it? Pattern-based designcreates a new application by findinga set of proven solutions to a clearlydelineated set of problems. Eachproblem and its solution is described by a designpattern that has been cataloged and vetted byother software engineers who have encounteredthe problem and implemented the solution whiledesigning other applications. Each design pat-tern provides you with a proven approach toone part of the problem to be solved.
Who does it? A software engineer examines eachproblem encountered for a new application andthen attempts to find a relevant solution bysearching one or more patterns repositories.
Why is it important? Have you ever heard thephrase “reinventing the wheel”? It happens allthe time in software development, and it’s awaste of time and energy. By using existingdesign patterns, you can acquire a proven solu-tion for a specific problem. As each pattern isapplied, solutions are integrated and the appli-cation to be built moves closer to a completedesign.QUICK
LOOKWhat are the steps? The requirements model isexamined in order to isolate the hierarchical setof problems to be solved. The problem space ispartitioned so that subsets of problems associ-ated with specific software functions and fea-tures can be identified. Problems can also beorganized by type: architectural, component-level, algorithmic, user interface, etc. Once asubset of problems is defined, one or more pat-tern repositories are searched to determine if anexisting design pattern, represented at an ap-propriate level of abstraction, exists. Patternsthat are applicable are adapted to the specificneeds of the software to be built. Custom prob-lem solving is applied in situations for which nopatterns can be found.
What is the work product? A design model thatdepicts the architectural structure, user interface,and component-level detail is developed.
How do I ensure that I’ve done it right? As eachdesign pattern is translated into some element ofthe design model, work products are reviewed forclarity, correctness, completeness, and consis-tency with requirements and with one another.KEY
CONCEPTS
design mistakes  . . . . .359forces  . . . . . . .349frameworks  . . .352granularity . . . .369patternlanguages  . . . .353patternsarchitectural  . .360behavioral  . . .351pre75977_ch12.qxd  11/27/08  3:58 PM  Page 347this codified method for describing problems and their solution allows the softwareengineering community to capture design knowledge in a way that enables it to bereused.The early history of software patterns begins not with a computer scientist but abuilding architect, Christopher Alexander, who recognized that a recurring set ofproblems were encountered whenever a building was designed. He characterizedthese recurring problems and their solutions as patterns, describing them in the following manner [Ale77]:
Each pattern describes a problem that occurs over and over again in our environment andthen describes the core of the solution to that problem in such a way that you can use thesolution a million times over without ever doing it the same way twice.
Alexander’s ideas were first translated into the software world in books by Gamma[Gam95], Buschmann [Bus96], and their many colleagues.
1Today, dozens of pattern repositories exist, and pattern-based design can be applied in many different appli-cation domains.348 PART TWOMODELING
component-level  . . . . . . .362generative  . . .350creational . . . .350structural  . . . .351userinterface  . . . .366WebApps  . . . .368
12.1 D ESIGN PATTERNS
A design patterncan be characterized as “a three-part rule which expresses a rela-tion between a certain context, a problem, and a solution” [Ale79]. For softwaredesign, contextallows the reader to understand the environment in which the prob-lem resides and what solution might be appropriate within that environment. A setof requirements, including limitations and constraints, acts as a system of forces that influences how the problem can be interpreted within its context and how the solu-tion can be effectively applied.To better understand these concepts, consider a situation
2in which a person must travel between New York and Los Angeles. In this context, travel will occur withinan industrialized country (the United States), using an existing transportation infra-structure (e.g., roads, airlines, railways). The system of forces that will affect the wayin which the travel problem is solved will include: how quickly the person wants toget from New York to LA, whether the trip will include site-seeing or stopovers, howmuch money the person can spend, whether the trip is intended to accomplish a spe-cific purpose, and the personal vehicles the person has at her disposal. Given theseforces, the problem (traveling from New York to LA) can be better defined. Forexample, investigation (requirements gathering) indicates that the person has verylittle money, owns only a bicycle (and is an avid cyclist), wants to make the trip toraise money for her favorite charity, and has plenty of time to spare. The solution tothe problem, given the context and the system of forces, might be a cross-country
1 Earlier discussions of software patterns do exist, but these two classic books were the first cohesivetreatments of the subject.2 This example has been adapted from [Cor98].Forcesare thosecharacteristics of theproblem and attributesof the solution thatconstrain the way inwhich the design canbe developed.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 348bike trip. If the forces were different (e.g., travel time must be minimized and the pur-pose of the trip is a business meeting), another solution might be more appropriate.It is reasonable to argue that most problems have multiple solutions, but that asolution is effective only if it is appropriate within the context of the existing prob-lem. It is the system of forces that causes a designer to choose a specific solution.The intent is to provide a solution that best satisfies the system of forces, even whenthese forces are contradictory. Finally, every solution has consequences that mayhave an impact on other aspects of the software and may themselves become partof the system of forces for other problems to be solved within the larger system.Coplien [Cop05] characterizes an effective design pattern in the following way:
•It solves a problem: Patterns capture solutions, not just abstract principles orstrategies.•It is a proven concept: Patterns capture solutions with a track record, not theo-ries or speculation.•The solution isn’t obvious: Many problem-solving techniques (such as softwaredesign paradigms or methods) try to derive solutions from first principles. Thebest patterns generatea solution to a problem indirectly—a necessary approachfor the most difficult problems of design.•It describes a relationship: Patterns don’t just describe modules, but describedeeper system structures and mechanisms.•The pattern has a significant human component (minimize human intervention).All software serves human comfort or quality of life; the best patterns explicitlyappeal to aesthetics and utility.
Stated even more pragmatically, a good design pattern captures hard-earned, prag-matic design knowledge in a way that enables others to reuse that knowledge “a mil-lion times over without ever doing it the same way twice.” A design pattern saves youfrom “reinventing the wheel,” or worse, inventing a “new wheel” that is slightly out ofround, too small for its intended use, and too narrow for the ground it will roll over. De-sign patterns, if used effectively, will invariably make you a better software designer.
12.1.1 Kinds of Patterns
One of the reasons that software engineers are interested in (and intrigued by)design patterns is that human beings are inherently good at pattern recognition. Ifwe weren’t, we’d be frozen in space and time—unable to learn from past experience,unwilling to venture forward because of our inability to recognize situations thatmight lead to high risk, unhinged by a world that seems to have no regularity or log-ical consistency. Luckily, none of this occurs because we do recognize patterns invirtually every aspect of our lives.In the real world, the patterns we recognize are learned over a lifetime of experi-ence. We recognize them instantly and inherently understand what they meanand how they might be used. Some of these patterns provide us with insight intoCHAPTER 12PATTERN-BASED DESIGN 349
uote:
“Our responsibilityis to do what wecan, learn what wecan, improve thesolutions, and passthem on.”Richard P .Feynmanpre75977_ch12.qxd  11/27/08  3:58 PM  Page 349recurring phenomenon. For example, you’re on your way home from work on theinterstate when your navigation system (or car radio) informs you that a seriousaccident has occurred on the interstate in the opposing direction. You’re 4 miles fromthe accident, but already you begin to see traffic slowing, recognizing a pattern thatwe’ll call RubberNecking.People in the travel lanes moving in your direction areslowing at the sight of the accident to get a better view of what happened on theopposite side of the highway. The RubberNecking pattern yields remarkably pre- dictable results (a traffic jam), but it does nothing more than describe a phenome-non. In patterns jargon, it might be called a nongenerative pattern because it describes a context and a problem but it does not provide any clear-cut solution.When software design patterns are considered, we strive to identify and documentgenerativepatterns. That is, we identify a pattern that describes an important andrepeatable aspect of a system and that provides us with a way to build that aspectwithin a system of forces that are unique to a given context. In an ideal setting, a col-lection of generative design patterns could be used to “generate” an application orcomputer-based system whose architecture enables it to adapt to change. Some-times calledgenerativity,“the successive application of several patterns, each encap-sulating its own problem and forces, unfolds a larger solution which emergesindirectly as a result of the smaller solutions” [App00].Design patterns span a broad spectrum of abstraction and application.Architectural patternsdescribe broad-based design problems that are solved using astructural approach. Data patternsdescribe recurring data-oriented problems and thedata modeling solutions that can be used to solve them. Component patterns (also referred to as design patterns) address problems associated with the development ofsubsystems and components, the manner in which they communicate with oneanother, and their placement within a larger architecture. Interface design patternsdescribe common user interface problems and their solution with a system of forcesthat includes the specific characteristics of end users. WebApp patterns address a problem set that is encountered when building WebApps and often incorporatesmany of the other patterns categories just mentioned. At a lower level of abstraction,idiomsdescribe how to implement all or part of a specific algorithm or data structurefor a software component within the context of a specific programming language.In their seminal book on design patterns, Gamma and his colleagues
3[Gam95] focus on three types of patterns that are particularly relevant to object-orienteddesign: creational patterns, structural patterns, and behavioral patterns.Creational patternsfocus on the “creation, composition, and representation” ofobjects. Gamma and his colleagues [Gam95] note that creational patterns“encapsulate knowledge about which concrete classes the system uses“ but atthe same time “hide how instances of these classes are created and put together.”Creational patterns provide mechanisms that make the instantiation of objects350 PART TWOMODELING
A “generative” patterndescribes the problem,a context, and forces,but it also describes apragmatic solution tothe problem.
Is there away tocategorize patterntypes??
3 Gamma and his colleagues [Gam95] are often referred to as the “Gang of Four” (GoF) in patternsliterature.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 350easier within a system and enforce “constraints on the type and number of objectsthat can be created within a system” [Maa07].Structural patternsfocus on problems and solutions associated with how classesand objects are organized and integrated to build a larger structure. In essence, theyhelp to establish relationships between entities within a system. For example, struc-tural patterns that focus on class-oriented issues might provide inheritance mecha-nisms that lead to more effective program interfaces. Structural patterns that focuson objects suggest techniques for combining objects within other objects or inte-grating objects into a larger structure.Behavioral patternsaddress problems associated with the assignment of respon-sibility between objects and the manner in which communication is effectedbetween objects.CHAPTER 12PATTERN-BASED DESIGN 351
A wide variety of design patterns that fit intocreational, structural, and behavioral categorieshave been proposed and can be found on the Web.Wikipedia (www.wikipedia.org) notes the followingsampling:Creational Patterns
•Abstract factory pattern:centralize decision ofwhat factory to instantiate.
•Factory method pattern:centralize creation ofan object of a specific type choosing one of severalimplementations.
•Builder pattern:separate the construction of acomplex object from its representation so that thesame construction process can create differentrepresentations.
•Prototype pattern:used when the inherent cost ofcreating a new object in the standard way (e.g., usingthe “new” keyword) is prohibitively expensive for agiven application.
•Singleton pattern:restrict instantiation of a class toone object.Structural Patterns
•Adapter pattern:“adapts” one interface for a classinto one that a client expects.
•Aggregate pattern:a version of the compositepattern with methods for aggregation of children.
•Bridge pattern:decouple an abstraction from itsimplementation so that the two can vary independently.
•Composite pattern:a tree structure of objectswhere every object has the same interface.•Container pattern:create objects for the solepurpose of holding other objects and managing them.
•Proxy pattern:a class functioning as an interface toanother thing.
•Pipes and filters:a chain of processes where theoutput of each process is the input of the next.Behavioral Patterns
•Chain of responsibility pattern:Commandobjects are handled or passed on to other objects bylogic-containing processing objects.
•Command pattern:Command objects encapsulatean action and its parameters.
•Event listener:Data are distributed to objects thatare registered to receive them.
•Interpreter pattern:Implement a specializedcomputer language to rapidly solve a specific set ofproblems.
•Iterator pattern:Iterators are used to access theelements of an aggregate object sequentially withoutexposing its underlying representation.
•Mediator pattern:Provides a unified interface to aset of interfaces in a subsystem.
•Visitor pattern:A way to separate an algorithmfrom an object.
•Single-serving visitor pattern:Optimize theimplementation of a visitor that is allocated, used onlyonce, and then deleted.
•Hierarchical visitor pattern:Provide a way to visitevery node in a hierarchical data structure such as a tree.Comprehensive descriptions of each of these patterns canbe obtained via links at www.wikipedia.org.INFO
Creational, Structural, and Behavioral Patternspre75977_ch12.qxd  11/27/08  3:58 PM  Page 35112.1.2 Frameworks
Patterns themselves may not be sufficient to develop a complete design. In somecases it may be necessary to provide an implementation-specific skeletal infrastruc-ture, called a framework,for design work. That is, you can select a “reusable mini-architecturethat provides the generic structure and behavior for a family of softwareabstractions, along with a context . . . which specifies their collaboration and usewithin a given domain” [Amb98].A framework is not an architectural pattern, but rather a skeleton with a collec-tion of “plug points” (also called hooksand slots) that enable it to be adapted to a spe- cific problem domain. The plug points enable you to integrate problem-specificclasses or functionality within the skeleton. In an object-oriented context, a frame-work is a collection of cooperating classes.Gamma and his colleagues [Gam95] describe the differences between designpatterns and frameworks in the following manner:
1.Design patterns are more abstract than frameworks. Frameworks can be embodiedin code, but only examplesof patterns can be embodied in code. A strength offrameworks is that they can be written down in programming languages and notonly studied but executed and reused directly .... 2.Design patterns are smaller architectural elements than frameworks. A typicalframework contains several design patterns but the reverse is never true.3.Design patterns are less specialized than frameworks . Frameworks always have a particular application domain. In contrast, design patterns can be used in nearly anykind of application. While more specialized design patterns are certainly possible,even these wouldn’t dictate an application architecture.
In essence, the designer of a framework will argue that one reusable mini-architecture is applicable to all software to be developed within a limited domain ofapplication. To be most effective, frameworks are applied with no changes. Addi-tional design elements may be added, but only via the plug points that allow thedesigner to flesh out the framework skeleton.
12.1.3 Describing a Pattern
Pattern-based design begins with the recognition of patterns within the applicationyou intend to build, continues with a search to determine whether others haveaddressed the pattern, and concludes with the application of an appropriate patternto the problem at hand. The second of these three tasks is often the most difficult.How do you find patterns that fit your needs?An answer to this question must rely on effective communication of the problemthe pattern addresses, the context in which the pattern resides, the system of forcesthat mold the context, and the solution that is proposed. To communicate thisinformation unambiguously, a standard form or template for pattern descriptions isrequired. Although a number of different pattern templates have been proposed,352 PART TWOMODELING
A frameworkis areusable “mini-architecture” thatserves as a foundationfrom which otherdesign patterns can beapplied.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 352almost all contain a major subset of the content suggested by Gamma and hiscolleagues [Gam95]. A simplified pattern template is shown in the sidebar.CHAPTER 12PATTERN-BASED DESIGN 353
INFO
The names of design patterns should be chosen with care. One of the key techni-cal problems in pattern-based design is the inability to find existing patterns whenhundreds or thousands of candidate patterns exist. The search for the “right” patternis aided immeasurably by a meaningful pattern name.A pattern template provides a standardized means for describing a design pattern.Each of the template entries represents characteristics of the design pattern that canbe searched (e.g., via a database) so that the appropriate pattern can be found.
12.1.4 Pattern Languages and Repositories
When we use the term language,the first thing that comes to mind is either a natu-ral language (e.g., English, Spanish, Chinese) or a programming language (e.g., C /H11001/H11001, Java). In both cases the language has a syntax and semantics that are used to com-municate ideas or procedural instructions in an effective manner.When the term languageis used in the context of design patterns, it takes on aslightly different meaning. A pattern language encompasses a collection of patterns, each described using a standardized template (Section 12.1.3) and interrelated toshow how these patterns collaborate to solve problems across an applicationdomain.
4
In a natural language, words are organized into sentences that impart meaning.The structure of sentences is described by the language’s syntax. In a pattern lan-guage, design patterns are organized in a way that provides a “structured method ofdescribing good design practices within a particular domain.”
5uote:
“Patterns are half-baked—meaningyou always haveto finish themyourself and adaptthem to your ownenvironment.”Martin Fowler
4 Christopher Alexander originally proposed pattern languages for building architecture and urbanplanning. Today, pattern languages have been developed for everything from the social sciences tothe software engineering process.5 This Wikipedia description can be found at http://en.wikipedia.org/wiki/Pattern_language.Design Pattern Template
Pattern name—describes the essence of thepattern in a short but expressive nameProblem—describes the problem that the pattern addressesMotivation—provides an example of the problemContext—describes the environment in which the problemresides including the application domainForces—lists the system of forces that affect the manner inwhich the problem must be solved; includes a discussionof limitations and constraints that must be consideredSolution—provides a detailed description of the solutionproposed for the problemIntent—describes the pattern and what it doesCollaborations—describes how other patterns contribute tothe solutionConsequences—describes the potential trade-offs that mustbe considered when the pattern is implemented andthe consequences of using the patternImplementation—identifies special issues that should beconsidered when implementing the patternKnown uses—provides examples of actual uses of thedesign pattern in real applicationsRelated patterns—cross-references related design patternspre75977_ch12.qxd  11/27/08  3:58 PM  Page 353In a way, a pattern language is analogous to a hypertext instruction manual forproblem solving in a specific application domain. The problem domain under con-sideration is first described hierarchically, beginning with broad design problems as-sociated with the domain and then refining each of the broad problems into lowerlevels of abstraction. In a software context, broad design problems tend to be archi-tectural in nature and address the overall structure of the application and the data orcontent that serve it. Architectural problems are refined to lower levels of abstrac-tion, leading to design patterns that solve subproblems and collaborate with oneanother at the component (or class) level. Rather than a sequential list of patterns,a pattern language represents an interconnected collection in which the user canbegin with a broad design problem and “burrow down” to uncover specific problemsand their solutions.Dozens of pattern languages have been proposed for software design [Hil08]. Inmost cases, the design patterns that are part of pattern language are stored in a Web-accessible patterns repository (e.g., [Boo08], [Cha03], [HPR02]). The repository pro-vides an index of all design patterns and contains hypermedia links that enable theuser to understand the collaborations between patterns.
12.2 P ATTERN -BASED SOFTWARE DESIGN
The best designers in any field have an uncanny ability to see patterns that charac-terize a problem and corresponding patterns that can be combined to create a solu-tion. The software developers at Microsoft [Mic04] discuss this when they write:
While pattern-based design is relatively new in the field of software development, indus-trial technology has used pattern-based design for decades, perhaps even centuries.Catalogs of mechanisms and standard configurations provide design elements that areused to engineer automobiles, aircraft, machine tools, and robots. Applying pattern-based design to software development promises the same benefits to software as it doesto industrial technology: predictability, risk mitigation, and increased productivity.
Throughout the design process, you should look for every opportunity to applyexisting design patterns (when they meet the needs of the design) rather than creat-ing new ones.
12.2.1 Pattern-Based Design in Context
Pattern-based design is not used in a vacuum. The concepts and techniques dis-cussed for architectural, component-level, and user interface design (Chapters 9through 11) are all used in conjunction with a pattern-based approach.In Chapter 8, I noted that a set of quality guidelines and attributes serve as thebasis for all software design decisions. The decisions themselves are influenced bya set of fundamental design concepts (e.g., separation of concerns, stepwise refine-ment, functional independence) that are achieved using heuristics that have evolvedover many decades, and best practices (e.g., techniques, modeling notation) that354 PART TWOMODELING
WebRef
For a listing of usefulpatterns languagesseec2.com/ppr/titles.html.Additional informationcan be obtained athillside.net/patterns/.If you can’t find apattern language thataddresses yourproblem domain, lookfor analogies inanother set ofpatterns.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 354have been proposed to make design easier to perform and more effective as a basisfor construction.The role of pattern-based design in all of this is illustrated in Figure 12.1. A soft-ware designer begins with a requirements model (either explicit or implied) thatpresents an abstract representation of the system. The requirements model describesthe problem set, establishes the context, and identifies the system of forces that holdsway. It may imply the design in an abstract manner, but the requirements modeldoes little to represent the design explicitly.As you begin your work as a designer, it’s always important to keep qualityattributes in mind. These attributes (e.g., a design must implement all explicit require-ments addressed in the requirements model) establish a way to assess software qual-ity but do little to help you actually achieve it. The design you create should exhibitthe fundamental design concepts discussed in Chapter 8. Therefore, you should ap-ply proven techniques for translating the abstractions contained in the requirementsmodel into a more concrete form that is the software design. To accomplish this,you’ll use the methods and modeling tools available for architectural, component-level, and interface design. But only when you’re faced with a problem, context, andsystem of forces that have not been solved before. If a solution already exists, use it!And that means applying a pattern-based design approach.CHAPTER 12PATTERN-BASED DESIGN 355
Design begins
Considerdesign conceptsExtractproblem, contextforcesRequirementsmodel
Considerdesign qualityattributes
Beginpattern-baseddesign tasks Apply otherdesign methodsand notationyes noAddressed bypattern?
DesignmodelFIGURE 12.1
Pattern-baseddesign incontextpre75977_ch12.qxd  11/27/08  3:58 PM  Page 35512.2.2 Thinking in Patterns
In an excellent book on pattern-based design, Shalloway and Trott [Sha05] commenton a “new way of thinking” when one uses patterns as part of the design activity:
I had to open my mind to a new way of thinking. And when I did so, I heard [Christopher]Alexander say that “good software design cannot be achieved simply by adding togetherperforming parts.”
Good design begins by considering context—the big picture. As context is evaluated,you extract a hierarchy of problems that must be solved. Some of these problems willbe global in nature, while others will address specific features and functions of thesoftware. All will be affected by a system of forces that will influence the nature ofthe solution that is proposed.Shalloway and Trott [Sha05] suggest the following approach
6that enables a designer to think in patterns:1.Be sure you understand the big picture—the context in which the software tobe built resides. The requirements model should communicate this to you.2.Examining the big picture, extract the patterns that are present at that levelof abstraction.3.Begin your design with “big picture” patterns that establish a context orskeleton for further design work.4.“Work inward from the context” [Sha05] looking for patterns at lower levelsof abstraction that contribute to the design solution.5.Repeat steps 1 to 4 until the complete design is fleshed out.6.Refine the design by adapting each pattern to the specifics of the softwareyou’re trying to build.It’s important to note that patterns are not independent entities. Design patterns thatare present at a high level of abstraction will invariably influence the manner inwhich other patterns are applied at lower levels of abstraction. In addition, patternsoften collaborate with one another. The implication—when you select an architec-tural pattern, it may very well influence the component-level design patterns youchoose. Likewise, when you select a specific interface design pattern, you are some-times forced to use other patterns that collaborate with it.To illustrate, consider the SafeHomeAssured.com WebApp. If you consider the big picture, the WebApp must address a number of fundamental problems such as:
•How to provide information about SafeHomeproducts and services
•How to sell SafeHomeproducts and services to customers
•How to establish Internet-based monitoring and control of an installedsecurity system356 PART TWOMODELING
Pattern-based designlooks interestingfor the problemI have to solve.How do I getstarted??
6 Based on the work of Christopher Alexander [Ale79].pre75977_ch12.qxd  11/27/08  3:58 PM  Page 356Each of these fundamental problems can be further refined into a set of subprob-lems. For example How to sell via the Internet implies an E-commercepattern that itself implies a large number of patterns at lower levels of abstraction. The E-commercepattern (likely, an architectural pattern) implies mechanisms forsetting up a customer account, displaying the products to be sold, selecting prod-ucts for purchase, and so forth. Hence, if you think in patterns, it is important todetermine whether a pattern for setting up an account exists. If SetUpAccount is available as a viable pattern for the problem context, it may collaborate withother patterns such as BuildInputForm, ManageFormsInput, and Validate- FormsEntry.Each of these patterns delineates problems to be solved and solu-tions that may be applied.
12.2.3 Design Tasks
The following design tasks are applied when a pattern-based design philosophy isused:1.Examine the requirements model and develop a problem hierarchy.Describe each problem and subproblem by isolating the problem, thecontext, and the system of forces that apply. Work from broad problems (highlevel of abstraction) to smaller subproblems (at lower levels of abstraction).2.Determine if a reliable pattern language has been developed for theproblem domain.As I noted in Section 12.1.4, a pattern language addressesproblems associated with a specific application domain. The SafeHome software team would look for a pattern language developed specifically forhome security products. If that level of pattern language specificity could notbe found, the team would partition the SafeHomesoftware problem into a series of generic problem domains (e.g., digital device monitoring problems,user interface problems, digital video management problems) and search forappropriate pattern languages.3.Beginning with a broad problem, determine whether one or morearchitectural patterns is available for it. If an architectural pattern is available, be certain to examine all collaborating patterns. If the pattern isappropriate, adapt the design solution proposed and build a design modelelement that adequately represents it. As I noted in Section 12.2.2, a broadproblem for the SafeHomeAssured.com WebApp is addressed with an E-commercepattern. This pattern will suggest a specific architecture foraddressing e-commerce requirements.4.Using the collaborations provided for the architectural pattern,examine subsystem or component-level problems and search forappropriate patterns to address them. It may be necessary to search through other pattern repositories as well as the list of patterns that corre-sponds to the architectural solution. If an appropriate pattern is found, adaptCHAPTER 12PATTERN-BASED DESIGN 357
What are thetasksrequired to createa pattern-baseddesign??pre75977_ch12.qxd  11/27/08  3:58 PM  Page 357the design solution proposed and build a design model element thatadequately represents it. Be certain to apply step 7.5.Repeat steps 2 through 5 until all broad problems have beenaddressed.The implication is to begin with the big picture and elaborate tosolve problems at increasingly more detailed levels.6.If user interface design problems have been isolated (this is almostalways the case), search the many user interface design patternrepositories for appropriate patterns. Proceed in a manner similar to steps 3, 4, and 5.7.Regardless of its level of abstraction, if a pattern language and/orpatterns repository or individual pattern shows promise, comparethe problem to be solved against the existing pattern(s) presented.Be certain to examine context and forces to ensure that the pattern does, infact, provide a solution that is amenable to the problem.8.Be certain to refine the design as it is derived from patterns usingdesign quality criteria as a guide.Although this design approach is top-down, real-life design solutions are sometimesmore complex. Gillis [Gil06] comments on this when he writes:
Design patterns in software engineering are meant to be used in a deductive, rationalis-tic fashion. So you have this general problem or requirement, X, design pattern Y solvesX, therefore use Y. Now, when I reflect on my own process—and I’ve got reason to believethat I’m not alone here—I find that it’s more organic than that, more inductive thandeductive, more bottom-up than top-down.Obviously, there’s a balance to be achieved. When a project is in the initial bootstrapphase and I’m trying to make the jump from abstract requirements to a concrete designsolution, I’ll often perform a sort of breadth-first search . . . I’ve found design patterns tobe helpful, allowing me to quickly frame up the design problem in concrete terms.
In addition, the pattern-based approach must be used in conjunction with other soft-ware design concepts and techniques.
12.2.4 Building a Pattern-Organizing Table
As pattern-based design proceeds, you may encounter trouble organizing andcategorizing candidate patterns from multiple pattern languages and repositories.To help organize your evaluation of candidate patterns, Microsoft [Mic04] suggeststhe creation of a pattern-organizing table that takes the general form shown in Figure 12.2.A pattern-organizing table can be implemented as a spreadsheet model using theform shown in the figure. An abbreviated list of problem statements, organized bydata/content, architecture, component-level, and user interface issues, is presentedin the left-hand (shaded) column. Four pattern types—database, application,358 PART TWOMODELING
Entries in the table canbe supplemented withan indication of therelative applicabilityof the pattern.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 358implementation, and infrastructure—are listed across the top row. The names ofcandidate patterns are noted in the cells of the table.To provide entries for the organizing table, you’ll search through patternlanguages and repositories for patterns that address a particular problem statement.When one or more candidate patterns is found, it is entered in the row correspon-ding to the problem statement and the column that corresponds to the pattern type.The name of the pattern is entered as a hyperlink to the URL of the Web address thatcontains a complete description of the pattern.
12.2.5 Common Design Mistakes
Pattern-based design can make you a better software designer, but it is not a panacea. Like all design methods, you must begin with first principles, emphasizingsoftware quality fundamentals and ensuring that the design does, in fact, address theneeds expressed by the requirements model.A number of common mistakes occur when pattern-based design is used. In somecases, not enough time has been spent to understand the underlying problem and itscontext and forces, and as a consequence, you select a pattern that looks right butis inappropriate for the solution required. Once the wrong pattern is selected, yourefuse to see your error and force-fit the pattern. In other cases, the problem hasforces that are not considered by the pattern you’ve chosen, resulting in a poor orCHAPTER 12PATTERN-BASED DESIGN 359
Problem statement ...Problem statement ...Problem statement ...User interfaceProblem statement ...Problem statement ...Problem statement ...Component-levelProblem statement ...Problem statement ...Problem statement ...ArchitectureProblem statement ...Problem statement ...Problem statement ... PatternName(s)PatternName(s)PatternName(s)PatternName(s)PatternName(s)PatternName(s) PatternName(s)PatternName(s) PatternName(s)PatternName(s) PatternName(s)PatternName(s) PatternName(s)PatternName(s) PatternName(s)PatternName(s)
PatternName(s)PatternName(s)PatternName(s)PatternName(s)DatabaseData/ContentApplication Implementation InfrastructureFIGURE 12.2
A pattern-organizingtableSource:Adapted from[Mic04].
Don’t force a pattern,even if it addresses theproblem at hand. If thecontext and forces arewrong, look foranother pattern.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 359erroneous fit. Sometimes a pattern is applied too literally and the required adapta-tions for your problem space are not implemented.Can these mistakes be avoided? In most cases the answer is “yes.” Every good de-signer looks for a second opinion and welcomes review of her work. The review tech-niques discussed in Chapter 15 can help to ensure that the pattern-based design you’vedeveloped will result in a high-quality solution for the software problem to be solved.
12.3 A RCHITECTURAL PATTERNS
If a house builder decides to construct a center-hall colonial, there is a single archi-tectural style that can be applied. The details of the style (e.g., number of fireplaces,façade of the house, placement of doors and windows) can vary considerably, but oncethe decision on the overall architecture of the house is made, the style is imposedon the design.
7
Architectural patterns are a bit different. For example, every house (and everyarchitectural style for houses) employs a Kitchen pattern. The Kitchenpattern and patterns it collaborates with address problems associated with the storage andpreparation of food, the tools required to accomplish these tasks, and rules for place-ment of these tools relative to workflow in the room. In addition, the pattern mightaddress problems associated with countertops, lighting, wall switches, a central is-land, flooring, and so on. Obviously, there is more than a single design for a kitchen,often dictated by the context and system of forces. But every design can be conceivedwithin the context of the “solution” suggested by the Kitchen pattern. As I have already noted, architectural patterns for software define a specificapproach for handling some characteristic of the system. Bosch [Bos00] and Booch[Boo08] define a number of architectural pattern domains. Representative examplesare provided in the paragraphs that follow:Access control.There are many situations in which access to data, features, andfunctionality delivered by an application is limited to specifically defined end users.From an architectural point of view, access to some portion of the software archi-tecture must be controlled rigorously.Concurrency.Many applications must handle multiple tasks in a manner that sim-ulates parallelism (i.e., this occurs whenever multiple “parallel” tasks or componentsare managed by a single processor). There are a number of different ways in whichan application can handle concurrency, and each can be presented by a differentarchitectural pattern. For example, one approach is to use an OperatingSystem-ProcessManagementpattern that provides built-in OS features that allow360 PART TWOMODELING
7 This implies that there will be a central foyer and hallway, that rooms will be placed to the left andright of the foyer, that the house will have two (or more) stories, that the bedrooms of the housewill be upstairs, and so on. These “rules” are imposed once the decision is made to use the center-hall colonial style.A software architecturemay have a number ofarchitectural patternsthat address issuessuch as concurrency,persistence, anddistribution.
What aresome typicalarchitecturalpattern domains??pre75977_ch12.qxd  11/27/08  3:58 PM  Page 360components to execute concurrently. The pattern also incorporates OS functionalitythat manages communication between processes, scheduling, and other capabilitiesrequired to achieve concurrency. Another approach might be to define a task sched-uler at the application level. A TaskScheduler pattern contains a set of active ob- jects that each contains a tick()operation [Bos00]. The scheduler periodically invokestick()for each object, which then performs the functions it must perform before re-turning control back to the scheduler which then invokes the tick() operation for the next concurrent object.Distribution.The distribution problem addresses the manner in which systems orcomponents within systems communicate with one another in a distributed environ-ment. Two subproblems are considered: (1) the way in which entities connect to oneanother, and (2) the nature of the communication that occurs. The most commonarchitectural pattern established to address the distribution problem is the Broker pattern. A broker acts as a “middleman” between the client component and a server com-ponent. The client sends a message to the broker (containing all appropriate informationfor the communication to be effected) and the broker completes the connection.Persistence.Data persists if it survives past the execution of the process that createdit. Persistent data are stored in a database or file and may be read or modified by otherprocesses at a later time. In object-oriented environments, the idea of a persistent ob-ject extends the persistence concept a bit further. The values of all of the object’s at-tributes, the general state of the object, and other supplementary information are storedfor future retrieval and use. In general, two architectural patterns are used to achievepersistence—a DatabaseManagementSystempattern that applies the storage and retrieval capability of a DBMS to the application architecture or an Application Level-Persistencepattern that builds persistence features into the application architecture(e.g., word processing software that manages its own document structure).Before any one of the representative architectural patterns noted in the precedingparagraphs can be chosen, it must be assessed for its appropriateness for the appli-cation and the overall architectural style, as well as the context and system of forcesthat it specifies.CHAPTER 12PATTERN-BASED DESIGN 361
Design Pattern Repositories
There are many sources for design patterns avail-able on the Web. Some patterns can be obtainedfrom individually published pattern languages, whileothers are available as part of a patterns portal or patternsrepository. The following Web sources are worth a look:Hillside.nethttp://hillside.net/patterns/One of the Web’s most comprehensive collections ofpatterns and pattern languages.Portland Pattern Repositoryhttp://c2.com/ppr/index.htmlContains pointers to a wide variety of patternsresources and collections.Pattern Indexhttp://c2.com/cgi/wiki?PatternIndex An “eclectic collection of patterns”Booch’s Architecture Patterns Handbookwww.booch.com/architecture/index.jspINFOpre75977_ch12.qxd  11/27/08  3:58 PM  Page 36112.4 C OMPONENT -LEVEL DESIGN PATTERNS
Component-level design patterns provide you with proven solutions that address oneor more subproblems extracted from the requirements model. In many cases, designpatterns of this type focus on some functional element of a system. For example, theSafeHomeAssured.comapplication must address the following design subproblem:How can we get product specifications and related information for any SafeHome device?Having enunciated the subproblem that must be solved, you should now considercontext and the system of forces that affect the solution. Examining the appropriaterequirements model use case, you learn that the consumer uses the specification fora SafeHomedevice (e.g., a security sensor or camera) for informational purposes.However, other information that is related to the specification (e.g., pricing) may beused when e-commerce functionality is selected.The solution to the subproblem involves a search. Since searching is a very com-mon problem, it should come as no surprise that there are many search-relatedpatterns. Looking through a number of patterns repositories, you find the followingpatterns, along with the problem that each solves:AdvancedSearch.Users must find a specific item in a large collection ofitems.HelpWizard.Users need help on a certain topic related to the website orwhen they need to find a specific page within the site.SearchArea.Users must find a page.SearchTips.Users need to know how to control the search engine.362 PART TWOMODELING
Bibliographic reference to hundreds of architecturaland component design patternsUI Patterns CollectionsUI/HCI Patternswww.hcipatterns.org/patterns.htmlJennifer Tidwell’s UI patternswww.time-tripper.com/uipatterns/Mobile UI Design Patternshttp://patterns.littlespringsdesign.com/wikka.php?wakka=MobilePatternsPattern Language for UI Designwww.maplefish.com/todd/papers/Experiences.htmlInteraction Design Library for Gameswww.eelke.com/research/usability.htmlUI Design Patternswww.cs.helsinki.fi/u/salaakso/patterns/Specialized Design Patterns:Aircraft Avionicshttp://g.oswego.edu/dl/acs/acs/acs.htmlBusiness Information Systemswww.objectarchitects.de/arcus/cookbook/Distributed Processingwww.cs.wustl.edu/~schmidt/IBM Patterns for e-Businesswww128.ibm.com/developerworks/patterns/Yahoo! Design Pattern Libraryhttp://developer.yahoo.com/ypatterns/WebPatterns.orghttp://webpatterns.org/pre75977_ch12.qxd  11/27/08  3:58 PM  Page 362SearchResults.Users have to process a list of search results.SearchBox.Users have to find an item or specific information.For SafeHomeAssured.comthe number of products is not particularly large,and each has a relatively simple categorization, so AdvancedSearchand HelpWizardare probably not necessary. Similarly, the search is simple enoughnot to require SearchTips. The description of SearchBox, however, is given (in part) as:
Search Box(Adapted from www.welie.com/patterns/showPattern.php?patternID=search.)Problem:The users need to find an item or specific information.Motivation:Any situation in which a keyword search is applied across acollection of content objects organized as Web pages.Context:Rather than using navigation to acquire information or content,the user wants to do a direct search through content containedon multiple Web pages. Any website that already has primarynavigation. User may want to search for an item in a category.User might want to further specify a query.Forces:The website already has primary navigation. Users may want tosearch for an item in a category. Users might want to furtherspecify a query using simple Boolean operators.Solution:Offer search functionality consisting of a search label, a keywordfield, a filter if applicable, and a “go” button. Pressing the returnkey has the same function as selecting the go button. Also pro-vide Search Tips and examples in a separate page. A link to thatpage is placed next to the search functionality. The edit box forthe search term is large enough to accommodate three typicaluser queries (typically around 20 characters). If the number offilters is more than 2, use a combo box for filters selection,otherwise a radio button.The search results are presented on a new page with a clearlabel containing at least “Search results” or similar. The searchfunction is repeated in the top part of the page with the enteredkeywords, so that the users know what the keywords were.
The pattern description continues with other entries as described in Section 12.1.3.The pattern goes on to describe how the search results are accessed, presented,matched, and so on. Based on this, the SafeHomeAssured.com team can design the components required to implement the search or (more likely) acquire existingreusable components.CHAPTER 12PATTERN-BASED DESIGN 363pre75977_ch12.qxd  11/27/08  3:58 PM  Page 36312.5 U SERINTERFACE DESIGN PATTERNS
Hundreds of user interface (UI) patterns have been proposed in recent years. Mostfall within one of the following 10 categories of patterns (discussed with a represen-tative example
8) as described by Tidwell [Tid02] and vanWelie [Wel01]:Whole UI.Provide design guidance for top-level structure and navigationthroughout the entire interface.Pattern: TopLevelNavigationBrief description:Used when a site or application implements a numberof major functions. Provides a top-level menu, often coupled with a logo or364 PART TWOMODELING
8 An abbreviated pattern template is used here. Full pattern descriptions (along with dozens of otherpatterns) can be found at [Tid02] and [Wel01].Applying Patterns
The scene:Informal discussion duringthe design of a software increment that implements sensorcontrol via the Internet for SafeHomeAssured.com.The players:Jamie (responsible for design) and Vinod(SafeHomeAssured.comchief system architect).The conversation:Vinod:So how is the design of the camera controlinterface coming along?Jamie:Not too bad. I’ve designed most of the capabilityto connect to the actual sensors without too many problems.I’ve also started thinking about the interface for the users toactually move, pan, and zoom the cameras from a remoteWeb page, but I’m not sure I’ve got it right yet.Vinod:What have you come up with?Jamie:Well, the requirements are that the camera controlneeds to be highly interactive—as the user moves the control,the camera should move as soon as possible. So, I wasthinking of having a set of buttons laid out like a normalcamera, but when the user clicks them, it controls the camera.Vinod:Hmmm. Yeah, that would work, but I’m not sureit’s right—for each click of a control you need to wait forthe whole client-server communication to occur, and soyou won’t get a good sense of quick feedback.Jamie:That’s what I thought—and why I wasn’t veryhappy with the approach, but I’m not sure how elseI might do it.Vinod:Well, why not just use theInteractiveDeviceControlpattern!Jamie:Uhmmm—what’s that? I haven’t heard of it?Vinod:It’s basically a pattern for exactly the problemyou are describing. The solution it proposes is basically tocreate a control connection to the server with the device,through which control commands can be sent. That wayyou don’t need to send normal HTTP requests. And thepattern even shows how you can implement this usingsome simple AJAX techniques. You have some simpleclient-side JavaScript that communicates directly with theserver and sends the commands as soon as the user doesanything.Jamie:Cool! That’s just what I needed to solve thisthing. Where do I find it?Vinod:It’s available in an online repository. Here’sthe URL.Jamie:I’ll go check it out.Vinod:Yep—but remember to check the consequencesfield for the pattern. I seem to remember that there wassomething in there about needing to be careful aboutissues of security. I think it might be because you arecreating a separate control channel and so bypassing thenormal Web security mechanisms.Jamie:Good point. I probably wouldn’t have thoughtof that! Thanks.SAFEHOMEpre75977_ch12.qxd  11/27/08  3:58 PM  Page 364CHAPTER 12PATTERN-BASED DESIGN 365
identifying graphic, that enables direct navigation to any of the system’smajor functions.Details:Major functions (generally limited to between four and seven func-tion names) are listed across the top of the display (vertical column formatsare also possible) in a horizontal line of text. Each name provides a link tothe appropriate function or information source. Often used with theBreadCrumbspattern discussed later.Navigation elements:Each function/content name represents a link to theappropriate function or content.Page layout.Address the general organization of pages (for websites) or distinctscreen displays (for interactive applications).Pattern: CardStackBrief description:Used when a number of specific subfunctions or contentcategories related to a feature or function must be selected in random order.Provides the appearance of a stack of tabbed cards, each selectable witha mouse click and each representing specific subfunctions or contentcategories.Details:Tabbed cards are a well-understood metaphor and are easy for theuser to manipulate. Each tabbed card (divider) may have a slightly differentformat. Some may require input and have buttons or other navigation mech-anisms; others may be informational. May be combined with other patternssuch as DropDownList,Fill-in-the-Blanks,and others. Navigation elements:A mouse click on a tab causes the appropriate cardto appear. Navigation features within the card may also be present, but ingeneral, these should initiate a function that is related to card data, not causean actual link to some other display.Forms and input.Consider a variety of design techniques for completing form-level input.Pattern: Fill-in-the-BlanksBrief description:Allow alphanumeric data to be entered in a “text box.”Details:Data may be entered within a text box. In general, the data arevalidated and processed after some text or graphic indicator (e.g., a buttoncontaining “go,” “submit,” “next”) is picked. In many cases this pattern can becombined with drop-down list or other patterns (e.g., SEARCH <drop downlist> FOR <fill-in-the-blankstext box>).Navigation elements:A text or graphic indicator that initiates validationand processing.Tables.Provide design guidance for creating and manipulating tabular data of allkinds.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 365Pattern: SortableTableBrief description:Display a long list of records that can be sorted byselecting a toggle mechanism for any column label.Details:Each row in the table represents a complete record. Each columnrepresents one field in the record. Each column header is actually a selec-table button that can be toggled to initiate an ascending or descending sorton the field associated with the column for all records displayed. The table isgenerally resizable and may have a scrolling mechanism if the number ofrecords is larger than available window space.Navigation elements:Each column header initiates a sort on all records.No other navigation is provided, although in some cases, each record mayitself contain navigation links to other content or functionality.Direct data manipulation.Address data editing, modification, and transformation.Pattern: BreadCrumbsBrief description:Provides a full navigation path when the user is workingwith a complex hierarchy of pages or display screens.Details:Each page or display screen is given a unique identifier. The naviga-tion path to the current location is specified in a predefined location for everydisplay. The path takes the form: home>major topic page>subtopic page>specific page>current page.Navigation elements:Any of the entries within the bread crumbs displaycan be used as a pointer to link back to a higher level of the hierarchy.Navigation.Assist the user in navigating through hierarchical menus, Webpages, and interactive display screens.Pattern: EditInPlaceBrief description:Provide simple text editing capability for certain types ofcontent in the location that it is displayed. No need for the user to enter a textediting function or mode explicitly.Details:The user sees content on the display that must be changed. Amouse double click on the content indicates to the system that editing isdesired. The content is highlighted to signify that editing mode is availableand the user makes appropriate changes.Navigation elements:None.Searching.Enable content-specific searches through information maintainedwithin a website or contained by persistent data stores that are accessible via aninteractive application.Pattern: SimpleSearchBrief description:Provides the ability to search a website or persistent datasource for a simple data item described by an alphanumeric string.366 PART TWOMODELINGpre75977_ch12.qxd  11/27/08  3:58 PM  Page 366Details:Provides the ability to search either locally (one page or one file) orglobally (entire site or complete database) for the search string. Generates alist of “hits” in order of their probability of meeting the user’s needs. Does notprovide multiple item searches or special Boolean operations (see advancedsearch pattern).Navigation elements:Each entry in the list of hits represents a navigationlink to the data referenced by the entry.Page elements.Implement specific elements of a Web page or display screen.Pattern: WizardBrief description:Takes the user through a complex task one step at atime, providing guidance for the completion of the task through a series ofsimple window displays.Details:Classic example is a registration process that contains four steps.The wizard pattern generates a window for each step, requesting specificinformation from the user one step at a time.Navigation elements:Forward and back navigation allows the user torevisit each step in the wizard process.E-commerce.Specific to websites, these patterns implement recurring elementsof e-commerce applications.Pattern: ShoppingCartBrief description:Provides a list of items selected for purchase.Details:Lists item, quantity, product code, availability (in stock, out of stock),price, delivery information, shipping costs, and other relevant purchase infor-mation. Also provides ability to edit (e.g., remove, change quantity).Navigation elements:Contains ability to proceed with shopping or go tocheckout.Miscellaneous.Patterns that do not easily fit into one of the preceding cate-gories. In some cases, these patterns are domain dependent or occur only forspecific classes of users.Pattern: ProgressIndicatorBrief description:Provides an indication of progress when an operationtakes longer than nseconds.Details:Represented as an animated icon or a message box that containssome visual indication (e.g., a rotating “barber pole,” a slider with a percentcomplete indicator) that processing is under way. May also contain a textcontent indication of the status of processing.Navigation elements:Often contains a button that allows the user topause or cancel processing.CHAPTER 12PATTERN-BASED DESIGN 367pre75977_ch12.qxd  11/27/08  3:58 PM  Page 367Each of the preceding example patterns (and all patterns within each category)would also have a complete component-level design, including design classes,attributes, operations, and interfaces.A comprehensive discussion of user interface patterns is beyond the scope of thisbook. If you have further interest, see [Duy02], [Bor01], [Tid02], and [Wel01] forfurther information.
12.6 W EBAPPDESIGN PATTERNS
Throughout this chapter you’ve learned that there are different types of patterns andmany different ways they can be categorized. When you consider the design prob-lems that must be solved when a WebApp is to be built, it’s worth considering pat-tern categories by focusing on two dimensions: the design focus of the pattern andits level of granularity. Design focusidentifies which aspect of the design model isrelevant (e.g., information architecture, navigation, interaction). Granularity identi- fies the level of abstraction that is being considered (e.g., does the pattern apply tothe entire WebApp, to a single Web page, to a subsystem, or an individual WebAppcomponent?).
12.6.1 Design Focus
In earlier chapters I emphasized a design progression that begins by consideringarchitecture, component-level issues, and user interface representations. At eachstep, the problems you consider and the solutions you propose begin at a high levelof abstraction and slowly become more detailed and specific. Stated another way,design focus becomes “narrower” as you move further into design. The problems(and solutions) you will encounter when designing an information architecture for aWebApp are different from the problems (and solutions) that are encountered whenperforming interface design. Therefore, it should come as no surprise that patternsfor WebApp design can be developed for different levels of design focus, so that youcan address the unique problems (and related solutions) that are encountered ateach level. WebApp patterns can be categorized using the following levels ofdesign focus:
•Information architecture patternsrelate to the overall structure ofthe information space, and the ways in which users will interact with theinformation.
•Navigation patternsdefine navigation link structures, such as hierarchies,rings, tours, and so on.
•Interaction patternscontribute to the design of the user interface. Patternsin this category address how the interface informs the user of the conse-quences of a specific action, how a user expands content based on usage368 PART TWOMODELING
Your focus becomes“narrower” the furtheryou move into design.pre75977_ch12.qxd  11/27/08  3:58 PM  Page 368context and user desires, how to best describe the destination that is impliedby a link, how to inform the user about the status of an ongoing interaction,and interface-related issues.
•Presentation patternsassist in the presentation of content as it is presentedto the user via the interface. Patterns in this category address how to organizeuser interface control functions for better usability, how to show the relation-ship between an interface action and the content objects it affects, and howto establish effective content hierarchies.
•Functional patternsdefine the workflows, behaviors, processing, commu-nication, and other algorithmic elements within a WebApp.In most cases, it would be fruitless to explore the collection of information architec-ture patterns when a problem in interaction design is encountered. You would ex-amine interaction patterns, because that is the design focus that is relevant to thework being performed.
12.6.2 Design Granularity
When a problem involves “big picture” issues, you should attempt to developsolutions (and use relevant patterns) that focus on the big picture. Conversely, whenthe focus is very narrow (e.g., uniquely selecting one item from a small set of five orfewer items), the solution (and the corresponding pattern) is targeted quite nar-rowly. In terms of the level of granularity, patterns can be described at the follow-ing levels:
•Architectural patterns.This level of abstraction will typically relate topatterns that define the overall structure of the WebApp, indicate the rela-tionships among different components or increments, and define the rulesfor specifying relationships among the elements (pages, packages, compo-nents, subsystems) of the architecture.
•Design patterns.These address a specific element of the design such asan aggregation of components to solve some design problem, relationshipsamong elements on a page, or the mechanisms for effecting component-to-component communication. An example might be the Broadsheetpattern for the layout of a WebApp home page.
•Component patterns.This level of abstraction relates to individual small-scale elements of a WebApp. Examples include individual interactionelements (e.g., radio buttons), navigation items (e.g., how might you formatlinks?) or functional elements (e.g., specific algorithms).It is also possible to define the relevance of different patterns to different classesof applications or domains. For example, a collection of patterns (at different levelsof design focus and granularity) might be particularly relevant to e-business.CHAPTER 12PATTERN-BASED DESIGN 369pre75977_ch12.qxd  11/27/08  3:58 PM  Page 369370 PART TWOMODELING
12.7 S UMMARY
Design patterns provide a codified mechanism for describing problems and theirsolution in a way that allows the software engineering community to capture designknowledge for reuse. A pattern describes a problem, indicates the context enablingthe user to understand the environment in which the problem resides, and lists a sys-tem of forces that indicate how the problem can be interpreted within its context andhow the solution can be applied. In software engineering work, we identify and doc-ument generative patterns that describe an important and repeatable aspect of a sys-tem and then provide us with a way to build that aspect within a system of forcesthat is unique to a given context.Architectural patterns describe broad-based design problems that are solvedusing a structural approach. Data patterns describe recurring data-oriented prob-lems and the data modeling solutions that can be used to solve them. Componentpatterns (also referred to as design patterns) address problems associated with thedevelopment of subsystems and components, the manner in which they communi-cate with one another, and their placement within a larger architecture. Interfacedesign patterns describe common user interface problems and their solution witha system of forces that includes the specific characteristics of end users. WebApppatterns address a problem set that is encountered when building WebApps and of-ten incorporates many of the other patterns categories just mentioned. A frameworkHypermedia Design Patterns Repositories
The IAWiki website (http://iawiki.net/WebsitePatterns), a collaborativediscussion space for information architects, containsmany useful resources. Among them are links to a number of useful hypermedia patterns catalogs andrepositories. Hundreds of design patterns are represented:Hypermedia Design Patterns Repositorywww.designpattern.lu.unisi.ch/InteractionPatterns by Tom Ericksonwww.pliant.org/personal/Tom_Erickson/InteractionPatterns.htmlWeb Design Patterns by Martijn vanWeliewww.welie.com/patterns/Web Patterns for UI Design http://harbinger.sims.berkeley.edu/ui_designpatterns/webpatterns2/webpatterns/home.phpPatterns for Personal Websiteswww.rdrop.com/%7Ehalf/Creations/Writings/Web.patterns/index.htmlImproving Web Information Systems with NavigationalPatternshttp://www8.org/w8-papers/5b-hypertext-media/improving/improving.htmlAn HTML 2.0 Pattern Languagewww.anamorph.com/docs/patterns/default.htmlCommon Ground—A Pattern Language for HCI Designwww.mit.edu/~jtidwell/interaction_patterns.htmlPatterns for Personal Websites www.rdrop.com/~half/Creations/Writings/Web.patterns/index.htmlIndexing Pattern Languagewww.cs.brown.edu/~rms/InformationStructures/Indexing/Overview.htmlINFOpre75977_ch12.qxd  11/27/08  3:58 PM  Page 370provides an infrastructure in which patterns may reside and idioms describe pro-gramming language–specific implementation detail for all or part of a specific algo-rithm or data structure. A standard form or template is used for pattern descriptions.A pattern language encompasses a collection of patterns, each described using astandardized template and interrelated to show how these patterns collaborate tosolve problems across an application domain.Pattern-based design is used in conjunction with architectural, component-level,and user interface design methods. The design approach begins with an examina-tion of the requirements model to isolate problems, define context, and describe thesystem of forces. Next, pattern languages for the problem domain are searched todetermine if patterns exist for the problems that have been isolated. Once appropri-ate patterns have been found, they are used as a design guide.
PROBLEMS AND POINTS TO PONDER
12.1.Discuss the three “parts” of a design pattern and provide a concrete example of each fromsome field other than software.12.2.What is the difference between a nongenerative and a generative pattern?12.3.How do architectural patterns differ from component patterns?12.4.What is a framework and how does it differ from a pattern? What is an idiom and howdoes it differ from a pattern?12.5.Using the design pattern template presented in Section 12.1.3, develop a completepattern description for a pattern suggested by your instructor.12.6.Develop a skeletal pattern language for a sport with which you are familiar. You canbegin by addressing the context, the system of forces, and the broad problems that a coach andteam must solve. You need only specify pattern names and provide a one-sentence descriptionfor each pattern.12.7.Find five patterns repositories and present an abbreviated description of the types ofpatterns contained in each.12.8.When Christopher Alexander says “good design cannot be achieved simply by addingtogether performing parts,” what do you think he means?12.9.Using the pattern-based design tasks noted in Section 12.2.3, develop a skeletal designfor the “interior design system” described in Section 11.3.2.12.10.Build a pattern-organizing table for the patterns you used in Problem 12.9.12.11.Using the design pattern template presented in Section 12.1.3, develop a completepattern description for the Kitchen pattern mentioned in Section 12.3.12.12.The gang of four [Gam95] have proposed a variety of component patterns that areapplicable to object-oriented systems. Select one (these are available on the Web) anddiscuss it.12.13.Find three patterns repositories for user interface patterns. Select one pattern from eachand present an abbreviated description of it.12.14.Find three patterns repositories for WebApp patterns. Select one pattern from each andpresent an abbreviated description of it.CHAPTER 12PATTERN-BASED DESIGN 371pre75977_ch12.qxd  11/27/08  3:58 PM  Page 371FURTHER READING AND INFORMATION SOURCES
Over the past decade, many books on pattern-based design have been written for softwareengineers. Gamma and his colleagues [Gam95] have written the seminal book on the subject.More recent contributions include books by Lasater (Design Patterns, Wordware Publishing, Inc., 2007), Holzner (Design Patterns for Dummies, For Dummies, 2006), Freeman and her colleagues (Head First Design Patterns,O’Reilly Media, Inc., 2005), and Shalloway and Trott ( Design Patterns Explained,2d. ed., Addison-Wesley, 2004). A special issues of IEEE Software (July/August, 2007) discusses a wide variety of software patterns topics. Kent Beck (Implementation Patterns,Addison-Wesley, 2008) addresses patterns for coding and implementation issues that areencountered during the construction activity.Other books focus on design patterns as they are supplied in specific application develop-ment and language environments. Contributions in this area include: Bowers (Pro CSS andHTML Design Patterns,Apress, 2007), Tropashko and Burleson (SQL Design Patterns: Expert Guideto SQL Programming,Rampant Techpress, 2007), Mahemoff ( Ajax Design Patterns,O’Reilly Media, Inc., 2006), Metsker and Wake (Design Patterns in Java, Addison-Wesley, 2006), Nilsson (Applying Domain-Driven Design and Patterns: With Examples in C# and .NET, Addison-Wesley, 2006), Sweat (PHPArchitect’s Guide to PHP Design Patterns, Marco Tabini & Associates, Inc., 2005), Metsker (Design Patterns C#, Addison-Wesley, 2004), Grand and Merrill (Visual Basic .NET Design Patterns,Wiley, 2003), Crawford and Kaplan ( J2EE Design Patterns,O’Reilly Media, Inc., 2003), Juric et al. (J2EE Design Patterns Applied,Wrox Press, 2002), and Marinescu and Roman (EJB Design Patterns,Wiley, 2002).Still other books address specific application domains. These include contributions byKuchana (Software Architecture Design Patterns in Java, Auerbach, 2004), Joshi (C/H11001/H11001Design Patterns and Derivatives Pricing,Cambridge University Press, 2004), Douglass (Real-Time DesignPatterns,Addison-Wesley, 2002), and Schmidt and Rising ( Design Patterns in Communication Software,Cambridge University Press, 2001).Classic books by the architect Christopher Alexander (Notes on the Synthesis of Form, Harvard University Press, 1964, and A Pattern Language: Towns, Buildings, Construction, Oxford Univer- sity Press, 1977) are worthwhile reading for a software designer who intends to fully understanddesign patterns.A wide variety of information sources on pattern-based design are available on the Internet.An up-to-date list of World Wide Web references that are relevant to pattern-based design canbe found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.372 PART TWOMODELINGpre75977_ch12.qxd  11/27/08  3:58 PM  Page 372In his authoritative book on Web design, Jakob Nielsen [Nie00] states: “Thereare essentially two basic approaches to design: the artistic ideal of expressingyourself and the engineering ideal of solving a problem for a customer.” Dur-ing the first decade of Web development, the artistic idea was the approach thatmany developers chose. Design occurred in an ad hoc manner and was usuallyconducted as HTML was generated. Design evolved out of an artistic vision thatevolved as WebApp construction occurred.Even today, many Web developers use WebApps as poster children for “limiteddesign.” They argue that WebApp immediacy and volatility mitigate againstformal design; that design evolves as an application is built (coded), and thatrelatively little time should be spent on creating a detailed design model. Thisargument has merit, but only for relatively simple WebApps. When content and
373CHAPTER
13WEBAPPDESIGN
What is it? Design for WebAppsencompasses technical and nontech-nical activities that include: establish-ing the look and feel of the WebApp,creating the aesthetic layout of the user inter-face, defining the overall architectural structure,developing the content and functionality thatreside within the architecture, and planning thenavigation that occurs within the WebApp.
Who does it? Web engineers, graphic designers,content developers, and other stakeholders allparticipate in the creation of a WebApp designmodel.
Why is it important? Design allows you to createa model that can be assessed for quality andimproved before content and code are gener-ated, tests are conducted, and end users becomeinvolved in large numbers. Design is the placewhere WebApp quality is established.
What are the steps? WebApp design encom-passes six major steps that are driven by informa-tion obtained during requirements modeling.Content design uses the content model (developedduring analysis) as the basis for establishingQUICK
LOOKthe design of content objects. Aesthetic design(also called graphic design) establishes the lookand feel that the end user sees. Architecturaldesign focuses on the overall hypermedia struc-ture of all content objects and functions.Interface design establishes the layout and inter-action mechanisms that define the user interface.Navigation design defines how the end usernavigates through the hypermedia structure,and component design represents the detailedinternal structure of functional elements of theWebApp.
What is the work product? A design model thatencompasses content, aesthetics, architecture,interface, navigation, and component-level de-sign issues is the primary work product that isproduced during WebApp design.
How do I ensure that I’ve done it right? Eachelement of the design model is reviewed in aneffort to uncover errors, inconsistencies, or omis-sions. In addition, alternative solutions are con-sidered, and the degree to which the currentdesign model will lead to an effective implemen-tation is also assessed.KEY
CONCEPTScontentarchitecture  . . .384objects . . . . . . .382designaesthetic  . . . . .380architectural  . . .383component-level  . . . . . . . .390content  . . . . . .382goals  . . . . . . . .377graphic . . . . . . .381navigation  . . . .388pre75977_ch13.qxd  11/27/08  5:47 PM  Page 373function are complex; when the size of the WebApp encompasses hundreds or thou-sands of content objects, functions, and analysis classes; and when the success ofthe WebApp will have a direct impact on the success of the business, design cannotand should not be taken lightly.This reality leads us to Nielsen’s second approach—“the engineering ideal of solv-ing a problem for a customer.” Web engineering
1adopts this philosophy, and a more rigorous approach to WebApp design enables developers to achieve it.374 PART TWOMODELING
pyramid  . . . . . .378quality  . . . . . . .374MVCarchitecture  . . . .386OOHDM  . . . . . . .390WebApparchitecture  . . . .386
1Web engineering[Pre08] is an adapted version of the software engineering approach that is pre-sented throughout this book. It proposes an agile, yet disciplined framework for building industry-quality Web-based systems and applications.2 These quality attributes are quite similar to those presented in Chapters 8 and 14. The implication:quality characteristics are universal for all software.13.1 W EBAPPDESIGN QUALITY
Design is the engineering activity that leads to a high-quality product. This leads usto a recurring question that is encountered in all engineering disciplines: Whatis quality? In this section I’ll examine the answer within the context of WebAppdevelopment.Every person who has surfed the Web or used a corporate Intranet has an opin-ion about what makes a “good” WebApp. Individual viewpoints vary widely. Someusers enjoy flashy graphics; others want simple text. Some demand copiousinformation; others desire an abbreviated presentation. Some like sophisticated an-alytical tools or database access; others like to keep it simple. In fact, the user’s per-ception of “goodness” (and the resultant acceptance or rejection of the WebApp as aconsequence) might be more important than any technical discussion of WebAppquality.But how is WebApp quality perceived? What attributes must be exhibited toachieve goodness in the eyes of end users and at the same time exhibit the techni-cal characteristics of quality that will enable you to correct, adapt, enhance, and sup-port the application over the long term?In reality, all of the technical characteristics of design quality discussed in Chapter 8and the generic quality attributes presented in Chapter 14 apply to WebApps. How-ever, the most relevant of these generic attributes—usability, functionality, reliabil-ity, efficiency, and maintainability—provide a useful basis for assessing the quality ofWeb-based systems.Olsina and his colleagues [Ols99] have prepared a “quality requirement tree” thatidentifies a set of technical attributes—usability, functionality, reliability, efficiency,and maintainability—that lead to high-quality WebApps.
2Figure 13.1 summarizes their work. The criteria noted in the figure are of particular interest if you design,build, and maintain WebApps over the long term.uote:
“If products aredesigned to betterfit the naturaltendencies ofhuman behavior,then people willbe more satisfied,more fulfilled, andmore productive.”SusanWeinschenkpre75977_ch13.qxd  11/27/08  5:47 PM  Page 374Offutt [Off02] extends the five major quality attributes noted in Figure 13.1 byadding the following attributes:Security.WebApps have become heavily integrated with critical corporate andgovernment databases. E-commerce applications extract and then store sensitivecustomer information. For these and many other reasons, WebApp security is para-mount in many situations. The key measure of security is the ability of the WebAppand its server environment to rebuff unauthorized access and/or thwart an outrightmalevolent attack. A detailed discussion of WebApp security is beyond the scope ofthis book. If you have further interest, see [Vac06], [Kiz05], or [Kal03].Availability.Even the best WebApp will not meet users’ needs if it is unavailable.In a technical sense, availability is the measure of the percentage of time that aWebApp is available for use. The typical end user expects WebApps to be available24/7/365. Anything less is deemed unacceptable.
3But “up-time” is not the only in- dicator of availability. Offutt [Off02] suggests that “using features available on onlyone browser or one platform” makes the WebApp unavailable to those with a differ-ent browser/platform configuration. The user will invariably go elsewhere.Scalability.Can the WebApp and its server environment be scaled to handle 100,1000, 10,000, or 100,000 users? Will the WebApp and the systems with which it isinterfaced handle significant variation in volume or will responsiveness drop dra-matically (or cease altogether)? It is not enough to build a WebApp that is successful.It is equally important to build a WebApp that can accommodate the burden of suc-cess (significantly more end users) and become even more successful.CHAPTER 13WEBAPP DESIGN 375
WebapplicationqualityUsabilityGlobal site understandabilityOnline feedback and help featuresInterface and aesthetic featuresSpecial featuresSearching and retrieving capabilityNavigation and browsing featuresApplication domain-related featuresCorrect link processingError recoveryUser input validation and recovery
Ease of correctionAdaptabilityExtensibilityResponse time performancePage generation speedGraphics generation speedFunctionalityReliabilityEfficiencyMaintainabilityFIGURE 13.1
Qualityrequirementstree.Source:[Ols99].
What arethe majorattributes ofquality forWebApps??
3 This expectation is, of course, unrealistic. Major WebApps must schedule “downtime” for fixes andupgrades.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 375Time-to-market.Although time-to-market is not a true quality attribute in thetechnical sense, it is a measure of quality from a business point of view. The firstWebApp to address a specific market segment often captures a disproportionatenumber of end users.376 PART TWOMODELING
The following checklist, adapted frominformation presented at Webreference.com , provides a set of questions that will help both Webdesigners and end users assess overall WebApp quality:•Can content and/or function and/or navigation optionsbe tailored to the user’s preferences?•Can content and/or functionality be customized to thebandwidth at which the user communicates?•Have graphics and other nontext media been usedappropriately? Are graphics file sizes optimized fordisplay efficiency?•Are tables organized and sized in a manner that makesthem understandable and displayed efficiently?•Is HTML optimized to eliminate inefficiencies?•Is the overall page design easy to read and navigate?•Do all pointers provide links to information that is ofinterest to users?•Is it likely that most links have persistence on the Web?•Is the WebApp instrumented with site managementutilities that include tools for usage tracking, link testing,local searching, and security?INFO
WebApp Design—Quality Checklist
Billions of Web pages are available for those in search of information. Even well-targeted Web searches result in an avalanche of content. With so many sourcesof information to choose from, how does the user assess the quality (e.g., veracity,accuracy, completeness, timeliness) of the content that is presented within a WebApp?Tillman [Til00] suggests a useful set of criteria for assessing the quality of content:
•Can the scope and depth of content be easily determined to ensure that itmeets the user’s needs?
•Can the background and authority of the content’s authors be easily identified?
•Is it possible to determine the currency of the content, the last update, andwhat was updated?
•Are the content and its location stable (i.e., will they remain at the referencedURL)?In addition to these content-related questions, the following might be added:
•Is content credible?
•Is content unique? That is, does the WebApp provide some unique benefit tothose who use it?
•Is content valuable to the targeted user community?
•Is content well organized? Indexed? Easily accessible?The checklists noted in this section represent only a small sampling of the issues thatshould be addressed as the design of a WebApp evolves.What shouldwe considerwhen assessingcontent quality??pre75977_ch13.qxd  11/27/08  5:47 PM  Page 37613.2 D ESIGN GOALS
In her regular column on Web design, Jean Kaiser [Kai02] suggests a set of designgoals that are applicable to virtually every WebApp regardless of application domain,size, or complexity:Simplicity.Although it may seem old-fashioned, the aphorism “all things in mod-eration” applies to WebApps. There is a tendency among some designers to providethe end user with “too much”—exhaustive content, extreme visuals, intrusive ani-mation, enormous Web pages, the list is long. Better to strive for moderation andsimplicity.Content should be informative but succinct and should use a delivery mode(e.g., text, graphics, video, audio) that is appropriate to the information that is beingdelivered. Aesthetics should be pleasing, but not overwhelming (e.g., too many colorstend to distract the user rather than enhancing the interaction). Architecture shouldachieve WebApp objectives in the simplest possible manner. Navigation should bestraightforward and navigation mechanisms should be intuitively obvious to the enduser. Functions should be easy to use and easier to understand.Consistency.This design goal applies to virtually every element of the designmodel. Content should be constructed consistently (e.g., text formatting and fontstyles should be the same across all text documents; graphic art should have a con-sistent look, color scheme, and style). Graphic design (aesthetics) should present aconsistent look across all parts of the WebApp. Architectural design should establishtemplates that lead to a consistent hypermedia structure. Interface design should de-fine consistent modes of interaction, navigation, and content display. Navigationmechanisms should be used consistently across all WebApp elements. As Kaiser[Kai02] notes: “Remember that to a visitor, a Web site is a physical place. It is con-fusing if pages within a site are not consistent in design.“Identity.The aesthetic, interface, and navigational design of a WebApp must beconsistent with the application domain for which it is to be built. A website for a hip-hop group will undoubtedly have a different look and feel than a WebApp designedfor a financial services company. The WebApp architecture will be entirely different,interfaces will be constructed to accommodate different categories of users; naviga-tion will be organized to accomplish different objectives. You (and other design con-tributors) should work to establish an identity for the WebApp through the design.Robustness.Based on the identity that has been established, a WebApp oftenmakes an implicit “promise” to a user. The user expects robust content and functionsthat are relevant to the user’s needs. If these elements are missing or insufficient, itis likely that the WebApp will fail.Navigability.I have already noted that navigation should be simple and consis-tent. It should also be designed in a manner that is intuitive and predictable. That is,CHAPTER 13WEBAPP DESIGN 377
uote:
“Just because youcan, doesn’t meanyou should.”Jean Kaiser
uote:
“To some, Webdesign focuses onvisual look andfeel . . . To others,Web design isabout structuringinformation andnavigation throughthe documentspace. Others mighteven consider Webdesign to be aboutthe technology . . .In reality, designincludes all of thesethings and maybemore.”Thomas Powellpre75977_ch13.qxd  11/27/08  5:47 PM  Page 377the user should understand how to move about the WebApp without having tosearch for navigation links or instructions. For example, if a field of graphic icons orimages contains selected icons or images that will be used as navigation mecha-nisms, these must be identified visually. Nothing is more frustrating than trying tofind the appropriate live link among many graphical images.It is also important to position links to major WebApp content and functions in apredictable location on every Web page. If page scrolling is required (and this is oftenthe case), links at the top and bottom of the page make the user’s navigation taskseasier.Visual Appeal.Of all software categories, Web applications are unquestionablythe most visual, the most dynamic, and the most unapologetically aesthetic. Beauty(visual appeal) is undoubtedly in the eye of the beholder, but many design charac-teristics (e.g., the look and feel of content; interface layout; color coordination; thebalance of text, graphics, and other media; navigation mechanisms) do contribute tovisual appeal.Compatibility.A WebApp will be used in a variety of environments (e.g., differenthardware, Internet connection types, operating systems, browsers) and must bedesigned to be compatible with each.
13.3 A D ESIGN PYRAMID FOR WEBAPPS
What is WebApp design? This simple question is more difficult to answer than onemight believe. In our book [Pre08] on Web engineering, David Lowe and I discuss thiswhen we write:
The creation of an effective design will typically require a diverse set of skills. Sometimes,for small projects, a single developer may need to be multi-skilled. For larger projects, itmay be advisable and/or feasible to draw on the expertise of specialists: Web engineers,graphic designers, content developers, programmers, database specialists, informationarchitects, network engineers, security experts, and testers. Drawing on these diverseskills allows the creation of a model that can be assessed for quality and improved before content and code are generated, tests are conducted, and end-users become involved inlarge numbers. If analysis is where WebApp quality is established, then design is where the quality is truly embedded.
The appropriate mix of design skills will vary depending upon the nature of theWebApp. Figure 13.2 depicts a design pyramid for WebApps. Each level of the pyra-mid represents a design action that is described in the sections that follow.
13.4 W EBAPPINTERFACE DESIGN
When a user interacts with a computer-based system, a set of fundamentalprinciples and overriding design guidelines apply. These have been discussed in378 PART TWOMODELING
uote:
“If a site isperfectly usablebut it lacks anelegant andappropriate designstyle, it will fail.”Curt Cloningerpre75977_ch13.qxd  11/27/08  5:47 PM  Page 378Chapter 11.4Although WebApps present a few special user interface design chal-lenges, the basic principles and guidelines are applicable.One of the challenges of interface design for WebApps is the indeterminate natureof the user’s entry point. That is, the user may enter the WebApp at a “home” loca-tion (e.g., the home page) or may be linked into some lower level of the WebApparchitecture. In some cases, the WebApp can be designed in a way that reroutes theuser to a home location, but if this is undesirable, the WebApp design must provideinterface navigation features that accompany all content objects and are availableregardless of how the user enters the system.The objectives of a WebApp interface are to: (1) establish a consistent windowinto the content and functionality provided by the interface, (2) guide the userthrough a series of interactions with the WebApp, and (3) organize the navigationoptions and content available to the user. To achieve a consistent interface, youshould first use aesthetic design (Section 13.5) to establish a coherent “look.” Thisencompasses many characteristics, but must emphasize the layout and form of nav-igation mechanisms. To guide user interaction, you may draw on an appropriatemetaphor
5that enables the user to gain an intuitive understanding of the interface.To implement navigation options, you can select from one of a number of interac-tion mechanisms:
•Navigation menus—keyword menus (organized vertically or horizontally) thatlist key content and/or functionality. These menus may be implemented soCHAPTER 13WEBAPP DESIGN 379
InterfacedesignAesthetic designContent designNavigation designArchitecture designComponent designuser
technologyFIGURE 13.2
A designpyramid forWebApps
4 Section 11.5 is dedicated to WebApp interface design. If you have not already done so, read it atthis time.5 In this context, a metaphoris a representation (drawn from the user’s real-world experience) thatcan be modeled within the context of the interface. A simple example might be a slider switch thatis used to control the auditory volume of an .mpg file.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 379that the user can choose from a hierarchy of subtopics that is displayed whenthe primary menu option is selected.
•Graphic icons—button, switches, and similar graphical images that enable theuser to select some property or specify a decision.
•Graphic images—some graphical representation that is selectable by the userand implements a link to a content object or WebApp functionality.It is important to note that one or more of these control mechanisms should beprovided at every level of the content hierarchy.
13.5 A ESTHETIC DESIGN
Aesthetic design, also called graphic design, is an artistic endeavor that complements the technical aspects of WebApp design. Without it, a WebApp may be functional, butunappealing. With it, a WebApp draws its users into a world that embraces them ona visceral, as well as an intellectual level.But what is aesthetic? There is an old saying, “beauty exists in the eye of the be-holder.” This is particularly appropriate when aesthetic design for WebApps is con-sidered. To perform effective aesthetic design, return to the user hierarchy developedas part of the requirements model (Chapter 5) and ask, Who are the WebApp’s usersand what “look” do they desire?
13.5.1 Layout Issues
Every Web page has a limited amount of “real estate” that can be used to support non-functional aesthetics, navigation features, informational content, and user-directedfunctionality. The development of this real estate is planned during aesthetic design.Like all aesthetic issues, there are no absolute rules when screen layout is de-signed. However, a number of general layout guidelines are worth considering:Don’t be afraid of white space.It is inadvisable to pack every squareinch of a Web page with information. The resulting clutter makes it difficultfor the user to identify needed information or features and create visualchaos that is not pleasing to the eye.Emphasize content.After all, that’s the reason the user is there. Nielsen[Nie00] suggests that the typical Web page should be 80 percent content withthe remaining real estate dedicated to navigation and other features.Organize layout elements from top-left to bottom-right. The vast majority of users will scan a Web page in much the same way as they scanthe page of a book—top-left to bottom-right.
6If layout elements have specific380 PART TWOMODELING
Whatinteractionmechanisms areavailable toWebAppdesigners??
Not every Webengineer (orsoftware engineer) hasartistic (aesthetic)talent. If you fall intothis category, hire anexperienced graphicdesigner for aestheticdesign work.?
uote:
“We find thatpeople quicklyevaluate a site byvisual designalone.”StanfordGuidelines forWeb Credibility
6 There are exceptions that are cultural and language-based, but this rule does hold for most users.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 380priorities, high-priority elements should be placed in the upper-left portion ofthe page real estate.Group navigation, content, and function geographically within thepage.Humans look for patterns in virtually all things. If there are no dis-cernable patterns within a Web page, user frustration is likely to increase(due to unnecessary searching for needed information).Don’t extend your real estate with the scrolling bar. Although scroll- ing is often necessary, most studies indicate that users would prefer not toscroll. It is better to reduce page content or to present necessary content onmultiple pages.Consider resolution and browser window size when designing layout.Rather than defining fixed sizes within a layout, the design should specify alllayout items as a percentage of available space [Nie00].
13.5.2 Graphic Design Issues
Graphic design considers every aspect of the look and feel of a WebApp. Thegraphic design process begins with layout (Section 13.5.1) and proceeds into a con-sideration of global color schemes; text types, sizes, and styles; the use of supple-mentary media (e.g., audio, video, animation); and all other aesthetic elements ofan application.A comprehensive discussion of graphic design issues for WebApps is beyond the scopeof this book. You can obtain design tips and guidelines from many websites that arededicated to the subject (e.g.,www.graphic-design.com,www.grantasticdesigns .com, www.wpdfd.com) or from one or more print resources (e.g., [Roc06] and[Gor02]).CHAPTER 13WEBAPP DESIGN 381
Well-Designed Websites
Sometimes, the best way to understand goodWebApp design is to look at a few examples. Inhis article, “The Top Twenty Web Design Tips,” MarcelleToor (www.graphic-design.com/Web/feature/tips.html) suggests the following websites as examples ofgood graphic design:www.creativepro.com/designresource/home/787.html—a design firm headed by Primo Angeliwww.workbook.com—this site showcases work byillustrators and designerswww.pbs.org/riverofsong—a television series forpublic TV and radio about American musicwww.RKDINC.com—a design firm with onlineportfolio and good design tipswww.creativehotlist.com/index.html —a good source for well-designed sites developed by adagencies, graphics arts firms, and othercommunications specialistswww.btdnyc.com—a design firm headed by BethToudreauINFOUsers tend to toleratevertical scrolling morereadily than horizontalscrolling. Avoid widepage formats.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 38113.6 C ONTENT DESIGN
Content design focuses on two different design tasks, each addressed by individualswith different skill sets. First, a design representation for content objects and the mech-anisms required to establish their relationship to one another is developed. In addition,the information within a specific content object is created. The latter task may be con-ducted by copywriters, graphic designers, and others who generate the content to beused within a WebApp.
13.6.1 Content Objects
The relationship between content objects defined as part of a requirements modelfor the WebApp and design objects representing content is analogous to the rela-tionship between analysis classes and design components described in earlier chap-ters. In the context of WebApp design, a content object is more closely aligned witha data object for traditional software. A content object has attributes that includecontent-specific information (normally defined during WebApp requirements mod-eling) and implementation-specific attributes that are specified as part of design.As an example, consider an analysis class,ProductComponent,developed for theSafeHomee-commerce system. The analysis class attribute, description,is repre- sented as a design class namedCompDescriptioncomposed of five content objects: MarketingDescription, Photograph, TechDescription, Schematic, andVideo shown as shaded objects noted in Figure 13.3. Information contained within the con-tent object is noted as attributes. For example, Photograph(a .jpg image) has the at- tributeshorizontal dimension, vertical dimension,andborder style. UML association and an aggregation
7may be used to represent relationships between content objects. For example, the UML association shown in Figure 13.3indicates that oneCompDescriptionis used for each instance of theProductComponentclass.CompDescriptionis composed on the five content ob- jects shown. However, the multiplicity notation shown indicates that Schematicand Videoare optional (0 occurrences are possible), oneMarketingDescriptionand one TechDescriptionare required, and one or more instances ofPhotographare used.
13.6.2 Content Design Issues
Once all content objects are modeled, the information that each object is to delivermust be authored and then formatted to best meet the customer’s needs. Content au-thoring is the job of specialists in the relevant area who design the content object byproviding an outline of information to be delivered and an indication of the types ofgeneric content objects (e.g., descriptive text, graphic images, photographs) that willbe used to deliver the information. Aesthetic design (Section 13.5) may also beapplied to represent the proper look and feel for the content.382 PART TWOMODELING
uote:
“Good designerscan createnormalcy outof chaos; theycan clearlycommunicate ideasthrough theorganizing andmanipulating ofwords andpictures.”Jeffery Veen
7 Both of these representations are discussed in Appendix 1.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 382As content objects are designed, they are “chunked” [Pow02] to form WebApppages. The number of content objects incorporated into a single page is a functionof user needs, constraints imposed by download speed of the Internet connection,and restrictions imposed by the amount of scrolling that the user will tolerate.
13.7 A RCHITECTURE DESIGN
Architecture design is tied to the goals established for a WebApp, the content to bepresented, the users who will visit, and the navigation philosophy that has beenestablished. As an architectural designer, you must identify content architecture andWebApp architecture. Content architecture
8focuses on the manner in which content objects (or composite objects such as Web pages) are structured for presentation andnavigation. WebApp architectureaddresses the manner in which the application isstructured to manage user interaction, handle internal processing tasks, effect nav-igation, and present content.In most cases, architecture design is conducted in parallel with interface design,aesthetic design, and content design. Because the WebApp architecture may have aCHAPTER 13WEBAPP DESIGN 383
ProductComponentpartNumberpartNamepartTypedescriptionpricecreateNewItem( )displayDescription( )display TechSpec
MarketingDescriptiontext colorfont stylefont sizeline spacingtext usage sizebackground colorPhotographhorizontal dimensionvertical dimensionborder styleSchematichorizontal dimensionvertical dimensionborder styleTechDescriptiontext colorfont stylefont sizeline spacingtext image sizebackground colorVideohorizontal dimensionvertical dimensionborder styleaudio volumeCompDescription1
1
11Is part of
0..10..10..1 11..*
Sensor Camera Control Panel SoftFeatureFIGURE 13.3
Design repre-sentation ofcontent objects
uote:
“. . . thearchitecturalstructure of a welldesigned site is notalways apparent tothe user—norshould it be.”Thomas Powell
8 The term information architecture is also used to connote structures that lead to better organization, labeling, navigation, and searching of content objects.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 383strong influence on navigation, the decisions made during this design action willinfluence work conducted during navigation design.
13.7.1 Content Architecture
The design of content architecture focuses on the definition of the overall hyperme-dia structure of the WebApp. Although custom architectures are sometimes created,you always have the option of choosing from four different content structures[Pow00]:Linear structures(Figure 13.4) are encountered when a predictable sequence of in-teractions (with some variation or diversion) is common. A classic example might bea tutorial presentation in which pages of information along with related graphics,short videos, or audio are presented only after prerequisite information has beenpresented. The sequence of content presentation is predefined and generally linear.Another example might be a product order entry sequence in which specific infor-mation must be specified in a specific order. In such cases, the structures shown inFigure 13.4 are appropriate. As content and processing become more complex, thepurely linear flow shown on the left of the figure gives way to more sophisticated lin-ear structures in which alternative content may be invoked or a diversion to acquirecomplementary content (structure shown on the right side of Figure 13.4) occurs.Grid structures(Figure 13.5) are an architectural option that you can apply whenWebApp content can be organized categorically in two (or more) dimensions. Forexample, consider a situation in which an e-commerce site sells golf clubs. The hori-zontal dimension of the grid represents the type of club to be sold (e.g., woods, irons,wedges, putters). The vertical dimension represents the offerings provided by vari-ous golf club manufacturers. Hence, a user might navigate the grid horizontally tofind the putters column and then vertically to examine the offerings provided by384 PART TWOMODELING
What typesof contentarchitectures arecommonlyencountered??
LinearLinearwithoptional flowLinearwithdiversionsFIGURE 13.4
Linear structurespre75977_ch13.qxd  11/27/08  5:47 PM  Page 384those manufacturers that sell putters. This WebApp architecture is useful only whenhighly regular content is encountered [Pow00].Hierarchical structures(Figure 13.6) are undoubtedly the most common WebApparchitecture. Unlike the partitioned software hierarchies discussed in Chapter 9 thatencourage flow of control only along vertical branches of the hierarchy, a WebApphierarchical structure can be designed in a manner that enables (via hypertext branch-ing) flow of control horizontally across vertical branches of the structure. Hence, con-tent presented on the far left-hand branch of the hierarchy can have hypertext linksthat lead directly to content that exists in the middle or right-hand branch of thestructure. It should be noted, however, that although such branching allows rapid nav-igation across WebApp content, it can lead to confusion on the part of the user.A networkedor “pure web” structure(Figure 13.7) is similar in many ways to the architecture that evolves for object-oriented systems. Architectural componentsCHAPTER 13WEBAPP DESIGN 385
FIGURE 13.5
Grid structure
FIGURE 13.6
Hierarchicalstructurepre75977_ch13.qxd  11/27/08  5:47 PM  Page 385(in this case, Web pages) are designed so that they may pass control (via hypertextlinks) to virtually every other component in the system. This approach allows con-siderable navigation flexibility, but at the same time, can be confusing to a user.The architectural structures discussed in the preceding paragraphs can be com-bined to form composite structures.The overall architecture of a WebApp may behierarchical, but part of the structure may exhibit linear characteristics, whileanother part of the architecture may be networked. Your goal as an architecturaldesigner is to match the WebApp structure to the content to be presented and theprocessing to be conducted.
13.7.2 WebApp Architecture
WebApp architecture describes an infrastructure that enables a Web-based system orapplication to achieve its business objectives. Jacyntho and his colleagues [Jac02b]describe the basic characteristics of this infrastructure in the following manner:
Applications should be built using layers in which different concerns are taken intoaccount; in particular, application data should be separated from the page’s contents(navigation nodes) and these contents, in turn, should be clearly separated from theinterface look-and-feel (pages).
The authors suggest a three-layer design architecture that decouples interface fromnavigation and from application behavior. They argue that keeping interface, appli-cation, and navigation separate simplifies implementation and enhances reuse.The Model-View-Controller(MVC) architecture [Kra88]
9is one of a number of suggested WebApp infrastructure models that decouple the user interface from the386 PART TWOMODELING
FIGURE 13.7
Networkstructure
9 It should be noted that MVC is actually an architectural design pattern developed for the Smalltalkenvironment (see www.cetus-links.org/oo_smalltalk.html ) and can be used for any interactive application.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 386WebApp functionality and informational content. The model (sometimes referred to as the “model object”) contains all application-specific content and processing logic,including all content objects, access to external data/information sources, and allprocessing functionality that is application specific. The view contains all interface- specific functions and enables the presentation of content and processing logic, in-cluding all content objects, access to external data/information sources, and allprocessing functionality required by the end user. The controllermanages access to the model and the view and coordinates the flow of data between them. In aWebApp, “the view is updated by the controller with data from the model based onuser input” [WMT02]. A schematic representation of the MVC architecture is shownin Figure 13.8.Referring to the figure, user requests or data are handled by the controller. The con-troller also selects the view object that is applicable based on the user request. Oncethe type of request is determined, a behavior request is transmitted to the model,which implements the functionality or retrieves the content required to accommodatethe request. The model object can access data stored in a corporate database, as partof a local data store, or as a collection of independent files. The data developed by themodel must be formatted and organized by the appropriate view object and thentransmitted from the application server back to the client-based browser for displayon the customer’s machine.In many cases, WebApp architecture is defined within the context of the develop-ment environment in which the application is to be implemented. If you have furtherinterest, see [Fow03] for a discussion of development environments and their role inthe design of Web application architectures.CHAPTER 13WEBAPP DESIGN 387
The MVC architecturedecouples the userinterface from WebAppfunctionality andinformation content.BrowserClientHTML dataUserrequestor dataControllerManages user requestsSelects model behaviorSelects view response
ViewPrepares data from modelRequest updates from modelPresents view selected bycontrollerModelEncapsulates functionalityEncapsulates content objectsIncorporates all WebApp states
View selectionBehavior request(state change)
Update request
ServerExternal dataData frommodelFIGURE 13.8
The MVCArchitectureSource:Adapted from[Jac02].pre75977_ch13.qxd  11/27/08  5:47 PM  Page 38713.8 N AVIGATION DESIGN
Once the WebApp architecture has been established and the components (pages,scripts, applets, and other processing functions) of the architecture have been iden-tified, you must define navigation pathways that enable users to access WebAppcontent and functions. To accomplish this, you should (1) identify the semantics ofnavigation for different users of the site, and (2) define the mechanics (syntax) ofachieving the navigation.
13.8.1 Navigation Semantics
Like many WebApp design actions, navigation design begins with a consideration ofthe user hierarchy and related use cases (Chapter 5) developed for each categoryof user (actor). Each actor may use the WebApp somewhat differently and thereforehave different navigation requirements. In addition, the use cases developed foreach actor will define a set of classes that encompass one or more content objectsor WebApp functions. As each user interacts with the WebApp, she encounters aseries of navigation semantic units(NSUs)—“a set of information and related naviga-tion structures that collaborate in the fulfillment of a subset of related userrequirements” [Cac02].An NSU is composed of a set of navigation elements called ways of navigating(WoN) [Gna99]. A WoN represents the best navigation pathway to achieve a naviga-tional goal for a specific type of user. Each WoN is organized as a set of navigational nodes(NN) that are connected by navigational links. In some cases, a navigationallink may be another NSU. Therefore, the overall navigation structure for a WebAppmay be organized as a hierarchy of NSUs.To illustrate the development of an NSU, consider the use case Select SafeHomeComponents:
Use Case: Select SafeHome ComponentsThe WebApp will recommend product components
(e.g., control panels, sensors, cam- eras) and other features (e.g., PC-based functionality implemented in software) for eachroom
and exterior entrance . If I request alternatives, the WebApp will provide them, ifthey exist. I will be able to get descriptive and pricing information
for each product component. The WebApp will create and display a bill-of-materials
as I select various components. I’ll be able to give the bill-of-materials a name and save it for futurereference (see use case Save Configuration).
The underlined items in the use-case description represent classes and content objectsthat will be incorporated into one or more NSUs that will enable a new customer toperform the scenario described in theSelect SafeHome Componentsuse case. Figure 13.9 depicts a partial semantic analysis of the navigation implied bytheSelect SafeHome Componentsuse case. Using the terminology intro- duced earlier, the figure also represents a way of navigating (WoN) for the388 PART TWOMODELING
uote:
“Just wait, Gretel,until the moonrises, and then weshall see thecrumbs of breadwhich I havestrewn about, theywill show us ourway home again.”Hansel andGretel
An NSU describesthe navigationrequirements for eachuse case. In essence,the NSU shows howan actor movesbetween contentobjects or WebAppfunctions.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 388SafeHomeAssured.comWebApp. Important problem domain classes are shownalong with selected content objects (in this case the package of content objectsnamed CompDescription,an attribute of the ProductComponent class). These items are navigation nodes. Each of the arrows represents a navigation link
10and is labeled with the user-initiated action that causes the link to occur.You can create an NSU for each use case associated with each user role. Forexample, a new customerfor SafeHomeAssured.commay have three different use cases, all resulting in access to different information and WebApp functions. AnNSU is created for each goal.During the initial stages of navigation design, the WebApp content architecture isassessed to determine one or more WoN for each use case. As noted earlier, a WoNidentifies navigation nodes (e.g., content) and then links that enable navigationbetween them. The WoN are then organized into NSUs.
13.8.2 Navigation Syntax
As design proceeds, your next task is to define the mechanics of navigation. A num-ber of options are available as you develop an approach for implementing each NSU:
•Individual navigation link—includes text-based links, icons, buttons andswitches, and graphical metaphors. You must choose navigation links thatare appropriate for the content and consistent with the heuristics that lead tohigh-quality interface design.
•Horizontal navigation bar—lists major content or functional categories in abar containing appropriate links. In general, between four and seven cate-gories are listed.CHAPTER 13WEBAPP DESIGN 389
<<navigation link>>select Room
<<navigation link>>view BillOfMaterials<<navigation link>>return to Room
<<navigation link>>purchase ProductComponent<<navigation link>>recommend component(s)<<navigation link>>request alternative<<navigation link>>show ProductComponent<<navigation link>>show description<<navigation link>>purchase ProductComponentRoom
BillOfMaterialsProductComponent
CompDescriptiontechDescription
photograph
schematic videoMarketingDescriptionFIGURE 13.9
Creating anNSU
uote:
”The problem ofWeb site navigationis conceptual,technical, spatial,philosophical andlogistic.Consequently,solutions tend tocall for compleximprovisationalcombinations ofart, science andorganizationalpsychology.”Tim Horgan
10 These are sometimes referred to as navigation semantic links (NSL) [Cac02].In most situations,choose either hori-zontal or vertical navi-gation mechanisms,but not both.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 389•Vertical navigation column—(1) lists major content or functional categories, or(2) lists virtually all major content objects within the WebApp. If you choosethe second option, such navigation columns can “expand” to present contentobjects as part of a hierarchy (i.e., selecting an entry in the original columncauses an expansion that lists a second layer of related content objects).
•Tabs—a metaphor that is nothing more than a variation of the navigation baror column, representing content or functional categories as tab sheets thatare selected when a link is required.
•Site maps—provide an all-inclusive table of contents for navigation to allcontent objects and functionality contained within the WebApp.In addition to choosing the mechanics of navigation, you should also establishappropriate navigation conventions and aids. For example, icons and graphical linksshould look “clickable” by beveling the edges to give the image a three-dimensionallook. Audio or visual feedback should be designed to provide the user with an indi-cation that a navigation option has been chosen. For text-based navigation, colorshould be used to indicate navigation links and to provide an indication of linksalready traveled. These are but a few of dozens of design conventions that makenavigation user-friendly.
13.9 C OMPONENT -LEVEL DESIGN
Modern WebApps deliver increasingly sophisticated processing functions that (1) per-form localized processing to generate content and navigation capability in a dynamicfashion, (2) provide computation or data processing capability that are appropriate forthe WebApp’s business domain, (3) provide sophisticated database query and access,and (4) establish data interfaces with external corporate systems. To achieve these(and many other) capabilities, you must design and construct program componentsthat are identical in form to software components for traditional software.The design methods discussed in Chapter 10 apply to WebApp componentswith little, if any, modification. The implementation environment, programming lan-guages, and design patterns, frameworks, and software may vary somewhat, but theoverall design approach remains the same.
13.10 O BJECT -ORIENTED HYPERMEDIA DESIGN METHOD (OOHDM)
A number of design methods for Web applications have been proposed over the pastdecade. To date, no single method has achieved dominance.
11In this section I pres- ent a brief overview of one of the most widely discussed WebApp design methods—OOHDM.390 PART TWOMODELING
The site map should beaccessible from everypage. The map itselfshould be organized sothat the structure ofWebApp information isreadily apparent.
11 In fact, relatively few Web developers use a specific method when designing a WebApp. Hopefully,this ad hoc approach to design will change as time passes.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 390Daniel Schwabe and his colleagues [Sch95, Sch98b] originally proposed theObject-Oriented Hypermedia Design Method (OOHDM), which is composed of four different design activities: conceptual design, navigational design, abstract inter-face design, and implementation. A summary of these design activities is shown inFigure 13.10 and discussed briefly in the sections that follow.
13.10.1 Conceptual Design for OOHDM
OOHDM conceptual designcreates a representation of the subsystems, classes, and re-lationships that define the application domain for the WebApp. UML may be used
12to create appropriate class diagrams, aggregations, and composite class representations,collaboration diagrams, and other information that describes the application domain.As a simple example of OOHDM conceptual design, consider the SafeHomeAssured .come-commerce application. A partial “conceptual schema” is shown in Figure 13.11. The class diagrams, aggregations, and related information developed as part ofWebApp analysis are reused during conceptual design to represent relationshipsbetween classes.
13.10.2 Navigational Design for OOHDM
Navigational designidentifies a set of “objects” that are derived from the classesdefined in conceptual design. A series of “navigational classes” or “nodes” areCHAPTER 13WEBAPP DESIGN 391
Work productsDesign mechanismsDesign concernsModeling semanticsof the applicationdomainClasses, subsystems,relationships, attributesClassification,composition,aggregation,generalizationspecializationConceptual designNavigational designAbstract interfacedesign
Implementation
Nodes links, accessstructures, navigationalcontexts, navigationaltransformationsMapping betweenconceptual andnavigation objectsTakes into account userprofile and task.Emphasis on cognitiveaspects.Abstract interfaceobjects, responses toexternal events,transformationsMapping betweennavigation andperceptible objectsModeling perceptibleobjects, implementingchosen metaphors.Describe interface fornavigational objects.ExecutableWebAppResourceprovided bytargetenvironmentCorrectness;applicationperformance;completenessFIGURE 13.10 Summary of the OOHDM method.Source:Adapted from [Sch95].
12 OOHDM does not prescribe a specific notation; however, the use of UML is common when thismethod is applied.pre75977_ch13.qxd  11/27/08  5:47 PM  Page 391defined to encapsulate these objects. UML may be used to create appropriate usecases, state charts, and sequence diagrams—all representations that assist you inbetter understanding navigational requirements. In addition, design patterns for nav-igational design may be used as the design is developed. OOHDM uses a predefinedset of navigation classes—nodes, links, anchors, and access structures [Sch98b].Access structures are more elaborate and include mechanisms such as a WebAppindex, a site map, or a guided tour.Once navigation classes are defined, OOHDM “structures the navigation space bygrouping navigation objects into sets called contexts” [Sch98b]. A contextincludes a description of the local navigation structure, restriction imposed on the access ofcontent objects, and methods (operations) required to effect access of contentobjects. A context template (analogous to CRC cards discussed in Chapter 6) is de-veloped and may be used to track the navigation requirements of each category ofuser through the various contexts defined in OOHDM. Doing this, specific navigationpaths (what we called WoN in Section 13.8.1) emerge.
13.10.3 Abstract Interface Design and Implementation
The abstract interface design action specifies the interface objects that the user seesas WebApp interaction occurs. A formal model of interface objects, called an abstractdata view(ADV), is used to represent the relationship between interface objects andnavigation objects, and the behavioral characteristics of interface objects.392 PART TWOMODELING
ProductComponentpartNumberpartNamepartTypedescriptionpricecreateNewItem( )getDescription( )getTechSpec
BillOfMaterialsidentifierBoMListnumberItemspriceTotaladdEntry( )deleteEntry( )editEntry( )name( )computePrice( )
BoMItemquantitypartNumberpartNamepartTypepriceaddtoList( )deletefromList( )getNextListEntry( )
OrderorderNumbercustomerInfobillOfMaterialsshippingInfobillingInfoRoomroomNamedimensionsexteriorWindowsexteriorDoors
Sensor Camera Control Panel SoftFeature
customer continuescomponent selection customerrequests purchasecomponent recommendationrequestedcustomer selects componentFIGURE 13.11 Partial conceptual schema for SafeHomeAssured.compre75977_ch13.qxd  11/27/08  5:47 PM  Page 392The ADV model defines a “static layout” [Sch98b] that represents the interfacemetaphor and includes a representation of navigation objects within the interfaceand the specification of the interface objects (e.g., menus, buttons, icons) that assistin navigation and interaction. In addition, the ADV model contains a behavioralcomponent (similar to the UML state diagram) that indicates how external events“trigger navigation and which interface transformations occur when the user inter-acts with the application” [Sch01a].The OOHDMimplementationactivity represents a design iteration that is spe-cific to the environment in which the WebApp will operate. Classes, navigation,and the interface are each characterized in a manner that can be constructed forthe client-server environment, operating systems, support software, program-ming languages, and other environmental characteristics that are relevant to theproblem.
13.11 S UMMARY
The quality of a WebApp—defined in terms of usability, functionality, reliability, effi-ciency, maintainability, security, scalability, and time-to-market—is introduced dur-ing design. To achieve these quality attributes, a good WebApp design should exhibitthe following characteristics: simplicity, consistency, identity, robustness, navigabil-ity, and visual appeal. To achieve these characteristics, the WebApp design activityfocuses on six different elements of the design.Interface design describes the structure and organization of the user interface andincludes a representation of screen layout, a definition of the modes of interaction,and a description of navigation mechanisms. A set of interface design principles andan interface design workflow guide you when layout and interface control mecha-nisms are designed.Aesthetic design, also called graphic design, describes the “look and feel” of theWebApp and includes color schemes; geometric layout; text size, font, and place-ment; the use of graphics; and related aesthetic decisions. A set of graphic designguidelines provides the basis for a design approach.Content design defines the layout, structure, and outline for all content that is pre-sented as part of the WebApp and establishes the relationships between contentobjects. Content design begins with the representation of content objects, their as-sociations, and relationships. A set of browsing primitives establishes the basis fornavigation design.Architecture design identifies the overall hypermedia structure for the WebAppand encompasses both content architecture and WebApp architecture. Architecturalstyles for content include linear, grid, hierarchical, and network structures. WebApparchitecture describes an infrastructure that enables a Web-based system or appli-cation to achieve its business objectives.CHAPTER 13WEBAPP DESIGN 393pre75977_ch13.qxd  11/27/08  5:47 PM  Page 393Navigation design represents the navigational flow between content objects andfor all WebApp functions. Navigation semantics are defined by describing a set ofnavigation semantic units. Each unit is composed of ways of navigating and naviga-tional links and nodes. Navigation syntax depicts the mechanisms used for effectingthe navigation described as part of the semantics.Component design develops the detailed processing logic required to implementfunctional components that implement a complete WebApp function. Designtechniques described in Chapter 10 are applicable for the engineering of WebAppcomponents.The Object-Oriented Hypermedia Design Method (OOHDM) is one of a numberof methods proposed for WebApp design. OOHDM suggests a design process thatincludes conceptual design, navigational design, abstract interface design, andimplementation.
PROBLEMS AND POINTS TO PONDER
13.1.Why is the “artistic ideal” an insufficient design philosophy when modern WebApps arebuilt? Is there ever a case in which the artistic ideal is the philosophy to follow?13.2.In this chapter we select a broad array of quality attributes for WebApps. Select the threethat you believe are most important, and make an argument that explains why each should beemphasized in WebApp design work.13.3.Add at least five additional questions to the WebApp Design—Quality Checklist presentedin Section 13.1.13.4.You are a WebApp designer for FutureLearning Corporation, a distance learning company.You intend to implement an Internet-based “learning engine” that will enable you to delivercourse content to a student. The learning engine provides the basic infrastructure for deliveringlearning content on any subject (content designers will prepare appropriate content). Developa prototype interface design for the learning engine.13.5.What is the most aesthetically pleasing website you have ever visited and why?13.6.Consider the content object Order, generated once a user of SafeHomeAssured.com has completed the selection of all components and is ready to finalize his purchase. Develop aUML description for Orderalong with all appropriate design representations.13.7.What is the difference between content architecture and WebApp architecture?13.8.Reconsidering the FutureLearning “learning engine” described in Problem 13.4, select a content architecture that would be appropriate for the WebApp. Discuss why you made thechoice.13.9.Use UML to develop three or four design representations for content objects that wouldbe encountered as the “learning engine” described in Problem 13.4 is designed.13.10.Do a bit of additional research on the MVC architecture and decide whether it would bean appropriate WebApp architecture for the “learning engine” discussed in Problem 13.4.13.11.What is the difference between navigation syntax and navigation semantics?13.12.Define two or three NSUs for the SafeHomeAssured.com WebApp. Describe each in some detail.13.13.Write a brief paper on a hypermedia design method other than OOHDM.394 PART TWOMODELINGpre75977_ch13.qxd  11/27/08  5:47 PM  Page 394FURTHER READINGS AND INFORMATION SOURCES
Van Duyne and his colleagues (The Design of Sites, 2d ed., Prentice Hall, 2007) have written a comprehensive book that covers most important aspects of the WebApp design process. Designprocess models and design patterns are covered in detail. Wodtke (Information Architecture, New Riders Publishing, 2003), Rosenfeld and Morville (Information Architecture for the World WideWeb,O’Reilly & Associates, 2002), and Reiss (Practical Information Architecture, Addison-Wesley, 2000) address content architecture and other topics.Although hundreds of books have been written on “Web design,” very few of these discussany meaningful technical methods for doing design work. At best, a variety of useful guidelinesfor WebApp design is presented, worthwhile examples of Web pages and Java programming areshown, and the technical details important for implementing modern WebApps are discussed.Among the many offerings in this category are books by Sklar (Principles of Web Design, 4th ed., Course Technology, 2008), McIntire ( Visual Design for the Modern Web,New Riders Press, 2007), Niederst (Web Design in a Nutshell,3d ed., O-Reilly, 2006), Eccher (Advanced Professional Web Design,Charles River Media, 2006), Cederholm (Bulletproof Web Design, New Riders Press, 2005),and Shelly and his colleagues (Web Design, 2d ed., Course Technology, 2005). Powell’s [Pow02] encyclopedic discussion and Nielsen’s [Nie00] in-depth discussion of design are also worthwhileadditions to any library.Books by Beaird (The Principles of Beautiful Web Design, SitePoint, 2007), Clarke and Holzschlag (Transcending CSS: The Fine Art of Web Design, New Riders Press, 2006), and Golbeck (Art Theory for Web Design,Addison Wesley, 2005) emphasize aesthetic design and are worth-while reading for practitioners who have little background in the subject.The agile view of design (and other topics) for WebApps is presented by Wallace and hiscolleagues (Extreme Programming for Web Projects, Addison-Wesley, 2003). Conallen (Building Web Applications with UML,2d ed., Addison-Wesley, 2002) and Rosenberg and Scott (ApplyingUse-Case Driven Object Modeling with UML, Addison-Wesley, 2001) present detailed examples of WebApps modeled using UML.Design techniques are also mentioned within the context of books written about specificdevelopment environments. Interested readers should examine books on HTML, CSS, J2EE,Java, .NET, XML, Perl, Ruby on Rails, Ajax, and a variety of WebApp creation applications(Dreamweaver, HomePage, Frontpage, GoLive, MacroMedia Flash, etc.) for useful design tidbits. A wide variety of information sources on design for WebApps is available on the Internet.An up-to-date list of World Wide Web references that are relevant to WebApp design can befound at the SEPA website:www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 13WEBAPP DESIGN 395pre75977_ch13.qxd  11/27/08  5:47 PM  Page 395pre75977_ch13.qxd  11/27/08  5:47 PM  Page 396QUALITY MANAGEMENT
397PART
Three
In this part of Software Engineering: A Practitioner’s Approachyou’ll learn about the principles, concepts, and techniques thatare applied to manage and control software quality. Thesequestions are addressed in the chapters that follow:•What are the generic characteristics of high-quality software?•How do we review quality and how are effective reviewsconducted?•What is software quality assurance?•What strategies are applicable for software testing?•What methods are used to design effective test cases?•Are there realistic methods that will ensure that software iscorrect?•How can we manage and control changes that always occuras software is built?•What measures and metrics can be used to assess the qualityof requirements and design models, source code, and testcases?Once these questions are answered you’ll be better prepared toensure that high-quality software has been produced.pre75977_ch14.qxd  11/27/08  5:51 PM  Page 397The drumbeat for improved software quality began in earnest as softwarebecame increasingly integrated in every facet of our lives. By the 1990s,major corporations recognized that billions of dollars each year were be-ing wasted on software that didn’t deliver the features and functionality that werepromised. Worse, both government and industry became increasingly concernedthat a major software fault might cripple important infrastructure, costing tensof billions more. By the turn of the century, CIO Magazine [Lev01] trumpeted the headline, “Let’s Stop Wasting $78 Billion a Year,” lamenting the fact that“American businesses spend billions for software that doesn’t do what it’s sup-posed to do.” InformationWeek[Ric01] echoed the same concern:
Despite good intentions, defective code remains the hobgoblin of the software indus-try, accounting for as much as 45% of computer-system downtime and costing U.S.companies about $100 billion last year in lost productivity and repairs, says theStandish Group, a market research firm. That doesn’t include the cost of losing angrycustomers. Because IT shops write applications that rely on packaged infrastructuresoftware, bad code can wreak havoc on custom apps as well. . . .Just how bad is bad software? Definitions vary, but experts say it takes only three orfour defects per 1,000 lines of code to make a program perform poorly. Factor in that mostprogrammers inject about one error for every 10 lines of code they write, multiply that bythe millions of lines of code in many commercial products, then figure it costs softwarevendors at least half their development budgets to fix errors while testing. Get the picture?
398CHAPTER
14QUALITY
CONCEPTS
KEY
CONCEPTS
cost of quality . .407good enough . . .406liability  . . . . . .410managementactions . . . . . . .411quality  . . . . . . .399qualitydilemma . . . . . .406qualitydimensions  . . . .401quality factors  .402quantitativeview  . . . . . . . .405risks  . . . . . . . .409security  . . . . . .410
What is it? The answer isn’t as easyas you might think. You know qualitywhen you see it, and yet, it can be anelusive thing to define. But for com-puter software, quality is something that we mustdefine, and that’s what I’ll do in this chapter.
Who does it? Everyone—software engineers,managers, all stakeholders—involved in thesoftware process is responsible for quality.
Why is it important? You can do it right, or youcan do it over again. If a software team stressesquality in all software engineering activities, itreduces the amount of rework that it must do.That results in lower costs, and more importantly,improved time-to-market.QUICK
LOOKWhat are the steps? To achieve high-qualitysoftware, four activities must occur: proven soft-ware engineering process and practice, solidproject management, comprehensive qualitycontrol, and the presence of a quality assuranceinfrastructure.
What is the work product? Software thatmeets its customer’s needs, performs accuratelyand reliably, and provides value to all whouse it.
How do I ensure that I’ve done it right? Trackquality by examining the results of all qualitycontrol activities, and measure quality by exam-ining errors before delivery and defectsreleased to the field.pre75977_ch14.qxd  11/27/08  5:51 PM  Page 398CHAPTER 14QUALITY CONCEPTS 399
In 2005, ComputerWorld[Hil05] lamented that “bad software plagues nearly everyorganization that uses computers, causing lost work hours during computer down-time, lost or corrupted data, missed sales opportunities, high IT support and mainte-nance costs, and low customer satisfaction. A year later, InfoWorld [Fos06] wrote about the “the sorry state of software quality” reporting that the quality problem hadnot gotten any better.Today, software quality remains an issue, but who is to blame? Customers blamedevelopers, arguing that sloppy practices lead to low-quality software. Developersblame customers (and other stakeholders), arguing that irrational delivery dates anda continuing stream of changes force them to deliver software before it has been fullyvalidated. Who’s right? Both—and that’s the problem. In this chapter, I consider soft-ware quality as a concept and examine why it’s worthy of serious considerationwhenever software engineering practices are applied.
14.1 W HATISQUALITY ?
In his mystical book, Zen and the Art of Motorcycle Maintenance, Robert Persig [Per74] commented on the thing we call quality:
Quality . . . you know what it is, yet you don’t know what it is. But that’s self-contradictory.But some things are better than others; that is, they have more quality. But when you tryto say what the quality is, apart from the things that have it, it all goes poof! There’s noth-ing to talk about. But if you can’t say what Quality is, how do you know what it is, or howdo you know that it even exists? If no one knows what it is, then for all practical purposesit doesn’t exist at all. But for all practical purposes it really does exist. What else are thegrades based on? Why else would people pay fortunes for some things and throw othersin the trash pile? Obviously some things are better than others . . . but what’s the better-ness? . . . So round and round you go, spinning mental wheels and nowhere finding any-place to get traction. What the hell is Quality? What is it?
Indeed—what is it?At a somewhat more pragmatic level, David Garvin [Gar84] of the Harvard Busi-ness School suggests that “quality is a complex and multifaceted concept” that canbe described from five different points of view. The transcendental viewargues (like Persig) that quality is something that you immediately recognize, but cannot explic-itly define. The user viewsees quality in terms of an end user’s specific goals. If aproduct meets those goals, it exhibits quality. The manufacturer’s view defines qual- ity in terms of the original specification of the product. If the product conforms to thespec, it exhibits quality. The product view suggests that quality can be tied to inher- ent characteristics (e.g., functions and features) of a product. Finally, the value-basedviewmeasures quality based on how much a customer is willing to pay for a prod-uct. In reality, quality encompasses all of these views and more.Quality of designrefers to the characteristics that designers specify for a product.The grade of materials, tolerances, and performance specifications all contribute tothe quality of design. As higher-grade materials are used, tighter tolerances and
What are the differentways in which qualitycan be viewed?pre75977_ch14.qxd  11/27/08  5:51 PM  Page 399greater levels of performance are specified, the design quality of a product increases,if the product is manufactured according to specifications.In software development, quality of design encompasses the degree to which thedesign meets the functions and features specified in the requirements model. Quality of conformancefocuses on the degree to which the implementation follows thedesign and the resulting system meets its requirements and performance goals.But are quality of design and quality of conformance the only issues that softwareengineers must consider? Robert Glass [Gla98] argues that a more “intuitive” rela-tionship is in order:
user satisfaction /H11549compliant product /H11545good quality /H11545delivery within budget and schedule
At the bottom line, Glass contends that quality is important, but if the user isn’tsatisfied, nothing else really matters. DeMarco [DeM98] reinforces this view when hestates: “A product’s quality is a function of how much it changes the world for thebetter.” This view of quality contends that if a software product provides substantialbenefit to its end users, they may be willing to tolerate occasional reliability or per-formance problems.
14.2 S OFTWARE QUALITY
Even the most jaded software developers will agree that high-quality software is animportant goal. But how do we define software quality? In the most general sense, software quality can be defined
1as: An effective software process applied in a mannerthat creates a useful product that provides measurable value for those who produce itand those who use it.There is little question that the preceding definition could be modified or extendedand debated endlessly. For the purposes of this book, the definition serves toemphasize three important points:1.An effective software processestablishes the infrastructure that supports anyeffort at building a high-quality software product. The management aspectsof process create the checks and balances that help avoid project chaos—akey contributor to poor quality. Software engineering practices allow thedeveloper to analyze the problem and design a solid solution—both criticalto building high-quality software. Finally, umbrella activities such as changemanagement and technical reviews have as much to do with quality as anyother part of software engineering practice.2.A useful productdelivers the content, functions, and features that the enduser desires, but as important, it delivers these assets in a reliable, error-free400 PART THREEQUALITY MANAGEMENT
uote:
“People forget howfast you did a job—but they alwaysremember howwell you did it.”Howard Newton
1 This definition has been adapted from [Bes04] and replaces a more manufacturing-oriented viewpresented in earlier editions of this book.pre75977_ch14.qxd  11/27/08  5:51 PM  Page 400way. A useful product always satisfies those requirements that have beenexplicitly stated by stakeholders. In addition, it satisfies a set of implicitrequirements (e.g., ease of use) that are expected of all high-quality software.3.By adding value for both the producer and user of a software product, high- quality software provides benefits for the software organization and the end-user community. The software organization gains added value becausehigh-quality software requires less maintenance effort, fewer bug fixes, andreduced customer support. This enables software engineers to spend moretime creating new applications and less on rework. The user communitygains added value because the application provides a useful capability ina way that expedites some business process. The end result is (1) greatersoftware product revenue, (2) better profitability when an applicationsupports a business process, and/or (3) improved availability of informationthat is crucial for the business.
14.2.1 Garvin’s Quality Dimensions
David Garvin [Gar87] suggests that quality should be considered by taking a multidi-mensional viewpoint that begins with an assessment of conformance and termi-nates with a transcendental (aesthetic) view. Although Garvin’s eight dimensions ofquality were not developed specifically for software, they can be applied when soft-ware quality is considered:Performance quality.Does the software deliver all content, functions, andfeatures that are specified as part of the requirements model in a way thatprovides value to the end user?Feature quality.Does the software provide features that surprise anddelight first-time end users?Reliability.Does the software deliver all features and capability withoutfailure? Is it available when it is needed? Does it deliver functionality that iserror-free?Conformance.Does the software conform to local and external softwarestandards that are relevant to the application? Does it conform to de factodesign and coding conventions? For example, does the user interface con-form to accepted design rules for menu selection or data input?Durability.Can the software be maintained (changed) or corrected(debugged) without the inadvertent generation of unintended side effects?Will changes cause the error rate or reliability to degrade with time?Serviceability.Can the software be maintained (changed) or corrected(debugged) in an acceptably short time period? Can support staff acquire allinformation they need to make changes or correct defects? Douglas Adams[Ada93] makes a wry comment that seems appropriate here: “The differenceCHAPTER 14QUALITY CONCEPTS 401pre75977_ch14.qxd  11/27/08  5:51 PM  Page 401between something that can go wrong and something that can’t possibly gowrong is that when something that can’t possibly go wrong goes wrong itusually turns out to be impossible to get at or repair.”Aesthetics.There’s no question that each of us has a different and verysubjective vision of what is aesthetic. And yet, most of us would agree thatan aesthetic entity has a certain elegance, a unique flow, and an obvious“presence” that are hard to quantify but are evident nonetheless. Aestheticsoftware has these characteristics.Perception.In some situations, you have a set of prejudices that will influ-ence your perception of quality. For example, if you are introduced to a soft-ware product that was built by a vendor who has produced poor quality inthe past, your guard will be raised and your perception of the current soft-ware product quality might be influenced negatively. Similarly, if a vendorhas an excellent reputation, you may perceive quality, even when it does notreally exist.Garvin’s quality dimensions provide you with a “soft” look at software quality.Many (but not all) of these dimensions can only be considered subjectively. For thisreason, you also need a set of “hard” quality factors that can be categorized in twobroad groups: (1) factors that can be directly measured (e.g., defects uncovered dur-ing testing) and (2) factors that can be measured only indirectly (e.g., usability ormaintainability). In each case measurement must occur. You should compare thesoftware to some datum and arrive at an indication of quality.
14.2.2 McCall’s Quality Factors
McCall, Richards, and Walters [McC77] propose a useful categorization of factorsthat affect software quality. These software quality factors, shown in Figure 14.1,focus on three important aspects of a software product: its operational characteris-tics, its ability to undergo change, and its adaptability to new environments.Referring to the factors noted in Figure 14.1, McCall and his colleagues providethe following descriptions:
Correctness.The extent to which a program satisfies its specification and fulfills thecustomer’s mission objectives.Reliability.The extent to which a program can be expected to perform its intended func-tion with required precision. [It should be noted that other, more complete definitions ofreliability have been proposed (see Chapter 25).]Efficiency.The amount of computing resources and code required by a program toperform its function.Integrity.Extent to which access to software or data by unauthorized persons can becontrolled.Usability.Effort required to learn, operate, prepare input for, and interpret output of aprogram.402 PART THREEQUALITY MANAGEMENTpre75977_ch14.qxd  11/27/08  5:51 PM  Page 402Maintainability.Effort required to locate and fix an error in a program. [This is a verylimited definition.]Flexibility.Effort required to modify an operational program.Testability.Effort required to test a program to ensure that it performs its intendedfunction.Portability.Effort required to transfer the program from one hardware and/or softwaresystem environment to another.Reusability.Extent to which a program [or parts of a program] can be reused in otherapplications—related to the packaging and scope of the functions that the programperforms.Interoperability.Effort required to couple one system to another.
It is difficult, and in some cases impossible, to develop direct measures2of these quality factors. In fact, many of the metrics defined by McCall et al. can be measuredonly indirectly. However, assessing the quality of an application using these factorswill provide you with a solid indication of software quality.
14.2.3 ISO 9126 Quality Factors
The ISO 9126 standard was developed in an attempt to identify the key qualityattributes for computer software. The standard identifies six key quality attributes:Functionality.The degree to which the software satisfies stated needs asindicated by the following subattributes: suitability, accuracy, interoperability,compliance, and security.Reliability.The amount of time that the software is available for use as indi-cated by the following subattributes: maturity, fault tolerance, recoverability.CHAPTER 14QUALITY CONCEPTS 403
PRODUCT OPERATIONPRODUCT TRANSITIONPRODUCT REVISION
Correctness                              Usability                              EfficiencyReliability                              IntegrityMaintainabilityFlexibilityTestabilityPortabilityReusabilityInteroperabilityFIGURE 14.1
McCall’ssoftwarequality factors
uote:
“The bitternessof poor qualityremains long afterthe sweetness ofmeeting theschedule has beenforgotten.”Karl Weigers(unattributedquote)
2A  direct measureimplies that there is a single countable value that provides a direct indication ofthe attribute being examined. For example, the “size” of a program can be measured directly bycounting the number of lines of code.pre75977_ch14.qxd  11/27/08  5:51 PM  Page 403Usability.The degree to which the software is easy to use as indicated bythe following subattributes: understandability, learnability, operability.Efficiency.The degree to which the software makes optimal use of systemresources as indicated by the following subattributes: time behavior, resourcebehavior.Maintainability.The ease with which repair may be made to the software asindicated by the following subattributes: analyzability, changeability, stability,testability.Portability.The ease with which the software can be transposed from oneenvironment to another as indicated by the following subattributes: adapt-ability, installability, conformance, replaceability.Like other software quality factors discussed in the preceding subsections, the ISO9126 factors do not necessarily lend themselves to direct measurement. However,they do provide a worthwhile basis for indirect measures and an excellent checklistfor assessing the quality of a system.
14.2.4 Targeted Quality Factors
The quality dimensions and factors presented in Sections 14.2.1 and 14.2.2 focus onthe software as a whole and can be used as a generic indication of the quality of anapplication. A software team can develop a set of quality characteristics and associ-ated questions that would probe
3the degree to which each factor has been satisfied.For example, McCall identifies usability as an important quality factor. If you were asked to review a user interface and assess its usability, how would you proceed?You might start with the subattributes suggested by McCall—understandability,learnability, and operability—but what do these mean in a pragmatic sense?To conduct your assessment, you’ll need to address specific, measurable (or atleast, recognizable) attributes of the interface. For example [Bro03]:Intuitiveness.The degree to which the interface follows expected usage patternsso that even a novice can use it without significant training.
•Is the interface layout conducive to easy understanding?
•Are interface operations easy to locate and initiate?
•Does the interface use a recognizable metaphor?
•Is input specified to economize key strokes or mouse clicks?
•Does the interface follow the three golden rules? (Chapter 11)
•Do aesthetics aid in understanding and usage?404 PART THREEQUALITY MANAGEMENT
uote:
“Any activitybecomes creativewhen the doercares about doingit right, or better.”John UpdikeAlthough it’s temptingto develop quantitativemeasures for thequality factors notedhere, you can alsocreate a simplechecklist of attributesthat provide a solidindication that thefactor is present.
3 These characteristics and questions would be addressed as part of a software review (Chapter 15).pre75977_ch14.qxd  11/27/08  5:51 PM  Page 404Efficiency.The degree to which operations and information can be located orinitiated.
•Does the interface layout and style allow a user to locate operations andinformation efficiently?
•Can a sequence of operations (or data input) be performed with an economyof motion?
•Are output data or content presented so that it is understood immediately?
•Have hierarchical operations been organized in a way that minimizes thedepth to which a user must navigate to get something done?Robustness.The degree to which the software handles bad input data or inap-propriate user interaction.
•Will the software recognize the error if data at or just outside prescribedboundaries is input? More importantly, will the software continue to operatewithout failure or degradation?
•Will the interface recognize common cognitive or manipulative mistakes andexplicitly guide the user back on the right track?
•Does the interface provide useful diagnosis and guidance when an errorcondition (associated with software functionality) is uncovered?Richness.The degree to which the interface provides a rich feature set.
•Can the interface be customized to the specific needs of a user?
•Does the interface provide a macro capability that enables a user to identify asequence of common operations with a single action or command?As the interface design is developed, the software team would review the designprototype and ask the questions noted. If the answer to most of these questions is“yes,” it is likely that the user interface exhibits high quality. A collection of questionssimilar to these would be developed for each quality factor to be assessed.
14.2.5 The Transition to a Quantitative View
In the preceding subsections, I have presented a variety of qualitative factors for the“measurement” of software quality. The software engineering community strives todevelop precise measures for software quality and is sometimes frustrated by thesubjective nature of the activity. Cavano and McCall [Cav78] discuss this situation:
The determination of quality is a key factor in every day events—wine tasting contests,sporting events [e.g., gymnastics], talent contests, etc. In these situations, quality isjudged in the most fundamental and direct manner: side by side comparison of objectsunder identical conditions and with predetermined concepts. The wine may be judgedaccording to clarity, color, bouquet, taste, etc. However, this type of judgment is very sub-jective; to have any value at all, it must be made by an expert.CHAPTER 14QUALITY CONCEPTS 405pre75977_ch14.qxd  11/27/08  5:51 PM  Page 405Subjectivity and specialization also apply to determining software quality. To helpsolve this problem, a more precise definition of software quality is needed as well as away to derive quantitative measurements of software quality for objective analysis. . . .Since there is no such thing as absolute knowledge, one should not expect to measuresoftware quality exactly, for every measurement is partially imperfect. Jacob Bronkowskidescribed this paradox of knowledge in this way: “Year by year we devise more preciseinstruments with which to observe nature with more fineness. And when we look at theobservations we are discomfited to see that they are still fuzzy, and we feel that they areas uncertain as ever.”
In Chapter 23, I’ll present a set of software metrics that can be applied to the quan-titative assessment of software quality. In all cases, the metrics represent indirectmeasures; that is, we never really measure qualitybut rather some manifestation of quality. The complicating factor is the precise relationship between the variable thatis measured and the quality of software.
14.3 T HESOFTWARE QUALITY DILEMMA
In an interview [Ven03] published on the Web, Bertrand Meyer discusses what I callthe quality dilemma:
If you produce a software system that has terrible quality, you lose because no one willwant to buy it. If on the other hand you spend infinite time, extremely large effort, andhuge sums of money to build the absolutely perfect piece of software, then it’s going totake so long to complete and it will be so expensive to produce that you’ll be out of busi-ness anyway. Either you missed the market window, or you simply exhausted all yourresources. So people in industry try to get to that magical middle ground where the prod-uct is good enough not to be rejected right away, such as during evaluation, but also notthe object of so much perfectionism and so much work that it would take too long or costtoo much to complete.
It’s fine to state that software engineers should strive to produce high-qualitysystems. It’s even better to apply good practices in your attempt to do so. But thesituation discussed by Meyer is real life and represents a dilemma for even the bestsoftware engineering organizations.
14.3.1 “Good Enough” Software
Stated bluntly, if we are to accept the argument made by Meyer, is it acceptableto produce “good enough” software? The answer to this question must be “yes,”because major software companies do it every day. They create software with knownbugs and deliver it to a broad population of end users. They recognize that some ofthe functions and features delivered in Version 1.0 may not be of the highest qualityand plan for improvements in Version 2.0. They do this knowing that some cus-tomers will complain, but they recognize that time-to-market may trump better qual-ity as long as the delivered product is “good enough.”406 PART THREEQUALITY MANAGEMENT
When you’re facedwith the qualitydilemma (andeveryone is facedwith it at one timeor another), try toachieve balance—enough effort toproduce acceptablequality without buryingthe project.pre75977_ch14.qxd  11/27/08  5:51 PM  Page 406Exactly what is “good enough”? Good enough software delivers high-quality func-tions and features that users desire, but at the same time it delivers other moreobscure or specialized functions and features that contain known bugs. The soft-ware vendor hopes that the vast majority of end users will overlook the bugs becausethey are so happy with other application functionality.This idea may resonate with many readers. If you’re one of them, I can only askyou to consider some of the arguments against “good enough.”It is true that “good enough” may work in some application domains and for a fewmajor software companies. After all, if a company has a large marketing budget andcan convince enough people to buy version 1.0, it has succeeded in locking them in.As I noted earlier, it can argue that it will improve quality in subsequent versions. Bydelivering a good enough version 1.0, it has cornered the market.If you work for a small company be wary of this philosophy. When you deliver agood enough (buggy) product, you risk permanent damage to your company’s repu-tation. You may never get a chance to deliver version 2.0 because bad buzz maycause your sales to plummet and your company to fold.If you work in certain application domains (e.g., real-time embedded software) orbuild application software that is integrated with hardware (e.g., automotive soft-ware, telecommunications software), delivering software with known bugs can benegligent and open your company to expensive litigation. In some cases, it can evenbe criminal. No one wants good enough aircraft avionics software!So, proceed with caution if you believe that “good enough” is a short cut that cansolve your software quality problems. It can work, but only for a few and only in alimited set of application domains.
4
14.3.2 The Cost of Quality
The argument goes something like this—we know that quality is important, but it costsus time and money—too much time and money to get the level of software quality wereally want.On its face, this argument seems reasonable (see Meyer’s comments ear-lier in this section). There is no question that quality has a cost, but lack of quality alsohas a cost—not only to end users who must live with buggy software, but also to thesoftware organization that has built and must maintain it. The real question is this:which cost should we be worried about?To answer this question, you must understandboth the cost of achieving quality and the cost of low-quality software.The cost of qualityincludes all costs incurred in the pursuit of quality or in per-forming quality-related activities and the downstream costs of lack of quality. Tounderstand these costs, an organization must collect metrics to provide a baselinefor the current cost of quality, identify opportunities for reducing these costs, andprovide a normalized basis of comparison. The cost of quality can be divided intocosts associated with prevention, appraisal, and failure.CHAPTER 14QUALITY CONCEPTS 407
4 A worthwhile discussion of the pros and cons of “good enough” software can be found in [Bre02].pre75977_ch14.qxd  11/27/08  5:52 PM  Page 407Prevention costsinclude (1) the cost of management activities required to plan andcoordinate all quality control and quality assurance activities, (2) the cost of addedtechnical activities to develop complete requirements and design models, (3) testplanning costs, and (4) the cost of all training associated with these activities.Appraisal costsinclude activities to gain insight into product condition the “firsttime through” each process. Examples of appraisal costs include:
•Cost of conducting technical reviews (Chapter 15) for software engineeringwork products
•Cost of data collection and metrics evaluation (Chapter 23)
•Cost of testing and debugging (Chapters 18 through 21)Failure costsare those that would disappear if no errors appeared before or aftershipping a product to customers. Failure costs may be subdivided into internal failurecosts and external failure costs. Internal failure costs are incurred when you detect an error in a product prior to shipment. Internal failure costs include
•Cost required to perform rework (repair) to correct an error
•Cost that occurs when rework inadvertently generates side effects that mustbe mitigated
•Costs associated with the collection of quality metrics that allow an organi-zation to assess the modes of failureExternal failure costsare associated with defects found after the product has beenshipped to the customer. Examples of external failure costs are complaint resolution,product return and replacement, help line support, and labor costs associated withwarranty work. A poor reputation and the resulting loss of business is anotherexternal failure cost that is difficult to quantify but nonetheless very real. Bad thingshappen when low-quality software is produced.In an indictment of software developers who refuse to consider external failurecosts, Cem Kaner [Kan95] states:
Many of the external failure costs, such as goodwill, are difficult to quantify, and many com-panies therefore ignore them when calculating their cost-benefit tradeoffs. Other externalfailure costs can be reduced (e.g. by providing cheaper, lower-quality, post-sale support, orby charging customers for support) without increasing customer satisfaction. By ignoringthe costs to our customers of bad products, quality engineers encourage quality -related decision-making that victimizes our customers, rather than delighting them.
As expected, the relative costs to find and repair an error or defect increase dra-matically as we go from prevention to detection to internal failure to external failurecosts. Figure 14.2, based on data collected by Boehm and Basili [Boe01b] and illus-trated by Cigital Inc. [Cig07], illustrates this phenomenon.The industry average cost to correct a defect during code generation is approxi-mately $977 per error. The industry average cost to correct the same error if it is408 PART THREEQUALITY MANAGEMENT
Don’t be afraid to incursignificant preventioncosts. Rest assuredthat your investmentwill provide anexcellent return.
uote:
“It takes less timeto do a thing rightthan to explainwhy you did itwrong.”H. W.Longfellowpre75977_ch14.qxd  11/27/08  5:52 PM  Page 408discovered during system testing is $7,136 per error. Cigital Inc. [Cig07] considers alarge application that has 200 errors introduced during coding.
According to industry average data, the cost of finding and correcting defects during thecoding phase is $977 per defect. Thus, the total cost for correcting the 200 “critical”defects during this phase (200 /H11003$977) is approximately $195,400.Industry average data shows that the cost of finding and correcting defects during thesystem testing phase is $7,136 per defect. In this case, assuming that the system testingphase revealed approximately 50 critical defects (or only 25% of those found by Cigital inthe coding phase), the cost of finding and fixing those defects (50 /H11003$7,136) would have been approximately $356,800. This would also have resulted in 150 critical errors goingundetected and uncorrected. The cost of finding and fixing these remaining 150 defectsin the maintenance phase (150 /H11003 $14,102) would have been $2,115,300. Thus, the total cost of finding and fixing the 200 defects after the coding phase would have been$2,472,100 ($2,115,300 /H11001$356,800).
Even if your software organization has costs that are half of the industry average(most have no idea what their costs are!), the cost savings associated with earlyquality control and assurance activities (conducted during requirements analysisand design) are compelling.
14.3.3 Risks
In Chapter 1 of this book, I wrote “people bet their jobs, their comforts, their safety, theirentertainment, their decisions, and their very lives on computer software. It better beright.” The implication is that low-quality software increases risks for both the devel-oper and the end user. In the preceding subsection, I discussed one of these risks (cost).But the downside of poorly designed and implemented applications does not alwaysstop with dollars and time. An extreme example [Gag04] might serve to illustrate.CHAPTER 14QUALITY CONCEPTS 409
Requirements$139$455$977$7,136$14,102
Design Coding Testing Maintenance$16,000.00$14,000.00$12,000.00$10,000.00$8,000.00$6,000.00$4,000.00$2,000.00$-FIGURE 14.2
Relative cost ofcorrecting errorsand defectsSource: Adapted from[Boe01b].pre75977_ch14.qxd  11/27/08  5:52 PM  Page 409Throughout the month of November 2000 at a hospital in Panama, 28 patientsreceived massive overdoses of gamma rays during treatment for a variety of cancers.In the months that followed, 5 of these patients died from radiation poisoning and15 others developed serious complications. What caused this tragedy? A softwarepackage, developed by a U.S. company, was modified by hospital technicians tocompute doses of radiation for each patient.The three Panamanian medical physicists, who “tweeked” the software to provideadditional capability, were charged with second-degree murder. The U.S. companyis faced with serious litigation in two countries. Gage and McCormick comment:
This is not a cautionary tale for medical technicians, even though they can find them-selves fighting to stay out of jail if they misunderstand or misuse technology. This alsois not a tale of how human beings can be injured or worse by poorly designed or poorlyexplained software, although there are plenty of examples to make the point. This is awarning for any creator of computer programs: that software quality matters, that appli-cations must be foolproof, and that—whether embedded in the engine of a car, a roboticarm in a factory or a healing device in a hospital—poorly deployed code can kill.
Poor quality leads to risks, some of them very serious.
14.3.4 Negligence and Liability
The story is all too common. A governmental or corporate entity hires a major soft-ware developer or consulting company to analyze requirements and then design andconstruct a software-based “system” to support some major activity. The systemmight support a major corporate function (e.g., pension management) or some gov-ernmental function (e.g., health care administration or homeland security).Work begins with the best of intentions on both sides, but by the time the system isdelivered, things have gone bad. The system is late, fails to deliver desired features andfunctions, is error-prone, and does not meet with customer approval. Litigation ensues.In most cases, the customer claims that the developer has been negligent (in themanner in which it has applied software practices) and is therefore not entitled topayment. The developer often claims that the customer has repeatedly changed itsrequirements and has subverted the development partnership in other ways. In everycase, the quality of the delivered system comes into question.
14.3.5 Quality and Security
As the criticality of Web-based systems and applications grows, application securityhas become increasingly important. Stated simply, software that does not exhibithigh quality is easier to hack, and as a consequence, low-quality software can indi-rectly increase the security risk with all of its attendant costs and problems.In an interview in ComputerWorld,author and security expert Gary McGraw com-ments [Wil05]:
Software security relates entirely and completely to quality. You must think about secu-rity, reliability, availability, dependability—at the beginning, in the design, architecture,test, and coding phases, all through the software life cycle [process]. Even people aware410 PART THREEQUALITY MANAGEMENTpre75977_ch14.qxd  11/27/08  5:52 PM  Page 410of the software security problem have focused on late life-cycle stuff. The earlier you findthe software problem, the better. And there are two kinds of software problems. One isbugs, which are implementation problems. The other is software flaws—architecturalproblems in the design. People pay too much attention to bugs and not enough on flaws.
To build a secure system, you must focus on quality, and that focus must begin dur-ing design. The concepts and methods discussed in Part 2 of this book lead to a soft-ware architecture that reduces “flaws.” By eliminating architectural flaws (therebyimproving software quality), you will make it far more difficult to hack the software.
14.3.6 The Impact of Management Actions
Software quality is often influenced as much by management decisions as it is bytechnology decisions. Even the best software engineering practices can be subvertedby poor business decisions and questionable project management actions.In Part 4 of this book I discuss project management within the context of the soft-ware process. As each project task is initiated, a project leader will make decisionsthat can have a significant impact on product quality.Estimation decisions.As I note in Chapter 26, a software team is rarely given theluxury of providing an estimate for a project before delivery dates are established and an overall budget is specified. Instead, the team conducts a “sanity check” to ensurethat delivery dates and milestones are rational. In many cases there is enormoustime-to-market pressure that forces a team to accept unrealistic delivery dates. As aconsequence, shortcuts are taken, activities that lead to higher-quality software maybe skipped, and product quality suffers. If a delivery date is irrational, it is importantto hold your ground. Explain why you need more time, or alternatively, suggest asubset of functionality that can be delivered (with high quality) in the time allotted.Scheduling decisions.When a software project schedule is established(Chapter 27), tasks are sequenced based on dependencies. For example, becausecomponent Adepends on processing that occurs within components B, C,and D, component Acannot be scheduled for testing until components B, C, and Dare fully tested. A project schedule would reflect this. But if time is very short, and A must be available for further critical testing, you might decide to test Awithout its subordi- nate components (which are running slightly behind schedule), so that you can makeit available for other testing that must be done before delivery. After all, the deadlinelooms. As a consequence, Amay have defects that are hidden, only to be discoveredmuch later. Quality suffers.Risk-oriented decisions.Risk management (Chapter 28) is one of the key attrib-utes of a successful software project. You really do need to know what might gowrong and establish a contingency plan if it does. Too many software teams preferblind optimism, establishing a development schedule under the assumption thatnothing will go wrong. Worse, they don’t have a way of handling things that do gowrong. As a consequence, when a risk becomes a reality, chaos reigns, and as thedegree of craziness rises, the level of quality invariably falls.CHAPTER 14QUALITY CONCEPTS 411pre75977_ch14.qxd  11/27/08  5:52 PM  Page 411The software quality dilemma can best be summarized by stating Meskimen’sLaw—There’s never time to do it right, but always time to do it over again. My advice: taking the time to do it right is almost never the wrong decision.
14.4 A CHIEVING SOFTWARE QUALITY
Software quality doesn’t just appear. It is the result of good project management andsolid software engineering practice. Management and practice are applied withinthe context of four broad activities that help a software team achieve high softwarequality: software engineering methods, project management techniques, qualitycontrol actions, and software quality assurance.
14.4.1 Software Engineering Methods
If you expect to build high-quality software, you must understand the problem to besolved. You must also be capable of creating a design that conforms to the problemwhile at the same time exhibiting characteristics that lead to software that exhibitsthe quality dimensions and factors discussed in Section 14.2.In Part 2 of this book, I presented a wide array of concepts and methods that canlead to a reasonably complete understanding of the problem and a comprehensivedesign that establishes a solid foundation for the construction activity. If you applythose concepts and adopt appropriate analysis and design methods, the likelihoodof creating high-quality software will increase substantially.
14.4.2 Project Management Techniques
The impact of poor management decisions on software quality has been discussed inSection 14.3.6. The implications are clear: if (1) a project manager uses estimation toverify that delivery dates are achievable, (2) schedule dependencies are understoodand the team resists the temptation to use short cuts, (3) risk planning is conducted soproblems do not breed chaos, software quality will be affected in a positive way.In addition, the project plan should include explicit techniques for quality andchange management. Techniques that lead to good project management practicesare discussed in Part 4 of this book.
14.4.3 Quality Control
Quality control encompasses a set of software engineering actions that help toensure that each work product meets its quality goals. Models are reviewed to ensurethat they are complete and consistent. Code may be inspected in order to uncoverand correct errors before testing commences. A series of testing steps is applied touncover errors in processing logic, data manipulation, and interface communication.A combination of measurement and feedback allows a software team to tune theprocess when any of these work products fail to meet quality goals. Quality controlactivities are discussed in detail throughout the remainder of Part 3 of this book.412 PART THREEQUALITY MANAGEMENT
What do Ineed to do toaffect quality in apositive way??
What issoftwarequality control??pre75977_ch14.qxd  11/27/08  5:52 PM  Page 41214.4.4 Quality Assurance
Quality assurance establishes the infrastructure that supports solid software engi-neering methods, rational project management, and quality control actions—allpivotal if you intend to build high-quality software. In addition, quality assuranceconsists of a set of auditing and reporting functions that assess the effectiveness andcompleteness of quality control actions. The goal of quality assurance is to providemanagement and technical staff with the data necessary to be informed about prod-uct quality, thereby gaining insight and confidence that actions to achieve productquality are working. Of course, if the data provided through quality assurance iden-tifies problems, it is management’s responsibility to address the problems and applythe necessary resources to resolve quality issues. Software quality assurance is dis-cussed in detail in Chapter 16.
14.5 S UMMARY
Concern for the quality of the software-based systems has grown as softwarebecomes integrated into every aspect of our daily lives. But it is difficult to developa comprehensive description of software quality. In this chapter quality has beendefined as an effective software process applied in a manner that creates a usefulproduct that provides measurable value for those who produce it and those whouse it.A wide variety of software quality dimensions and factors have been proposedover the years. All try to define a set of characteristics that, if achieved, will lead tohigh software quality. McCall’s and the ISO 9126 quality factors establish character-istics such as reliability, usability, maintainability, functionality, and portability asindicators that quality exists.Every software organization is faced with the software quality dilemma. Inessence, everyone wants to build high-quality systems, but the time and effortrequired to produce “perfect” software are simply unavailable in a market-drivenworld. The question becomes, should we build software that is “good enough”?Although many companies do just that, there is a significant downside that must beconsidered.Regardless of the approach that is chosen, quality does have a cost that can bediscussed in terms of prevention, appraisal, and failure. Prevention costs include allsoftware engineering actions that are designed to prevent defects in the first place.Appraisal costs are associated with those actions that assess software work prod-ucts to determine their quality. Failure costs encompass the internal price of failureand the external effects that poor quality precipitates.Software quality is achieved through the application of software engineeringmethods, solid management practices, and comprehensive quality control—all sup-ported by a software quality assurance infrastructure. In the chapters that follow,quality control and assurance are discussed in some detail.CHAPTER 14QUALITY CONCEPTS 413
WebRef
Useful links to SQAresources can be found atwww.niwotridge.com/Resources/PM-SWEResources/SoftwareQualityAssurance.htmpre75977_ch14.qxd  11/27/08  5:52 PM  Page 413PROBLEMS AND POINTS TO PONDER
14.1.Describe how you would assess the quality of a university before applying to it. Whatfactors would be important? Which would be critical?14.2.Garvin [Gar84] describes five different views of quality. Provide an example of each usingone or more well-known electronic products with which you are familiar.14.3.Using the definition of software quality proposed in Section 14.2, do you think it’s possi-ble to create a useful product that provides measurable value without using an effectiveprocess? Explain your answer.14.4.Add two additional questions to each of Garvin’s quality dimensions presented in Section14.2.1.14.5.McCall’s quality factors were developed during the 1970s. Almost every aspect ofcomputing has changed dramatically since the time that they were developed, and yet,McCall’s factors continue to apply to modern software. Can you draw any conclusions based onthis fact?14.6.Using the subattributes noted for the ISO 9126 quality factor “maintainability” in Section14.2.3, develop a set of questions that explore whether or not these attributes are present.Follow the example shown in Section 14.2.4.14.7.Describe the software quality dilemma in your own words.14.8.What is “good enough” software? Name a specific company and specific products thatyou believe were developed using the good enough philosophy.14.9.Considering each of the four aspects of the cost of quality, which do you think is the mostexpensive and why?14.10.Do a Web search and find three other examples of “risks” to the public that can bedirectly traced to poor software quality. Consider beginning your search at http:// catless.ncl.ac.uk/risks.14.11.Are qualityand securitythe same thing? Explain.14.12.Explain why it is that many of us continue to live by Meskimen’s law. What is it aboutthe software business that causes this?
FURTHER READINGS AND INFORMATION SOURCES
Basic software quality concepts are considered in books by Henry and Hanlon (Software QualityAssurance,Prentice-Hall, 2008), Khan and his colleagues ( Software Quality: Concepts and Practice,Alpha Science International, Ltd., 2006), O’Regan ( A Practical Approach to Software Quality,Springer, 2002), and Daughtrey (Fundamental Concepts for the Software Quality Engineer, ASQ Quality Press, 2001).Duvall and his colleagues (Continuous Integration: Improving Software Quality and ReducingRisk,Addison-Wesley, 2007), Tian (Software Quality Engineering,Wiley-IEEE Computer Society Press, 2005), Kandt (Software Engineering Quality Practices, Auerbach, 2005), Godbole (Software Quality Assurance: Principles and Practice, Alpha Science International, Ltd., 2004), and Galin (Software Quality Assurance: From Theory to Implementation, Addison-Wesley, 2003) present detailed treatments of SQA. Quality assurance in the context of the agile process is consideredby Stamelos and Sfetsos (Agile Software Development Quality Assurance, IGI Global, 2007). Solid design leads to high software quality. Jayasawal and Patton ( Design for Trustworthy Software,Prentice-Hall, 2006) and Ploesch (Contracts, Scenarios and Prototypes, Springer, 2004) discuss tools and techniques for developing “robust” software.414 PART THREEQUALITY MANAGEMENTpre75977_ch14.qxd  11/27/08  5:52 PM  Page 414Measurement is an important component of software quality engineering. Ejiogu ( Software Metrics: The Discipline of Software Quality, BookSurge Publishing, 2005), Kan ( Metrics and Mod- els in Software Quality Engineering, Addison-Wesley, 2002), and Nance and Arthur (Managing Software Quality,Springer, 2002) discuss important quality-related metrics and models. Theteam-oriented aspects of software quality are considered by Evans (Achieving Software Qualitythrough Teamwork,Artech House Publishers, 2004).A wide variety of information sources on software quality is available on the Internet. An up-to-date list of World Wide Web references relevant to software quality can be found  at the SEPAwebsite: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 14QUALITY CONCEPTS 415pre75977_ch14.qxd  11/27/08  5:52 PM  Page 415Software reviews are a “filter” for the software process. That is, reviews areapplied at various points during software engineering and serve to uncovererrors and defects that can then be removed. Software reviews “purify” soft-ware engineering work products, including requirements and design models,code, and testing data. Freedman and Weinberg [Fre90] discuss the need forreviews this way:
Technical work needs reviewing for the same reason that pencils need erasers: To erris human.The second reason we need technical reviews is that although people aregood at catching some of their own errors, large classes of errors escape the origina-tor more easily than they escape anyone else. The review process is, therefore, theanswer to the prayer of Robert Burns:O wad some power the giftie give usto see ourselves as other see usA review—any review—is a way of using the diversity of a group of people to:1. Point out needed improvements in the product of a single person or team;
416CHAPTER
15REVIEW
TECHNIQUES
KEY
CONCEPTS
defect amplification . . .418defects . . . . . . .417error density  . .421errors  . . . . . . .417record keeping . .427reviewmetrics . . . . . .420reporting  . . . .427reviewscosteffectiveness . .421informal . . . . .424sample-driven  . . . . . .429technical . . . . .426
What is it? You’ll make mistakes asyou develop software engineeringwork products. There’s no shame inthat—as long as you try hard, veryhard, to find and correct the mistakes beforethey are delivered to end users. Technicalreviews are the most effective mechanism forfinding mistakes early in the software process.
Who does it? Software engineers perform techni-cal reviews, also called peer reviews, with theircolleagues.
Why is it important? If you find an error early inthe process, it is less expensive to correct. In addi-tion, errors have a way of amplifying as theprocess proceeds. So a relatively minor error leftuntreated early in the process can be amplifiedinto a major set of errors later in the project.Finally, reviews save time by reducing the amountof rework that will be required late in the project.QUICK
LOOKWhat are the steps? Your approach to reviewswill vary depending on the degree of formalityyou select. In general, six steps are employed,although not all are used for every type ofreview: planning, preparation, structuring themeeting, noting errors, making corrections(done outside the review), and verifying thatcorrections have been performed properly.
What is the work product? The output of areview is a list of issues and/or errors that havebeen uncovered. In addition, the technical statusof the work product is also indicated.
How do I ensure that I’ve done it right? First,select the type of review that is appropriate foryour development culture. Follow the guidelinesthat lead to successful reviews. If the reviewsthat you conduct lead to higher-quality soft-ware, you’ve done it right.pre75977_ch15.qxd  11/27/08  5:54 PM  Page 4162. Confirm those parts of a product in which improvement is either not desired or notneeded;3. Achieve technical work of more uniform, or at least more predictable, quality than can beachieved without reviews, in order to make technical work more manageable.
Many different types of reviews can be conducted as part of software engineering.Each has its place. An informal meeting around the coffee machine is a form ofreview, if technical problems are discussed. A formal presentation of softwarearchitecture to an audience of customers, management, and technical staff is also aform of review. In this book, however, I focus on technical or peer reviews,exempli- fied by casual reviews, walkthroughs,and inspections.A technical review (TR) is the most effective filter from a quality control standpoint. Conducted by software engi-neers (and others) for software engineers, the TR is an effective means for uncover-ing errors and improving software quality.
15.1 C OSTIMPACT OF SOFTWARE DEFECTS
Within the context of the software process, the terms defect and faultare synony- mous. Both imply a quality problem that is discovered afterthe software has been released to end users (or to another framework activity in the software process). Inearlier chapters, we used the term errorto depict a quality problem that is discovered by software engineers (or others) before the software is released to the end user (or to another framework activity in the software process).CHAPTER 15REVIEW TECHNIQUES 417
Reviews are like afilter in the softwareprocess workflow. Toofew, and the flow is“dirty.” Too many, andthe flow slows to atrickle. Use metrics todetermine whichreviews work andemphasize them.Remove ineffectivereviews from the flowto accelerate theprocess.
1 If software process improvement is considered, a quality problem that is propagated from oneprocess framework activity (e.g., modeling) to another (e.g., construction) can also be called a“defect” (because the problem should have been found before a work product (e.g., a design model)was “released” to the next activity.Bugs, Errors, and Defects
The goal of software quality control, and in abroader sense, quality management in general,is to remove quality problems in the software. Theseproblems are referred to by various names— bugs, faults, errors,or defectsto name a few. Are each of these termssynonymous, or are there subtle differences between them?In this book I make a clear distinction between an error (a quality problem found beforethe software is released toend users) and a defect(a quality problem found only afterthe software has been released to end users
1). I make this distinction because errors and defects have very differenteconomic, business, psychological, and human impact. Assoftware engineers, we want to find and correct as manyerrors as possible before the customer and/or end userencounter them. We want to avoid defects—becausedefects (justifiably) make software people look bad.It is important to note, however, that the temporaldistinction made between errors and defects in this book isnotmainstream thinking. The general consensus within thesoftware engineering community is that defects and errors,faults, and bugs are synonymous. That is, the point in timethat the problem was encountered has no bearing on theterm used to describe the problem. Part of the argument infavor of this view is that it is sometimes difficult to make aINFOpre75977_ch15.qxd  11/27/08  5:54 PM  Page 417418 PART THREEQUALITY MANAGEMENT
The primary objective of technical reviews is to find errors during the process sothat they do not become defects after release of the software. The obvious benefit oftechnical reviews is the early discovery of errors so that they do not propagate to thenext step in the software process.A number of industry studies indicate that design activities introduce between 50and 65 percent of all errors (and ultimately, all defects) during the software process.However, review techniques have been shown to be up to 75 percent effective[Jon86] in uncovering design flaws. By detecting and removing a large percentage ofthese errors, the review process substantially reduces the cost of subsequent activi-ties in the software process.
15.2 D EFECT AMPLIFICATION AND REMOVAL
A defect amplification model[IBM81] can be used to illustrate the generation anddetection of errors during the design and code generation actions of a softwareprocess. The model is illustrated schematically in Figure 15.1. A box represents a soft-ware engineering action. During the action, errors may be inadvertently generated.Review may fail to uncover newly generated errors and errors from previous steps,resulting in some number of errors that are passed through. In some cases, errorspassed through from previous steps are amplified (amplification factor, x) by current work. The box subdivisions represent each of these characteristics and the percent ofefficiency for detecting errors, a function of the thoroughness of the review.Figure 15.2 illustrates a hypothetical example of defect amplification for a softwareprocess in which no reviews are conducted. Referring to the figure, each test step isassumed to uncover and correct 50 percent of all incoming errors without intro-ducing any new errors (an optimistic assumption). Ten preliminary design defects areamplified to 94 errors before testing commences. Twelve latent errors (defects) arereleased to the field. Figure 15.3 considers the same conditions except that design andcode reviews are conducted as part of each software engineering action. In this case,10 initial preliminary (architectural) design errors are amplified to 24 errors beforetesting commences. Only three latent errors exist. The relative costs associated withthe discovery and correction of errors, overall cost (with and without review for ourhypothetical example) can be established. The number of errors uncovered duringeach of the steps noted in Figures 15.2 and 15.3 is multiplied by the cost to remove anclear distinction between pre- and post-release (e.g.,consider an incremental process used in agiledevelopment).Regardless of how you choose to interpret theseterms, recognize that the point in time at which aproblem is discovered does matter and that softwareengineers should try hard—veryhard—to find problemsbefore their customers and end users encounter them. Ifyou have further interest in this issue, a reasonablythorough discussion of the terminology surrounding“bugs” can be found atwww.softwaredevelopment.ca/bugs.shtml .
The primary objectiveof an FTR is to finderrors before they arepassed on to anothersoftware engineeringactivity or released tothe end user.
uote:
“Some maladies, asdoctors say, at theirbeginning are easyto cure but difficultto recognize … butin the course of timewhen they have notat first beenrecognized andtreated, becomeeasy to recognizebut difficult tocure.”NiccoloMachiavellipre75977_ch15.qxd  11/27/08  5:54 PM  Page 418CHAPTER 15REVIEW TECHNIQUES 419
Errors passed throughDevelopment stepDefectsDetectionErrors fromprevious stepAmplified errors 1 : xNewly generated errorsPercentefficiencyfor errordetectionErrors passedto next stepFIGURE 15.1
Defect amplifi-cation model
6Preliminary design01000%1064Detail design4 × 1.5   x = 1.5250%371027Code/unit test102527 × 3     x = 320%94To integration94Integration test0050%47Validation test0050%24System test0050%12Latent errors(defects)FIGURE 15.2
Defect amplifi-cation—noreviews
Preliminary design 0100Detail design
25Code/unit test
25To integrationIntegration test0050%Validation test0050%System test0050%Latent errors(defects) 32170%50%21   1.524632460%510  315 51012FIGURE 15.3
Defect amplifi-cation—reviewsconductedpre75977_ch15.qxd  11/27/08  5:54 PM  Page 419error (1.5 cost units for design, 6.5 cost units before test, 15 cost units during test, and67 cost units after release).
2Using these data, the total cost for development andmaintenance when reviews are conducted is 783 cost units. When no reviews areconducted, total cost is 2177 units—nearly three times more costly.To conduct reviews, you must expend time and effort, and your developmentorganization must spend money. However, the results of the preceding exampleleave little doubt that you can pay now or pay much more later.
15.3 R EVIEW METRICS AND THEIR USE
Technical reviews are one of many actions that are required as part of good softwareengineering practice. Each action requires dedicated human effort, Since availableproject effort is finite, it is important for a software engineering organization tounderstand the effectiveness of each action by defining a set of metrics (Chapter 23)that can be used to assess their efficacy.Although many metrics can be defined for technical reviews, a relatively smallsubset can provide useful insight. The following review metrics can be collected foreach review that is conducted:
•Preparation effort, Ep—the effort (in person-hours) required to review a workproduct prior to the actual review meeting
•Assessment effort, Ea—the effort (in person-hours) that is expended during theactual review
•Rework effort, Er—the effort (in person-hours) that is dedicated to the correc-tion of those errors uncovered during the review
•Work product size, WPS—a measure of the size of the work product that hasbeen reviewed (e.g., the number of UML models, or the number of documentpages, or the number of lines of code)
•Minor errors found, Errminor—the number of errors found that can be catego-rized as minor (requiring less than some prespecified effort to correct)
•Major errors found, Errmajor—the number of errors found that can be catego-rized as major (requiring more than some prespecified effort to correct)These metrics can be further refined by associating the type of work product that wasreviewed for the metrics collected.
15.3.1 Analyzing Metrics
Before analysis can begin, a few simple computations must occur. The total revieweffort and the total number of errors discovered are defined as:E
review /H11005Ep/H11001Ea/H11001Er
Errtot/H11005Errminor /H11001Errmajor420 PART THREEQUALITY MANAGEMENT
2 These multipliers are somewhat different than the data presented in Figure 14.2, which is morecurrent. However, they serve to illustrate the costs of defect amplification nicely.pre75977_ch15.qxd  11/27/08  5:54 PM  Page 420Error densityrepresents the errors found per unit of work product reviewed.Error density /H11005For example, if a requirements model is reviewed to uncover errors, inconsistencies,and omissions, it would be possible to compute the error density in a number of dif-ferent ways. The requirements model contains 18 UML diagrams as part of 32 over-all pages of descriptive materials. The review uncovers 18 minor errors and 4 majorerrors. Therefore, Err
tot/H1100522. Error density is 1.2 errors per UML diagram or 0.68errors per requirements model page.If reviews are conducted for a number of different types of work products (e.g.,requirements model, design model, code, test cases), the percentage of errorsuncovered for each review can be computed against the total number of errorsfound for all reviews. In addition, the error density for each work product can becomputed.Once data are collected for many reviews conducted across many projects, aver-age values for error density enable you to estimate the number of errors to be foundin a new (as yet unreviewed document). For example, if the average error density fora requirements model is 0.6 errors per page, and a new requirement model is 32pages long, a rough estimate suggests that your software team will find about 19 or20 errors during the review of the document. If you find only 6 errors, you’ve donean extremely good job in developing the requirements model or your reviewapproach was not thorough enough.Once testing has been conducted (Chapters 17 through 20), it is possible to collectadditional error data, including the effort required to find and correct errors uncov-ered during testing and the error density of the software. The costs associated withfinding and correcting an error during testing can be compared to those for reviews.This is discussed in Section 15.3.2.
15.3.2 Cost Effectiveness of Reviews
It is difficult to measure the cost effectiveness of any technical review in real time. Asoftware engineering organization can assess the effectiveness of reviews and theircost benefit only after reviews have been completed, review metrics have been col-lected, average data have been computed, and then the downstream quality of thesoftware is measured (via testing).Returning to the example presented in Section 15.3.1, the average error densityfor requirements models was determined to be 0.6 errors per page. The effortrequired to correct a minor model error (immediately after the review) was found torequire 4 person-hours. The effort required for a major requirement error was foundto be 18 person-hours. Examining the review data collected, you find that minorerrors occur about 6 times more frequently than major errors. Therefore, you canestimate that the average effort to find and correct a requirements error duringreview is about 6 person-hours.Errtot
WPSCHAPTER 15REVIEW TECHNIQUES 421pre75977_ch15.qxd  11/27/08  5:54 PM  Page 421Requirements-related errors uncovered during testing require an average of 45person-hours to find and correct (no data are available on the relative severity of theerror). Using the averages noted, we get:Effort saved per error /H11005E
testing /H11002Ereviews
45 /H110026 /H1100530 person-hours/error Since 22 errors were found during the review of the requirements model, a saving ofabout 660 person-hours of testing effort would be achieved. And that’s just forrequirements-related errors. Errors associated with design and code would add tothe overall benefit. The bottom line—effort saved leads to shorter delivery cycles andimproved time to market.In his book on peer reviews, Karl Wiegers [Wie02] discusses anecdotal data frommajor companies that have used inspections (a relatively formal type of technical review) as part of their software quality control activities. Hewlett Packard reporteda 10 to 1 return on investment for inspections and noted that actual product deliveryaccelerated by an average of 1.8 calendar months. AT&T indicated that inspectionsreduced the overall cost of software errors by a factor of 10 and that quality improvedby an order of magnitude and productivity increased by 14 percent. Others reportsimilar benefits. Technical reviews (for design and other technical activities) providea demonstrable cost benefit and actually save time.But for many software people, this statement is counterintuitive. “Reviews taketime,” software people argue, “and we don’t have the time to spare!” They argue thattime is a precious commodity on every software project and the ability to review“every work product in detail” absorbs too much time.The examples presented earlier in this section indicate otherwise. More impor-tantly, industry data for software reviews has been collected for more than twodecades and is summarized qualitatively using the graphs illustrated in Figure 15.4.422 PART THREEQUALITY MANAGEMENT
PlanningRequirementsWithoutinspections
WithinspectionsDeploymentDesign Code TestEffort
TimeFIGURE 15.4
Effortexpended withand withoutreviewsSource:Adapted from[Fag86].pre75977_ch15.qxd  11/27/08  5:54 PM  Page 422Referring to the figure, the effort expended when reviews are used does increaseearly in the development of a software increment, but this early investment forreviews pays dividends because testing and corrective effort is reduced. As impor-tant, the deployment date for development with reviews is sooner than the deploy-ment date without reviews. Reviews don’t take time, they save it!
15.4 R EVIEWS : A F ORMALITY SPECTRUM
Technical reviews should be applied with a level of formality that is appropriate forthe product to be built, the project time line, and the people who are doing the work.Figure 15.5 depicts a reference model for technical reviews [Lai02] that identifies fourcharacteristics that contribute to the formality with which a review is conducted.Each of the reference model characteristics helps to define the level of reviewformality. The formality of a review increases when (1) distinct roles are explicitlydefined for the reviewers, (2) there is a sufficient amount of planning and prepara-tion for the review, (3) a distinct structure for the review (including tasks and inter-nal work products) is defined, and (4) follow-up by the reviewers occurs for anycorrections that are made.To understand the reference model, let’s assume that you’ve decided to review theinterface design for SafeHomeAssured.com. You can do this in a variety of differentways that range from relatively casual to extremely rigorous. If you decide that thecasual approach is most appropriate, you ask a few colleagues (peers) to examinethe interface prototype in an effort to uncover potential problems. All of you decidethat there will be no advance preparation, but that you will evaluate the prototype ina reasonably structured way—looking at layout first, aesthetics next, navigation op-tions after that, and so on. As the designer, you decide to take a few notes, but noth-ing formal.CHAPTER 15REVIEW TECHNIQUES 423
ReviewPlanning& preparationRolesindividualsplayMeetingstructureCorrection &verificationFIGURE 15.5
Referencemodel fortechnicalreviewspre75977_ch15.qxd  11/27/08  5:54 PM  Page 423But what if the interface is pivotal to the success of the entire project? What if humanlives depended on an interface that was ergonomically sound? You might decide thata more rigorous approach was necessary. A review team would be formed. Each per-son on the team would have a specific role to play—leading the team, recording find-ings, presenting the material, and so on. Each reviewer would be given access to thework product (in this case, the interface prototype) before the review and would spendtime looking for errors, inconsistencies, and omissions. A set of specific tasks wouldbe conducted based on an agenda that was developed before the review occurred. Theresults of the review would be formally recorded, and the team would decide on thestatus of the work product based on the outcome of the review. Members of the reviewteam might also verify that the corrections made were done properly.In this book I consider two broad categories of technical reviews: informal reviewsand more formal technical reviews. Within each broad category, a number of differ-ent approaches can be chosen. These are presented in the sections that follow.
15.5 I NFORMAL REVIEWS
Informal reviews include a simple desk check of a software engineering workproduct with a colleague, a casual meeting (involving more than two people) forthe purpose of reviewing a work product, or the review-oriented aspects of pairprogramming (Chapter 3).A simple desk checkor a casual meetingconducted with a colleague is a review. However, because there is no advance planning or preparation, no agenda or meet-ing structure, and no follow-up on the errors that are uncovered, the effectiveness ofsuch reviews is considerably lower than more formal approaches. But a simple deskcheck can and does uncover errors that might otherwise propagate further into thesoftware process.One way to improve the efficacy of a desk check review is to develop a set of sim-ple review checklists for each major work product produced by the software team.The questions posed within the checklist are generic, but they will serve to guide thereviewers as they check the work product. For example, let’s reexamine a desk checkof the interface prototype for SafeHomeAssured.com. Rather than simply playingwith the prototype at the designer’s workstation, the designer and a colleagueexamine the prototype using a checklist for interfaces:
•Is the layout designed using standard conventions? Left to right? Top tobottom?
•Does the presentation need to be scrolled?
•Are color and placement, typeface, and size used effectively?
•Are all navigation options or functions represented at the same level ofabstraction?
•Are all navigation choices clearly labeled?424 PART THREEQUALITY MANAGEMENTpre75977_ch15.qxd  11/27/08  5:54 PM  Page 424and so on. Any errors or issues noted by the reviewers are recorded by the designerfor resolution at a later time. Desk checks may be scheduled in an ad hoc manner,or they may be mandated as part of good software engineering practice. In general,the amount of material to be reviewed is relatively small and the overall time spenton a desk check spans little more than one or two hours.In Chapter 3, I described pair programming in the following manner: “XP recom- mends that two people work together at one computer workstation to create codefor a story. This provides a mechanism for real-time problem solving (two heads areoften better than one) and real-time quality assurance.”Pair programming can be characterized as a continuous desk check. Rather thanscheduling a review at some point in time, pair programming encourages continu-ous review as a work product (design or code) is created. The benefit is immediatediscovery of errors and better work product quality as a consequence.In their discussion of the efficacy of pair programming, Williams and Kessler[Wil00] state:
Anecdotal and initial statistical evidence indicates that pair programming is a powerfultechnique for productively generating high quality software products. The pair works andshares ideas together to tackle the complexities of software development. They continu-ously perform inspections on each other’s artifacts leading to the earliest, most efficientform of defect removal possible. In addition, they keep each other intently focused on thetask at hand.
Some software engineers argue that the inherent redundancy built into pair pro-gramming is wasteful of resources. After all, why assign two people to a job that oneperson can accomplish? The answer to this question can be found in Section 15.3.2.If the quality of the work product produced as a consequence of pair programmingis significantly better than the work of an individual, the quality-related savings canmore than justify the “redundancy” implied by pair programming.CHAPTER 15REVIEW TECHNIQUES 425
Review Checklists
Even when reviews are well organized andproperly conducted, it’s not a bad idea toprovide reviewers with a “crib sheet.” That is, it’sworthwhile to have a checklist that provides each reviewerwith the questions that should be asked about the specificwork product that is undergoing review.One of the most comprehensive collections of reviewchecklists has been developed by NASA at the GoddardSpace Flight Center and is available at http://sw-assurance.gsfc.nasa.gov/disciplines/quality/index.phpOther useful technical review checklists have also beenproposed by:Process Impact (www.processimpact.com/pr_goodies.shtml)Software Dioxide(www.softwaredioxide.com/Channels/ConView.asp?id=6309)Macadamian(www.macadamian.com) The Open Group Architecture Review Checklist(www.opengroup.org/architecture/togaf7-doc/arch/p4/comp/clists/syseng.htm ) DFAS[downloadable] (www.dfas.mil/technology/pal/ssps/docstds/spm036.doc )INFOpre75977_ch15.qxd  11/27/08  5:54 PM  Page 42515.6 F ORMAL TECHNICAL REVIEWS
A formal technical review(FTR) is a software quality control activity performed bysoftware engineers (and others). The objectives of an FTR are: (1) to uncover errorsin function, logic, or implementation for any representation of the software; (2) toverify that the software under review meets its requirements; (3) to ensure that thesoftware has been represented according to predefined standards; (4) to achievesoftware that is developed in a uniform manner; and (5) to make projects more man-ageable. In addition, the FTR serves as a training ground, enabling junior engineersto observe different approaches to software analysis, design, and implementation.The FTR also serves to promote backup and continuity because a number of peoplebecome familiar with parts of the software that they may not have otherwise seen.The FTR is actually a class of reviews that includes walkthroughs and inspections. Each FTR is conducted as a meeting and will be successful only if it is properlyplanned, controlled, and attended. In the sections that follow, guidelines similar tothose for a walkthrough are presented as a representative formal technical review.If you have interest in software inspections, as well as additional information onwalkthroughs, see [Rad02], [Wie02], or [Fre90].
15.6.1 The Review Meeting
Regardless of the FTR format that is chosen, every review meeting should abide bythe following constraints:
•Between three and five people (typically) should be involved in the review.
•Advance preparation should occur but should require no more than twohours of work for each person.
•The duration of the review meeting should be less than two hours.Given these constraints, it should be obvious that an FTR focuses on a specific (andsmall) part of the overall software. For example, rather than attempting to review anentire design, walkthroughs are conducted for each component or small group ofcomponents. By narrowing the focus, the FTR has a higher likelihood of uncoveringerrors.The focus of the FTR is on a work product (e.g., a portion of a requirements model,a detailed component design, source code for a component). The individual who hasdeveloped the work product—the producer—informs the project leader that the workproduct is complete and that a review is required. The project leader contacts areview leader,who evaluates the product for readiness, generates copies of productmaterials, and distributes them to two or three reviewers for advance preparation. Each reviewer is expected to spend between one and two hours reviewing the prod-uct, making notes, and otherwise becoming familiar with the work. Concurrently, thereview leader also reviews the product and establishes an agenda for the reviewmeeting, which is typically scheduled for the next day.426 PART THREEQUALITY MANAGEMENT
uote:
“There is no urgeso great as for oneman to editanother man’swork.”Mark Twain
WebRef
The NASA SATCFormal InspectionGuidebookcan bedownloaded fromsatc.gsfc.nasa.gov/Documents/fi/gdb/fi.pdf.
An FTR focuses on arelatively small portionof a work product.pre75977_ch15.qxd  11/27/08  5:54 PM  Page 426The review meeting is attended by the review leader, all reviewers, and the pro-ducer. One of the reviewers takes on the role of a recorder,that is, the individual who records (in writing) all important issues raised during the review. The FTR beginswith an introduction of the agenda and a brief introduction by the producer. The pro-ducer then proceeds to “walk through” the work product, explaining the material,while reviewers raise issues based on their advance preparation. When valid prob-lems or errors are discovered, the recorder notes each.At the end of the review, all attendees of the FTR must decide whether to: (1) ac-cept the product without further modification, (2) reject the product due to severe er-rors (once corrected, another review must be performed), or (3) accept the productprovisionally (minor errors have been encountered and must be corrected, but noadditional review will be required). After the decision is made, all FTR attendeescomplete a sign-off, indicating their participation in the review and their concur-rence with the review team’s findings.
15.6.2 Review Reporting and Record Keeping
During the FTR, a reviewer (the recorder) actively records all issues that have beenraised. These are summarized at the end of the review meeting, and a review issues listis produced. In addition, a formal technical review summary report is completed. A review summary report answers three questions:1.What was reviewed?2.Who reviewed it?3.What were the findings and conclusions?The review summary report is a single page form (with possible attachments). It be-comes part of the project historical record and may be distributed to the projectleader and other interested parties.The review issues list serves two purposes: (1) to identify problem areas withinthe product and (2) to serve as an action item checklist that guides the producer ascorrections are made. An issues list is normally attached to the summary report.You should establish a follow-up procedure to ensure that items on the issues listhave been properly corrected. Unless this is done, it is possible that issues raised can“fall between the cracks.” One approach is to assign the responsibility for follow-upto the review leader.
15.6.3 Review Guidelines
Guidelines for conducting formal technical reviews must be established in advance,distributed to all reviewers, agreed upon, and then followed. A review that is un-controlled can often be worse than no review at all. The following represents a min-imum set of guidelines for formal technical reviews:1.Review the product, not the producer.An FTR involves people and egos. Con-ducted properly, the FTR should leave all participants with a warm feeling ofCHAPTER 15REVIEW TECHNIQUES 427
In some situations, it’sa good idea to havesomeone other thanthe producer walkthrough the productundergoing review.This leads to a literalinterpretation of thework product andbetter error recogni-tion.
Don’t point out errorsharshly. One way to begentle is to ask aquestion that enablesthe producer todiscover the error.pre75977_ch15.qxd  11/27/08  5:54 PM  Page 427accomplishment. Conducted improperly, the FTR can take on the aura of aninquisition. Errors should be pointed out gently; the tone of the meetingshould be loose and constructive; the intent should not be to embarrass orbelittle. The review leader should conduct the review meeting to ensure thatthe proper tone and attitude are maintained and should immediately halt areview that has gotten out of control.2.Set an agenda and maintain it.One of the key maladies of meetings of alltypes is drift. An FTR must be kept on track and on schedule. The reviewleader is chartered with the responsibility for maintaining the meeting sched-ule and should not be afraid to nudge people when drift sets in.3.Limit debate and rebuttal.When an issue is raised by a reviewer, there maynot be universal agreement on its impact. Rather than spending time debat-ing the question, the issue should be recorded for further discussion off-line.4.Enunciate problem areas, but don’t attempt to solve every problem noted. A re- view is not a problem-solving session. The solution of a problem can oftenbe accomplished by the producer alone or with the help of only one other in-dividual. Problem solving should be postponed until after the review meeting.5.Take written notes.It is sometimes a good idea for the recorder to make noteson a wall board, so that wording and priorities can be assessed by other re-viewers as information is recorded. Alternatively, notes may be entered di-rectly into a notebook computer.6.Limit the number of participants and insist upon advance preparation. Two heads are better than one, but 14 are not necessarily better than 4. Keep thenumber of people involved to the necessary minimum. However, all reviewteam members must prepare in advance. Written comments should besolicited by the review leader (providing an indication that the reviewerhas reviewed the material).7.Develop a checklist for each product that is likely to be reviewed. A checklist helps the review leader to structure the FTR meeting and helps each reviewerto focus on important issues. Checklists should be developed for analysis,design, code, and even testing work products.8.Allocate resources and schedule time for FTRs. For reviews to be effective, they should be scheduled as tasks during the software process. In addition, timeshould be scheduled for the inevitable modifications that will occur as theresult of an FTR.9.Conduct meaningful training for all reviewers. To be effective all review partici- pants should receive some formal training. The training should stress bothprocess-related issues and the human psychological side of reviews. Freed-man and Weinberg [Fre90] estimate a one-month learning curve for every20 people who are to participate effectively in reviews.428 PART THREEQUALITY MANAGEMENT
uote:
“A meeting is toooften an event inwhich minutes aretaken and hoursare wasted.”Author unknown
uote:
“It is one of themost beautifulcompensations oflife, that no mancan sincerely try tohelp anotherwithout helpinghimself.”Ralph WaldoEmersonpre75977_ch15.qxd  11/27/08  5:54 PM  Page 42810.Review your early reviews.Debriefing can be beneficial in uncovering prob-lems with the review process itself. The very first product to be reviewedshould be the review guidelines themselves.Because many variables (e.g., number of participants, type of work products, tim-ing and length, specific review approach) have an impact on a successful review, asoftware organization should experiment to determine what approach works best ina local context.
15.6.4 Sample-Driven Reviews
In an ideal setting, every software engineering work product would undergo a for-mal technical review. In the real word of software projects, resources are limited andtime is short. As a consequence, reviews are often skipped, even though their valueas a quality control mechanism is recognized.Thelin and his colleagues [The01] suggest a sample-driven review process inwhich samples of all software engineering work products are inspected to determinewhich work products are most error prone. Full FTR resources are then focused onlyon those work products that are likely (based on data collected during sampling) tobe error prone.To be effective, the sample-driven review process must attempt to quantify thosework products that are primary targets for full FTRs. To accomplish this, the follow-ing steps are suggested [The01]:1.Inspect a fraction a
iof each software work product i.Record the number of faults f
ifound within ai.2.Develop a gross estimate of the number of faults within work product i by multiplying f
iby 1/ai.3.Sort the work products in descending order according to the gross estimateof the number of faults in each.4.Focus available review resources on those work products that have the high-est estimated number of faults.The fraction of the work product that is sampled must be representative of the workproduct as a whole and large enough to be meaningful to the reviewers who do thesampling. As a
iincreases, the likelihood that the sample is a valid representation ofthe work product also increases. However, the resources required to do samplingalso increase. A software engineering team must establish the best value for a
ifor the types of work products produced.
3CHAPTER 15REVIEW TECHNIQUES 429
3 Thelin and his colleagues have conducted a detailed simulation that can assist in making thisdetermination. See [The01] for details.Reviews take time, butit’s time well spend.However, if time isshort and you have noother option, do notdispense with reviews.Rather, use sample-driven reviews.pre75977_ch15.qxd  11/27/08  5:54 PM  Page 42915.7 S UMMARY
The intent of every technical review is to find errors and uncover issues that would havea negative impact on the software to be deployed. The sooner an error is uncovered andcorrected, the less likely that error will propagate to other software engineering workproducts and amplify itself, resulting in significantly more effort to correct it.To determine whether quality control activities are working, a set of metricsshould be collected. Review metrics focus on the effort required to conduct the re-view and the types and severity of errors uncovered during the review. Once metricsdata are collected, they can be used to assess the efficacy of the reviews you do con-duct. Industry data indicates that reviews provide a significant return on investment.A reference model for review formality identifies the roles people play, planningand preparation, meeting structure, correction approach, and verification as thecharacteristics that indicate the degree of formality with which a review is con-ducted. Informal reviews are casual in nature, but can still be used effectively to un-cover errors. Formal reviews are more structured and have the highest probability ofleading to high-quality software.430 PART THREEQUALITY MANAGEMENT
Quality Issues
The scene:Doug Miller’s office as theSafeHomesoftware project begins.The players:Doug Miller (manager of the SafeHome software engineering team) and other members of theproduct software engineering team.The conversation:Doug:I know we didn’t spend time developing a qualityplan for this project, but we’re already into it and wehave to consider quality … right?Jamie:Sure. We’ve already decided that as we develop therequirements model [Chapters 6 and 7], Ed has committed todevelop a testing procedure for each requirement.Doug:That’s really good, but we’re not going to waituntil testing to evaluate quality, are we?Vinod:No! Of course not. We’ve got reviews scheduledinto the project plan for this software increment. We’llbegin quality control with the reviews.Jamie:I’m a bit concerned that we won’t have enoughtime to conduct all the reviews. In fact, I know we won’t.Doug:Hmmm. So what do you propose?Jamie:I say we select those elements of the requirementsand design model that are most critical to SafeHome and review them.Vinod:But what if we miss something in a part of themodel we don’t review?Shakira:I read something about a sampling technique[Section 15.6.4] that might help us target candidates forreview. (Shakira explains the approach.)Jamie:Maybe … but I’m not sure we even have time tosample every element of the models.Vinod:What do you want us to do, Doug?Doug:Let’s steal something from Extreme Programming[Chapter 3]. We’ll develop the elements of each model inpairs—two people—and conduct an informal review ofeach as we go. We’ll then target “critical” elements for amore formal team review, but keep those reviews to aminimum. That way, everything gets looked at by morethan one set of eyes, but we still maintain our deliverydates.Jamie:That means we’re going to have to revise theschedule.Doug:So be it. Quality trumps schedule on this project.SAFEHOMEpre75977_ch15.qxd  11/27/08  5:54 PM  Page 430Informal reviews are characterized by minimal planning and preparation and littlerecord keeping. Desk checks and pair programming fall into the informal review category.A formal technical review is a stylized meeting that has been shown to be ex-tremely effective in uncovering errors. Walkthroughs and inspections establish de-fined roles for each reviewer, encourage planning and advance preparation, requirethe application of defined review guidelines, and mandate record keeping and sta-tus reporting. Sample-driven reviews can be used when it is not possible to conductformal technical reviews for all work products.
PROBLEMS AND POINTS TO PONDER
15.1. Explain the difference between an error and a defect. 15.2.Why can’t we just wait until testing to find and correct all software errors?15.3.Assume that 10 errors have been introduced in the requirements model and that eacherror will be amplified by a factor of 2:1 into design and an addition 20 design errors are intro-duced and then amplified 1.5:1 into code where an additional 30 errors are introduced. Assumefurther that all unit testing will find 30 percent of all errors, integration will find 30 percent ofthe remaining errors, and validation tests will find 50 percent of the remaining errors. Noreviews are conducted. How many errors will be released to the field.15.4.Reconsider the situation described in Problem 15.3, but now assume that requirements,design, and code reviews are conducted and are 60 percent effective in uncovering all errors atthat step. How many errors will be released to the field?15.5.Reconsider the situation described in Problems 15.3 and 15.4. If each of the errorsreleased to the field costs $4,800 to find and correct and each error found in review costs $240to find and correct, how much money is saved by conducting reviews?15.6.Describe the meaning of Figure 15.4 in your own words.15.7.Which of the reference model characteristics do you think has the strongest bearing onreview formality? Explain why.15.8.Can you think of a few instances in which a desk check might create problems rather thanprovide benefits?15.9.A formal technical review is effective only if everyone has prepared in advance. How do yourecognize a review participant who has not prepared? What do you do if you’re the review leader?15.10.Considering all of the review guidelines presented in Section 15.6.3, which do you thinkis most important and why?
FURTHER READINGS AND INFORMATION SOURCES
There have been relatively few books written on software reviews. Recent editions that provideworthwhile guidance include books by Wong (Modern Software Review, IRM Press, 2006), Radice (High Quality, Low Cost Software Inspections, Paradoxicon Publishers, 2002), Wiegers (Peer Reviews in Software: A Practical Guide, Addison-Wesley, 2001), and Gilb and Graham ( Software Inspection,Addison-Wesley, 1993). Freedman and Weinberg (Handbook of Walkthroughs,Inspections and Technical Reviews, Dorset House, 1990) remains a classic text and continues to provide worthwhile information about this important subject.A wide variety of information sources on software reviews is available on the Internet.An up-to-date list of World Wide Web references relevant to software reviews can be foundat the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 15REVIEW TECHNIQUES 431pre75977_ch15.qxd  11/27/08  5:54 PM  Page 431The software engineering approach described in this book works toward asingle goal: to produce on-time, high-quality software. Yet many readerswill be challenged by the question: “What is software quality?”Philip Crosby [Cro79], in his landmark book on quality, provides a wry answerto this question:
The problem of quality management is not what people don’t know about it. The prob-lem is what they think they do know. . . .In this regard, quality has much in common with sex. Everybody is for it. (Undercertain conditions, of course.) Everyone feels they understand it. (Even though theywouldn’t want to explain it.) Everyone thinks execution is only a matter of followingnatural inclinations. (After all, we do get along somehow.) And, of course, most peo-ple feel that problems in these areas are caused by other people. (If only they wouldtake the time to do things right.)
432CHAPTER
16SOFTWARE QUALITY
ASSURANCE
KEY
CONCEPTSformal approaches . . . . .438goals  . . . . . . . . .436ISO 9001:2000standard  . . . . . .445Six Sigma . . . . . .441softwarereliability  . . . . . .442softwaresafety  . . . . . . . .443SQAelements of  . . .434plan  . . . . . . . . .445statistical . . . . .439tasks  . . . . . . . .436
What is it? It’s not enough to talk thetalk by saying that software quality isimportant. You have to (1) explicitlydefine what is meant when you say“software quality,” (2) create a set of activities thatwill help ensure that every software engineeringwork product exhibits high quality, (3) performquality control and assurance activities on everysoftware project, (4) use metrics to develop strate-gies for improving your software process and, asa consequence, the quality of the end product.
Who does it? Everyone involved in the softwareengineering process is responsible for quality.
Why is it important? You can do it right, or youcan do it over again. If a software team stressesquality in all software engineering activities, itreduces the amount of rework that it must do.That results in lower costs, and more importantly,improved time-to-market.
What are the steps? Before software qualityassurance (SQA) activities can be initiated, it isQUICK
LOOKimportant to define software qualityat a num-ber of different levels of abstraction. Once youunderstand what quality is, a software teammust identify a set of SQA activities that will fil-ter errors out of work products before they arepassed on.
What is the work product? A Software QualityAssurance Plan is created to define a softwareteam’s SQA strategy. During modeling and cod-ing, the primary SQA work product is the outputof technical reviews (Chapter 15). During testing(Chapters 17 through 20), test plans and proce-dures are produced. Other work products asso-ciated with process improvement may also begenerated.
How do I ensure that I’ve done it right? Finderrors before they become defects! That is,work to improve your defect removal efficiency(Chapter 23), thereby reducing the amountof rework that your software team has toperform.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 432Indeed, quality is a challenging concept—one that I addressed in some detail inChapter 14.
1
Some software developers continue to believe that software quality is somethingyou begin to worry about after code has been generated. Nothing could be furtherfrom the truth! Software quality assurance (often called quality management) is an um- brella activity (Chapter 2) that is applied throughout the software process.Software quality assurance (SQA) encompasses (1) an SQA process, (2) specificquality assurance and quality control tasks (including technical reviews and a multi-tiered testing strategy), (3) effective software engineering practice (methods andtools), (4) control of all software work products and the changes made to them(Chapter 22), (5) a procedure to ensure compliance with software development stan-dards (when applicable), and (6) measurement and reporting mechanisms.In this chapter, I focus on the management issues and the process-specific activ-ities that enable a software organization to ensure that it does “the right things at theright time in the right way.”
16.1 B ACKGROUND ISSUES
Quality control and assurance are essential activities for any business that producesproducts to be used by others. Prior to the twentieth century, quality control was thesole responsibility of the craftsperson who built a product. As time passed and massproduction techniques became commonplace, quality control became an activityperformed by people other than the ones who built the product.The first formal quality assurance and control function was introduced at BellLabs in 1916 and spread rapidly throughout the manufacturing world. During the1940s, more formal approaches to quality control were suggested. These relied onmeasurement and continuous process improvement [Dem86] as key elements ofquality management.Today, every company has mechanisms to ensure quality in its products. In fact,explicit statements of a company’s concern for quality have become a marketingploy during the past few decades.The history of quality assurance in software development parallels the history ofquality in hardware manufacturing. During the early days of computing (1950s and1960s), quality was the sole responsibility of the programmer. Standards for qualityassurance for software were introduced in military contract software developmentduring the 1970s and have spread rapidly into software development in the com-mercial world [IEE93]. Extending the definition presented earlier, software qualityassurance is a “planned and systematic pattern of actions” [Sch98c] that are requiredto ensure high quality in software. The scope of quality assurance responsibilitymight best be characterized by paraphrasing a once-popular automobile commercial:“Quality Is Job #1.” The implication for software is that many different constituenciesCHAPTER 16SOFTWARE QUALITY ASSURANCE 433
1 If you have not read Chapter 14, you should do so now.uote:
“You made toomany wrongmistakes.”Yogi Berrapre75977_ch16.qxd  11/27/08  6:07 PM  Page 433434 PART THREEQUALITY MANAGEMENT
have software quality assurance responsibility—software engineers, project man-agers, customers, salespeople, and the individuals who serve within an SQA group.The SQA group serves as the customer’s in-house representative. That is, thepeople who perform SQA must look at the software from the customer’s point ofview. Does the software adequately meet the quality factors noted in Chapter 14? Hassoftware development been conducted according to preestablished standards? Havetechnical disciplines properly performed their roles as part of the SQA activity? TheSQA group attempts to answer these and other questions to ensure that softwarequality is maintained.
16.2 E LEMENTS OF SOFTWARE QUALITY ASSURANCE
Software quality assurance encompasses a broad range of concerns and activitiesthat focus on the management of software quality. These can be summarized in thefollowing manner [Hor03]:Standards.The IEEE, ISO, and other standards organizations have pro-duced a broad array of software engineering standards and related docu-ments. Standards may be adopted voluntarily by a software engineeringorganization or imposed by the customer or other stakeholders. The job ofSQA is to ensure that standards that have been adopted are followed andthat all work products conform to them.Reviews and audits.Technical reviews are a quality control activityperformed by software engineers for software engineers (Chapter 15).Their intent is to uncover errors. Audits are a type of review performed bySQA personnel with the intent of ensuring that quality guidelines are beingfollowed for software engineering work. For example, an audit of thereview process might be conducted to ensure that reviews are beingperformed in a manner that will lead to the highest likelihood ofuncovering errors.Testing.Software testing (Chapters 17 through 20) is a quality control func-tion that has one primary goal—to find errors. The job of SQA is to ensurethat testing is properly planned and efficiently conducted so that it has thehighest likelihood of achieving its primary goal.Error/defect collection and analysis. The only way to improve is to measure how you’re doing. SQA collects and analyzes error and defect datato better understand how errors are introduced and what software engineer-ing activities are best suited to eliminating them.Change management.Change is one of the most disruptive aspects ofany software project. If it is not properly managed, change can lead to con-fusion, and confusion almost always leads to poor quality. SQA ensures thatadequate change management practices (Chapter 22) have been instituted.WebRef
An in-depth discussionof SQA, includinga wide array ofdefinitions, canbe obtained atwww.swqual.com/newsletter/vol2/no1/vol2no1.html.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 434Education.Every software organization wants to improve its softwareengineering practices. A key contributor to improvement is education of soft-ware engineers, their managers, and other stakeholders. The SQA organiza-tion takes the lead in software process improvement (Chapter 30) and is akey proponent and sponsor of educational programs.Vendor management.Three categories of software are acquired fromexternal software vendors—shrink-wrapped packages(e.g., Microsoft Office), a tailored shell[Hor03] that provides a basic skeletal structure that is customtailored to the needs of a purchaser, and contracted software that is custom designed and constructed from specifications provided by the customerorganization. The job of the SQA organization is to ensure that high-qualitysoftware results by suggesting specific quality practices that the vendorshould follow (when possible), and incorporating quality mandates as part ofany contract with an external vendor.Security management.With the increase in cyber crime and new govern-ment regulations regarding privacy, every software organization should insti-tute policies that protect data at all levels, establish firewall protection forWebApps, and ensure that software has not been tampered with internally.SQA ensures that appropriate process and technology are used to achievesoftware security.Safety.Because software is almost always a pivotal component of human-rated systems (e.g., automotive or aircraft applications), the impact of hiddendefects can be catastrophic. SQA may be responsible for assessing the impactof software failure and for initiating those steps required to reduce risk.Risk management.Although the analysis and mitigation of risk (Chapter28) is the concern of software engineers, the SQA organization ensures thatrisk management activities are properly conducted and that risk-relatedcontingency plans have been established.In addition to each of these concerns and activities, SQA works to ensure that soft-ware support activities (e.g., maintenance, help lines, documentation, and manuals)are conducted or produced with quality as a dominant concern.CHAPTER 16SOFTWARE QUALITY ASSURANCE 435
uote:
“Excellence is theunlimited ability toimprove the qualityof what you haveto offer.”Rick Petin
Quality Management Resources
There are dozens of quality managementresources available on the Web, includingprofessional societies, standards organizations, andgeneral information sources. The sites that follow providea good starting point:American Society for Quality (ASQ) Software Divisionwww.asq.org/softwareAssociation for Computer Machinerywww.acm.orgData and Analysis Center for Software (DACS)www.dacs.dtic.mil/International Organization for Standardization (ISO)www.iso.chISO SPICEwww.isospice.comINFOpre75977_ch16.qxd  11/27/08  6:07 PM  Page 43516.3 SQA T ASKS , GOALS , AND METRICS
Software quality assurance is composed of a variety of tasks associated with two dif-ferent constituencies—the software engineers who do technical work and an SQAgroup that has responsibility for quality assurance planning, oversight, record keep-ing, analysis, and reporting.Software engineers address quality (and perform quality control activities) byapplying solid technical methods and measures, conducting technical reviews, andperforming well-planned software testing.
16.3.1 SQA Tasks
The charter of the SQA group is to assist the software team in achieving a high-quality end product. The Software Engineering Institute recommends a set of SQAactions that address quality assurance planning, oversight, record keeping, analysis,and reporting. These actions are performed (or facilitated) by an independent SQAgroup that:Prepares an SQA plan for a project. The plan is developed as part of project planning and is reviewed by all stakeholders. Quality assuranceactionsperformed by the software engineering team and the SQA group aregoverned by the plan. The plan identifies evaluations to be performed,audits and reviews to be conducted, standards that are applicable to theproject, procedures for error reporting and tracking, work products thatare produced by the SQA group, and feedback that will be provided to thesoftware team.Participates in the development of the project’s software processdescription.The software team selects a process for the work to beperformed. The SQA group reviews the process description for compli-ance with organizational policy, internal software standards, externallyimposed standards (e.g., ISO-9001), and other parts of the softwareproject plan.436 PART THREEQUALITY MANAGEMENT
Malcolm Baldridge National Quality Awardwww.quality.nist.govSoftware Engineering Institutewww.sei.cmu.edu/Software Testing and Quality Engineeringwww.stickyminds.comSix Sigma Resourceswww.isixsigma.com/www.asq.org/sixsigma/TickIT International: Quality certification topicswww.tickit.org/international.htmTotal Quality Management (TQM)General information:www.gslis.utexas.edu/~rpollock/tqm.htmlArticles: www.work911.com/tqmarticles.htmGlossary: www.quality.org/TQM-MSI/TQM-glossary.html
What is therole of anSQA group??pre75977_ch16.qxd  11/27/08  6:07 PM  Page 436Reviews software engineering activities to verify compliance with thedefined software process.The SQA group identifies, documents, and tracksdeviations from the process and verifies that corrections have been made.Audits designated software work products to verify compliance withthose defined as part of the software process. The SQA group reviews selected work products; identifies, documents, and tracks deviations; verifiesthat corrections have been made; and periodically reports the results of itswork to the project manager.Ensures that deviations in software work and work products aredocumented and handled according to a documented procedure.Deviations may be encountered in the project plan, process description,applicable standards, or software engineering work products.Records any noncompliance and reports to senior management.Noncompliance items are tracked until they are resolved.In addition to these actions, the SQA group coordinates the control and managementof change (Chapter 22) and helps to collect and analyze software metrics.
16.3.2 Goals, Attributes, and Metrics
The SQA actions described in the preceding section are performed to achieve a setof pragmatic goals:Requirements quality.The correctness, completeness, and consistencyof the requirements model will have a strong influence on the quality of allwork products that follow. SQA must ensure that the software team hasproperly reviewed the requirements model to achieve a high level of quality.Design quality.Every element of the design model should be assessed bythe software team to ensure that it exhibits high quality and that the designitself conforms to requirements. SQA looks for attributes of the design thatare indicators of quality.Code quality.Source code and related work products (e.g., other descrip-tive information) must conform to local coding standards and exhibit charac-teristics that will facilitate maintainability. SQA should isolate those attributesthat allow a reasonable analysis of the quality of code.Quality control effectiveness.A software team should apply limited re-sources in a way that has the highest likelihood of achieving a high-qualityresult. SQA analyzes the allocation of resources for reviews and testing toassess whether they are being allocated in the most effective manner.Figure 16.1 (adapted from [Hya96]) identifies the attributes that are indicators forthe existence of quality for each of the goals discussed. Metrics that can be used toindicate the relative strength of an attribute are also shown.CHAPTER 16SOFTWARE QUALITY ASSURANCE 437
uote:
“Quality is neveran accident; it isalways the result ofhigh intention,sincere effort,intelligent directionand skillfulexecution; itrepresents the wisechoice of manyalternatives.”William A.Fosterpre75977_ch16.qxd  11/27/08  6:07 PM  Page 437438 PART THREEQUALITY MANAGEMENT
FIGURE 16.1
GoalAttributeMetric Requirement qualityAmbiguityNumber of ambiguous modifiers (e.g., many, large,human-friendly)CompletenessNumber of TBA, TBDUnderstandability Number of sections/subsectionsVolatilityNumber of changes per requirementTime (by activity) when change is requestedTraceabilityNumber of requirements not traceable to design/codeModel clarityNumber of UML modelsNumber of descriptive pages per modelNumber of UML errors Design qualityArchitectural integrity Existence of architectural modelComponent completeness Number of components that trace to architectural modelComplexity of procedural designInterface complexity Average number of pick to get to a typical function or contentLayout appropriatenessPatternsNumber of patterns used Code qualityComplexityCyclomatic complexityMaintainabilityDesign factors (Chapter 8)Understandability Percent internal commentsVariable naming conventionsReusabilityPercent reused componentsDocumentationReadability index QC effectivenessResource allocation Staff hour percentage per activityCompletion rateActual vs. budgeted completion timeReview effectiveness See review metrics (Chapter 14)Testing effectiveness Number of errors found and criticalityEffort required to correct an error
Origin of errorSoftware quality goals, attributes, and metricsSource:Adapted from [Hya96].
16.4 F ORMAL APPROACHES TO SQA
In the preceding sections, I have argued that software quality is everyone’s job andthat it can be achieved through competent software engineering practice as well asthrough the application of technical reviews, a multi-tiered testing strategy, bettercontrol of software work products and the changes made to them, and the applica-tion of accepted software engineering standards. In addition, quality can be definedpre75977_ch16.qxd  11/27/08  6:07 PM  Page 438in terms of a broad array of quality attributes and measured (indirectly) using avariety of indices and metrics.Over the past three decades, a small, but vocal, segment of the software engineer-ing community has argued that a more formal approach to software quality assuranceis required. It can be argued that a computer program is a mathematical object. A rig-orous syntax and semantics can be defined for every programming language, and arigorous approach to the specification of software requirements (Chapter 21) is avail-able. If the requirements model (specification) and the programming language can berepresented in a rigorous manner, it should be possible to apply mathematic proof ofcorrectness to demonstrate that a program conforms exactly to its specifications.Attempts to prove programs correct are not new. Dijkstra [Dij76a] and Linger,Mills, and Witt [Lin79], among others, advocated proofs of program correctness andtied these to the use of structured programming concepts (Chapter 10).
16.5 S TATISTICAL SOFTWARE QUALITY ASSURANCE
Statistical quality assurance reflects a growing trend throughout industry to becomemore quantitative about quality. For software, statistical quality assurance impliesthe following steps:1.Information about software errors and defects is collected and categorized.2.An attempt is made to trace each error and defect to its underlying cause(e.g., nonconformance to specifications, design error, violation of standards,poor communication with the customer).3.Using the Pareto principle (80 percent of the defects can be traced to 20 per-cent of all possible causes), isolate the 20 percent (the vital few).4.Once the vital few causes have been identified, move to correct the problemsthat have caused the errors and defects.This relatively simple concept represents an important step toward the creation ofan adaptive software process in which changes are made to improve those elementsof the process that introduce error.
16.5.1 A Generic Example
To illustrate the use of statistical methods for software engineering work, assumethat a software engineering organization collects information on errors and defectsfor a period of one year. Some of the errors are uncovered as software is being de-veloped. Others (defects) are encountered after the software has been released to itsend users. Although hundreds of different problems are uncovered, all can betracked to one (or more) of the following causes:
•Incomplete or erroneous specifications (IES)
•Misinterpretation of customer communication (MCC)CHAPTER 16SOFTWARE QUALITY ASSURANCE 439
WebRef
Useful information onSQA and formal qualitymethods can be foundat www.gslis.utexas.edu/~rpollock/tqm.html.
What stepsare requiredto performstatistical SQA??
uote:
“A statisticalanalysis, properlyconducted, is adelicate dissectionof uncertainties,a surgery ofsuppositions.”M. J. Moroneypre75977_ch16.qxd  11/27/08  6:07 PM  Page 439•Intentional deviation from specifications (IDS)
•Violation of programming standards (VPS)
•Error in data representation (EDR)
•Inconsistent component interface (ICI)
•Error in design logic (EDL)
•Incomplete or erroneous testing (IET)
•Inaccurate or incomplete documentation (IID)
•Error in programming language translation of design (PLT)
•Ambiguous or inconsistent human/computer interface (HCI)
•Miscellaneous (MIS)To apply statistical SQA, the table in Figure 16.2 is built. The table indicates that IES,MCC, and EDR are the vital few causes that account for 53 percent of all errors. Itshould be noted, however, that IES, EDR, PLT, and EDL would be selected as the vitalfew causes if only serious errors are considered. Once the vital few causes aredetermined, the software engineering organization can begin corrective action. Forexample, to correct MCC, you might implement requirements gathering techniques(Chapter 5) to improve the quality of customer communication and specifications. Toimprove EDR, you might acquire tools for data modeling and perform more stringentdata design reviews.It is important to note that corrective action focuses primarily on the vital few. Asthe vital few causes are corrected, new candidates pop to the top of the stack.Statistical quality assurance techniques for software have been shown to providesubstantial quality improvement [Art97]. In some cases, software organizations440 PART THREEQUALITY MANAGEMENT
TotalSeriousModerateMinor
Error No.% No.% No.% No.%IES205 22% 34 27% 68 18% 103 24%MCC 156 17% 12 9% 68 18% 76 17% IDS485%11% 246% 235% VPS253%00% 154% 102% EDR 130 14% 26 20% 68 18% 36 8% ICI586%97% 185% 317% EDL455% 14 11% 12 3% 194% IET95 10% 12 9% 359% 48 11% IID364%22% 205% 143% PLT606% 15 12% 19 5% 266% HCI283%32% 174%82%
MIS566%00% 154% 419%
Totals 942 100% 128 100% 379 100% 435 100%FIGURE 16.2
Data collectionfor statisticalSQAuote:
“20 percent of thecode has 80percent of theerrors. Find them,fix them!”Lowell Arthurpre75977_ch16.qxd  11/27/08  6:07 PM  Page 440have achieved a 50 percent reduction per year in defects after applying thesetechniques.The application of the statistical SQA and the Pareto principle can be summarizedin a single sentence: Spend your time focusing on things that really matter, but first besure that you understand what really matters!
16.5.2 Six Sigma for Software Engineering
Six Sigmais the most widely used strategy for statistical quality assurance in indus-try today. Originally popularized by Motorola in the 1980s, the Six Sigma strategy“is a rigorous and disciplined methodology that uses data and statistical analysis tomeasure and improve a company’s operational performance by identifying and elim-inating defects’ in manufacturing and service-related processes” [ISI08]. The termSix Sigma is derived from six standard deviations—3.4 instances (defects) per millionoccurrences—implying an extremely high quality standard. The Six Sigma method-ology defines three core steps:
•Definecustomer requirements and deliverables and project goals via well-defined methods of customer communication.
•Measurethe existing process and its output to determine current qualityperformance (collect defect metrics).
•Analyzedefect metrics and determine the vital few causes.If an existing software process is in place, but improvement is required, Six Sigmasuggests two additional steps:
•Improvethe process by eliminating the root causes of defects.
•Controlthe process to ensure that future work does not reintroduce thecauses of defects.These core and additional steps are sometimes referred to as the DMAIC (define,measure, analyze, improve, and control) method.If an organization is developing a software process (rather than improving anexisting process), the core steps are augmented as follows:
•Designthe process to (1) avoid the root causes of defects and (2) to meetcustomer requirements.
•Verifythat the process model will, in fact, avoid defects and meet customerrequirements.This variation is sometimes called the DMADV (define, measure, analyze, design,and verify) method.A comprehensive discussion of Six Sigma is best left to resources dedicated to thesubject. If you have further interest, see [ISI08], [Pyz03], and [Sne03].CHAPTER 16SOFTWARE QUALITY ASSURANCE 441
What are thecore steps ofthe Six Sigmamethodology??pre75977_ch16.qxd  11/27/08  6:07 PM  Page 44116.6 S OFTWARE RELIABILITY
There is no doubt that the reliability of a computer program is an important elementof its overall quality. If a program repeatedly and frequently fails to perform, it mat-ters little whether other software quality factors are acceptable.Software reliability, unlike many other quality factors, can be measured directlyand estimated using historical and developmental data. Software reliability is defined in statistical terms as “the probability of failure-free operation of a computer programin a specified environment for a specified time” [Mus87]. To illustrate, program X is estimated to have a reliability of 0.999 over eight elapsed processing hours. In otherwords, if program Xwere to be executed 1000 times and require a total of eight hoursof elapsed processing time (execution time), it is likely to operate correctly (withoutfailure) 999 times.Whenever software reliability is discussed, a pivotal question arises: What is meantby the term failure? In the context of any discussion of software quality and reliabil-ity, failure is nonconformance to software requirements. Yet, even within this defini-tion, there are gradations. Failures can be only annoying or catastrophic. One failurecan be corrected within seconds, while another requires weeks or even months tocorrect. Complicating the issue even further, the correction of one failure may in factresult in the introduction of other errors that ultimately result in other failures.
16.6.1 Measures of Reliability and Availability
Early work in software reliability attempted to extrapolate the mathematics of hard-ware reliability theory to the prediction of software reliability. Most hardware-relatedreliability models are predicated on failure due to wear rather than failure due to de-sign defects. In hardware, failures due to physical wear (e.g., the effects of tempera-ture, corrosion, shock) are more likely than a design-related failure. Unfortunately,the opposite is true for software. In fact, all software failures can be traced to designor implementation problems; wear (see Chapter 1) does not enter into the picture.There has been an ongoing debate over the relationship between key concepts inhardware reliability and their applicability to software. Although an irrefutable linkhas yet to be established, it is worthwhile to consider a few simple concepts thatapply to both system elements.If we consider a computer-based system, a simple measure of reliability is mean- time-between-failure(MTBF):MTBF /H11005MTTF /H11001MTTRwhere the acronyms MTTF and MTTR are mean-time-to-failure and mean-time-to- repair,
2respectively.442 PART THREEQUALITY MANAGEMENT
uote:
“The unavoidableprice of reliabilityis simplicity.”C. A. R. Hoare
Software reliabilityproblems can almostalways be tracedto defects in design orimplementation.
2 Although debugging (and related corrections) may be required as a consequence of failure, in manycases the software will work properly after a restart with no other change.It is important to notethat MTBF and relatedmeasures are based onCPU time, not wallclock time.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 442Many researchers argue that MTBF is a far more useful measure than otherquality-related software metrics discussed in Chapter 23. Stated simply, an end useris concerned with failures, not with the total defect count. Because each defect con-tained within a program does not have the same failure rate, the total defect countprovides little indication of the reliability of a system. For example, consider a pro-gram that has been in operation for 3000 processor hours without failure. Many de-fects in this program may remain undetected for tens of thousand of hours beforethey are discovered. The MTBF of such obscure errors might be 30,000 or even60,000 processor hours. Other defects, as yet undiscovered, might have a failure rateof 4000 or 5000 hours. Even if every one of the first category of errors (those withlong MTBF) is removed, the impact on software reliability is negligible.However, MTBF can be problematic for two reasons: (1) it projects a time span be-tween failures, but does not provide us with a projected failure rate, and (2) MTBF canbe misinterpreted to mean average life span even though this is not what it implies. An alternative measure of reliability is failures-in-time (FIT)—a statistical measure of how many failures a component will have over one billion hours of operation.Therefore, 1 FIT is equivalent to one failure in every billion hours of operation.In addition to a reliability measure, you should also develop a measure of avail-ability. Software availabilityis the probability that a program is operating according torequirements at a given point in time and is defined asAvailability /H11005/H11003 100%The MTBF reliability measure is equally sensitive to MTTF and MTTR. The avail-ability measure is somewhat more sensitive to MTTR, an indirect measure of themaintainability of software.
16.6.2 Software Safety
Software safetyis a software quality assurance activity that focuses on the identificationand assessment of potential hazards that may affect software negatively and cause anentire system to fail. If hazards can be identified early in the software process, softwaredesign features can be specified that will either eliminate or control potential hazards.A modeling and analysis process is conducted as part of software safety. Initially,hazards are identified and categorized by criticality and risk. For example, some ofthe hazards associated with a computer-based cruise control for an automobilemight be: (1) causes uncontrolled acceleration that cannot be stopped, (2) does notrespond to depression of brake pedal (by turning off), (3) does not engage whenswitch is activated, and (4) slowly loses or gains speed. Once these system-level haz-ards are identified, analysis techniques are used to assign severity and probability ofoccurrence.
3To be effective, software must be analyzed in the context of the entireMTTFMTTF /H11001MTTRCHAPTER 16SOFTWARE QUALITY ASSURANCE 443
Some aspects ofavailability (notdiscussed here) havenothing to do withfailure. For example,scheduling downtime(for support functions)causes the software tobe unavailable.
uote:
“The safety of thepeople shall be thehighest law.”Cicero
3 This approach is similar to the risk analysis methods described in Chapter 28. The primary differ-ence is the emphasis on technology issues rather than project-related topics.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 443system. For example, a subtle user input error (people are system components) maybe magnified by a software fault to produce control data that improperly positions amechanical device. If and only if a set of external environmental conditions is met,the improper position of the mechanical device will cause a disastrous failure. Analy-sis techniques [Eri05] such as fault tree analysis, real-time logic, and Petri net mod-els can be used to predict the chain of events that can cause hazards and theprobability that each of the events will occur to create the chain.Once hazards are identified and analyzed, safety-related requirements can bespecified for the software. That is, the specification can contain a list of undesirableevents and the desired system responses to these events. The role of software inmanaging undesirable events is then indicated.Although software reliability and software safety are closely related to one another,it is important to understand the subtle difference between them. Software reliabilityuses statistical analysis to determine the likelihood that a software failure will occur.However, the occurrence of a failure does not necessarily result in a hazard or mishap.Software safety examines the ways in which failures result in conditions that can leadto a mishap. That is, failures are not considered in a vacuum, but are evaluated in thecontext of an entire computer-based system and its environment.A comprehensive discussion of software safety is beyond the scope of this book.If you have further interest in software safety and related system issues, see [Smi05],[Dun02], and [Lev95].
16.7 T HEISO 9000 Q UALITY STANDARDS4
A quality assurance systemmay be defined as the organizational structure, responsi-bilities, procedures, processes, and resources for implementing quality management[ANS87]. Quality assurance systems are created to help organizations ensure theirproducts and services satisfy customer expectations by meeting their specifications.These systems cover a wide variety of activities encompassing a product’s entire lifecycle including planning, controlling, measuring, testing and reporting, and improv-ing quality levels throughout the development and manufacturing process. ISO 9000describes quality assurance elements in generic terms that can be applied to anybusiness regardless of the products or services offered.To become registered to one of the quality assurance system models contained in ISO9000, a company’s quality system and operations are scrutinized by third-party auditorsfor compliance to the standard and for effective operation. Upon successful registration,a company is issued a certificate from a registration body represented by the auditors.Semiannual surveillance audits ensure continued compliance to the standard.444 PART THREEQUALITY MANAGEMENT
uote:
“I cannot imagineany conditionwhich wouldcause this ship tofounder. Modernshipbuilding hasgone beyond that.”E. I. Smith,captain of theTitanic
WebRef
A worthwhile collectionof papers on softwaresafety can be found atwww.safeware-eng.com/.
4 This section, written by Michael Stovsky, has been adapted from “Fundamentals of ISO 9000,”a workbook developed for Essential Software Engineering, a video curriculum developed by R. S. Pressman & Associates, Inc. Reprinted with permission.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 444The requirements delineated by ISO 9001:2000 address topics such as manage-ment responsibility, quality system, contract review, design control, document anddata control, product identification and traceability, process control, inspection andtesting, corrective and preventive action, control of quality records, internal qualityaudits, training, servicing, and statistical techniques. In order for a software organi-zation to become registered to ISO 9001:2000, it must establish policies and proce-dures to address each of the requirements just noted (and others) and then be ableto demonstrate that these policies and procedures are being followed. If you desirefurther information on ISO 9001:2000, see [Ant06], [Mut03], or [Dob04].CHAPTER 16SOFTWARE QUALITY ASSURANCE 445
WebRef
Extensive links to ISO9000/9001 resourcescan be found atwww.tantara.ab.ca/info.htm.
The ISO 9001:2000 Standard
The following outline defines the basicelements of the ISO 9001:2000 standard.Comprehensive information on the standard can beobtained from the International Organization forStandardization (www.iso.ch) and other Internetsources (e.g., www.praxiom.com).Establish the elements of a quality management system.Develop, implement, and improve the system.Define a policy that emphasizes the importance of thesystem.Document the quality system.Describe the process.Produce an operational manual.Develop methods for controlling (updating) documents.Establish methods for record keeping.Support quality control and assurance.Promote the importance of quality among all stakeholders.Focus on customer satisfaction.Define a quality plan that addresses objectives,responsibilities, and authority.Define communication mechanisms among stakeholders.Establish review mechanisms for the quality managementsystem.Identify review methods and feedback mechanisms.Define follow-up procedures.Identify quality resources including personnel, training,and infrastructure elements.Establish control mechanisms.For planningFor customer requirementsFor technical activities (e.g., analysis, design, testing)For project monitoring and managementDefine methods for remediation.Assess quality data and metrics.Define approach for continuous process and qualityimprovement.INFO
16.8 T HESQA P LAN
The SQA Planprovides a road map for instituting software quality assurance. Developedby the SQA group (or by the software team if an SQA group does not exist), the planserves as a template for SQA activities that are instituted for each software project.A standard for SQA plans has been published by the IEEE [IEE93]. The standardrecommends a structure that identifies: (1) the purpose and scope of the plan, (2) adescription of all software engineering work products (e.g., models, documents,source code) that fall within the purview of SQA, (3) all applicable standards andpractices that are applied during the software process, (4) SQA actions and taskspre75977_ch16.qxd  11/27/08  6:07 PM  Page 445(including reviews and audits) and their placement throughout the softwareprocess, (5) the tools and methods that support SQA actions and tasks, (6) softwareconfiguration management (Chapter 22) procedures, (7) methods for assembling,safeguarding, and maintaining all SQA-related records, and (8) organizational rolesand responsibilities relative to product quality.446 PART THREEQUALITY MANAGEMENT
Software Quality Management
Objective:The objective of SQA tools is toassist a project team in assessing andimproving the quality of software work product.Mechanics:Tools mechanics vary. In general, the intentis to assess the quality of a specific work product. Note:A wide array of software testing tools (see Chapters 17through 20) are often included within the SQA toolscategory.Representative Tools:
5
ARM,developed by NASA (satc.gsfc.nasa.gov/tools/index.html), provides measures that can beused to assess the quality of a software requirementsdocument.QPR ProcessGuide and Scorecard,developed by QPRSoftware (www.qpronline.com), provides supportfor Six Sigma and other quality managementapproaches.Quality Tools and Templates,developed by iSixSigma(www.isixsigma.com/tt/), describes a wide arrayof useful tools and methods for quality management.NASA Quality Resources,developed by the GoddardSpace Flight Center (sw-assurance.gsfc.nasa.gov/index.php) provides useful forms, templates,checklists, and tools for SQA.SOFTWARE TOOLS
5 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.16.9 S UMMARY
Software quality assurance is a software engineering umbrella activity that is appliedat each step in the software process. SQA encompasses procedures for the effectiveapplication of methods and tools, oversight of quality control activities such as tech-nical reviews and software testing, procedures for change management, proceduresfor assuring compliance to standards, and measurement and reporting mechanisms.To properly conduct software quality assurance, data about the software engi-neering process should be collected, evaluated, and disseminated. Statistical SQAhelps to improve the quality of the product and the software process itself. Softwarereliability models extend measurements, enabling collected defect data to be ex-trapolated into projected failure rates and reliability predictions.In summary, you should note the words of Dunn and Ullman [Dun82]: “Softwarequality assurance is the mapping of the managerial precepts and design disciplinesof quality assurance onto the applicable managerial and technological space ofsoftware engineering.” The ability to ensure quality is the measure of a matureengineering discipline. When the mapping is successfully accomplished, maturesoftware engineering is the result.pre75977_ch16.qxd  11/27/08  6:07 PM  Page 446PROBLEMS AND POINTS TO PONDER
16.1.Some people say that “variation control is the heart of quality control.” Since every pro-gram that is created is different from every other program, what are the variations that we lookfor and how do we control them?16.2.Is it possible to assess the quality of software if the customer keeps changing what it issupposed to do?16.3.Quality and reliability are related concepts but are fundamentally different in a numberof ways. Discuss the differences.16.4.Can a program be correct and still not be reliable? Explain.16.5.Can a program be correct and still not exhibit good quality? Explain.16.6.Why is there often tension between a software engineering group and an independentsoftware quality assurance group? Is this healthy?16.7.You have been given the responsibility for improving the quality of software across yourorganization. What is the first thing that you should do? What’s next?16.8.Besides counting errors and defects, are there other countable characteristics of softwarethat imply quality? What are they and can they be measured directly?16.9.The MTBF concept for software is open to criticism. Explain why?16.10.Consider two safety-critical systems that are controlled by computer. List at least threehazards for each that can be directly linked to software failures.16.11.Acquire a copy of ISO 9001:2000 and ISO 9000-3. Prepare a presentation that discussesthree ISO 9001 requirements and how they apply in a software context.
FURTHER READINGS AND INFORMATION SOURCES
Books by Hoyle (Quality Management Fundamentals, Butterworth-Heinemann, 2007), Tian (Software Quality Engineering,Wiley-IEEE Computer Society Press, 2005), El Emam ( The ROI from Software Quality,Auerbach, 2005), Horch (Practical Guide to Software Quality Management, Artech House, 2003), and Nance and Arthur ( Managing Software Quality,Springer, 2002) are excellent management-level presentations on the benefits of formal quality assurance programs for com-puter software. Books by Deming [Dem86], Juran (Juran on Quality by Design, Free Press, 1992), and Crosby ([Cro79] andQuality Is Still Free,McGraw-Hill, 1995) do not focus on software, but are must reading for senior managers with software development responsibility. Gluckman andRoome (Everyday Heroes of the Quality Movement, Dorset House, 1993) humanizes quality issues by telling the story of the players in the quality process. Kan ( Metrics and Models in Software Qual- ity Engineering,Addison-Wesley, 1995) presents a quantitative view of software quality.Books by Evans (Total Quality: Management, Organization and Strategy, 4th ed., South- Western College Publishing, 2004), Bru (Six Sigma for Managers, McGraw-Hill, 2005), and Dobb (ISO 9001:2000 Quality Registration Step-by-Step, 3d ed., Butterworth-Heinemann, 2004) are rep- resentative of the many books written on TQM, Six Sigma, and ISO 9001:2000, respectively.Pham (System Software Reliability, Springer, 2006), Musa ( Software Reliability Engineering: More Reliable Software, Faster Development and Testing, 2d ed., McGraw-Hill, 2004) and Peled (Software Reliability Methods, Springer, 2001) have written practical guides that describe meth-ods for measuring and analyzing software reliability.Vincoli (Basic Guide to System Safety, Wiley, 2006), Dhillon (Engineering Safety, World Scien- tific Publishing Co., Inc., 2003), Hermann ( Software Safety and Reliability,Wiley-IEEE Computer Society Press, 2000), Storey (Safety-Critical Computer Systems, Addison-Wesley, 1996), and Leveson [Lev95] are the most comprehensive discussions of software and system safetypublished to date. In addition, van der Meulen (Definitions for Hardware and Software SafetyCHAPTER 16SOFTWARE QUALITY ASSURANCE 447pre75977_ch16.qxd  11/27/08  6:07 PM  Page 447Engineers,Springer-Verlag, 2000) offers a complete compendium of important concepts andterms for reliability and safety; Gartner (Testing Safety-Related Software, Springer-Verlag, 1999) provides specialized guidance for testing safety critical systems; Friedman and Voas (SoftwareAssessment: Reliability Safety and Testability, Wiley, 1995) provide useful models for assessing reliability and safety. Ericson (Hazard Analysis Techniques for System Safety, Wiley, 2005) addresses the increasingly important domain of hazard analysis.A wide variety of information sources on software quality assurance and related topics isavailable on the Internet. An up-to-date list of World Wide Web references relevant to SQA canbe found at the SEPA website www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.448 PART THREEQUALITY MANAGEMENTpre75977_ch16.qxd  11/27/08  6:07 PM  Page 448Astrategy for software testing provides a road map that describes the stepsto be conducted as part of testing, when these steps are planned and thenundertaken, and how much effort, time, and resources will be required.Therefore, any testing strategy must incorporate test planning, test case design,test execution, and resultant data collection and evaluation.A software testing strategy should be flexible enough to promote a customizedtesting approach. At the same time, it must be rigid enough to encourage reason-able planning and management tracking as the project progresses. Shooman[Sho83] discusses these issues:
In many ways, testing is an individualistic process, and the number of different typesof tests varies as much as the different development approaches. For many years, our
449CHAPTER
17SOFTWARE TESTING
STRATEGIES
What is it? Software is tested touncover errors that were made inad-vertently as it was designed andconstructed. But how do you conductthe tests? Should you develop a formal plan foryour tests? Should you test the entire program asa whole or run tests only on a small part of it?Should you rerun tests you’ve already conductedas you add new components to a large system?When should you involve the customer? Theseand many other questions are answered whenyou develop a software testing strategy.
Who does it? A strategy for software testing isdeveloped by the project manager, softwareengineers, and testing specialists.
Why is it important? Testing often accounts formore project effort than any other software engi-neering action. If it is conducted haphazardly,time is wasted, unnecessary effort is expended,and even worse, errors sneak through undetected.It would therefore seem reasonable to establisha systematic strategy for testing software.
What are the steps? Testing begins “in the small”and progresses “to the large.” By this I meanQUICK
LOOKthat early testing focuses on a single componentor a small group of related components andapplies tests to uncover errors in the data andprocessing logic that have been encapsulatedby the component(s). After components aretested they must be integrated until the completesystem is constructed. At this point, a series ofhigh-order tests are executed to uncover errorsin meeting customer requirements. As errors areuncovered, they must be diagnosed and cor-rected using a process that is called debugging.
What is the work product? A Test Specificationdocuments the software team’s approach to test-ing by defining a plan that describes an overallstrategy and a procedure that defines specifictesting steps and the types of tests that will beconducted.
How do I ensure that I’ve done it right? Byreviewing the Test Specificationprior to testing,you can assess the completeness of test casesand testing tasks. An effective test plan and pro-cedure will lead to the orderly construction ofthe software and the discovery of errors at eachstage in the construction process.KEY
CONCEPTS
alpha test  . . . . . . 469
beta test  . . . . . . . 469
class testing . . . . . 466
configurationreview  . . . . . . . .
468
debugging  . . . . . . 473
deploymenttesting . . . . . . . . .
472
independenttest group  . . . . . .
452pre75977_ch17.qxd  11/27/08  6:09 PM  Page 449450 PART THREEQUALITY MANAGEMENT
integrationtesting . . . . . . . . .
459
regressiontesting . . . . . . . . .
467
system testing  . . . 470
unit testing  . . . . . 456
validationtesting . . . . . . . . .
467
V&V  . . . . . . . . . .450only defense against programming errors was careful design and the native intelligenceof the programmer. We are now in an era in which modern design techniques [and tech-nical reviews] are helping us to reduce the number of initial errors that are inherent in thecode. Similarly, different test methods are beginning to cluster themselves into severaldistinct approaches and philosophies.
These “approaches and philosophies” are what I call strategy—the topic to be pre-sented in this chapter. In Chapters 18 through 20, the testing methods and tech-niques that implement the strategy are presented.
17.1 A S TRATEGIC APPROACH TO SOFTWARE TESTING
Testing is a set of activities that can be planned in advance and conducted system-atically. For this reason a template for software testing—a set of steps into which youcan place specific test case design techniques and testing methods—should bedefined for the software process.A number of software testing strategies have been proposed in the literature.All provide you with a template for testing and all have the following genericcharacteristics:
•To perform effective testing, you should conduct effective technical reviews(Chapter 15). By doing this, many errors will be eliminated before testingcommences.
•Testing begins at the component level and works “outward” toward theintegration of the entire computer-based system.
•Different testing techniques are appropriate for different software engi-neering approaches and at different points in time.
•Testing is conducted by the developer of the software and (for large projects)an independent test group.
•Testing and debugging are different activities, but debugging must be accom-modated in any testing strategy.A strategy for software testing must accommodate low-level tests that are neces-sary to verify that a small source code segment has been correctly implementedas well as high-level tests that validate major system functions against customerrequirements. A strategy should provide guidance for the practitioner and a set ofmilestones for the manager. Because the steps of the test strategy occur at a timewhen deadline pressure begins to rise, progress must be measurable and problemsshould surface as early as possible.
17.1.1 Verification and Validation
Software testing is one element of a broader topic that is often referred to as verifi-cation and validation (V&V). Verification refers to the set of tasks that ensure thatWebRef
Useful resources forsoftware testing can befound at www.mtsu.edu/~storm/.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 450software correctly implements a specific function. Validation refers to a different set of tasks that ensure that the software that has been built is traceable to customerrequirements. Boehm [Boe81] states this another way:
Verification: “Are we building the product right?”Validation: “Are we building the right product?”
The definition of V&V encompasses many software quality assurance activities(Chapter 16).
1
Verification and validation includes a wide array of SQA activities: technicalreviews, quality and configuration audits, performance monitoring, simulation, feasi-bility study, documentation review, database review, algorithm analysis, developmenttesting, usability testing, qualification testing, acceptance testing, and installation test-ing. Although testing plays an extremely important role in V&V, many other activitiesare also necessary.Testing does provide the last bastion from which quality can be assessed and,more pragmatically, errors can be uncovered. But testing should not be viewed as asafety net. As they say, “You can’t test in quality. If it’s not there before you begin test-ing, it won’t be there when you’re finished testing.” Quality is incorporated into soft-ware throughout the process of software engineering. Proper application of methodsand tools, effective technical reviews, and solid management and measurement alllead to quality that is confirmed during testing.Miller [Mil77] relates software testing to quality assurance by stating that “theunderlying motivation of program testing is to affirm software quality with methodsthat can be economically and effectively applied to both large-scale and small-scalesystems.”
17.1.2 Organizing for Software Testing
For every software project, there is an inherent conflict of interest that occurs astesting begins. The people who have built the software are now asked to test the soft-ware. This seems harmless in itself; after all, who knows the program better than itsdevelopers? Unfortunately, these same developers have a vested interest in demon-strating that the program is error-free, that it works according to customer require-ments, and that it will be completed on schedule and within budget. Each of theseinterests mitigate against thorough testing.From a psychological point of view, software analysis and design (along withcoding) are constructive tasks. The software engineer analyzes, models, and thencreates a computer program and its documentation. Like any builder, the softwareCHAPTER 17SOFTWARE TESTING STRATEGIES 451
uote:
“Testing is theunavoidable partof any responsibleeffort to develop asoftware system.”William Howden
Don’t get sloppy andview testing as a“safety net” that willcatch all errors thatoccurred because ofweak software engi-neering practices. Itwon’t. Stress qualityand error detectionthroughout thesoftware process.
1 It should be noted that there is a strong divergence of opinion about what types of testing consti-tute “validation.” Some people believe that all testing is verification and that validation is conducted when requirements are reviewed and approved, and later, by the user when the system is opera-tional. Other people view unit and integration testing (Sections 17.3.1 and 17.3.2) as verificationand higher-order testing (Sections 17.6 and 17.7) as validation.uote:
“Optimism is theoccupationalhazard ofprogramming;testing is thetreatment.”Kent Beckpre75977_ch17.qxd  11/27/08  6:09 PM  Page 451engineer is proud of the edifice that has been built and looks askance at anyonewho attempts to tear it down. When testing commences, there is a subtle, yet def-inite, attempt to “break” the thing that the software engineer has built. From thepoint of view of the builder, testing can be considered to be (psychologically)destructive. So the builder treads lightly, designing and executing tests that willdemonstrate that the program works, rather than uncovering errors. Unfortunately,errors will be present. And, if the software engineer doesn’t find them, the cus-tomer will!There are often a number of misconceptions that you might infer erroneouslyfrom the preceding discussion: (1) that the developer of software should do no test-ing at all, (2) that the software should be “tossed over the wall” to strangers who willtest it mercilessly, (3) that testers get involved with the project only when the testingsteps are about to begin. Each of these statements is incorrect.The software developer is always responsible for testing the individual units(components) of the program, ensuring that each performs the function or exhibitsthe behavior for which it was designed. In many cases, the developer also conductsintegration testing—a testing step that leads to the construction (and test) of thecomplete software architecture. Only after the software architecture is completedoes an independent test group become involved.The role of an independent test group (ITG) is to remove the inherent problems associated with letting the builder test the thing that has been built. Independenttesting removes the conflict of interest that may otherwise be present. After all, ITGpersonnel are paid to find errors.However, you don’t turn the program over to ITG and walk away. The developerand the ITG work closely throughout a software project to ensure that thorough testswill be conducted. While testing is conducted, the developer must be available tocorrect errors that are uncovered.The ITG is part of the software development project team in the sense that itbecomes involved during analysis and design and stays involved (planning and spec-ifying test procedures) throughout a large project. However, in many cases the ITGreports to the software quality assurance organization, thereby achieving a degreeof independence that might not be possible if it were a part of the software engi-neering organization.
17.1.3 Software Testing Strategy—The Big Picture
The software process may be viewed as the spiral illustrated in Figure 17.1. Initially,system engineering defines the role of software and leads to software requirementsanalysis, where the information domain, function, behavior, performance, con-straints, and validation criteria for software are established. Moving inward alongthe spiral, you come to design and finally to coding. To develop computer software,you spiral inward (counterclockwise) along streamlines that decrease the level ofabstraction on each turn.452 PART THREEQUALITY MANAGEMENT
An independent testgroup does not havethe “conflict ofinterest” that buildersof the software mightexperience.
uote:
“The first mistakethat people makeis thinking that thetesting team isresponsible forassuring quality.”Brian Marickpre75977_ch17.qxd  11/27/08  6:09 PM  Page 452A strategy for software testing may also be viewed in the context of the spiral(Figure 17.1). Unit testingbegins at the vortex of the spiral and concentrates on eachunit (e.g., component, class, or WebApp content object) of the software as imple-mented in source code. Testing progresses by moving outward along the spiral tointegration testing,where the focus is on design and the construction of the softwarearchitecture. Taking another turn outward on the spiral, you encounter validationtesting,where requirements established as part of requirements modeling are vali-dated against the software that has been constructed. Finally, you arrive at systemtesting,where the software and other system elements are tested as a whole. To testcomputer software, you spiral out in a clockwise direction along streamlines thatbroaden the scope of testing with each turn.Considering the process from a procedural point of view, testing within the con-text of software engineering is actually a series of four steps that are implementedsequentially. The steps are shown in Figure 17.2. Initially, tests focus on eachCHAPTER 17SOFTWARE TESTING STRATEGIES 453
System testingValidation testingIntegration testingUnit testingCodeDesignRequirementsSystem engineeringFIGURE 17.1
Testingstrategy
UnittestCodeDesignRequirements
Testing“direction”Integration testHigh-ordertestsFIGURE 17.2
Softwaretesting stepsWhat is theoverallstrategy forsoftware testing??
WebRef
Useful resources forsoftware testers canbe found at www.SQAtester.com.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 453component individually, ensuring that it functions properly as a unit. Hence, thename unit testing.Unit testing makes heavy use of testing techniques that exercisespecific paths in a component’s control structure to ensure complete coverage andmaximum error detection. Next, components must be assembled or integrated toform the complete software package. Integration testing addresses the issues associ- ated with the dual problems of verification and program construction. Test casedesign techniques that focus on inputs and outputs are more prevalent duringintegration, although techniques that exercise specific program paths may be usedto ensure coverage of major control paths. After the software has been integrated(constructed), a set of high-order tests is conducted. Validation criteria (estab- lished during requirements analysis) must be evaluated. Validation testing provides final assurance that software meets all informational, functional, behavioral, andperformance requirements.The last high-order testing step falls outside the boundary of software engineer-ing and into the broader context of computer system engineering. Software, oncevalidated, must be combined with other system elements (e.g., hardware, people,databases). System testingverifies that all elements mesh properly and that overallsystem function/performance is achieved.454 PART THREEQUALITY MANAGEMENT
The scene:Doug Miller’s office, ascomponent-level design continues andconstruction of certain components begins.The players:Doug Miller, software engineeringmanager, Vinod, Jamie, Ed, and Shakira—members ofthe SafeHomesoftware engineering team.The conversation:Doug:It seems to me that we haven’t spent enough timetalking about testing.Vinod:True, but we’ve all been just a little busy. Andbesides, we have been thinking about it . . . in fact, morethan thinking.Doug (smiling):I know . . . we’re all overloaded, butwe’ve still got to think down the line.Shakira:I like the idea of designing unit tests before Ibegin coding any of my components, so that’s what I’vebeen trying to do. I have a pretty big file of tests to runonce code for my components is complete.Doug:That’s an Extreme Programming [an agilesoftware development process, see Chapter 3] concept, no?Ed:It is. Even though we’re not using Extreme Programmingper se, we decided that it’d be a good idea to design unittests before we build the component—the design gives usall of the information we need.Jamie:I’ve been doing the same thing.Vinod:And I’ve taken on the role of the integrator, soevery time one of the guys passes a component to me,I’ll integrate it and run a series of regression tests on thepartially integrated program. I’ve been working todesign a set of appropriate tests for each function in thesystem.Doug (to Vinod):How often will you run the tests?Vinod:Every day . . . until the system is integrated . . .well, I mean until the software increment we plan todeliver is integrated.Doug:You guys are way ahead of me!Vinod (laughing):Anticipation is everything in thesoftware biz, Boss.SAFEHOMEPreparing for Testingpre75977_ch17.qxd  11/27/08  6:09 PM  Page 45417.1.4 Criteria for Completion of Testing
A classic question arises every time software testing is discussed: “When are wedone testing—how do we know that we’ve tested enough?” Sadly, there is no defin-itive answer to this question, but there are a few pragmatic responses and earlyattempts at empirical guidance.One response to the question is: “You’re never done testing; the burden simplyshifts from you (the software engineer) to the end user.” Every time the user executesa computer program, the program is being tested. This sobering fact underlines theimportance of other software quality assurance activities. Another response (some-what cynical but nonetheless accurate) is: “You’re done testing when you run out oftime or you run out of money.”Although few practitioners would argue with these responses, you need more rig-orous criteria for determining when sufficient testing has been conducted. Thecleanroom software engineeringapproach (Chapter 21) suggests statistical use tech-niques [Kel00] that execute a series of tests derived from a statistical sample of allpossible program executions by all users from a targeted population. Others (e.g.,[Sin99]) advocate using statistical modeling and software reliability theory to predictthe completeness of testing.By collecting metrics during software testing and making use of existing softwarereliability models, it is possible to develop meaningful guidelines for answering thequestion: “When are we done testing?” There is little debate that further workremains to be done before quantitative rules for testing can be established, but theempirical approaches that currently exist are considerably better than raw intuition.
17.2 S TRATEGIC ISSUES
Later in this chapter, I present a systematic strategy for software testing. But even thebest strategy will fail if a series of overriding issues are not addressed. Tom Gilb[Gil95] argues that a software testing strategy will succeed when software testers:Specify product requirements in a quantifiable manner long before testing com-mences.Although the overriding objective of testing is to find errors, a good testingstrategy also assesses other quality characteristics such as portability, maintain-ability, and usability (Chapter 14). These should be specified in a way that is meas-urable so that testing results are unambiguous.State testing objectives explicitly.The specific objectives of testing should bestated in measurable terms. For example, test effectiveness, test coverage, mean-time-to-failure, the cost to find and fix defects, remaining defect density or fre-quency of occurrence, and test work-hours should be stated within the test plan.Understand the users of the software and develop a profile for each user category.Use cases that describe the interaction scenario for each class of user can reduceoverall testing effort by focusing testing on actual use of the product.CHAPTER 17SOFTWARE TESTING STRATEGIES 455
When arewe finishedtesting??
WebRef
A comprehensiveglossary of testing termscan be found atwww.testingstandards.co.uk/living_glossary.htm.
Whatguidelineslead to asuccessfulsoftware testingstrategy??
WebRef
An excellent list oftesting resources canbe found at www.io.com/~wazmo/qa/.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 455Develop a testing plan that emphasizes “rapid cycle testing.” Gilb [Gil95] recom- mends that a software team “learn to test in rapid cycles (2 percent of projecteffort) of customer-useful, at least field ‘trialable,’ increments of functionalityand/or quality improvement.” The feedback generated from these rapid cycle testscan be used to control quality levels and the corresponding test strategies.Build “robust” software that is designed to test itself. Software should be designed in a manner that uses antibugging (Section 17.3.1) techniques. That is, softwareshould be capable of diagnosing certain classes of errors. In addition, the designshould accommodate automated testing and regression testing.Use effective technical reviews as a filter prior to testing. Technical reviews (Chapter 15) can be as effective as testing in uncovering errors. For this reason,reviews can reduce the amount of testing effort that is required to produce high-quality software.Conduct technical reviews to assess the test strategy and test cases themselves.Technical reviews can uncover inconsistencies, omissions, and outright errors inthe testing approach. This saves time and also improves product quality.Develop a continuous improvement approach for the testing process. The test strat- egy should be measured. The metrics collected during testing should be used aspart of a statistical process control approach for software testing.
17.3 T ESTSTRATEGIES FOR CONVENTIONAL SOFTWARE2
There are many strategies that can be used to test software. At one extreme, you canwait until the system is fully constructed and then conduct tests on the overall sys-tem in hopes of finding errors. This approach, although appealing, simply does notwork. It will result in buggy software that disappoints all stakeholders. At the otherextreme, you could conduct tests on a daily basis, whenever any part of the systemis constructed. This approach, although less appealing to many, can be very effec-tive. Unfortunately, some software developers hesitate to use it. What to do?A testing strategy that is chosen by most software teams falls between the twoextremes. It takes an incremental view of testing, beginning with the testing of indi-vidual program units, moving to tests designed to facilitate the integration of theunits, and culminating with tests that exercise the constructed system. Each of theseclasses of tests is described in the sections that follow.
17.3.1 Unit Testing
Unit testingfocuses verification effort on the smallest unit of software design—thesoftware component or module. Using the component-level design description as a456 PART THREEQUALITY MANAGEMENT
uote:
“Testing onlyto end-userrequirements islike inspecting abuilding basedon the work doneby the interiordesigner at theexpense of thefoundations,girders, andplumbing.”Boris Beizer
2 Throughout this book, I use the terms conventional software or traditional softwareto refer to com- mon hierarchical or call-and-return software architectures that are frequently encountered in avariety of application domains. Traditional software architectures are not object-oriented and do not encompass WebApps.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 456guide, important control paths are tested to uncover errors within the boundary ofthe module. The relative complexity of tests and the errors those tests uncover is lim-ited by the constrained scope established for unit testing. The unit test focuses on theinternal processing logic and data structures within the boundaries of a component.This type of testing can be conducted in parallel for multiple components.Unit-test considerations.Unit tests are illustrated schematically in Figure 17.3.The module interface is tested to ensure that information properly flows into and outof the program unit under test. Local data structures are examined to ensure thatdata stored temporarily maintains its integrity during all steps in an algorithm’sexecution. All independent paths through the control structure are exercised to ensurethat all statements in a module have been executed at least once. Boundary conditionsare tested to ensure that the module operates properly at boundaries established tolimit or restrict processing. And finally, all error-handling paths are tested.Data flow across a component interface is tested before any other testing is initi-ated. If data do not enter and exit properly, all other tests are moot. In addition, localdata structures should be exercised and the local impact on global data should be as-certained (if possible) during unit testing.Selective testing of execution paths is an essential task during the unit test. Testcases should be designed to uncover errors due to erroneous computations, incor-rect comparisons, or improper control flow.Boundary testing is one of the most important unit testing tasks. Software oftenfails at its boundaries. That is, errors often occur when the nth element of ann-dimensional array is processed, when the i th repetition of a loop with ipasses is invoked, when the maximum or minimum allowable value is encountered. Testcases that exercise data structure, control flow, and data values just below, at, andjust above maxima and minima are very likely to uncover errors.CHAPTER 17SOFTWARE TESTING STRATEGIES 457
TestcasesModule InterfaceLocal data structuresBoundary conditionsIndependent pathsError-handling pathsFIGURE 17.3
Unit test
It’s not a bad idea todesign unit test casesbeforeyou developcode for a component.It helps ensure thatyou’ll develop codethat will pass the tests.
What errorsare commonlyfound during unittesting??pre75977_ch17.qxd  11/27/08  6:09 PM  Page 457A good design anticipates error conditions and establishes error-handling pathsto reroute or cleanly terminate processing when an error does occur. Yourdon[You75] calls this approach antibugging. Unfortunately, there is a tendency to incor- porate error handling into software and then never test it. A true story may serve toillustrate:
A computer-aided design system was developed under contract. In one transaction pro-cessing module, a practical joker placed the following error handling message after aseries of conditional tests that invoked various control flow branches: ERROR! THERE ISNO WAY YOU CAN GET HERE. This “error message” was uncovered by a customer duringuser training!
Among the potential errors that should be tested when error handling is evalu-ated are: (1) error description is unintelligible, (2) error noted does not correspond toerror encountered, (3) error condition causes system intervention prior to error han-dling, (4) exception-condition processing is incorrect, or (5) error description doesnot provide enough information to assist in the location of the cause of the error.Unit-test procedures.Unit testing is normally considered as an adjunct to thecoding step. The design of unit tests can occur before coding begins or after sourcecode has been generated. A review of design information provides guidance forestablishing test cases that are likely to uncover errors in each of the categories dis-cussed earlier. Each test case should be coupled with a set of expected results.Because a component is not a stand-alone program, driver and/or stub softwaremust often be developed for each unit test. The unit test environment is illustrated inFigure 17.4. In most applications a driver is nothing more than a “main program” that accepts test case data, passes such data to the component (to be tested), and prints458 PART THREEQUALITY MANAGEMENT
WebRef
Useful information on awide variety of articlesand resources for“agile testing” can befound at testing.com/agile/.
Be sure that youdesign tests to executeevery error-handlingpath. If you don’t, thepath may fail when itis invoked, exacer-bating an already diceysituation.
TestcasesInterfaceLocal data structuresBoundary conditionsIndependent pathsError-handling paths
Moduleto betested
Stub StubDriver
RESULTSFIGURE 17.4
Unit-testenvironmentpre75977_ch17.qxd  11/27/08  6:09 PM  Page 458relevant results. Stubsserve to replace modules that are subordinate (invoked by) thecomponent to be tested. A stub or “dummy subprogram” uses the subordinate mod-ule’s interface, may do minimal data manipulation, prints verification of entry, andreturns control to the module undergoing testing.Drivers and stubs represent testing “overhead.” That is, both are software thatmust be written (formal design is not commonly applied) but that is not delivered withthe final software product. If drivers and stubs are kept simple, actual overhead is rel-atively low. Unfortunately, many components cannot be adequately unit tested with“simple” overhead software. In such cases, complete testing can be postponed untilthe integration test step (where drivers or stubs are also used).Unit testing is simplified when a component with high cohesion is designed.When only one function is addressed by a component, the number of test cases isreduced and errors can be more easily predicted and uncovered.
17.3.2 Integration Testing
A neophyte in the software world might ask a seemingly legitimate question once allmodules have been unit tested: “If they all work individually, why do you doubt thatthey’ll work when we put them together?” The problem, of course, is “putting themtogether”—interfacing. Data can be lost across an interface; one component canhave an inadvertent, adverse effect on another; subfunctions, when combined, maynot produce the desired major function; individually acceptable imprecision may bemagnified to unacceptable levels; global data structures can present problems.Sadly, the list goes on and on.Integration testing is a systematic technique for constructing the software archi-tecture while at the same time conducting tests to uncover errors associated withinterfacing. The objective is to take unit-tested components and build a programstructure that has been dictated by design.There is often a tendency to attempt nonincremental integration; that is, to con-struct the program using a “big bang” approach. All components are combined inadvance. The entire program is tested as a whole. And chaos usually results! A setof errors is encountered. Correction is difficult because isolation of causes is com-plicated by the vast expanse of the entire program. Once these errors are corrected,new ones appear and the process continues in a seemingly endless loop.Incremental integration is the antithesis of the big bang approach. The programis constructed and tested in small increments, where errors are easier to isolate andcorrect; interfaces are more likely to be tested completely; and a systematic testapproach may be applied. In the paragraphs that follow, a number of different incre-mental integration strategies are discussed.Top-down integration.Top-down integration testingis an incremental approach to construction of the software architecture. Modules are integrated by movingdownward through the control hierarchy, beginning with the main control moduleCHAPTER 17SOFTWARE TESTING STRATEGIES 459
There are some situa-tions in which you willnot have the resourcesto do comprehensiveunit testing. Selectcritical or complexmodules and unit testonly those.
Taking the “big bang”approach to integrationis a lazy strategy thatis doomed to failure.Integrate incremen-tally, testing as you go.
When you develop aproject schedule, you’llhave to consider themanner in which inte-gration will occur sothat components willbe available whenneeded.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 459(main program). Modules subordinate (and ultimately subordinate) to the main con-trol module are incorporated into the structure in either a depth-first or breadth-firstmanner.Referring to Figure 17.5, depth-first integration integrates all components on a major control path of the program structure. Selection of a major path is somewhatarbitrary and depends on application-specific characteristics. For example, selectingthe left-hand path, components M
1, M2, M5would be integrated first. Next, M8or (if necessary for proper functioning of M
2) M6would be integrated. Then, the central and right-hand control paths are built. Breadth-first integration incorporates all com- ponents directly subordinate at each level, moving across the structure horizontally.From the figure, components M
2, M3, and M4would be integrated first. The next con- trol level, M
5, M6, and so on, follows. The integration process is performed in a seriesof five steps:1.The main control module is used as a test driver and stubs are substituted forall components directly subordinate to the main control module.2.Depending on the integration approach selected (i.e., depth or breadth first),subordinate stubs are replaced one at a time with actual components.3.Tests are conducted as each component is integrated.4.On completion of each set of tests, another stub is replaced with the realcomponent.5.Regression testing (discussed later in this section) may be conducted toensure that new errors have not been introduced.The process continues from step 2 until the entire program structure is built.460 PART THREEQUALITY MANAGEMENT
What are thesteps fortop-downintegration??M1
M3M2
M7M6M5
M8M4FIGURE 17.5
Top-downintegrationpre75977_ch17.qxd  11/27/08  6:09 PM  Page 460The top-down integration strategy verifies major control or decision points earlyin the test process. In a “well-factored” program structure, decision making occursat upper levels in the hierarchy and is therefore encountered first. If major controlproblems do exist, early recognition is essential. If depth-first integration is selected,a complete function of the software may be implemented and demonstrated. Earlydemonstration of functional capability is a confidence builder for all stakeholders.Top-down strategy sounds relatively uncomplicated, but in practice, logisticalproblems can arise. The most common of these problems occurs when processingat low levels in the hierarchy is required to adequately test upper levels. Stubsreplace low-level modules at the beginning of top-down testing; therefore, no sig-nificant data can flow upward in the program structure. As a tester, you are left withthree choices: (1) delay many tests until stubs are replaced with actual modules,(2) develop stubs that perform limited functions that simulate the actual module, or(3) integrate the software from the bottom of the hierarchy upward.The first approach (delay tests until stubs are replaced by actual modules) cancause you to lose some control over correspondence between specific tests andincorporation of specific modules. This can lead to difficulty in determining the causeof errors and tends to violate the highly constrained nature of the top-downapproach. The second approach is workable but can lead to significant overhead, asstubs become more and more complex. The third approach, called bottom-up inte-gration is discussed in the paragraphs that follow.Bottom-up integration.Bottom-up integration testing,as its name implies, begins construction and testing with atomic modules (i.e., components at the lowest levels in the program structure). Because components are integrated from the bottom up,the functionality provided by components subordinate to a given level is alwaysavailable and the need for stubs is eliminated. A bottom-up integration strategy maybe implemented with the following steps:1.Low-level components are combined into clusters (sometimes called builds)that perform a specific software subfunction.2.A driver(a control program for testing) is written to coordinate test case inputand output.3.The cluster is tested.4.Drivers are removed and clusters are combined moving upward in theprogram structure.Integration follows the pattern illustrated in Figure 17.6. Components are com-bined to form clusters 1, 2, and 3. Each of the clusters is tested using a driver (shownas a dashed block). Components in clusters 1 and 2 are subordinate to M
a. Drivers D1
and D2are removed and the clusters are interfaced directly to Ma. Similarly, driver D3
for cluster 3 is removed prior to integration with module Mb. Both Maand Mbwill ultimately be integrated with component M
c, and so forth.CHAPTER 17SOFTWARE TESTING STRATEGIES 461
Whatproblemsmay beencounteredwhen top-downintegration ischosen??
What are thesteps forbottom-upintegration??
Bottom-up integrationeliminates the need forcomplex stubs.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 461As integration moves upward, the need for separate test drivers lessens. In fact,if the top two levels of program structure are integrated top down, the number ofdrivers can be reduced substantially and integration of clusters is greatly simplified.Regression testing.Each time a new module is added as part of integration test-ing, the software changes. New data flow paths are established, new I/O may occur,and new control logic is invoked. These changes may cause problems with functionsthat previously worked flawlessly. In the context of an integration test strategy,regression testingis the reexecution of some subset of tests that have already beenconducted to ensure that changes have not propagated unintended side effects.In a broader context, successful tests (of any kind) result in the discovery of errors,and errors must be corrected. Whenever software is corrected, some aspect of thesoftware configuration (the program, its documentation, or the data that support it)is changed. Regression testing helps to ensure that changes (due to testing or forother reasons) do not introduce unintended behavior or additional errors.Regression testing may be conducted manually, by reexecuting a subset of all testcases or using automated capture/playback tools. Capture/playback tools enable the software engineer to capture test cases and results for subsequent playback andcomparison. The regression test suite(the subset of tests to be executed) containsthree different classes of test cases:
•A representative sample of tests that will exercise all software functions.
•Additional tests that focus on software functions that are likely to be affectedby the change.
•Tests that focus on the software components that have been changed.462 PART THREEQUALITY MANAGEMENT
Mc
Ma
D2D3D1Mb
Cluster 1Cluster 3
Cluster 2FIGURE 17.6
Bottom-upintegration
Regression testing isan important strategyfor reducing “sideeffects.” Run regres-sion tests every timea major change ismade to the software(including theintegration of newcomponents).pre75977_ch17.qxd  11/27/08  6:09 PM  Page 462As integration testing proceeds, the number of regression tests can grow quitelarge. Therefore, the regression test suite should be designed to include only thosetests that address one or more classes of errors in each of the major program func-tions. It is impractical and inefficient to reexecute every test for every program func-tion once a change has occurred.Smoke testing.Smoke testingis an integration testing approach that is com-monly used when product software is developed. It is designed as a pacing mecha-nism for time-critical projects, allowing the software team to assess the project ona frequent basis. In essence, the smoke-testing approach encompasses the follow-ing activities:1.Software components that have been translated into code are integrated intoa build.A build includes all data files, libraries, reusable modules, and engi-neered components that are required to implement one or more productfunctions.2.A series of tests is designed to expose errors that will keep the build fromproperly performing its function. The intent should be to uncover “show-stopper” errors that have the highest likelihood of throwing the softwareproject behind schedule.3.The build is integrated with other builds, and the entire product (in its currentform) is smoke tested daily. The integration approach may be top down orbottom up.The daily frequency of testing the entire product may surprise some readers. How-ever, frequent tests give both managers and practitioners a realistic assessment ofintegration testing progress. McConnell [McC96] describes the smoke test in thefollowing manner:
The smoke test should exercise the entire system from end to end. It does not have to beexhaustive, but it should be capable of exposing major problems. The smoke test shouldbe thorough enough that if the build passes, you can assume that it is stable enough tobe tested more thoroughly.
Smoke testing provides a number of benefits when it is applied on complex, time-critical software projects:
•Integration risk is minimized.Because smoke tests are conducted daily,incompatibilities and other show-stopper errors are uncovered early, therebyreducing the likelihood of serious schedule impact when errors areuncovered.
•The quality of the end product is improved. Because the approach is construc- tion (integration) oriented, smoke testing is likely to uncover functionalerrors as well as architectural and component-level design errors. If theseerrors are corrected early, better product quality will result.CHAPTER 17SOFTWARE TESTING STRATEGIES 463
Smoke testing mightbe characterized as arolling integrationstrategy. The softwareis rebuilt (with newcomponents added)and smoke testedevery day.
uote:
“Treat the dailybuild as theheartbeat of theproject. If there’sno heartbeat, theproject is dead.”Jim McCarthy
Whatbenefits canbe derived fromsmoke testing??pre75977_ch17.qxd  11/27/08  6:09 PM  Page 463•Error diagnosis and correction are simplified. Like all integration testing approaches, errors uncovered during smoke testing are likely to be associ-ated with “new software increments”—that is, the software that has just beenadded to the build(s) is a probable cause of a newly discovered error.
•Progress is easier to assess.With each passing day, more of the software hasbeen integrated and more has been demonstrated to work. This improves teammorale and gives managers a good indication that progress is being made.Strategic options.There has been much discussion (e.g., [Bei84]) about the rela-tive advantages and disadvantages of top-down versus bottom-up integration test-ing. In general, the advantages of one strategy tend to result in disadvantages for theother strategy. The major disadvantage of the top-down approach is the need forstubs and the attendant testing difficulties that can be associated with them. Prob-lems associated with stubs may be offset by the advantage of testing major controlfunctions early. The major disadvantage of bottom-up integration is that “the pro-gram as an entity does not exist until the last module is added” [Mye79]. This draw-back is tempered by easier test case design and a lack of stubs.Selection of an integration strategy depends upon software characteristics and,sometimes, project schedule. In general, a combined approach (sometimes calledsandwich testing) that uses top-down tests for upper levels of the program structure,coupled with bottom-up tests for subordinate levels may be the best compromise.As integration testing is conducted, the tester should identify critical modules. Acritical modulehas one or more of the following characteristics: (1) addresses severalsoftware requirements, (2) has a high level of control (resides relatively high in theprogram structure), (3) is complex or error prone, or (4) has definite performancerequirements. Critical modules should be tested as early as is possible. In addition,regression tests should focus on critical module function.Integration test work products.An overall plan for integration of the softwareand a description of specific tests is documented in a Test Specification.This work prod- uct incorporates a test plan and a test procedure and becomes part of the softwareconfiguration. Testing is divided into phases and builds that address specific func-tional and behavioral characteristics of the software. For example, integration testingfor theSafeHomesecurity system might be divided into the following test phases:
•User interaction(command input and output, display representation, errorprocessing and representation)
•Sensor processing(acquisition of sensor output, determination of sensorconditions, actions required as a consequence of conditions)
•Communications functions(ability to communicate with central monitoringstation)
•Alarm processing(tests of software actions that occur when an alarm isencountered)464 PART THREEQUALITY MANAGEMENT
WebRef
Pointers to commentaryon testing strategiescan be found atwww.qalinks.com.
What is a“criticalmodule” andwhy should weidentify it??pre75977_ch17.qxd  11/27/08  6:09 PM  Page 464Each of these integration test phases delineates a broad functional categorywithin the software and generally can be related to a specific domain within the soft-ware architecture. Therefore, program builds (groups of modules) are created to cor-respond to each phase. The following criteria and corresponding tests are applied forall test phases:Interface integrity.Internal and external interfaces are tested as each module(or cluster) is incorporated into the structure.Functional validity.Tests designed to uncover functional errors are conducted.Information content.Tests designed to uncover errors associated with local orglobal data structures are conducted.Performance.Tests designed to verify performance bounds established duringsoftware design are conducted.A schedule for integration, the development of overhead software, and relatedtopics are also discussed as part of the test plan. Start and end dates for each phaseare established and “availability windows” for unit-tested modules are defined. Abrief description of overhead software (stubs and drivers) concentrates on charac-teristics that might require special effort. Finally, test environment and resources aredescribed. Unusual hardware configurations, exotic simulators, and special testtools or techniques are a few of many topics that may also be discussed.The detailed testing procedure that is required to accomplish the test plan isdescribed next. The order of integration and corresponding tests at each integrationstep are described. A listing of all test cases (annotated for subsequent reference)and expected results are also included.A history of actual test results, problems, or peculiarities is recorded in a TestReportthat can be appended to the Test Specification,if desired.Information con- tained in this section can be vital during software maintenance. Appropriate refer-ences and appendixes are also presented.Like all other elements of a software configuration, the test specification formatmay be tailored to the local needs of a software engineering organization. It is impor-tant to note, however, that an integration strategy (contained in a test plan) and test-ing details (described in a test procedure) are essential ingredients and must appear.
17.4 T ESTSTRATEGIES FOR OBJECT -ORIENTED SOFTWARE3
The objective of testing, stated simply, is to find the greatest possible number oferrors with a manageable amount of effort applied over a realistic time span.Although this fundamental objective remains unchanged for object-oriented software,the nature of object-oriented software changes both testing strategy and testingtactics (Chapter 19).CHAPTER 17SOFTWARE TESTING STRATEGIES 465
3 Basic object-oriented concepts are presented in Appendix 2.What criteriashould beused to designintegration tests??pre75977_ch17.qxd  11/27/08  6:09 PM  Page 46517.4.1 Unit Testing in the OO Context
When object-oriented software is considered, the concept of the unit changes.Encapsulation drives the definition of classes and objects. This means that each classand each instance of a class packages attributes (data) and the operations thatmanipulate these data. An encapsulated class is usually the focus of unit testing. How-ever, operations (methods) within the class are the smallest testable units. Because aclass can contain a number of different operations, and a particular operation mayexist as part of a number of different classes, the tactics applied to unit testing mustchange.You can no longer test a single operation in isolation (the conventional view ofunit testing) but rather as part of a class. To illustrate, consider a class hierarchy inwhich an operation Xis defined for the superclass and is inherited by a number ofsubclasses. Each subclass uses operation X, but it is applied within the context of theprivate attributes and operations that have been defined for the subclass. Becausethe context in which operation Xis used varies in subtle ways, it is necessary to testoperation Xin the context of each of the subclasses. This means that testing opera-tion Xin a stand-alone fashion (the conventional unit-testing approach) is usuallyineffective in the object-oriented context.Class testing for OO software is the equivalent of unit testing for conventionalsoftware. Unlike unit testing of conventional software, which tends to focus on thealgorithmic detail of a module and the data that flow across the module interface,class testing for OO software is driven by the operations encapsulated by the classand the state behavior of the class.
17.4.2 Integration Testing in the OO Context
Because object-oriented software does not have an obvious hierarchical controlstructure, traditional top-down and bottom-up integration strategies (Section 17.3.2)have little meaning. In addition, integrating operations one at a time into a class (theconventional incremental integration approach) is often impossible because of the“direct and indirect interactions of the components that make up the class” [Ber93].There are two different strategies for integration testing of OO systems [Bin94b].The first, thread-based testing,integrates the set of classes required to respond to oneinput or event for the system. Each thread is integrated and tested individually.Regression testing is applied to ensure that no side effects occur. The second inte-gration approach, use-based testing,begins the construction of the system by testingthose classes (called independent classes ) that use very few (if any) serverclasses. After the independent classes are tested, the next layer of classes, called dependentclasses,that use the independent classes are tested. This sequence of testing layersof dependent classes continues until the entire system is constructed.The use of drivers and stubs also changes when integration testing of OO systemsis conducted. Drivers can be used to test operations at the lowest level and for thetesting of whole groups of classes. A driver can also be used to replace the user inter-face so that tests of system functionality can be conducted prior to implementation466 PART THREEQUALITY MANAGEMENT
Class testing for OOsoftware is analogous tomodule testing forconventional software. Itis not advisable to testoperations in isolation.
An important strategyfor integration testingof OO software isthread-based testing.Threads are sets ofclasses that respond toan input or event. Use-based tests focus onclasses that do notcollaborate heavilywith other classes.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 466of the interface. Stubs can be used in situations in which collaboration betweenclasses is required but one or more of the collaborating classes has not yet been fullyimplemented.Cluster testingis one step in the integration testing of OO software. Here, a clusterof collaborating classes (determined by examining the CRC and object-relationshipmodel) is exercised by designing test cases that attempt to uncover errors in thecollaborations.
17.5 T ESTSTRATEGIES FOR WEBAPPS
The strategy for WebApp testing adopts the basic principles for all software testingand applies a strategy and tactics that are used for object-oriented systems. Thefollowing steps summarize the approach:1.The content model for the WebApp is reviewed to uncover errors.2.The interface model is reviewed to ensure that all use cases can beaccommodated.3.The design model for the WebApp is reviewed to uncover navigation errors.4.The user interface is tested to uncover errors in presentation and/or naviga-tion mechanics.5.Each functional component is unit tested.6.Navigation throughout the architecture is tested.7.The WebApp is implemented in a variety of different environmental configu-rations and is tested for compatibility with each configuration.8.Security tests are conducted in an attempt to exploit vulnerabilities in theWebApp or within its environment.9.Performance tests are conducted.10.The WebApp is tested by a controlled and monitored population of end users.The results of their interaction with the system are evaluated for content andnavigation errors, usability concerns, compatibility concerns, and WebAppreliability and performance.Because many WebApps evolve continuously, the testing process is an ongoingactivity, conducted by support staff who use regression tests derived from the testsdeveloped when the WebApp was first engineered. Methods for WebApp testing areconsidered in Chapter 20.
17.6 V ALIDATION TESTING
Validation testing begins at the culmination of integration testing, when individualcomponents have been exercised, the software is completely assembled as a pack-age, and interfacing errors have been uncovered and corrected. At the validationor system level, the distinction between conventional software, object-orientedCHAPTER 17SOFTWARE TESTING STRATEGIES 467
The overall strategy forWebApp testing canbe summarized in the10 steps noted here.
WebRef
Excellent articles onWebApp testing can befound at www.stickyminds.com/testing.asp.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 467software, and WebApps disappears. Testing focuses on user-visible actions anduser-recognizable output from the system.Validation can be defined in many ways, but a simple (albeit harsh) definition isthat validation succeeds when software functions in a manner that can be reason-ably expected by the customer. At this point a battle-hardened software developermight protest: “Who or what is the arbiter of reasonable expectations?” If a Software Requirements Specificationhas been developed, it describes all user-visible attributesof the software and contains a Validation Criteriasection that forms the basis for a validation-testing approach.
17.6.1 Validation-Test Criteria
Software validation is achieved through a series of tests that demonstrate conform-ity with requirements. A test plan outlines the classes of tests to be conducted, anda test procedure defines specific test cases that are designed to ensure that all func-tional requirements are satisfied, all behavioral characteristics are achieved, all con-tent is accurate and properly presented, all performance requirements are attained,documentation is correct, and usability and other requirements are met (e.g., trans-portability, compatibility, error recovery, maintainability).After each validation test case has been conducted, one of two possible condi-tions exists: (1) The function or performance characteristic conforms to specificationand is accepted or (2) a deviation from specification is uncovered and a deficiencylist is created. Deviations or errors discovered at this stage in a project can rarely becorrected prior to scheduled delivery. It is often necessary to negotiate with the cus-tomer to establish a method for resolving deficiencies.
17.6.2 Configuration Review
An important element of the validation process is a configuration review. The intent of the review is to ensure that all elements of the software configuration have beenproperly developed, are cataloged, and have the necessary detail to bolster the sup-port activities. The configuration review, sometimes called an audit, is discussed inmore detail in Chapter 22.
17.6.3 Alpha and Beta Testing
It is virtually impossible for a software developer to foresee how the customer willreally use a program. Instructions for use may be misinterpreted; strange combina-tions of data may be regularly used; output that seemed clear to the tester may beunintelligible to a user in the field.When custom software is built for one customer, a series of acceptance tests areconducted to enable the customer to validate all requirements. Conducted by the enduser rather than software engineers, an acceptance test can range from an informal“test drive” to a planned and systematically executed series of tests. In fact, accept-ance testing can be conducted over a period of weeks or months, thereby uncover-ing cumulative errors that might degrade the system over time.468 PART THREEQUALITY MANAGEMENT
Like all other testingsteps, validation triesto uncover errors, butthe focus is at therequirements level—on things that will beimmediately apparentto the end user.
uote:
“Given enougheyeballs, all bugsare shallow (e.g.,given a largeenough beta-testerand co-developerbase, almost everyproblem will becharacterizedquickly and thefix obvious tosomeone).”E. Raymondpre75977_ch17.qxd  11/27/08  6:09 PM  Page 468If software is developed as a product to be used by many customers, it is imprac-tical to perform formal acceptance tests with each one. Most software productbuilders use a process called alpha and beta testing to uncover errors that only theend user seems able to find.The alpha testis conducted at the developer’s site by a representative group of endusers. The software is used in a natural setting with the developer “looking over theshoulder” of the users and recording errors and usage problems. Alpha tests are con-ducted in a controlled environment.The beta testis conducted at one or more end-user sites. Unlike alpha testing, thedeveloper generally is not present. Therefore, the beta test is a “live” application ofthe software in an environment that cannot be controlled by the developer. The cus-tomer records all problems (real or imagined) that are encountered during beta test-ing and reports these to the developer at regular intervals. As a result of problemsreported during beta tests, you make modifications and then prepare for release ofthe software product to the entire customer base.A variation on beta testing, called customer acceptance testing, is sometimes per- formed when custom software is delivered to a customer under contract. The cus-tomer performs a series of specific tests in an attempt to uncover errors beforeaccepting the software from the developer. In some cases (e.g., a major corporate orgovernmental system) acceptance testing can be very formal and encompass manydays or even weeks of testing.CHAPTER 17SOFTWARE TESTING STRATEGIES 469
What is thedifferencebetween an alphatest and a betatest??
The scene:Doug Miller’s office, ascomponent-level design continues and construction ofcertain components continues.The players:Doug Miller, software engineeringmanager, Vinod, Jamie, Ed, and Shakira—members ofthe SafeHomesoftware engineering team.The conversation:Doug:The first increment will be ready for validation inwhat . . . about three weeks?Vinod:That’s about right. Integration is going well.We’re smoke testing daily, finding some bugs but nothingwe can’t handle. So far, so good.Doug:Talk to me about validation.Shakira:Well, we’ll use all of the use cases as thebasis for our test design. I haven’t started yet, but I’ll bedeveloping tests for all of the use cases that I’ve beenresponsible for.Ed:Same here.Jamie:Me too, but we’ve got to get our act together foracceptance test and also for alpha and beta testing, no?Doug:Yes. In fact I’ve been thinking; we could bring in anoutside contractor to help us with validation. I have themoney in the budget . . . and it’d give us a new point of view.Vinod:I think we’ve got it under control.Doug:I’m sure you do, but an ITG gives us anindependent look at the software.Jamie:We’re tight on time here, Doug. I for one don’t havethe time to babysit anybody you bring in to do the job.Doug:I know, I know. But if an ITG works fromrequirements and use cases, not too much babysittingwill be required.Vinod:I still think we’ve got it under control.Doug:I hear you, Vinod, but I going to overrule on thisone. Let’s plan to meet with the ITG rep later this week.Get ‘em started and see what they come up with.Vinod:Okay, maybe it’ll lighten the load a bit.SAFEHOMEPreparing for Validationpre75977_ch17.qxd  11/27/08  6:09 PM  Page 46917.7 S YSTEM TESTING
At the beginning of this book, I stressed the fact that software is only one element ofa larger computer-based system. Ultimately, software is incorporated with other sys-tem elements (e.g., hardware, people, information), and a series of system integra-tion and validation tests are conducted. These tests fall outside the scope of thesoftware process and are not conducted solely by software engineers. However,steps taken during software design and testing can greatly improve the probabilityof successful software integration in the larger system.A classic system-testing problem is “finger pointing.” This occurs when an erroris uncovered, and the developers of different system elements blame each other forthe problem. Rather than indulging in such nonsense, you should anticipate poten-tial interfacing problems and (1) design error-handling paths that test all informationcoming from other elements of the system, (2) conduct a series of tests that simulatebad data or other potential errors at the software interface, (3) record the results oftests to use as “evidence” if finger pointing does occur, and (4) participate in plan-ning and design of system tests to ensure that software is adequately tested.System testingis actually a series of different tests whose primary purpose is tofully exercise the computer-based system. Although each test has a different pur-pose, all work to verify that system elements have been properly integrated and per-form allocated functions. In the sections that follow, I discuss the types of systemtests that are worthwhile for software-based systems.
17.7.1 Recovery Testing
Many computer-based systems must recover from faults and resume processingwith little or no downtime. In some cases, a system must be fault tolerant; that is,processing faults must not cause overall system function to cease. In other cases, asystem failure must be corrected within a specified period of time or severe eco-nomic damage will occur.Recovery testingis a system test that forces the software to fail in a variety of waysand verifies that recovery is properly performed. If recovery is automatic (performedby the system itself), reinitialization, checkpointing mechanisms, data recovery, andrestart are evaluated for correctness. If recovery requires human intervention, themean-time-to-repair (MTTR) is evaluated to determine whether it is within accept-able limits.
17.7.2 Security Testing
Any computer-based system that manages sensitive information or causes actionsthat can improperly harm (or benefit) individuals is a target for improper or illegalpenetration. Penetration spans a broad range of activities: hackers who attempt topenetrate systems for sport, disgruntled employees who attempt to penetrate forrevenge, dishonest individuals who attempt to penetrate for illicit personal gain.470 PART THREEQUALITY MANAGEMENT
uote:
“Like death andtaxes, testing isboth unpleasantand inevitable.”Ed Yourdonpre75977_ch17.qxd  11/27/08  6:09 PM  Page 470Security testingattempts to verify that protection mechanisms built into a systemwill, in fact, protect it from improper penetration. To quote Beizer [Bei84]: “The sys-tem’s security must, of course, be tested for invulnerability from frontal attack—butmust also be tested for invulnerability from flank or rear attack.”During security testing, the tester plays the role(s) of the individual who desires topenetrate the system. Anything goes! The tester may attempt to acquire passwordsthrough external clerical means; may attack the system with custom softwaredesigned to break down any defenses that have been constructed; may overwhelmthe system, thereby denying service to others; may purposely cause system errors,hoping to penetrate during recovery; may browse through insecure data, hoping tofind the key to system entry.Given enough time and resources, good security testing will ultimately penetratea system. The role of the system designer is to make penetration cost more than thevalue of the information that will be obtained.
17.7.3 Stress Testing
Earlier software testing steps resulted in thorough evaluation of normal programfunctions and performance. Stress tests are designed to confront programs withabnormal situations. In essence, the tester who performs stress testing asks: “Howhigh can we crank this up before it fails?”Stress testingexecutes a system in a manner that demands resources in abnor-mal quantity, frequency, or volume. For example, (1) special tests may be designedthat generate ten interrupts per second, when one or two is the average rate,(2) input data rates may be increased by an order of magnitude to determine howinput functions will respond, (3) test cases that require maximum memory or otherresources are executed, (4) test cases that may cause thrashing in a virtual oper-ating system are designed, (5) test cases that may cause excessive hunting fordisk-resident data are created. Essentially, the tester attempts to break theprogram.A variation of stress testing is a technique called sensitivity testing. In some situa- tions (the most common occur in mathematical algorithms), a very small range ofdata contained within the bounds of valid data for a program may cause extreme andeven erroneous processing or profound performance degradation. Sensitivity testingattempts to uncover data combinations within valid input classes that may causeinstability or improper processing.
17.7.4 Performance Testing
For real-time and embedded systems, software that provides required function butdoes not conform to performance requirements is unacceptable. Performance test-ing is designed to test the run-time performance of software within the context of anintegrated system. Performance testing occurs throughout all steps in the testingprocess. Even at the unit level, the performance of an individual module may beCHAPTER 17SOFTWARE TESTING STRATEGIES 471
uote:
“If you’re trying tofind true systembugs and youhaven’t subjectedyour software to areal stress test,then it’s high timeyou started.”Boris Beizerpre75977_ch17.qxd  11/27/08  6:09 PM  Page 471assessed as tests are conducted. However, it is not until all system elements are fullyintegrated that the true performance of a system can be ascertained.Performance tests are often coupled with stress testing and usually require bothhardware and software instrumentation. That is, it is often necessary to measureresource utilization (e.g., processor cycles) in an exacting fashion. External instru-mentation can monitor execution intervals, log events (e.g., interrupts) as they oc-cur, and sample machine states on a regular basis. By instrumenting a system, thetester can uncover situations that lead to degradation and possible system failure.
17.7.5 Deployment Testing
In many cases, software must execute on a variety of platforms and under morethan one operating system environment. Deployment testing,sometimes called configuration testing,exercises the software in each environment in which it is tooperate. In addition, deployment testing examines all installation procedures andspecialized installation software (e.g., “installers”) that will be used by customers,and all documentation that will be used to introduce the software to end users.As an example, consider the Internet-accessible version of SafeHomesoftware that would allow a customer to monitor the security system from remote locations.The SafeHomeWebApp must be tested using all Web browsers that are likely to beencountered. A more thorough deployment test might encompass combinationsof Web browsers with various operating systems (e.g., Linux, Mac OS, Windows).Because security is a major issue, a complete set of security tests would be integratedwith the deployment test.472 PART THREEQUALITY MANAGEMENT
Test Planning and Management
Objective:These tools assist a software teamin planning the testing strategy that is chosenand managing the testing process as it is conducted.Mechanics:Tools in this category address test planning,test storage, management and control, requirementstraceability, integration, error tracking, and reportgeneration. Project managers use them to supplementproject scheduling tools. Testers use these tools to plantesting activities and to control the flow of information asthe testing process proceeds.Representative Tools:
4
QaTraq Test Case Management Tool,developed byTraq Software (www.testmanagement.com ), “encourages a structured approach to test management.”QADirector,developed by Compuware Corp.(www.compuware.com/qacenter), provides asingle point of control for managing all phases of thetesting process.TestWorks,developed by Software Research, Inc.(www.soft.com/Products/index.html ), contains a fully integrated suite of testing toolsincluding tools for test management and reporting.OpensourceTesting.org(www.opensourcetesting.org/testmgt.php ) lists a variety of open-source test management andplanning tools.NI TestStand,developed by National Instruments Corp.(www.ni.com), allows you to “develop, manage,and execute test sequences written in anyprogramming language.”SOFTWARE TOOLS
4 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 47217.8 T HEART OF DEBUGGING
Software testing is a process that can be systematically planned and specified. Test-case design can be conducted, a strategy can be defined, and results can be evalu-ated against prescribed expectations.Debuggingoccurs as a consequence of successful testing. That is, when a testcase uncovers an error, debugging is the process that results in the removal of theerror. Although debugging can and should be an orderly process, it is still very muchan art. As a software engineer, you are often confronted with a “symptomatic” indi-cation of a software problem as you evaluate the results of a test. That is, the exter-nal manifestation of the error and its internal cause may have no obviousrelationship to one another. The poorly understood mental process that connects asymptom to a cause is debugging.
17.8.1 The Debugging Process
Debugging is not testing but often occurs as a consequence of testing.5Referring to Figure 17.7, the debugging process begins with the execution of a test case. Resultsare assessed and a lack of correspondence between expected and actual perform-ance is encountered. In many cases, the noncorresponding data are a symptom ofan underlying cause as yet hidden. The debugging process attempts to match symp-tom with cause, thereby leading to error correction.The debugging process will usually have one of two outcomes: (1) the cause willbe found and corrected or (2) the cause will not be found. In the latter case, the per-son performing debugging may suspect a cause, design a test case to help validatethat suspicion, and work toward error correction in an iterative fashion.Why is debugging so difficult? In all likelihood, human psychology (see Sec-tion 17.8.2) has more to do with an answer than software technology. However, afew characteristics of bugs provide some clues:1.The symptom and the cause may be geographically remote. That is, thesymptom may appear in one part of a program, while the cause may actuallybe located at a site that is far removed. Highly coupled components(Chapter 8) exacerbate this situation.2.The symptom may disappear (temporarily) when another error is corrected.3.The symptom may actually be caused by nonerrors (e.g., round-offinaccuracies).4.The symptom may be caused by human error that is not easily traced.CHAPTER 17SOFTWARE TESTING STRATEGIES 473
uote:
“We found to oursurprise that itwasn’t as easy toget programs rightas we had thought.I can rememberthe exact instantwhen I realizedthat a large part ofmy life from thenon was going to bespent in findingmistakes in myown programs.”Maurice Wilkes,discoversdebugging, 1949
5 In making the statement, we take the broadest possible view of testing. Not only does the devel-oper test software prior to release, but the customer/user tests software every time it is used!Be certain to avoid athird outcome: Thecause is found, but the“correction” does notsolve the problem orintroduces still anothererror.
Why isdebugging sodifficult??pre75977_ch17.qxd  11/27/08  6:09 PM  Page 4735.The symptom may be a result of timing problems, rather than processingproblems.6.It may be difficult to accurately reproduce input conditions (e.g., a real-timeapplication in which input ordering is indeterminate).7.The symptom may be intermittent. This is particularly common in embeddedsystems that couple hardware and software inextricably.8.The symptom may be due to causes that are distributed across a number oftasks running on different processors.During debugging, you’ll encounter errors that range from mildly annoying (e.g.,an incorrect output format) to catastrophic (e.g., the system fails, causing seriouseconomic or physical damage). As the consequences of an error increase, theamount of pressure to find the cause also increases. Often, pressure forces somesoftware developers to fix one error and at the same time introduce two more.
17.8.2 Psychological Considerations
Unfortunately, there appears to be some evidence that debugging prowess is an innatehuman trait. Some people are good at it and others aren’t. Although experimentalevidence on debugging is open to many interpretations, large variances in debugging474 PART THREEQUALITY MANAGEMENT
RegressiontestsCorrectionsIdentifiedcausesAdditional testsSuspected causesResults
DebuggingTestCasesFIGURE 17.7
Thedebuggingprocess
“Everyoneknows thatdebugging istwice as hard aswriting a pro-gram in the firstplace. So if youare as clever asyou can be whenyou write it, howwill you everdebug it?”BrianKernighan?pre75977_ch17.qxd  11/27/08  6:09 PM  Page 474ability have been reported for programmers with the same education and experience.Commenting on the human aspects of debugging, Shneiderman [Shn80] states:
Debugging is one of the more frustrating parts of programming. It has elements of prob-lem solving or brain teasers, coupled with the annoying recognition that you have madea mistake. Heightened anxiety and the unwillingness to accept the possibility of errorsincreases the task difficulty. Fortunately, there is a great sigh of relief and a lessening oftension when the bug is ultimately . . . corrected.
Although it may be difficult to “learn” debugging, a number of approaches to theproblem can be proposed. I examine them in Section 17.8.3.CHAPTER 17SOFTWARE TESTING STRATEGIES 475
Set a time limit, saytwo hours, on theamount of time youspend trying to debuga problem on yourown. After that, gethelp!Debugging
The scene:Ed’s cubical as code andunit testing is conducted.The players:Ed and Shakira—members of theSafeHomesoftware engineering team.The conversation:Shakira (looking in through the entrance tothe cubical):Hey . . . where were you at lunchtime?Ed:Right here...working.Shakira:You look miserable. . . what’s the matter?Ed (sighing audibly):I’ve been working on this . . .bug since I discovered it at 9:30 this morning and it’swhat, 2:45. . . I’m clueless.Shakira:I thought we all agreed to spend no morethan one hour debugging stuff on our own; then we gethelp, right?Ed:Yeah, but . . .Shakira (walking into the cubical): So what’s the problem?Ed:It’s complicated, and besides, I’ve been looking atthis for, what, 5 hours. You’re not going to see it in5 minutes.Shakira:Indulge me . . . what’s the problem?[Ed explains the problem to Shakira, who looks at it forabout 30 seconds without speaking, then . . .]Shakira (a smile is gathering on her face):Uh, right there, the variable named setAlarmCondition.Shouldn’t it be set to “false” before the loop gets started?[Ed stares at the screen in disbelief, bends forward, andbegins to bang his head gently against the monitor.Shakira, smiling broadly now, stands and walks out.]SAFEHOME
17.8.3 Debugging Strategies
Regardless of the approach that is taken, debugging has one overriding objective—to find and correct the cause of a software error or defect. The objective is realizedby a combination of systematic evaluation, intuition, and luck. Bradley [Bra85]describes the debugging approach in this way:
Debugging is a straightforward application of the scientific method that has been devel-oped over 2,500 years. The basis of debugging is to locate the problem’s source [thecause] by binary partitioning, through working hypotheses that predict new values to beexamined.Take a simple non-software example: A lamp in my house does not work. If nothingin the house works, the cause must be in the main circuit breaker or outside; I look aroundpre75977_ch17.qxd  11/27/08  6:09 PM  Page 475to see whether the neighborhood is blacked out. I plug the suspect lamp into a workingsocket and a working appliance into the suspect circuit. So goes the alternation ofhypothesis and test.
In general, three debugging strategies have been proposed [Mye79]: (1) bruteforce, (2) backtracking, and (3) cause elimination. Each of these strategies canbe conducted manually, but modern debugging tools can make the process muchmore effective.Debugging tactics.The brute forcecategory of debugging is probably the most common and least efficient method for isolating the cause of a software error. Youapply brute force debugging methods when all else fails. Using a “let the computerfind the error” philosophy, memory dumps are taken, run-time traces are invoked,and the program is loaded with output statements. You hope that somewhere in themorass of information that is produced you’ll find a clue that can lead to the causeof an error. Although the mass of information produced may ultimately lead tosuccess, it more frequently leads to wasted effort and time. Thought must beexpended first!Backtrackingis a fairly common debugging approach that can be used success-fully in small programs. Beginning at the site where a symptom has been uncovered,the source code is traced backward (manually) until the cause is found. Unfortu-nately, as the number of source lines increases, the number of potential backwardpaths may become unmanageably large.The third approach to debugging—cause elimination—is manifested by inductionor deduction and introduces the concept of binary partitioning. Data related to theerror occurrence are organized to isolate potential causes. A “cause hypothesis” isdevised and the aforementioned data are used to prove or disprove the hypothesis.Alternatively, a list of all possible causes is developed and tests are conducted toeliminate each. If initial tests indicate that a particular cause hypothesis showspromise, data are refined in an attempt to isolate the bug.Automated debugging.Each of these debugging approaches can be supple-mented with debugging tools that can provide you with semiautomated support asdebugging strategies are attempted. Hailpern and Santhanam [Hai02] summarizethe state of these tools when they note, “. . . many new approaches have been pro-posed and many commercial debugging environments are available. Integrateddevelopment environments (IDEs) provide a way to capture some of the language-specific predetermined errors (e.g., missing end-of-statement characters, unde-fined variables, and so on) without requiring compilation.” A wide variety ofdebugging compilers, dynamic debugging aids (“tracers”), automatic test-casegenerators, and cross-reference mapping tools are available. However, tools arenot a substitute for careful evaluation based on a complete design model and clearsource code.476 PART THREEQUALITY MANAGEMENT
uote:
“The first step infixing a brokenprogram is gettingit to fail repeatably(on the simplestexample possible).”T. Duffpre75977_ch17.qxd  11/27/08  6:09 PM  Page 476The people factor.Any discussion of debugging approaches and tools is incom-plete without mention of a powerful ally—other people! A fresh viewpoint, un-clouded by hours of frustration, can do wonders.
7A final maxim for debugging might be: “When all else fails, get help!”
17.8.4 Correcting the Error
Once a bug has been found, it must be corrected. But, as we have already noted, thecorrection of a bug can introduce other errors and therefore do more harm thangood. Van Vleck [Van89] suggests three simple questions that you should ask beforemaking the “correction” that removes the cause of a bug:1.Is the cause of the bug reproduced in another part of the program? In many situ- ations, a program defect is caused by an erroneous pattern of logic that maybe reproduced elsewhere. Explicit consideration of the logical pattern mayresult in the discovery of other errors.2.What “next bug” might be introduced by the fix I’m about to make? Before the correction is made, the source code (or, better, the design) should be evalu-ated to assess coupling of logic and data structures. If the correction is to bemade in a highly coupled section of the program, special care must be takenwhen any change is made.CHAPTER 17SOFTWARE TESTING STRATEGIES 477
Debugging
Objective:These tools provide automatedassistance for those who must debug softwareproblems. The intent is to provide insight that may bedifficult to obtain if approaching the debugging processmanually.Mechanics:Most debugging tools are programminglanguage and environment specific.Representative Tools:
6
Borland Gauntlet,distributed by Borland(www.borland.com), assists in both testing anddebugging.Coverty Prevent SQS, developed by Coverty(www.coverty.com), provides debuggingassistance for both C++ and Java.C++Test,developed by Parasoft (www.parasoft.com),is a unit-testing tool that supports a full range of testson C and C++ code. Debugging features assist in thediagnosis of errors that are found.CodeMedic,developed by NewPlanet Software(www.newplanetsoftware.com/medic/ ), provides a graphical interface for the standard UNIXdebugger, gdb,and implements its most importantfeatures. gdbcurrently supports C/C++, Java,PalmOS, various embedded systems, assemblylanguage, FORTRAN, and Modula-2.GNATS, a freeware application (www.gnu.org/software/gnats/), is a set of tools for tracking bugreports.SOFTWARE TOOLS
6 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.7 The concept of pair programming (recommended as part of the Extreme Programming model dis-cussed in Chapter 3) provides a mechanism for “debugging” as the software is designed and coded.uote:
“The best testerisn’t the one whofinds the mostbugs … the besttester is the onewho gets the mostbugs fixed.”Cem Kaner et al.pre75977_ch17.qxd  11/27/08  6:09 PM  Page 4773.What could we have done to prevent this bug in the first place? This question is the first step toward establishing a statistical software quality assurance ap-proach (Chapter 16). If you correct the process as well as the product, the bugwill be removed from the current program and may be eliminated from allfuture programs.
17.9 S UMMARY
Software testing accounts for the largest percentage of technical effort in the soft-ware process. Regardless of the type of software you build, a strategy for systematictest planning, execution, and control begins by considering small elements of thesoftware and moves outward toward the program as a whole.The objective of software testing is to uncover errors. For conventional software,this objective is achieved through a series of test steps. Unit and integration testsconcentrate on functional verification of a component and incorporation of compo-nents into the software architecture. Validation testing demonstrates traceability tosoftware requirements, and system testing validates software once it has beenincorporated into a larger system. Each test step is accomplished through a series ofsystematic test techniques that assist in the design of test cases. With each testingstep, the level of abstraction with which software is considered is broadened.The strategy for testing object-oriented software begins with tests that exercisethe operations within a class and then moves to thread-based testing for integration.Threads are sets of classes that respond to an input or event. Use-based tests focuson classes that do not collaborate heavily with other classes.WebApps are tested in much the same way as OO systems. However, tests aredesigned to exercise content, functionality, the interface, navigation, and aspects ofWebApp performance and security.Unlike testing (a systematic, planned activity), debugging can be viewed as anart. Beginning with a symptomatic indication of a problem, the debugging activitymust track down the cause of an error. Of the many resources available duringdebugging, the most valuable is the counsel of other members of the softwareengineering staff.
PROBLEMS AND POINTS TO PONDER
17.1.Using your own words, describe the difference between verification and validation.Do both make use of test-case design methods and testing strategies?17.2.List some problems that might be associated with the creation of an independent testgroup. Are an ITG and an SQA group made up of the same people?17.3.Is it always possible to develop a strategy for testing software that uses the sequence oftesting steps described in Section 17.1.3? What possible complications might arise for embed-ded systems?17.4.Why is a highly coupled module difficult to unit test?478 PART THREEQUALITY MANAGEMENTpre75977_ch17.qxd  11/27/08  6:09 PM  Page 47817.5.The concept of “antibugging” (Section 17.2.1) is an extremely effective way to providebuilt-in debugging assistance when an error is uncovered:a. Develop a set of guidelines for antibugging.b. Discuss advantages of using the technique.c. Discuss disadvantages.17.6.How can project scheduling affect integration testing?17.7.Is unit testing possible or even desirable in all circumstances? Provide examples to justifyyour answer.17.8.Who should perform the validation test—the software developer or the software user?Justify your answer.17.9.Develop a complete test strategy for the SafeHome system discussed earlier in this book. Document it in a Test Specification.17.10.As a class project, develop a Debugging Guide for your installation. The guide should provide language and system-oriented hints that have been learned through the school of hardknocks! Begin with an outline of topics that will be reviewed by the class and your instructor.Publish the guide for others in your local environment.
FURTHER READINGS AND INFORMATION SOURCES
Virtually every book on software testing discusses strategies along with methods for test-casedesign. Everett and Raymond (Software Testing, Wiley-IEEE Computer Society Press, 2007), Black (Pragmatic Software Testing,Wiley, 2007), Spiller and his colleagues (Software Testing Process: TestManagement,Rocky Nook, 2007), Perry (Effective Methods for Software Testing, 3d ed., Wiley, 2005), Lewis (Software Testing and Continuous Quality Improvement, 2d ed., Auerbach, 2004), Loveland and his colleagues (Software Testing Techniques, Charles River Media, 2004), Burnstein ( Practical Software Testing,Springer, 2003), Dustin (Effective Software Testing,Addison-Wesley, 2002), Craig and Kaskiel (Systematic Software Testing, Artech House, 2002), Tamres (Introducing Software Test- ing,Addison-Wesley, 2002), Whittaker (How to Break Software, Addison-Wesley, 2002), and Kaner and his colleagues (Lessons Learned in Software Testing, Wiley, 2001) are only a small sampling of many books that discuss testing principles, concepts, strategies, and methods.For those readers with interest in agile software development methods, Crispin and House(Testing Extreme Programming,Addison-Wesley, 2002) and Beck ( Test Driven Development: By Example,Addison-Wesley, 2002) present testing strategies and tactics for Extreme Program-ming. Kamer and his colleagues (Lessons Learned in Software Testing, Wiley, 2001) present a collection of over 300 pragmatic “lessons” (guidelines) that every software tester should learn.Watkins (Testing IT: An Off-the-Shelf Testing Process, Cambridge University Press, 2001) estab- lishes an effective testing framework for all types of developed and acquired software. Mangesand O’Brien (Agile Testing with Ruby and Rails, Apress, 2008) addresses testing strategies and techniques for the Ruby programming language and Web framework.Sykes and McGregor (Practical Guide to Testing Object-Oriented Software, Addison-Wesley, 2001), Bashir and Goel (Testing Object-Oriented Software, Springer-Verlag, 2000), Binder (Testing Object-Oriented Systems,Addison-Wesley, 1999), Kung and his colleagues ( Testing Object- Oriented Software,IEEE Computer Society Press, 1998), and Marick ( The Craft of Software Testing, Prentice-Hall, 1997) present strategies and methods for testing OO systems.Guidelines for debugging are contained in books by Grötker and his colleagues (The Devel-oper’s Guide to Debugging,Springer, 2008), Agans (Debugging,Amacon, 2006), Zeller (Why Programs Fail: A Guide to Systematic Debugging, Morgan Kaufmann, 2005), Tells and Hsieh ( The Science of Debugging,The Coreolis Group, 2001), and Robbins ( Debugging Applications, Microsoft Press, 2000). Kaspersky ( Hacker Debugging Uncovered,A-List Publishing, 2005) addresses the technology of debugging tools. Younessi (Object-Oriented Defect Management ofSoftware,Prentice-Hall, 2002) presents techniques for managing defects that are encountered inCHAPTER 17SOFTWARE TESTING STRATEGIES 479pre75977_ch17.qxd  11/27/08  6:09 PM  Page 479object-oriented systems. Beizer [Bei84] presents an interesting “taxonomy of bugs” that can leadto effective methods for test planning.Books by Madisetti and Akgul (Debugging Embedded Systems,Springer, 2007), Robbins (Debugging Microsoft .NET 2.0 Applications, Microsoft Press, 2005), Best (Linux Debugging and Performance Tuning,Prentice-Hall, 2005), Ford and Teorey ( Practical Debugging in C++,Prentice- Hall, 2002), Brown (Debugging Perl,McGraw-Hill, 2000), and Mitchell (Debugging Java,McGraw- Hill, 2000) address the special nature of debugging for the environments implied by their titles.A wide variety of information sources on software testing strategies are available on theInternet. An up-to-date list of World Wide Web references that are relevant to software testingstrategies can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.480 PART THREEQUALITY MANAGEMENTpre75977_ch17.qxd  11/27/08  6:09 PM  Page 480Testing presents an interesting anomaly for software engineers, who by theirnature are constructive people. Testing requires that the developer discardpreconceived notions of the “correctness” of software just developed andthen work hard to design test cases to “break” the software. Beizer [Bei90]describes this situation effectively when he states:
There’s a myth that if we were really good at programming, there would be no bugs tocatch. If only we could really concentrate, if only everyone used structured program-ming, top-down design,. . . then there would be no bugs. So goes the myth. There arebugs, the myth says, because we are bad at what we do; and if we are bad at it, weshould feel guilty about it. Therefore, testing and test case design is an admission offailure, which instills a goodly dose of guilt. And the tedium of testing is just punish-ment for our errors. Punishment for what? For being human? Guilt for what? For fail-ing to achieve inhuman perfection? For not distinguishing between what anotherprogrammer thinks and what he says? For failing to be telepathic? For not solvinghuman communications problems that have been kicked around . . . for forty centuries?
Should testing instill guilt? Is testing really destructive? The answer to these ques-tions is “No!”In this chapter, I discuss techniques for software test-case design for conven-tional applications. Test-case design focuses on a set of techniques for the cre-ation of test cases that meet overall testing objectives and the testing strategiesdiscussed in Chapter 17.
481CHAPTER
18TESTING CONVENTIONAL
APPLICATIONS
What is it? Once source code hasbeen generated, software must betested to uncover (and correct) asmany errors as possible before deliv-ery to your customer. Your goal is to design aseries of test cases that have a high likelihood offinding errors—but how? That’s where softwaretesting techniques enter the picture. These tech-niques provide systematic guidance for design-ing tests that (1) exercise the internal logic andinterfaces of every software component and (2)exercise the input and output domains of the pro-gram to uncover errors in program function,behavior, and performance.QUICK
LOOKWho does it? During early stages of testing, asoftware engineer performs all tests. However,as the testing process progresses, testing spe-cialists may become involved.
Why is it important? Reviews and other SQAactions can and do uncover errors, but they arenot sufficient. Every time the program is executed,the customer tests it! Therefore, you have to exe-cute the program before it gets to the customerwith the specific intent of finding and removing allerrors. In order to find the highest possible num-ber of errors, tests must be conducted systemati-cally and test cases must be designed usingdisciplined techniques.KEY
CONCEPTS
basis path testing  . . . . . . . . .485black-boxtesting  . . . . . . . . .495boundary valueanalysis  . . . . . . . .498control structuretesting  . . . . . . . . .492cyclomaticcomplexity  . . . . . .488equivalencepartitioning . . . . . .497flow graph  . . . . . .485graph-based testingmethods  . . . . . . . .495graph matrices  . . .491model-based testing  . . . . . . . . .502orthogonal arraytesting  . . . . . . . . .499patterns  . . . . . . . .507specializedenvironments  . . . .503white-box testing  . . . . . . . . .485pre75977_ch18.qxd  11/27/08  6:12 PM  Page 481482 PART THREEQUALITY MANAGEMENT
18.1 S OFTWARE TESTING FUNDAMENTALS
The goal of testing is to find errors, and a good test is one that has a high probabil-ity of finding an error. Therefore, you should design and implement a computer-based system or a product with “testability” in mind. At the same time, the teststhemselves must exhibit a set of characteristics that achieve the goal of finding themost errors with a minimum of effort.Testability.James Bach
1provides the following definition for testability: “Softwaretestabilityis simply how easily [a computer program] can be tested.” The followingcharacteristics lead to testable software.Operability.“The better it works, the more efficiently it can be tested.” If a systemis designed and implemented with quality in mind, relatively few bugs will blockthe execution of tests, allowing testing to progress without fits and starts.Observability.“What you see is what you test.” Inputs provided as part of testingproduce distinct outputs. System states and variables are visible or queriable dur-ing execution. Incorrect output is easily identified. Internal errors are automaticallydetected and reported. Source code is accessible.Controllability.“The better we can control the software, the more the testing canbe automated and optimized.” All possible outputs can be generated through somecombination of input, and I/O formats are consistent and structured. All code isexecutable through some combination of input. Software and hardware states anduote:
“Every programdoes somethingright, it just maynot be the thing wewant it to do.”Author unknown
What are thecharacter-istics oftestability??
1 The paragraphs that follow are used with permission of James Bach (copyright 1994) and have beenadapted from material that originally appeared in a posting in the newsgroup comp.software-eng.What are the steps? For conventional applica-tions, software is tested from two different per-spectives: (1) internal program logic is exercisedusing “white box” test-case design techniquesand (2) software requirements are exercisedusing “black box” test-case design techniques.Use cases assist in the design of tests to uncovererrors at the software validation level. In everycase, the intent is to find the maximum numberof errors with the minimum amount of effortand time.
What is the work product? A set of test casesdesigned to exercise both internal logic,interfaces, component collaborations, andexternal requirements is designed and docu-mented, expected results are defined, and actualresults are recorded.How do I ensure that I’ve done it right? Whenyou begin testing, change your point of view. Tryhard to “break” the software! Design test casesin a disciplined fashion and review the test casesyou do create for thoroughness. In addition, youcan evaluate test coverage and track errordetection activities.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 482variables can be controlled directly by the test engineer. Tests can be convenientlyspecified, automated, and reproduced.Decomposability.“By controlling the scope of testing, we can more quicklyisolate problems and perform smarter retesting.” The software system is built fromindependent modules that can be tested independently.Simplicity.“The less there is to test, the more quickly we can test it.” The pro-gram should exhibit functional simplicity (e.g., the feature set is the minimum nec- essary to meet requirements);structural simplicity(e.g., architecture is modularized to limit the propagation of faults), and code simplicity(e.g., a coding standard is adopted for ease of inspection and maintenance).Stability.“The fewer the changes, the fewer the disruptions to testing.” Changesto the software are infrequent, controlled when they do occur, and do not invali-date existing tests. The software recovers well from failures.Understandability.“The more information we have, the smarter we will test.” Thearchitectural design and the dependencies between internal, external, and sharedcomponents are well understood. Technical documentation is instantly accessible,well organized, specific and detailed, and accurate. Changes to the design arecommunicated to testers.You can use the attributes suggested by Bach to develop a software configuration(i.e., programs, data, and documents) that is amenable to testing.Test Characteristics.And what about the tests themselves? Kaner, Falk, andNguyen [Kan93] suggest the following attributes of a “good” test:A good test has a high probability of finding an error. To achieve this goal, the tester must understand the software and attempt to develop a mental picture ofhow the software might fail. Ideally, the classes of failure are probed. For example,one class of potential failure in a graphical user interface is the failure to recognizeproper mouse position. A set of tests would be designed to exercise the mouse inan attempt to demonstrate an error in mouse position recognition.A good test is not redundant.Testing time and resources are limited. There is nopoint in conducting a test that has the same purpose as another test. Every testshould have a different purpose (even if it is subtly different).A good test should be “best of breed”[Kan93]. In a group of tests that have a simi-lar intent, time and resource limitations may mitigate toward the execution of onlya subset of these tests. In such cases, the test that has the highest likelihood ofuncovering a whole class of errors should be used.A good test should be neither too simple nor too complex. Although it is sometimes possible to combine a series of tests into one test case, the possible side effectsassociated with this approach may mask errors. In general, each test should beexecuted separately.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 483
uote:
“Errors are morecommon, morepervasive, andmore troublesomein software thanwith othertechnologies.”David Parnas
What is a“good”test??pre75977_ch18.qxd  11/27/08  6:12 PM  Page 48318.2 I NTERNAL AND EXTERNAL VIEWS OF TESTING
Any engineered product (and most other things) can be tested in one of two ways:(1) Knowing the specified function that a product has been designed to perform, testscan be conducted that demonstrate each function is fully operational while at the sametime searching for errors in each function. (2) Knowing the internal workings of a prod-uct, tests can be conducted to ensure that “all gears mesh,” that is, internal operationsare performed according to specifications and all internal components have been ade-quately exercised. The first test approach takes an external view and is called black-boxtesting. The second requires an internal view and is termed white-box testing.
2
Black-box testingalludes to tests that are conducted at the software interface.A black-box test examines some fundamental aspect of a system with little regardfor the internal logical structure of the software. White-box testing of software is pred- icated on close examination of procedural detail. Logical paths through the softwareand collaborations between components are tested by exercising specific sets ofconditions and/or loops.At first glance it would seem that very thorough white-box testing would leadto “100 percent correct programs.” All we need do is define all logical paths, developtest cases to exercise them, and evaluate results, that is, generate test cases toexercise program logic exhaustively. Unfortunately, exhaustive testing presents484 PART THREEQUALITY MANAGEMENT
Designing Unique Tests
The scene:Vinod’s cubical.The players:Vinod and Ed—members of theSafeHomesoftware engineering team.The conversation:Vinod:So these are the test cases you intend to run forthe passwordValidationoperation.Ed:Yeah, they should cover pretty much all possibilitiesfor the kinds of passwords a user might enter.Vinod:So let’s see . . . you note that the correctpassword will be 8080, right?Ed:Uh huh.Vinod:And you specify passwords 1234 and 6789 totest for error in recognizing invalid passwords?Ed:Right, and I also test passwords that are close to thecorrect password, see . . . 8081 and 8180.Vinod:Those are okay, but I don’t see much point inrunning both the 1234 and 6789 inputs. They’reredundant . . . test the same thing, don’t they?Ed:Well, they’re different values.Vinod:That’s true, but if 1234 doesn’t uncover anerror . . . in other words...t h e  passwordValidationoperation notes that it’s an invalid password, it’s not likelythat 6789 will show us anything new.Ed:I see what you mean.Vinod:I’m not trying to be picky here . . . it’s just thatwe have limited time to do testing, so it’s a good idea torun tests that have a high likelihood of finding new errors.Ed:Not a problem . . . I’ll give this a bit more thought.SAFEHOME
2 The terms functional testing and structural testingare sometimes used in place of black-box and white-box testing, respectively.uote:
“There is only onerule in designingtest cases: cover allfeatures, but donot make toomany test cases.”Tsuneo Yamaura
White-box tests can bedesigned only aftercomponent-level design(or source code)exists. The logicaldetails of the programmust be available.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 484certain logistical problems. For even small programs, the number of possible logicalpaths can be very large. White-box testing should not, however, be dismissed asimpractical. A limited number of important logical paths can be selected andexercised. Important data structures can be probed for validity.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 485
Exhaustive Testing
Consider a 100-line program in the languageC. After some basic data declaration, theprogram contains two nested loops that execute from 1 to20 times each, depending on conditions specified at input.Inside the interior loop, four if-then-else constructs arerequired. There are approximately 10
14possible paths thatmay be executed in this program!To put this number in perspective, we assume that amagic test processor (“magic” because no such processorexists) has been developed for exhaustive testing. Theprocessor can develop a test case, execute it, and evaluatethe results in one millisecond. Working 24 hours a day,365 days a year, the processor would work for 3170 yearsto test the program. This would, undeniably, cause havocin most development schedules.Therefore, it is reasonable to assert that exhaustivetesting is impossible for large software systems.INFO
18.3 W HITE-BOXTESTING
White-box testing,sometimes called glass-box testing,is a test-case design philoso- phy that uses the control structure described as part of component-level design toderive test cases. Using white-box testing methods, you can derive test cases that(1) guarantee that all independent paths within a module have been exercised atleast once, (2) exercise all logical decisions on their true and false sides, (3) executeall loops at their boundaries and within their operational bounds, and (4) exerciseinternal data structures to ensure their validity.
18.4 B ASIS PATHTESTING
Basis path testingis a white-box testing technique first proposed by Tom McCabe[McC76]. The basis path method enables the test-case designer to derive a logicalcomplexity measure of a procedural design and use this measure as a guide for defin-ing a basis set of execution paths. Test cases derived to exercise the basis set are guar-anteed to execute every statement in the program at least one time during testing.
18.4.1 Flow Graph Notation
Before we consider the basis path method, a simple notation for the representationof control flow, called a flow graph(or program graph) must be introduced.
3The flow graph depicts logical control flow using the notation illustrated in Figure 18.1. Eachstructured construct (Chapter 10) has a corresponding flow graph symbol.uote:
“Bugs lurk incorners andcongregate atboundaries.”Boris Beizer
3 In actuality, the basis path method can be conducted without the use of flow graphs. However, theyserve as a useful notation for understanding control flow and illustrating the approach.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 485To illustrate the use of a flow graph, consider the procedural design representation inFigure 18.2a. Here, a flowchart is used to depict program control structure. Figure 18.2bmaps the flowchart into a corresponding flow graph (assuming that no compoundconditions are contained in the decision diamonds of the flowchart). Referring toFigure 18.2b, each circle, called a flow graph node, represents one or more procedural statements. A sequence of process boxes and a decision diamond can map into a sin-gle node. The arrows on the flow graph, called edges or links,represent flow of con- trol and are analogous to flowchart arrows. An edge must terminate at a node, evenif the node does not represent any procedural statements (e.g., see the flow graphsymbol for the if-then-else construct). Areas bounded by edges and nodes are calledregions.When counting regions, we include the area outside the graph as a region.
4486 PART THREEQUALITY MANAGEMENT
IfWhileThe structured constructs in flow graph form:
Where each circle represents one or morenonbranching PDL or source code statementsUntilCaseSequenceFIGURE 18.1
Flow graphnotation
1
3
10(a)
6924
5 8 7
11 (b)1
2,3
4,5 6
9
10
118 7
R1R3R2
R4RegionNodeEdgeFIGURE 18.2 (a) Flowchart and (b) flow graph
4 A more detailed discussion of graphs and their uses is presented in Section 18.6.1.A flow graph should bedrawn only when thelogical structure of acomponent is complex.The flow graph allowsyou to trace programpaths more readily.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 486When compound conditions are encountered in a procedural design, the genera-tion of a flow graph becomes slightly more complicated. A compound conditionoccurs when one or more Boolean operators (logical OR, AND, NAND, NOR) is pres-ent in a conditional statement. Referring to Figure 18.3, the program design language(PDL) segment translates into the flow graph shown. Note that a separate node iscreated for each of the conditions aand bin the statement IF aOR b.Each node that contains a condition is called a predicate node and is characterized by two or more edges emanating from it.
18.4.2 Independent Program Paths
An independent pathis any path through the program that introduces at least onenew set of processing statements or a new condition. When stated in terms of a flowgraph, an independent path must move along at least one edge that has not beentraversed before the path is defined. For example, a set of independent paths for theflow graph illustrated in Figure 18.2b isPath 1: 1-11Path 2: 1-2-3-4-5-10-1-11Path 3: 1-2-3-6-8-9-10-1-11Path 4: 1-2-3-6-7-9-10-1-11Note that each new path introduces a new edge. The path1-2-3-4-5-10-1-2-3-6-8-9-10-1-11is not considered to be an independent path because it is simply a combination ofalready specified paths and does not traverse any new edges.Paths 1 through 4 constitute a basis set for the flow graph in Figure 18.2b. That is, if you can design tests to force execution of these paths (a basis set), every statementin the program will have been guaranteed to be executed at least one time and everycondition will have been executed on its true and false sides. It should be noted thatCHAPTER 18TESTING CONVENTIONAL APPLICATIONS 487
Predicatenode...IF a OR bthen procedure   xelse procedure   yENDIFybaxxFIGURE 18.3
Compoundlogicpre75977_ch18.qxd  11/27/08  6:12 PM  Page 487the basis set is not unique. In fact, a number of different basis sets can be derived fora given procedural design.How do you know how many paths to look for? The computation of cyclomaticcomplexity provides the answer. Cyclomatic complexity is a software metric that pro- vides a quantitative measure of the logical complexity of a program. When used inthe context of the basis path testing method, the value computed for cyclomatic com-plexity defines the number of independent paths in the basis set of a program andprovides you with an upper bound for the number of tests that must be conducted toensure that all statements have been executed at least once.Cyclomatic complexity has a foundation in graph theory and provides you with anextremely useful software metric. Complexity is computed in one of three ways:1.The number of regions of the flow graph corresponds to the cyclomaticcomplexity.2.Cyclomatic complexity V(G) for a flow graph Gis defined as V(G) /H11005E/H11002N/H110012where Eis the number of flow graph edges and N is the number of flow graph nodes.3.Cyclomatic complexity V(G) for a flow graph Gis also defined as V(G) /H11005P/H110011where Pis the number of predicate nodes contained in the flow graph G.Referring once more to the flow graph in Figure 18.2b, the cyclomatic complexity canbe computed using each of the algorithms just noted:1.The flow graph has four regions.2.V(G)/H1100511 edges /H110029 nodes /H110012/H110054.3.V(G)/H110053 predicate nodes /H110011/H110054.Therefore, the cyclomatic complexity of the flow graph in Figure 18.2b is 4.More important, the value for V(G) provides you with an upper bound for the num-ber of independent paths that form the basis set and, by implication, an upper boundon the number of tests that must be designed and executed to guarantee coverageof all program statements.488 PART THREEQUALITY MANAGEMENT
Cyclomatic complexityis a useful metric forpredicting thosemodules that are likelyto be error prone. Useit for test planning aswell as test-casedesign.
How do Icomputecyclomaticcomplexity??
Cyclomatic complexityprovides the upperbound on the numberof test cases that willbe required toguarantee that everystatement in theprogram has beenexecuted at least onetime.
The scene:Shakira’s cubicle.The players:Vinod and Shakira—members of theSafeHomesoftware engineering team who are workingon test planning for the security function.The conversation:Shakira:Look . . . I know that we should unit-test all thecomponents for the security function, but there are a lot of‘em and if you consider the number of operations thatSAFEHOMEUsing Cyclomatic Complexitypre75977_ch18.qxd  11/27/08  6:12 PM  Page 48818.4.3 Deriving Test Cases
The basis path testing method can be applied to a procedural design or to sourcecode. In this section, I present basis path testing as a series of steps. The procedureaverage,depicted in PDL in Figure 18.4, will be used as an example to illustrate eachstep in the test-case design method. Note that average, although an extremely sim- ple algorithm, contains compound conditions and loops. The following steps can beapplied to derive the basis set:1.Using the design or code as a foundation, draw a correspondingflow graph.A flow graph is created using the symbols and constructionrules presented in Section 18.4.1. Referring to the PDL for averagein Figure 18.4, a flow graph is created by numbering those PDL statements thatwill be mapped into corresponding flow graph nodes. The correspondingflow graph is shown in Figure 18.5.2.Determine the cyclomatic complexity of the resultant flow graph.The cyclomatic complexity V(G) is determined by applying the algorithmsdescribed in Section 18.4.2. It should be noted that V(G) can be determinedwithout developing a flow graph by counting all conditional statements inthe PDL (for the procedure average,compound conditions count as two) andadding 1. Referring to Figure 18.5,V(G) /H110056 regionsV(G) /H1100517 edges /H1100213 nodes /H110012 /H110056V(G) /H110055 predicate nodes /H110011 /H110056CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 489
have to be exercised, I don’t know...m aybe we should forget white-box testing, integrate everything, and startrunning black-box tests.Vinod:You figure we don’t have enough time to docomponent tests, exercise the operations, and thenintegrate?Shakira:The deadline for the first increment is gettingcloser than I’d like . . . yeah, I’m concerned.Vinod:Why don’t you at least run white-box tests onthe operations that are likely to be the most error prone?Shakira (exasperated):And exactly how do I knowwhich are the most error prone?Vinod:Vof G.Shakira:Huh?Vinod:Cyclomatic complexity—Vof G. Just computeV(G) for each of the operations within each of the components and see which have the highest values forV(G). They’re the ones that are most likely to be errorprone.Shakira:And how do I compute Vof G?Vinod:It’s really easy. Here’s a book that describes howto do it.Shakira (leafing through the pages): Okay, it doesn’t look hard. I’ll give it a try. The ops with the highest V(G) will be the candidates for white-boxtests.Vinod:Just remember that there are no guarantees.A component with a low V(G) can still be error prone.Shakira:Alright. But at least this’ll help me to narrowdown the number of components that have to undergowhite-box testing.
uote:
“The Ariane 5rocket blew up onlift-off due solelyto a softwaredefect (a bug)involving theconversion of a 64-bit floating pointvalue into a 16-bitinteger. The rocketand its foursatellites wereuninsuredandworth $500million. [Path teststhat exercised theconversion path]would have foundthe bug but werevetoed forbudgetaryreasons.”A news reportpre75977_ch18.qxd  11/27/08  6:12 PM  Page 489490 PART THREEQUALITY MANAGEMENT
PROCEDURE average;
INTERFACE RETURNS average, total.input, total.valid;INTERFACE ACCEPTS value, minimum, maximum;TYPE value[1:100] IS SCALAR ARRAY;TYPE average, total.input, total.valid; minimum, maximum, sum IS SCALAR;TYPE i IS INTEGER;* This procedure computes the average of 100 or fewer numbers that lie between bounding values; it also computes the sum and the total number valid.
i = 1;total.input = total.valid = 0;sum = 0;DO WHILE value[i] <> –999 AND total.input < 100
ENDDOIF total.valid > 0ENDIFEND averageincrement total.input by 1;IF value[i] > = minimum AND value[i] < = maximum
ENDIFincrement i by 1;THEN average = sum / total.valid;ELSE average = –999;THEN increment total.valid by 1; sum = s sum + value[i]ELSE skip
1
3
64
5
7
8
9
10
1112
132FIGURE 18.4
PDL withnodesidentified
12345678910111213FIGURE 18.5
Flow graph forthe procedureaverage3.Determine a basis set of linearly independent paths. The value of V(G) provides the upper bound on the number of linearly independent pathsthrough the program control structure. In the case of procedure average,we expect to specify six paths:Path 1: 1-2-10-11-13Path 2: 1-2-10-12-13pre75977_ch18.qxd  11/27/08  6:12 PM  Page 490Path 3: 1-2-3-10-11-13Path 4: 1-2-3-4-5-8-9-2-. . .Path 5: 1-2-3-4-5-6-8-9-2-. . .Path 6: 1-2-3-4-5-6-7-8-9-2-. . .The ellipsis (. . .) following paths 4, 5, and 6 indicates that any path throughthe remainder of the control structure is acceptable. It is often worthwhile toidentify predicate nodes as an aid in the derivation of test cases. In this case,nodes 2, 3, 5, 6, and 10 are predicate nodes.4.Prepare test cases that will force execution of each path in the basisset.Data should be chosen so that conditions at the predicate nodes areappropriately set as each path is tested. Each test case is executed and com-pared to expected results. Once all test cases have been completed, the testercan be sure that all statements in the program have been executed at leastonce.It is important to note that some independent paths (e.g., path 1 in our example)cannot be tested in stand-alone fashion. That is, the combination of data required totraverse the path cannot be achieved in the normal flow of the program. In suchcases, these paths are tested as part of another path test.
18.4.4 Graph Matrices
The procedure for deriving the flow graph and even determining a set of basis pathsis amenable to mechanization. A data structure, called a graph matrix,can be quite useful for developing a software tool that assists in basis path testing.A graph matrix is a square matrix whose size (i.e., number of rows and columns)is equal to the number of nodes on the flow graph. Each row and column corre-sponds to an identified node, and matrix entries correspond to connections (an edge)between nodes. A simple example of a flow graph and its corresponding graphmatrix [Bei90] is shown in Figure 18.6.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 491
13425
abcdefgFlow graph13 4251342
5a
e gcfdbConnected tonodeNode
Graph matrixFIGURE 18.6
Graph matrixpre75977_ch18.qxd  11/27/08  6:12 PM  Page 491Referring to the figure, each node on the flow graph is identified by numbers,while each edge is identified by letters. A letter entry is made in the matrix tocorrespond to a connection between two nodes. For example, node 3 is connectedto node 4 by edge b.To this point, the graph matrix is nothing more than a tabular representation of aflow graph. However, by adding a link weight to each matrix entry, the graph matrix can become a powerful tool for evaluating program control structure during testing.The link weight provides additional information about control flow. In its simplestform, the link weight is 1 (a connection exists) or 0 (a connection does not exist). Butlink weights can be assigned other, more interesting properties:
•The probability that a link (edge) will be execute.
•The processing time expended during traversal of a link
•The memory required during traversal of a link
•The resources required during traversal of a link.Beizer [Bei90] provides a thorough treatment of additional mathematical algo-rithms that can be applied to graph matrices. Using these techniques, the analysisrequired to design test cases can be partially or fully automated.
18.5 C ONTROL STRUCTURE TESTING
The basis path testing technique described in Section 18.4 is one of a number of tech-niques for control structure testing. Although basis path testing is simple and highlyeffective, it is not sufficient in itself. In this section, other variations on control struc-ture testing are discussed. These broaden testing coverage and improve the qualityof white-box testing.
18.5.1 Condition Testing
Condition testing[Tai89] is a test-case design method that exercises the logical con-ditions contained in a program module. A simple condition is a Boolean variable ora relational expression, possibly preceded with one NOT (¬) operator. A relationalexpression takes the formE
1<relational-operator> E2
where E1andE2are arithmetic expressions and <relational-operator> is one of thefollowing: /H11021,/H11349,/H11005,/HS33527(nonequality), /H11022, or/H11350. A compound conditionis composed of two or more simple conditions, Boolean operators, and parentheses. We assumethat Boolean operators allowed in a compound condition include OR ( /H20841), AND (&), and NOT (¬). A condition without relational expressions is referred to as a Booleanexpression.If a condition is incorrect, then at least one component of the condition is incor-rect. Therefore, types of errors in a condition include Boolean operator errors492 PART THREEQUALITY MANAGEMENT
What is agraph matrixand how do Iextend it for usein testing??
uote:
“Paying moreattention torunning tests thanto designing themis a classicmistake.”Brian Marick
Errors are much morecommon in theneighborhood oflogical conditions thanthey are in the locus ofsequential processingstatements.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 492(incorrect/missing/extra Boolean operators), Boolean variable errors, Booleanparenthesis errors, relational operator errors, and arithmetic expression errors. Thecondition testing method focuses on testing each condition in the program to ensurethat it does not contain errors.
18.5.2 Data Flow Testing
The data flow testing method [Fra93] selects test paths of a program according to thelocations of definitions and uses of variables in the program. To illustrate the dataflow testing approach, assume that each statement in a program is assigned a uniquestatement number and that each function does not modify its parameters or globalvariables. For a statement with Sas its statement number,DEF(S) /H11005{X| statement Scontains a definition of X}USE(S) /H11005{X| statement Scontains a use of X}If statement Sis aniforloop statement,its DEF set is empty and its USE set is based on the condition of statement S.The definition of variable Xat statement Sis said to be liveat statement S’if there exists a path from statement Sto statement S’that con- tains no other definition of X.A definition-use (DU) chainof variable Xis of the form [X, S, S’], where Sand S’are statement numbers, Xis in DEF(S) and USE(S’), and the definition of X in statement Sis live at statementS’.One simple data flow testing strategy is to require that every DU chain be coveredat least once. We refer to this strategy as the DU testing strategy. It has been shownthat DU testing does not guarantee the coverage of all branches of a program. How-ever, a branch is not guaranteed to be covered by DU testing only in rare situationssuch as if-then-else constructs in which the then parthas no definition of any vari- able and theelse partdoes not exist. In this situation, the else branch of the ifstate- ment is not necessarily covered by DU testing.
18.5.3 Loop Testing
Loops are the cornerstone for the vast majority of all algorithms implemented insoftware. And yet, we often pay them little heed while conducting software tests.Loop testingis a white-box testing technique that focuses exclusively on thevalidity of loop constructs. Four different classes of loops [Bei90] can be defined: sim-ple loops, concatenated loops, nested loops, and unstructured loops (Figure 18.7).Simple loops.The following set of tests can be applied to simple loops, where n is the maximum number of allowable passes through the loop.1.Skip the loop entirely.2.Only one pass through the loop.3.Two passes through the loop.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 493
It is unrealistic toassume that data flowtesting will be usedextensively whentesting a large system.However, it can beused in a targetedfashion for areas ofsoftware that aresuspect.uote:
“Good testers aremasters at noticing‘something funny’and acting on it.”Brian Marickpre75977_ch18.qxd  11/27/08  6:12 PM  Page 4934.mpasses through the loop where m /H11021n.5.n/H110021, n, n/H110011 passes through the loop.Nested loops.If we were to extend the test approach for simple loops to nestedloops, the number of possible tests would grow geometrically as the level of nestingincreases. This would result in an impractical number of tests. Beizer [Bei90] sug-gests an approach that will help to reduce the number of tests:1.Start at the innermost loop. Set all other loops to minimum values.2.Conduct simple loop tests for the innermost loop while holding the outerloops at their minimum iteration parameter (e.g., loop counter) values. Addother tests for out-of-range or excluded values.3.Work outward, conducting tests for the next loop, but keeping all other outerloops at minimum values and other nested loops to “typical” values.4.Continue until all loops have been tested.Concatenated loops.Concatenated loops can be tested using the approachdefined for simple loops, if each of the loops is independent of the other. However,if two loops are concatenated and the loop counter for loop 1 is used as the initialvalue for loop 2, then the loops are not independent. When the loops are not inde-pendent, the approach applied to nested loops is recommended.Unstructured loops.Whenever possible, this class of loops should be redesignedto reflect the use of the structured programming constructs (Chapter 10).494 PART THREEQUALITY MANAGEMENT
Simple loopsNested loopsConcatenatedloopsUnstructuredloopsFIGURE 18.7
Classes ofLoops
You can’t test unstruc-tured loops effectively.Refactor them.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 49418.6 B LACK -BOXTESTING
Black-box testing, also called behavioral testing, focuses on the functional require- ments of the software. That is, black-box testing techniques enable you to derive setsof input conditions that will fully exercise all functional requirements for a program.Black-box testing is not an alternative to white-box techniques. Rather, it is a com-plementary approach that is likely to uncover a different class of errors than white-box methods.Black-box testing attempts to find errors in the following categories: (1) incorrector missing functions, (2) interface errors, (3) errors in data structures or externaldatabase access, (4) behavior or performance errors, and (5) initialization andtermination errors.Unlike white-box testing, which is performed early in the testing process, black-box testing tends to be applied during later stages of testing (see Chapter 17). Becauseblack-box testing purposely disregards control structure, attention is focused on theinformation domain. Tests are designed to answer the following questions:
•How is functional validity tested?
•How are system behavior and performance tested?
•What classes of input will make good test cases?
•Is the system particularly sensitive to certain input values?
•How are the boundaries of a data class isolated?
•What data rates and data volume can the system tolerate?
•What effect will specific combinations of data have on system operation?By applying black-box techniques, you derive a set of test cases that satisfy the fol-lowing criteria [Mye79]: (1) test cases that reduce, by a count that is greater than one,the number of additional test cases that must be designed to achieve reasonabletesting, and (2) test cases that tell you something about the presence or absence ofclasses of errors, rather than an error associated only with the specific test at hand.
18.6.1 Graph-Based Testing Methods
The first step in black-box testing is to understand the objects5that are modeled in software and the relationships that connect these objects. Once this has beenaccomplished, the next step is to define a series of tests that verify “all objects havethe expected relationship to one another” [Bei95]. Stated in another way, softwaretesting begins by creating a graph of important objects and their relationships andCHAPTER 18TESTING CONVENTIONAL APPLICATIONS 495
Whatquestions doblack-box testsanswer??
A graph represents therelationships betweendata objects andprogram objects,enabling you to derivetest cases that searchfor errors associatedwith theserelationships.
5 In this context, you should consider the term objects in the broadest possible context. It encom- passes data objects, traditional components (modules), and object-oriented elements of computersoftware.uote:
“To err is human,to find a bug isdivine.”Robert Dunnpre75977_ch18.qxd  11/27/08  6:12 PM  Page 495then devising a series of tests that will cover the graph so that each object and rela-tionship is exercised and errors are uncovered.To accomplish these steps, you begin by creating a graph—a collection of nodes that represent objects, linksthat represent the relationships between objects, node weightsthat describe the properties of a node (e.g., a specific data value or statebehavior), and link weightsthat describe some characteristic of a link.The symbolic representation of a graph is shown in Figure 18.8a. Nodes arerepresented as circles connected by links that take a number of different forms.Adirected link(represented by an arrow) indicates that a relationship moves in onlyone direction. A bidirectional link,also called a symmetric link,implies that the rela- tionship applies in both directions. Parallel links are used when a number of different relationships are established between graph nodes.As a simple example, consider a portion of a graph for a word-processingapplication (Figure 18.8b) whereObject #1/H11005newFile (menu selection)Object #2/H11005documentWindowObject #3/H11005documentTextReferring to the figure, a menu select on newFile generates a document window. The node weight of documentWindow provides a list of the window attributes that are to be expected when the window is generated. The link weight indicates that the496 PART THREEQUALITY MANAGEMENT
New filemenuselect Menu select generatesDocumentwindow
DocumenttextIs represented asContains
(b)Object#1Directed linkObject#2
Object#3Undirected linkParallel linksNode weight(value)(a)
Allows editing of(link weight)
(generation time < 1.0 sec)Attributes:Start dimension: default setting          or preferencesBackground color: whiteText color: default color   or preferencesFIGURE 18.8
(a) Graphnotation; (b)simpleexamplepre75977_ch18.qxd  11/27/08  6:12 PM  Page 496window must be generated in less than 1.0 second. An undirected link establishes asymmetric relationship between the newFile menu selection and documentText, and parallel links indicate relationships between documentWindowand documentText.In reality, a far more detailed graph would have to be generatedas a precursor to test-case design. You can then derive test cases by traversing thegraph and covering each of the relationships shown. These test cases are designedin an attempt to find errors in any of the relationships. Beizer [Bei95] describes anumber of behavioral testing methods that can make use of graphs:Transaction flow modeling.The nodes represent steps in some transac-tion (e.g., the steps required to make an airline reservation using an onlineservice), and the links represent the logical connection between steps (e.g.,flightInformationInputis followed by validationAvailabilityProcessing).The data flow diagram (Chapter 7) can be used to assist in creating graphs ofthis type.Finite state modeling.The nodes represent different user-observable statesof the software (e.g., each of the “screens” that appear as an order entry clerktakes a phone order), and the links represent the transitions that occur to movefrom state to state (e.g.,orderInformationis verified duringinventoryAvail- abilityLook-upand is followed bycustomerBillingInformationinput). The state diagram (Chapter 7) can be used to assist in creating graphs of this type.Data flow modeling.The nodes are data objects, and the links are thetransformations that occur to translate one data object into another. Forexample, the node FICA tax withheld (FTW) is computed from gross wages(GW) using the relationship, FTW /H115490.62/H11547GW.Timing modeling.The nodes are program objects, and the links are thesequential connections between those objects. Link weights are used tospecify the required execution times as the program executes.A detailed discussion of each of these graph-based testing methods is beyondthe scope of this book. If you have further interest, see [Bei95] for a comprehensivecoverage.
18.6.2 Equivalence Partitioning
Equivalence partitioningis a black-box testing method that divides the input domainof a program into classes of data from which test cases can be derived. An ideal testcase single-handedly uncovers a class of errors (e.g., incorrect processing of allcharacter data) that might otherwise require many test cases to be executed beforethe general error is observed.Test-case design for equivalence partitioning is based on an evaluation ofequivalence classesfor an input condition. Using concepts introduced in the preced-ing section, if a set of objects can be linked by relationships that are symmetric,CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 497
Input classes areknown relatively earlyin the softwareprocess. For thisreason, begin thinkingabout equivalencepartitioning as thedesign is created.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 497transitive, and reflexive, an equivalence class is present [Bei95]. An equivalenceclass represents a set of valid or invalid states for input conditions. Typically, an inputcondition is either a specific numeric value, a range of values, a set of related values,or a Boolean condition. Equivalence classes may be defined according to thefollowing guidelines:1.If an input condition specifies a range, one valid and two invalid equivalenceclasses are defined.2.If an input condition requires a specific value, one valid and two invalidequivalence classes are defined.3.If an input condition specifies a member of a set, one valid and one invalidequivalence class are defined.4.If an input condition is Boolean, one valid and one invalid class are defined.By applying the guidelines for the derivation of equivalence classes, test cases foreach input domain data item can be developed and executed. Test cases are selectedso that the largest number of attributes of an equivalence class are exercised at once.
18.6.3 Boundary Value Analysis
A greater number of errors occurs at the boundaries of the input domain rather thanin the “center.” It is for this reason that boundary value analysis (BVA) has been de- veloped as a testing technique. Boundary value analysis leads to a selection of testcases that exercise bounding values.Boundary value analysis is a test-case design technique that complements equiv-alence partitioning. Rather than selecting any element of an equivalence class, BVAleads to the selection of test cases at the “edges” of the class. Rather than focusingsolely on input conditions, BVA derives test cases from the output domain as well[Mye79].Guidelines for BVA are similar in many respects to those provided for equivalencepartitioning:1.If an input condition specifies a range bounded by values aandb,test cases should be designed with valuesaandband just above and just belowaandb. 2.If an input condition specifies a number of values, test cases should be devel-oped that exercise the minimum and maximum numbers. Values just aboveand below minimum and maximum are also tested.3.Apply guidelines 1 and 2 to output conditions. For example, assume that a tem-perature versus pressure table is required as output from an engineering analy-sis program. Test cases should be designed to create an output report thatproduces the maximum (and minimum) allowable number of table entries.4.If internal program data structures have prescribed boundaries (e.g., a tablehas a defined limit of 100 entries), be certain to design a test case to exercisethe data structure at its boundary.498 PART THREEQUALITY MANAGEMENT
How do Idefineequivalenceclasses fortesting??
uote:
“An effective wayto test code is toexercise it at itsnaturalboundaries.”Brian Kernighan
BVA extendsequivalencepartitioning by focusingon data at the “edges”of an equivalenceclass.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 498Most software engineers intuitively perform BVA to some degree. By applyingthese guidelines, boundary testing will be more complete, thereby having a higherlikelihood for error detection.
18.6.4 Orthogonal Array Testing
There are many applications in which the input domain is relatively limited. That is,the number of input parameters is small and the values that each of the parametersmay take are clearly bounded. When these numbers are very small (e.g., three inputparameters taking on three discrete values each), it is possible to consider everyinput permutation and exhaustively test the input domain. However, as the numberof input values grows and the number of discrete values for each data item increases,exhaustive testing becomes impractical or impossible.Orthogonal array testingcan be applied to problems in which the input domain isrelatively small but too large to accommodate exhaustive testing. The orthogonalarray testing method is particularly useful in finding region faults—an error categoryassociated with faulty logic within a software component.To illustrate the difference between orthogonal array testing and more conven-tional “one input item at a time” approaches, consider a system that has three inputitems, X, Y,andZ.Each of these input items has three discrete values associated withit. There are 3
3/H1100527 possible test cases. Phadke [Pha97] suggests a geometric viewof the possible test cases associated with X, Y, and Z illustrated in Figure 18.9.Referring to the figure, one input item at a time may be varied in sequence along eachinput axis. This results in relatively limited coverage of the input domain (repre-sented by the left-hand cube in the figure).When orthogonal array testing occurs, an L9 orthogonal array of test cases is created. The L9 orthogonal array has a “balancing property” [Pha97]. That is, testcases (represented by dark dots in the figure) are “dispersed uniformly throughoutthe test domain,” as illustrated in the right-hand cube in Figure 18.9. Test coverageacross the input domain is more complete.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 499
Y YX
XZZ
One input item at a timeL9 orthogonal arrayFIGURE 18.9
A geometricview of testcasesSource: [Pha97]Orthogonal arraytesting enables you todesign test cases thatprovide maximum testcoverage with areasonable number oftest cases.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 499To illustrate the use of the L9 orthogonal array, consider the send function for a fax application. Four parameters, P1, P2, P3, and P4, are passed to the sendfunction. Each takes on three discrete values. For example, P1 takes on values:P1/H110051, send it nowP1/H110052, send it one hour laterP1/H110053, send it after midnightP2, P3, and P4 would also take on values of 1, 2, and 3, signifying other sendfunctions.If a “one input item at a time” testing strategy were chosen, the followingsequence of tests (P1, P2, P3, P4) would be specified: (1, 1, 1, 1), (2, 1, 1, 1), (3, 1, 1, 1),(1, 2, 1, 1), (1, 3, 1, 1), (1, 1, 2, 1), (1, 1, 3, 1), (1, 1, 1, 2), and (1, 1, 1, 3). Phadke [Pha97]assesses these test cases by stating:
Such test cases are useful only when one is certain that these test parameters do notinteract. They can detect logic faults where a single parameter value makes the softwaremalfunction. These faults are called single mode faults. This method cannot detect logic faults that cause malfunction when two or more parameters simultaneously take certainvalues; that is, it cannot detect any interactions. Thus its ability to detect faults is limited.
Given the relatively small number of input parameters and discrete values,exhaustive testing is possible. The number of tests required is 3
4/H1100581, large but man- ageable. All faults associated with data item permutation would be found, but theeffort required is relatively high.The orthogonal array testing approach enables you to provide good test coveragewith far fewer test cases than the exhaustive strategy. An L9 orthogonal array for thefax sendfunction is illustrated in Figure 18.10.500 PART THREEQUALITY MANAGEMENT
TestcaseTest parameters
P1 P2 P3 P4123312231123231312123123123111222333123456789FIGURE 18.10
An L9 orthog-onal arraypre75977_ch18.qxd  11/27/08  6:12 PM  Page 500Phadke [Pha97] assesses the result of tests using the L9 orthogonal array in thefollowing manner:
Detect and isolate all single mode faults. A single mode fault is a consistent prob- lem with any level of any single parameter. For example, if all test cases of factor P1 /H110051 cause an error condition, it is a single mode failure. In this example tests 1, 2 and 3[Figure 18.10] will show errors. By analyzing the information about which tests showerrors, one can identify which parameter values cause the fault. In this example, by not-ing that tests 1, 2, and 3 cause an error, one can isolate [logical processing associatedwith “send it now” (P1/H110051)] as the source of the error. Such an isolation of fault isimportant to fix the fault.Detect all double mode faults. If there exists a consistent problem when specific levels of two parameters occur together, it is called a double mode fault. Indeed, a double mode fault is an indication of pairwise incompatibility or harmful interactions betweentwo test parameters.Multimode faults.Orthogonal arrays [of the type shown] can assure the detection ofonly single and double mode faults. However, many multimode faults are also detectedby these tests.
You can find a detailed discussion of orthogonal array testing in [Pha89].CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 501
Test-Case Design
Objective:To assist the software team indeveloping a complete set of test cases for bothblack-box and white-box testing.Mechanics:These tools fall into two broad categories:static testing tools and dynamic testing tools. Threedifferent types of static testing tools are used in theindustry: code-based testing tools, specialized testinglanguages, and requirements-based testing tools. Code-based testing tools accept source code as input andperform a number of analyses that result in the generationof test cases. Specialized testing languages (e.g., ATLAS)enable a software engineer to write detailed testspecifications that describe each test case and the logisticsfor its execution. Requirements-based testing tools isolatespecific user requirements and suggest test cases (orclasses of tests) that will exercise the requirements.Dynamic testing tools interact with an executing program,checking path coverage, testing assertions about the valueof specific variables, and otherwise instrumenting theexecution flow of the program.Representative Tools:6
McCabeTest,developed by McCabe & Associates(www.mccabe.com), implements a variety of pathtesting techniques derived from an assessment ofcyclomatic complexity and other software metrics.TestWorks,developed by Software Research, Inc.(www.soft.com/Products), is a complete set ofautomated testing tools that assists in the design of testscases for software developed in C/C++ and Java andprovides support for regression testing.T-VEC Test Generation System,developed by T-VECTechnologies (www.t-vec.com), is a tool set thatsupports unit, integration, and validation testing byassisting in the design of test cases using informationcontained in an OO requirements specification.e-TEST Suite,developed by Empirix, Inc. (www.empirix.com), encompasses a complete set of tools for testingWebApps, including tools that assist test-case designand test planning.SOFTWARE TOOLS
6 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 50118.7 M ODEL -BASED TESTING
Model-based testing(MBT) is a black-box testing technique that uses informationcontained in the requirements model as the basis for the generation of test cases. Inmany cases, the model-based testing technique uses UML state diagrams, an ele-ment of the behavioral model (Chapter 7), as the basis for the design of test cases.
7
The MBT technique requires five steps:1.Analyze an existing behavioral model for the software or create one.Recall that a behavioral modelindicates how software will respond to exter-nal events or stimuli. To create the model, you should perform the stepsdiscussed in Chapter 7: (1) evaluate all use cases to fully understand thesequence of interaction within the system, (2) identify events that drive theinteraction sequence and understand how these events relate to specificobjects, (3) create a sequence for each use case, (4) build a UML statediagram for the system (e.g., see Figure 7.6), and (5) review the behavioralmodel to verify accuracy and consistency.2.Traverse the behavioral model and specify the inputs that will forcethe software to make the transition from state to state. The inputs will trigger events that will cause the transition to occur.3.Review the behavioral model and note the expected outputs as thesoftware makes the transition from state to state. Recall that each state transition is triggered by an event and that as a consequence of thetransition, some function is invoked and outputs are created. For each set ofinputs (test cases) you specified in step 2, specify the expected outputs asthey are characterized in the behavioral model. “A fundamental assumptionof this testing is that there is some mechanism, a test oracle, that will deter- mine whether or not the results of a test execution are correct” [DAC03]. Inessence, a test oracle establishes the basis for any determination of the cor-rectness of the output. In most cases, the oracle is the requirements model,but it could also be another document or application, data recorded else-where, or even a human expert.4.Execute the test cases.Tests can be executed manually or a test script canbe created and executed using a testing tool.5.Compare actual and expected results and take corrective action asrequired.MBT helps to uncover errors in software behavior, and as a consequence, it isextremely useful when testing event-driven applications.502 PART THREEQUALITY MANAGEMENT
uote:
“It’s hard enoughto find an error inyour code whenyou’re looking forit; it’s even harderwhen you’veassumed your codeis error-free.”Steve McConnell
7 Model-based testing can also be used when software requirements are represented with decisiontables, grammars, or Markov chains [DAC03].pre75977_ch18.qxd  11/27/08  6:12 PM  Page 50218.8 T ESTING FOR SPECIALIZED ENVIRONMENTS ,
ARCHITECTURES , AND APPLICATIONS
Unique guidelines and approaches to testing are sometimes warranted when spe-cialized environments, architectures, and applications are considered. Although thetesting techniques discussed earlier in this chapter and in Chapters 19 and 20 canoften be adapted to specialized situations, it’s worth considering their unique needsindividually.
18.8.1 Testing GUIs
Graphical user interfaces (GUIs) will present you with interesting testing challenges.Because reusable components are now a common part of GUI development envi-ronments, the creation of the user interface has become less time consuming andmore precise (Chapter 11). But, at the same time, the complexity of GUIs has grown,leading to more difficulty in the design and execution of test cases.Because many modern GUIs have the same look and feel, a series of standardtests can be derived. Finite-state modeling graphs may be used to derive a series oftests that address specific data and program objects that are relevant to the GUI. Thismodel-based testing technique was discussed in Section 18.7.Because of the large number of permutations associated with GUI operations, GUItesting should be approached using automated tools. A wide array of GUI testingtools has appeared on the market over the past few years.
8
18.8.2 Testing of Client-Server Architectures
The distributed nature of client-server environments, the performance issues asso-ciated with transaction processing, the potential presence of a number of differenthardware platforms, the complexities of network communication, the need to serv-ice multiple clients from a centralized (or in some cases, distributed) database, andthe coordination requirements imposed on the server all combine to make testing ofclient-server architectures and the software that resides within them considerablymore difficult than stand-alone applications. In fact, recent industry studies indicatea significant increase in testing time and cost when client-server environments aredeveloped.In general, the testing of client-server software occurs at three different levels:(1) Individual client applications are tested in a “disconnected” mode; the operationof the server and the underlying network are not considered. (2) The client softwareand associated server applications are tested in concert, but network operations arenot explicitly exercised. (3) The complete client-server architecture, including net-work operation and performance, is tested.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 503
8 Hundreds, if not thousands, of GUI testing tool resources can be evaluated on the Web. A goodstarting point for open-source tools is www.opensourcetesting.org/functional.php .uote:
“The topic oftesting is onearea in which agood deal ofcommonality existsbetween traditionalsystem and client/server systems.”Kelley Bourne
WebRef
Useful client-severtesting information andresources can be foundat www.csst-technologies.com.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 503Although many different types of tests are conducted at each of these levels ofdetail, the following testing approaches are commonly encountered for client-serverapplications:
•Application function tests.The functionality of client applications is testedusing the methods discussed earlier in this chapter and in Chapters 19 and20. In essence, the application is tested in stand-alone fashion in an attemptto uncover errors in its operation.
•Server tests.The coordination and data management functions of the serverare tested. Server performance (overall response time and data throughput)is also considered.
•Database tests.The accuracy and integrity of data stored by the server istested. Transactions posted by client applications are examined to ensurethat data are properly stored, updated, and retrieved. Archiving is also tested.
•Transaction tests.A series of tests are created to ensure that each classof transactions is processed according to requirements. Tests focus on thecorrectness of processing and also on performance issues (e.g., transactionprocessing times and transaction volume).
•Network communication tests.These tests verify that communicationamong the nodes of the network occurs correctly and that message passing,transactions, and related network traffic occur without error. Networksecurity tests may also be conducted as part of these tests.To accomplish these testing approaches, Musa [Mus93] recommends the devel-opment of operational profilesderived from client-server usage scenarios.
9An oper- ational profile indicates how different types of users interoperate with theclient-server system. That is, the profiles provide a “pattern of usage” that can beapplied when tests are designed and executed. For example, for a particular type ofuser, what percentage of transactions will be inquiries? updates? orders?To develop the operational profile, it is necessary to derive a set of scenarios thatare similar to use cases (Chapters 5 and 6). Each scenario addresses who, where,what, and why. That is, who the user is, where (in the physical client-server architec-ture) the system interaction occurs, what the transaction is, and why it has occurred.Scenarios can be derived using requirements elicitation techniques (Chapter 5) orthrough less formal discussions with end users. The result, however, should be thesame. Each scenario should provide an indication of the system functions that will berequired to service a particular user, the order in which those functions are required,the timing and response that is expected, and the frequency with which each func-tion is used. These data are then combined (for all users) to create the operationalprofile. In general, testing effort and the number of test cases to be executed are504 PART THREEQUALITY MANAGEMENT
What typesof tests areconducted forclient-serversystems??
9 It should be noted that operational profiles can be used in testing for all types of system architec-tures, not just client-server architecture.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 504allocated to each usage scenario based on frequency of usage and criticality of thefunctions performed.
18.8.3 Testing Documentation and Help Facilities
The term software testingconjures images of large numbers of test cases prepared toexercise computer programs and the data that they manipulate. Recalling the defi-nition of software presented in Chapter 1, it is important to note that testing mustalso extend to the third element of the software configuration—documentation.Errors in documentation can be as devastating to the acceptance of the programas errors in data or source code. Nothing is more frustrating than following a userguide or an online help facility exactly and getting results or behaviors that do notcoincide with those predicted by the documentation. It is for this reason that thatdocumentation testing should be a meaningful part of every software test plan.Documentation testing can be approached in two phases. The first phase, techni-cal review (Chapter 15), examines the document for editorial clarity. The secondphase, live test, uses the documentation in conjunction with the actual program.Surprisingly, a live test for documentation can be approached using techniquesthat are analogous to many of the black-box testing methods discussed earlier.Graph-based testing can be used to describe the use of the program; equivalencepartitioning and boundary value analysis can be used to define various classes ofinput and associated interactions. MBT can be used to ensure that documentedbehavior and actual behavior coincide. Program usage is then tracked through thedocumentation.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 505
Documentation Testing
The following questions should be answeredduring documentation and/or help facilitytesting:
•Does the documentation accurately describe how toaccomplish each mode of use?
•Is the description of each interaction sequenceaccurate?
•Are examples accurate?
•Are terminology, menu descriptions, and systemresponses consistent with the actual program?
•Is it relatively easy to locate guidance within thedocumentation?
•Can troubleshooting be accomplished easily with thedocumentation?
•Are the document’s table of contents and index robust,accurate, and complete?•Is the design of the document (layout, typefaces,indentation, graphics) conducive to understanding andquick assimilation of information?
•Are all software error messages displayed for the userdescribed in more detail in the document? Are actionsto be taken as a consequence of an error messageclearly delineated?
•If hypertext links are used, are they accurate andcomplete?
•If hypertext is used, is the navigation designappropriate for the information required?The only viable way to answer these questions is tohave an independent third party (e.g., selected users) testthe documentation in the context of program usage. Alldiscrepancies are noted and areas of document ambiguityor weakness are defined for potential rewrite.INFOpre75977_ch18.qxd  11/27/08  6:12 PM  Page 50518.8.4 Testing for Real-Time Systems
The time-dependent, asynchronous nature of many real-time applications adds anew and potentially difficult element to the testing mix—time. Not only does the test-case designer have to consider conventional test cases but also event handling (i.e.,interrupt processing), the timing of the data, and the parallelism of the tasks(processes) that handle the data. In many situations, test data provided when a real-time system is in one state will result in proper processing, while the same data pro-vided when the system is in a different state may lead to error.For example, the real-time software that controls a new photocopier acceptsoperator interrupts (i.e., the machine operator hits control keys such as RESET orDARKEN) with no error when the machine is making copies (in the “copying” state).These same operator interrupts, if input when the machine is in the “jammed” state,cause a display of the diagnostic code indicating the location of the jam to be lost(an error).In addition, the intimate relationship that exists between real-time software andits hardware environment can also cause testing problems. Software tests mustconsider the impact of hardware faults on software processing. Such faults can beextremely difficult to simulate realistically.Comprehensive test-case design methods for real-time systems continue toevolve. However, an overall four-step strategy can be proposed:
•Task testing.The first step in the testing of real-time software is to testeach task independently. That is, conventional tests are designed for eachtask and executed independently during these tests. Task testing uncoverserrors in logic and function but not timing or behavior.
•Behavioral testing.Using system models created with automated tools, itis possible to simulate the behavior of a real-time system and examine itsbehavior as a consequence of external events. These analysis activities canserve as the basis for the design of test cases that are conducted when thereal-time software has been built. Using a technique that is similar to equiva-lence partitioning (Section 18.6.2), events (e.g., interrupts, control signals)are categorized for testing. For example, events for the photocopier mightbe user interrupts (e.g., reset counter), mechanical interrupts (e.g., paperjammed), system interrupts (e.g., toner low), and failure modes (e.g., rolleroverheated). Each of these events is tested individually, and the behavior ofthe executable system is examined to detect errors that occur as a conse-quence of processing associated with these events. The behavior of thesystem model (developed during the analysis activity) and the executablesoftware can be compared for conformance. Once each class of events hasbeen tested, events are presented to the system in random order and withrandom frequency. The behavior of the software is examined to detectbehavior errors.506 PART THREEQUALITY MANAGEMENT
What is aneffectivestrategy fortesting a real-timesystem??pre75977_ch18.qxd  11/27/08  6:12 PM  Page 506•Intertask testing.Once errors in individual tasks and in system behaviorhave been isolated, testing shifts to time-related errors. Asynchronous tasksthat are known to communicate with one another are tested with differentdata rates and processing load to determine if intertask synchronization errorswill occur. In addition, tasks that communicate via a message queue or datastore are tested to uncover errors in the sizing of these data storage areas.
•System testing.Software and hardware are integrated, and a full range ofsystem tests are conducted in an attempt to uncover errors at the software-hardware interface. Most real-time systems process interrupts. Therefore,testing the handling of these Boolean events is essential. Using the statediagram (Chapter 7), the tester develops a list of all possible interrupts andthe processing that occurs as a consequence of the interrupts. Tests are thendesigned to assess the following system characteristics:
•Are interrupt priorities properly assigned and properly handled?
•Is processing for each interrupt handled correctly?
•Does the performance (e.g., processing time) of each interrupt-handlingprocedure conform to requirements?
•Does a high volume of interrupts arriving at critical times create problemsin function or performance?In addition, global data areas that are used to transfer information as part ofinterrupt processing should be tested to assess the potential for the generation ofside effects.
18.9 P ATTERNS FOR SOFTWARE TESTING
The use of patterns as a mechanism for describing solutions to specific design problemswas discussed in Chapter 12. But patterns can also be used to propose solutions to othersoftware engineering situations—in this case, software testing. Testing patternsdescribe common testing problems and solutions that can assist you in dealing with them.Not only do testing patterns provide you with useful guidance as testing activitiescommence, they also provide three additional benefits described by Marick [Mar02]:
1. They [patterns] provide a vocabulary for problem-solvers. “Hey, you know, we shoulduse a Null Object.”2. They focus attention on the forces behind a problem. That allows [test case] designersto better understand when and why a solution applies.3. They encourage iterative thinking. Each solution creates a new context in which newproblems can be solved.
Although these benefits are “soft,” they should not be overlooked. Much ofsoftware testing, even during the past decade, has been an ad hoc activity. If testingpatterns can help a software team to communicate about testing more effectively;CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 507
WebRef
A software testingpatterns catalog can befound atwww.rbsc.com/pages/TestPatternList.htm.
Testing patterns canhelp a software teamcommunicate moreeffectively abouttesting and betterunderstand the forcesthat lead to a specifictesting approach.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 507to understand the motivating forces that lead to a specific approach to testing, andto approach the design of tests as an evolutionary activity in which each iterationresults in a more complete suite of test cases, then patterns have accomplished much.Testing patterns are described in much the same way as design patterns(Chapter 12). Dozens of testing patterns have been proposed in the literature (e.g.,[Mar02]). The following three testing patterns (presented in abstract form only)provide representative examples:
Pattern name:PairTestingAbstract:A process-oriented pattern, PairTesting describes a technique that is anal- ogous to pair programming (Chapter 3) in which two testers work together to design andexecute a series of tests that can be applied to unit, integration or validation testingactivities.Pattern name:SeparateTestInterfaceAbstract:There is a need to test every class in an object-oriented system, including“internal classes” (i.e., classes that do not expose any interface outside of the componentthat used them). The SeparateTestInterface pattern describes how to create “a test interface that can be used to describe specific tests on classes that are visible only inter-nally to a component” [Lan01].Pattern name:ScenarioTestingAbstract:Once unit and integration tests have been conducted, there is a need todetermine whether the software will perform in a manner that satisfies users. TheScenarioTestingpattern describes a technique for exercising the software from theuser’s point of view. A failure at this level indicates that the software has failed to meet auser visible requirement [Kan01].
A comprehensive discussion of testing patterns is beyond the scope of this book.If you have further interest, see [Bin99] and [Mar02] for additional information onthis important topic.
18.10 S UMMARY
The primary objective for test-case design is to derive a set of tests that have thehighest likelihood for uncovering errors in software. To accomplish this objective,two different categories of test-case design techniques are used: white-box testingand black-box testing.White-box tests focus on the program control structure. Test cases are derived toensure that all statements in the program have been executed at least once duringtesting and that all logical conditions have been exercised. Basis path testing, awhite-box technique, makes use of program graphs (or graph matrices) to derivethe set of linearly independent tests that will ensure statement coverage. Conditionand data flow testing further exercise program logic, and loop testing complementsother white-box techniques by providing a procedure for exercising loops of varyingdegrees of complexity.508 PART THREEQUALITY MANAGEMENT
WebRef
Patterns that describetesting organization,efficiency, strategy, andproblem resolution canbe found at: www.testing.com/test-patterns/patterns/.pre75977_ch18.qxd  11/27/08  6:12 PM  Page 508Hetzel [Het84] describes white-box testing as “testing in the small.” His implica-tion is that the white-box tests that have been considered in this chapter are typicallyapplied to small program components (e.g., modules or small groups of modules).Black-box testing, on the other hand, broadens your focus and might be called“testing in the large.”Black-box tests are designed to validate functional requirements without regardto the internal workings of a program. Black-box testing techniques focus on theinformation domain of the software, deriving test cases by partitioning the input andoutput domain of a program in a manner that provides thorough test coverage.Equivalence partitioning divides the input domain into classes of data that are likelyto exercise a specific software function. Boundary value analysis probes the pro-gram’s ability to handle data at the limits of acceptability. Orthogonal array testingprovides an efficient, systematic method for testing systems with small numbers ofinput parameters. Model-based testing uses elements of the requirements model totest the behavior of an application.Specialized testing methods encompass a broad array of software capabilities andapplication areas. Testing for graphical user interfaces, client-server architectures,documentation and help facilities, and real-time systems each require specializedguidelines and techniques.Experienced software developers often say, “Testing never ends, it just gets trans-ferred from you [the software engineer] to your customer. Every time your customeruses the program, a test is being conducted.” By applying test-case design, you canachieve more complete testing and thereby uncover and correct the highest numberof errors before the “customer’s tests” begin.
PROBLEMS AND POINTS TO PONDER
18.1.Myers [Mye79] uses the following program as a self-assessment for your ability to spec-ify adequate testing: A program reads three integer values. The three values are interpreted asrepresenting the lengths of the sides of a triangle. The program prints a message that stateswhether the triangle is scalene, isosceles, or equilateral. Develop a set of test cases that you feelwill adequately test this program.18.2.Design and implement the program (with error handling where appropriate) specified inProblem 18.1. Derive a flow graph for the program and apply basis path testing to develop testcases that will guarantee that all statements in the program have been tested. Execute the casesand show your results.18.3.Can you think of any additional testing objectives that are not discussed in Section 18.1.1?18.4.Select a software component that you have designed and implemented recently. Design aset of test cases that will ensure that all statements have been executed using basis path testing.18.5.Specify, design, and implement a software tool that will compute the cyclomatic com-plexity for the programming language of your choice. Use the graph matrix as the operative datastructure in your design.18.6.Read Beizer [Bei95] or a related Web-based source (e.g., www.laynetworks.com/Discrete%20Mathematics_1g.htm ) and determine how the program you have developed in Problem 18.5 can be extended to accommodate various link weights. Extend your tool toprocess execution probabilities or link processing times.CHAPTER 18TESTING CONVENTIONAL APPLICATIONS 509pre75977_ch18.qxd  11/27/08  6:12 PM  Page 50918.7.Design an automated tool that will recognize loops and categorize them as indicated inSection 18.5.3.18.8.Extend the tool described in Problem 18.7 to generate test cases for each loop category,once encountered. It will be necessary to perform this function interactively with the tester.18.9.Give at least three examples in which black-box testing might give the impression that“everything’s OK,” while white-box tests might uncover an error. Give at least three examplesin which white-box testing might give the impression that “everything’s OK,” while black-boxtests might uncover an error.18.10.Will exhaustive testing (even if it is possible for very small programs) guarantee that theprogram is 100 percent correct?18.11.Test a user manual (or help facility) for an application that you use frequently. Find atleast one error in the documentation.
FURTHER READINGS AND INFORMATION SOURCES
Virtually all books dedicated to software testing consider both strategy and tactics. Therefore,further readings noted for Chapter 17 are equally applicable for this chapter. Everett andRaymond (Software Testing,Wiley-IEEE Computer Society Press, 2007), Black (Pragmatic Soft-ware Testing,Wiley, 2007), Spiller and his colleagues ( Software Testing Process: Test Management, Rocky Nook, 2007), Perry (Effective Methods for Software Testing, 3d ed., Wiley, 2005), Lewis (Software Testing and Continuous Quality Improvement, 2d ed., Auerbach, 2004), Loveland and his colleagues (Software Testing Techniques, Charles River Media, 2004), Burnstein (Practical Soft- ware Testing,Springer, 2003), Dustin (Effective Software Testing, Addison-Wesley, 2002), Craig and Kaskiel (Systematic Software Testing, Artech House, 2002), Tamres (Introducing Software Testing,Addison-Wesley, 2002), and Whittaker ( How to Break Software,Addison-Wesley, 2002) are only a small sampling of many books that discuss testing principles, concepts, strategies,and methods.A second edition of Myers [Mye79] classic text has been produced by Myers and his col-leagues (The Art of Software Testing, 2d ed., Wiley, 2004) and covers test-case design techniques in considerable detail. Pezze and Young (Software Testing and Analysis, Wiley, 2007), Perry (Effective Methods for Software Testing, 3d ed., Wiley, 2006), Copeland (A Practitioner’s Guide to Software Test Design,Artech, 2003), Hutcheson (Software Testing Fundamentals, Wiley, 2003), Jorgensen (Software Testing: A Craftsman’s Approach, 2d ed., CRC Press, 2002) each provide use- ful presentations of test-case design methods and techniques. Beizer’s [Bei90] classic text pro-vides comprehensive coverage of white-box techniques, introducing a level of mathematicalrigor that has often been missing in other treatments of testing. His later book [Bei95] presentsa concise treatment of important methods.Software testing is a resource-intensive activity. It is for this reason that many organizationsautomate parts of the testing process. Books by Li and Wu (Effective Software Test Automation,Sybex, 2004); Mosely and Posey (Just Enough Software Test Automation, Prentice-Hall, 2002); Dustin, Rashka, and Poston (Automated Software Testing: Introduction, Management, and Perfor-mance,Addison-Wesley, 1999); Graham and her colleagues (Software Test Automation, Addison-Wesley, 1999); and Poston (Automating Specification-Based Software Testing, IEEE Computer Society, 1996) discuss tools, strategies, and methods for automated testing. Nquyen and his col-leagues (Global Software Test Automation, Happy About Press, 2006) present an executive overview of testing automation.Thomas and his colleagues (Java Testing Patterns, Wiley, 2004) and Binder [Bin99] describe testing patterns that cover testing of methods, classes/clusters, subsystems, reusable compo-nents, frameworks, and systems as well as test automation and specialized database testing.A wide variety of information sources on test-case design methods is available on the Inter-net. An up-to-date list of World Wide Web references that are relevant to testing techniques canbe found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.510 PART THREEQUALITY MANAGEMENTpre75977_ch18.qxd  11/27/08  6:12 PM  Page 510In Chapter 18, I noted that the objective of testing, stated simply, is to find thegreatest possible number of errors with a manageable amount of effortapplied over a realistic time span. Although this fundamental objectiveremains unchanged for object-oriented software, the nature of OO programschanges both testing strategy and testing tactics.It could be argued that as reusable class libraries grow in size, greater reusewill mitigate the need for heavy testing of OO systems. Exactly the opposite istrue. Binder [Bin94b] discusses this when he states:
[E]ach reuse is a new context of usage and retesting is prudent. It seems likely that more,not less testing will be needed to obtain high reliability in object-oriented systems.
511CHAPTER
19TESTING OBJECT-ORIENTED
APPLICATIONS
What is it? The architecture ofobject-oriented (OO) software resultsin a series of layered subsystems thatencapsulate collaborating classes.Each of these system elements (subsystems andclasses) performs functions that help to achievesystem requirements. It is necessary to test anOO system at a variety of different levels in aneffort to uncover errors that may occur as classescollaborate with one another and subsystemscommunicate across architectural layers.
Who does it? Object-oriented testing is performedby software engineers and testing specialists.
Why is it important? You have to execute theprogram before it gets to the customer with thespecific intent of removing all errors, so thatthe customer will not experience the frustrationassociated with a poor-quality product. In orderto find the highest possible number of errors,tests must be conducted systematically and testcases must be designed using disciplinedtechniques.
What are the steps? OO testing is strategicallyanalogous to the testing of conventional systems,but it is tactically different. Because the OOQUICK
LOOKanalysis and design models are similar in struc-ture and content to the resultant OO program,“testing” is initiated with the review of thesemodels. Once code has been generated, OOtesting begins “in the small” with class testing. Aseries of tests are designed that exercise classoperations and examine whether errors existas one class collaborates with other classes. Asclasses are integrated to form a subsystem,thread-based, use-based, and cluster testingalong with fault-based approaches are appliedto fully exercise collaborating classes. Finally,use cases (developed as part of the requirementsmodel) are used to uncover errors at the soft-ware validation level.
What is the work product? A set of test cases,designed to exercise classes, their collabora-tions, and behaviors is designed and docu-mented; expected results are defined, and actualresults are recorded.
How do I ensure that I’ve done it right? Whenyou begin testing, change your point of view. Tryhard to “break” the software! Design test casesin a disciplined fashion, and review the testscases you do create for thoroughness.KEY
CONCEPTS
class testing  . . .516cluster testing . .517fault-basedtesting  . . . . . . .519multiple classtesting  . . . . . . .524partitiontesting  . . . . . . .524randomtesting  . . . . . . .522pre75977_ch19.qxd  11/27/08  6:13 PM  Page 511512 PART THREEQUALITY MANAGEMENT
To adequately test OO systems, three things must be done: (1) the definition oftesting must be broadened to include error discovery techniques applied to object-oriented analysis and design models, (2) the strategy for unit and integration testingmust change significantly, and (3) the design of test cases must account for theunique characteristics of OO software.
19.1 B ROADENING THE VIEW OF TESTING
The construction of object-oriented software begins with the creation of require-ments (analysis) and design models.
1Because of the evolutionary nature of the OOsoftware engineering paradigm, these models begin as relatively informal represen-tations of system requirements and evolve into detailed models of classes, class re-lationships, system design and allocation, and object design (incorporating a modelof object connectivity via messaging). At each stage, the models can be “tested” inan attempt to uncover errors prior to their propagation to the next iteration.It can be argued that the review of OO analysis and design models is especiallyuseful because the same semantic constructs (e.g., classes, attributes, operations,messages) appear at the analysis, design, and code levels. Therefore, a problem inthe definition of class attributes that is uncovered during analysis will circumventside effects that might occur if the problem were not discovered until design or code(or even the next iteration of analysis).For example, consider a class in which a number of attributes are defined duringthe first iteration of analysis. An extraneous attribute is appended to the class (dueto a misunderstanding of the problem domain). Two operations are then specified tomanipulate the attribute. A review is conducted and a domain expert points out theproblem. By eliminating the extraneous attribute at this stage, the following prob-lems and unnecessary effort may be avoided during analysis:1.Special subclasses may have been generated to accommodate the unneces-sary attribute or exceptions to it. Work involved in the creation of unneces-sary subclasses has been avoided.2.A misinterpretation of the class definition may lead to incorrect or extrane-ous class relationships.3.The behavior of the system or its classes may be improperly characterized toaccommodate the extraneous attribute.If the problem is not uncovered during analysis and propagated further, thefollowing problems could occur (and will have been avoided because of the earlierreview) during design:1.Improper allocation of the class to subsystem and/or tasks may occur duringsystem design.scenario-basedtesting  . . . . . . .520thread-basedtesting  . . . . . . .517use-basedtesting  . . . . . . .517
1 Analysis and design modeling techniques are presented in Part 2 of this book. Basic OO conceptsare presented in Appendix 2.Although the review ofthe OO analysis anddesign models is anintegral part of“testing” an OO appli-cation, recognize thatit is not sufficient inand of itself. You mustconduct executabletests as well.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 5122.Unnecessary design work may be expended to create the procedural designfor the operations that address the extraneous attribute.3.The messaging model will be incorrect (because messages must be designedfor the operations that are extraneous).If the problem remains undetected during design and passes into the codingactivity, considerable effort will be expended to generate code that implements anunnecessary attribute, two unnecessary operations, messages that drive interobjectcommunication, and many other related issues. In addition, testing of the class willabsorb more time than necessary. Once the problem is finally uncovered, modifica-tion of the system must be carried out with the ever-present potential for side effectsthat are caused by change.During latter stages of their development, object-oriented analysis (OOA) anddesign (OOD) models provide substantial information about the structure andbehavior of the system. For this reason, these models should be subjected to rigor-ous review prior to the generation of code.All object-oriented models should be tested (in this context, the term testingincorporates technical reviews) for correctness, completeness, and consistencywithin the context of the model’s syntax, semantics, and pragmatics [Lin94a].
19.2 T ESTING OOA AND OOD M ODELS
Analysis and design models cannot be tested in the conventional sense, becausethey cannot be executed. However, technical reviews (Chapter 15) can be used toexamine their correctness and consistency.
19.2.1 Correctness of OOA and OOD Models
The notation and syntax used to represent analysis and design models will be tied tothe specific analysis and design methods that are chosen for the project. Hence syn-tactic correctness is judged on proper use of the symbology; each model is reviewedto ensure that proper modeling conventions have been maintained.During analysis and design, you can assess semantic correctness based on themodel’s conformance to the real-world problem domain. If the model accuratelyreflects the real world (to a level of detail that is appropriate to the stage of devel-opment at which the model is reviewed), then it is semantically correct. To deter-mine whether the model does, in fact, reflect real-world requirements, it should bepresented to problem domain experts who will examine the class definitions andhierarchy for omissions and ambiguity. Class relationships (instance connections)are evaluated to determine whether they accurately reflect real-world objectconnections.
2CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 513
2 Use cases can be invaluable in tracking analysis and design models against real-world usagescenarios for the OO system.uote:
“The tools we usehave a profound(and devious!)influence on ourthinking habits,and, therefore, onour thinkingabilities.”Edsger Dijkstrapre75977_ch19.qxd  11/27/08  6:13 PM  Page 51319.2.2 Consistency of Object-Oriented Models
The consistency of object-oriented models may be judged by “considering the rela-tionships among entities in the model. An inconsistent analysis or design model hasrepresentations in one part that are not correctly reflected in other portions of themodel” [McG94].To assess consistency, you should examine each class and its connections toother classes. The class-responsibility-collaboration (CRC) model or an object-relationship diagram can be used to facilitate this activity. As you learned in Chap-ter 6, the CRC model is composed of CRC index cards. Each CRC card lists the classname, its responsibilities (operations), and its collaborators (other classes to whichit sends messages and on which it depends for the accomplishment of its responsi-bilities). The collaborations imply a series of relationships (i.e., connections)between classes of the OO system. The object relationship model provides a graphicrepresentation of the connections between classes. All of this information can beobtained from the analysis model (Chapters 6 and 7).To evaluate the class model the following steps have been recommended [McG94]:1.Revisit the CRC model and the object-relationship model. Cross-check to ensure that all collaborations implied by the requirements model are prop-erly reflected in the both.2.Inspect the description of each CRC index card to determine if a del-egated responsibility is part of the collaborator’s definition. For exam- ple, consider a class defined for a point-of-sale checkout system and calledCreditSale.This class has a CRC index card as illustrated in Figure 19.1.514 PART THREEQUALITY MANAGEMENT
FIGURE 19.1
An exampleCRC indexcard used forreviewpre75977_ch19.qxd  11/27/08  6:13 PM  Page 514For this collection of classes and collaborations, ask whether a responsi-bility (e.g., read credit card) is accomplished if delegated to the namedcollaborator (CreditCard). That is, does the class CreditCard have an operation that enables it to be read? In this case the answer is “yes.”The object-relationship is traversed to ensure that all such connectionsare valid.3.Invert the connection to ensure that each collaborator that is askedfor service is receiving requests from a reasonable source. For exam- ple, if the CreditCardclass receives a request for purchase amountfrom the CreditSaleclass, there would be a problem. CreditCard does not know the purchase amount.4.Using the inverted connections examined in step 3, determinewhether other classes might be required or whether responsibilitiesare properly grouped among the classes.5.Determine whether widely requested responsibilities might be com-bined into a single responsibility.For example, read credit cardand get authorizationoccur in every situation. They might be combined into a validatecredit requestresponsibility that incorporates getting the credit card numberand gaining authorization.You should apply steps 1 through 5 iteratively to each class and through each evolu-tion of the requirements model.Once the design model (Chapters 9 through 11) is created, you should also con-duct reviews of the system design and the object design. The system design depictsthe overall product architecture, the subsystems that compose the product, the man-ner in which subsystems are allocated to processors, the allocation of classes to sub-systems, and the design of the user interface. The object model presents the detailsof each class and the messaging activities that are necessary to implement collabo-rations between classes.The system design is reviewed by examining the object-behavior model devel-oped during object-oriented analysis and mapping required system behavior againstthe subsystems designed to accomplish this behavior. Concurrency and task alloca-tion are also reviewed within the context of system behavior. The behavioral statesof the system are evaluated to determine which exist concurrently. Use cases areused to exercise the user interface design.The object model should be tested against the object-relationship network toensure that all design objects contain the necessary attributes and operations to im-plement the collaborations defined for each CRC index card. In addition, the detailedspecification of operation details (i.e., the algorithms that implement the operations)is reviewed.CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 515pre75977_ch19.qxd  11/27/08  6:13 PM  Page 51519.3 O BJECT -ORIENTED TESTING STRATEGIES
As I noted in Chapter 18, the classical software testing strategy begins with “testingin the small” and works outward toward “testing in the large.” Stated in the jargonof software testing (Chapter 18), you begin with unit testing,then progress toward integration testing,and culminate with validation and system testing. In conventional applications, unit testing focuses on the smallest compilable program unit—the sub-program (e.g., component, module, subroutine, procedure). Once each of these unitshas been testing individually, it is integrated into a program structure while a seriesof regression tests are run to uncover errors due to interfacing the modules and sideeffects that are caused by the addition of new units. Finally, the system as a whole istested to ensure that errors in requirements are uncovered.
19.3.1 Unit Testing in the OO Context
When object-oriented software is considered, the concept of the unit changes.Encapsulation drives the definition of classes and objects. This means that each classand each instance of a class (object) packages attributes (data) and the operations(also known as methods or services) that manipulate these data. Rather than testingan individual module, the smallest testable unit is the encapsulated class. Because aclass can contain a number of different operations and a particular operation mayexist as part of a number of different classes, the meaning of unit testing changesdramatically.We can no longer test a single operation in isolation (the conventional view of unittesting) but rather, as part of a class. To illustrate, consider a class hierarchy in whichan operation X()is defined for the superclass and is inherited by a number of sub-classes. Each subclass uses operation X(), but it is applied within the context of theprivate attributes and operations that have been defined for each subclass. Becausethe context in which operation X()is used varies in subtle ways, it is necessary to testoperation X()in the context of each of the subclasses. This means that testing oper-ation X()in a vacuum (the traditional unit-testing approach) is ineffective in theobject-oriented context.Class testing for OO software is the equivalent of unit testing for conventionalsoftware.
3Unlike unit testing of conventional software, which tends to focus on thealgorithmic detail of a module and the data that flows across the module interface,class testing for OO software is driven by the operations encapsulated by the classand the state behavior of the class.
19.3.2 Integration Testing in the OO Context
Because object-oriented software does not have a hierarchical control structure,conventional top-down and bottom-up integration strategies have little meaning.516 PART THREEQUALITY MANAGEMENT
The smallest testable“unit” in OO softwareis the class. Classtesting is driven bythe operationsencapsulated by theclass and the statebehavior of the class.
3 Test-case design methods for OO classes are discussed in Sections 19.4 through 19.6.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 516In addition, integrating operations one at a time into a class (the conventionalincremental integration approach) is often impossible because of the “direct andindirect interactions of the components that make up the class” [Ber93].There are two different strategies for integration testing of OO systems [Bin94a].The first, thread-based testing,integrates the set of classes required to respond to oneinput or event for the system. Each thread is integrated and tested individually. Re-gression testing is applied to ensure that no side effects occur. The second integra-tion approach, use-based testing,begins the construction of the system by testingthose classes (called independent classes ) that use very few (if any) of server classes. After the independent classes are tested, the next layer of classes, called dependentclasses,that use the independent classes are tested. This sequence of testing layersof dependent classes continues until the entire system is constructed. Unlike con-ventional integration, the use of driver and stubs (Chapter 18) as replacement oper-ations is to be avoided, when possible.Cluster testing[McG94] is one step in the integration testing of OO software. Here,a cluster of collaborating classes (determined by examining the CRC and object-relationship model) is exercised by designing test cases that attempt to uncovererrors in the collaborations.
19.3.3 Validation Testing in an OO Context
At the validation or system level, the details of class connections disappear. Likeconventional validation, the validation of OO software focuses on user-visibleactions and user-recognizable outputs from the system. To assist in the derivation ofvalidation tests, the tester should draw upon use cases (Chapters 5 and 6) that arepart of the requirements model. The use case provides a scenario that has a high like-lihood of uncovered errors in user-interaction requirements.Conventional black-box testing methods (Chapter 18) can be used to drive vali-dation tests. In addition, you may choose to derive test cases from the object-behavior model and from an event flow diagram created as part of OOA.
19.4 O BJECT -ORIENTED TESTING METHODS
The architecture of object-oriented software results in a series of layered subsystemsthat encapsulate collaborating classes. Each of these system elements (subsystemsand classes) performs functions that help to achieve system requirements. It isnecessary to test an OO system at a variety of different levels in an effort to uncovererrors that may occur as classes collaborate with one another and subsystems com-municate across architectural layers.Test-case design methods for object-oriented software continue to evolve. How-ever, an overall approach to OO test-case design has been suggested by Berard [Ber93]:1.Each test case should be uniquely identified and explicitly associated with theclass to be tested.CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 517
Integration testing forOO software tests aset of classes that arerequired to respond toa given event.
uote:
“I see testers as thebodyguards of theproject. We defendour developer’sflank from failure,while they focus oncreating success.”James Bachpre75977_ch19.qxd  11/27/08  6:13 PM  Page 5172.The purpose of the test should be stated.3.A list of testing steps should be developed for each test and should contain:a.A list of specified states for the class that is to be testedb.A list of messages and operations that will be exercised as a consequenceof the testc.A list of exceptions that may occur as the class is testedd.A list of external conditions (i.e., changes in the environment external tothe software that must exist in order to properly conduct the test)e.Supplementary information that will aid in understanding or implementingthe testUnlike conventional test-case design, which is driven by an input-process-outputview of software or the algorithmic detail of individual modules, object-oriented test-ing focuses on designing appropriate sequences of operations to exercise the statesof a class.
19.4.1 The Test-Case Design Implications of OO Concepts
As a class evolves through the requirements and design models, it becomes a targetfor test-case design. Because attributes and operations are encapsulated, testingoperations outside of the class is generally unproductive. Although encapsulation isan essential design concept for OO, it can create a minor obstacle when testing. AsBinder [Bin94a] notes, “Testing requires reporting on the concrete and abstract stateof an object.” Yet, encapsulation can make this information somewhat difficult toobtain. Unless built-in operations are provided to report the values for class attrib-utes, a snapshot of the state of an object may be difficult to acquire.Inheritance may also present you with additional challenges during test-casedesign. I have already noted that each new usage context requires retesting, eventhough reuse has been achieved. In addition, multiple inheritance
4complicates test- ing further by increasing the number of contexts for which testing is required[Bin94a]. If subclasses instantiated from a superclass are used within the same prob-lem domain, it is likely that the set of test cases derived for the superclass can be usedwhen testing the subclass. However, if the subclass is used in an entirely differentcontext, the superclass test cases will have little applicability and a new set of testsmust be designed.
19.4.2 Applicability of Conventional Test-Case Design Methods
The white-box testing methods described in Chapter 18 can be applied to the opera-tions defined for a class. Basis path, loop testing, or data flow techniques can help toensure that every statement in an operation has been tested. However, the concise518 PART THREEQUALITY MANAGEMENT
WebRef
An excellent collectionof papers and resourceson OO testing canbe found atwww.rbsc.com.
4 An OO concept that should be used with extreme care.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 518structure of many class operations causes some to argue that the effort applied towhite-box testing might be better redirected to tests at a class level.Black-box testing methods are as appropriate for OO systems as they are for sys-tems developed using conventional software engineering methods. As I noted inChapter 18, use cases can provide useful input in the design of black-box and state-based tests.
19.4.3 Fault-Based Testing5
The object offault-based testingwithin an OO system is to design tests that have ahigh likelihood of uncovering plausible faults. Because the product or system mustconform to customer requirements, preliminary planning required to perform fault-based testing begins with the analysis model. The tester looks for plausible faults (i.e.,aspects of the implementation of the system that may result in defects). To determinewhether these faults exist, test cases are designed to exercise the design or code.Of course, the effectiveness of these techniques depends on how testers perceivea plausible fault. If real faults in an OO system are perceived to be implausible, thenthis approach is really no better than any random testing technique. However, if theanalysis and design models can provide insight into what is likely to go wrong, thenfault-based testing can find significant numbers of errors with relatively low expen-ditures of effort.Integration testing looks for plausible faults in operation calls or message connec-tions. Three types of faults are encountered in this context: unexpected result, wrongoperation/message used, and incorrect invocation. To determine plausible faults asfunctions (operations) are invoked, the behavior of the operation must be examined.Integration testing applies to attributes as well as to operations. The “behaviors”of an object are defined by the values that its attributes are assigned. Testing shouldexercise the attributes to determine whether proper values occur for distinct types ofobject behavior.It is important to note that integration testing attempts to find errors in the clientobject, not the server. Stated in conventional terms, the focus of integration testing isto determine whether errors exist in the calling code, not the called code. The operationcall is used as a clue, a way to find test requirements that exercise the calling code.
19.4.4 Test Cases and the Class Hierarchy
Inheritance does not obviate the need for thorough testing of all derived classes. Infact, it can actually complicate the testing process. Consider the following situation.A class Basecontains operations inherited()and redefined().A class Derivedrede- fines redefined()to serve in a local context. There is little doubt that Derived::redefined()CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 519
5 Sections 19.4.3 through 19.4.6 have been adapted from an article by Brian Marick posted on theInternet newsgroup comp.testing. This adaptation is included with the permission of the author.For further information on these topics, see [Mar94]. It should be noted that the techniques dis-cussed in Sections 19.4.3 through 19.4.6 are also applicable for conventional software.The strategy for fault-based testing is tohypothesize a set ofplausible faults andthen derive tests toprove each hypothesis.
What typesof faults areencountered inoperation callsand messageconnections??pre75977_ch19.qxd  11/27/08  6:13 PM  Page 519has to be tested because it represents a new design and new code. But doesDerived::inherited()have to be retested?If Derived::inherited()calls redefined()and the behavior of redefined()has changed, Derived::inherited()may mishandle the new behavior. Therefore, it needs new testseven though the design and code have not changed. It is important to note, however,that only a subset of all tests for Derived::inherited()may have to be conducted. If part of the design and code for inherited()does not depend on redefined()(i.e., that does not call it nor call any code that indirectly calls it), that code need not be retested inthe derived class.Base::redefined()and Derived::redefined()are two different operations with different specifications and implementations. Each would have a set of test requirements de-rived from the specification and implementation. Those test requirements probe forplausible faults: integration faults, condition faults, boundary faults, and so forth. Butthe operations are likely to be similar. Their sets of test requirements will overlap.The better the OO design, the greater is the overlap. New tests need to be derivedonly for those Derived::redefined()requirements that are not satisfied by theBase::redefined()tests.To summarize, the Base::redefined()tests are applied to objects of class Derived.Test inputs may be appropriate for both base and derived classes, but the expectedresults may differ in the derived class.
19.4.5 Scenario-Based Test Design
Fault-based testing misses two main types of errors: (1) incorrect specifications and(2) interactions among subsystems. When errors associated with an incorrect spec-ification occur, the product doesn’t do what the customer wants. It might do thewrong thing or omit important functionality. But in either circumstance, quality(conformance to requirements) suffers. Errors associated with subsystem interactionoccur when the behavior of one subsystem creates circumstances (e.g., events, dataflow) that cause another subsystem to fail.Scenario-based testing concentrates on what the user does, not what the productdoes. This means capturing the tasks (via use cases) that the user has to perform andthen applying them and their variants as tests.Scenarios uncover interaction errors. But to accomplish this, test cases must bemore complex and more realistic than fault-based tests. Scenario-based testingtends to exercise multiple subsystems in a single test (users do not limit themselvesto the use of one subsystem at a time).As an example, consider the design of scenario-based tests for a text editor byreviewing the use cases that follow:
Use Case: Fix the Final DraftBackground:It’s not unusual to print the “final” draft, read it, and discover someannoying errors that weren’t obvious from the on-screen image. This use case describesthe sequence of events that occurs when this happens.520 PART THREEQUALITY MANAGEMENT
Even though a baseclass has beenthoroughly tested, youwill still have to test allclasses derived from it.
Scenario-based testingwill uncover errors thatoccur when any actorinteracts with thesoftware.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 5201. Print the entire document.2. Move around in the document, changing certain pages.3. As each page is changed, it’s printed.4. Sometimes a series of pages is printed.
This scenario describes two things: a test and specific user needs. The user needsare obvious: (1) a method for printing single pages and (2) a method for printing arange of pages. As far as testing goes, there is a need to test editing after printing(as well as the reverse). Therefore, you work to design tests that will uncover errorsin the editing function that were caused by the printing function; that is, errors thatwill indicate that the two software functions are not properly independent.
Use Case: Print a New CopyBackground:Someone asks the user for a fresh copy of the document. It must beprinted.1. Open the document.2. Print it.3. Close the document.
Again, the testing approach is relatively obvious. Except that this document didn’tappear out of nowhere. It was created in an earlier task. Does that task affect thisone?In many modern editors, documents remember how they were last printed. Bydefault, they print the same way next time. After the Fix the Final Draft scenario, just selecting “Print” in the menu and clicking the Print button in the dialog box willcause the last corrected page to print again. So, according to the editor, the correctscenario should look like this:
Use Case: Print a New Copy1. Open the document.2. Select “Print” in the menu.3. Check if you’re printing a page range; if so, click to print the entire document.4. Click on the Print button.5. Close the document.
But this scenario indicates a potential specification error. The editor does notdo what the user reasonably expects it to do. Customers will often overlook thecheck noted in step 3. They will then be annoyed when they trot off to the printerand find one page when they wanted 100. Annoyed customers signal specificationbugs.You might miss this dependency as you design tests, but it is likely that the prob-lem would surface during testing. You would then have to contend with the proba-ble response, “That’s the way it’s supposed to work!”CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 521
Although scenario-based testing hasmerit, you will get ahigher return on timeinvested by reviewinguse cases when theyare developed as partof the analysis model.uote:
“If you want andexpect a programto work, you willmore likely seea workingprogram—youwill miss failures.”Cem Kaner et al.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 52119.4.6 Testing Surface Structure and Deep Structure
Surface structurerefers to the externally observable structure of an OO program. Thatis, the structure that is immediately obvious to an end user. Rather than performingfunctions, the users of many OO systems may be given objects to manipulate in someway. But whatever the interface, tests are still based on user tasks. Capturing thesetasks involves understanding, watching, and talking with representative users (andas many nonrepresentative users as are worth considering).There will surely be some difference in detail. For example, in a conventional sys-tem with a command-oriented interface, the user might use the list of all commandsas a testing checklist. If no test scenarios existed to exercise a command, testing haslikely overlooked some user tasks (or the interface has useless commands). In anobject-based interface, the tester might use the list of all objects as a testing checklist.The best tests are derived when the designer looks at the system in a new orunconventional way. For example, if the system or product has a command-basedinterface, more thorough tests will be derived if the test-case designer pretends thatoperations are independent of objects. Ask questions like, “Might the user want touse this operation—which applies only to the Scanner object—while working with the printer?” Whatever the interface style, test-case design that exercises the surfacestructure should use both objects and operations as clues leading to overlookedtasks.Deep structurerefers to the internal technical details of an OO program, that is, thestructure that is understood by examining the design and/or code. Deep structuretesting is designed to exercise dependencies, behaviors, and communication mech-anisms that have been established as part of the design model for OO software.The requirements and design models are used as the basis for deep structure test-ing. For example, the UML collaboration diagram or the deployment model depictscollaborations between objects and subsystems that may not be externally visible.The test-case design then asks: “Have we captured (as a test) some task that exer-cises the collaboration noted on the collaboration diagram? If not, why not?”
19.5 T ESTING METHODS APPLICABLE AT THE CLASS LEVEL
Testing “in the small” focuses on a single class and the methods that are encapsu-lated by the class. Random testing and partitioning are methods that can be used toexercise a class during OO testing.
19.5.1 Random Testing for OO Classes
To provide brief illustrations of these methods, consider a banking application inwhich an Accountclass has the following operations: open(), setup(), deposit(), with-draw(), balance(), summarize(), creditLimit(), and close()[Kir94]. Each of these opera- tions may be applied for Account,but certain constraints (e.g., the account must beopened before other operations can be applied and closed after all operations are522 PART THREEQUALITY MANAGEMENT
Testing surfacestructure is analogousto black-box testing.Deep structure testingis similar to white-boxtesting.
uote:
“Be not ashamedof mistakes andthus make themcrimes.”Confucius
The number of possiblepermutations forrandom testing cangrow quite large.A strategy similar toorthogonal arraytesting can be usedto improve testingefficiency.pre75977_ch19.qxd  11/27/08  6:13 PM  Page 522completed) are implied by the nature of the problem. Even with these constraints,there are many permutations of the operations. The minimum behavioral life historyof an instance of Accountincludes the following operations:
open•setup•deposit•withdraw•close
This represents the minimum test sequence for account. However, a wide varietyof other behaviors may occur within this sequence:
open•setup•deposit•[deposit|withdraw|balance|summarize|creditLimit]n•withdraw•close
A variety of different operation sequences can be generated randomly. For example:Test case r
1:open•setup•deposit•deposit•balance•summarize•withdraw•close
Test case r2:open•setup•deposit•withdraw•deposit•balance•creditLimit•withdraw•close
These and other random order tests are conducted to exercise different classinstance life histories.CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 523
Class Testing
The scene:Shakira’s cubicle.The players:Jamie and Shakira—members of theSafeHomesoftware engineering team who are workingon test-case design for the security function.The conversation:Shakira:I’ve developed some tests for the Detector class [Figure 10.4]—you know, the one that allows accessto all of the Sensorobjects for the security function. Youfamiliar with it?Jamie (laughing):Sure, it’s the one that allowed youto add the “doggie angst” sensor.Shakira:The one and only. Anyway, it has an interfacewith four ops:read(), enable(), disable(),andtest().Before a sensor can be read, it must be enabled. Once it’s enabled,it can be read and tested. It can be disabled at any time,except if an alarm condition is being processed. So I defineda simple test sequence that will exercise its behavioral lifehistory. [Shows Jamie the following sequence.]#1: enable•test•read•disableJamie:That’ll work, but you’ve got to do more testingthan that!Shakira:I know, I know, here are some other sequencesI’ve come up with. [Shows Jamie the following sequences.]#2: enable•test*[read] n•test•disable#3: [read]
n
#4: enable*disable•[test | read]Jamie:So let me see if I understand the intent of these.#1 goes through a normal life history, sort of aconventional usage. #2 repeats the read operation n times, and that’s a likely scenario. #3 tries to read thesensor before it’s been enabled. . . that should producean error message of some kind, right? #4 enables anddisables the sensor and then tries to read it. Isn’t that thesame as test #2?Shakira:Actually no. In #4, the sensor has beenenabled. What #4 really tests is whether the disable opworks as it should. A read()or test()after disable()should generate the error message. If it doesn’t, then we have anerror in the disable op.Jamie:Cool. Just remember that the four tests have to beapplied for every sensor type since all the ops may besubtly different depending on the type of sensor.Shakira:Not to worry. That’s the plan.SAFEHOMEpre75977_ch19.qxd  11/27/08  6:13 PM  Page 52319.5.2 Partition Testing at the Class Level
Partition testingreduces the number of test cases required to exercise the class inmuch the same manner as equivalence partitioning (Chapter 18) for traditional soft-ware. Input and output are categorized and test cases are designed to exercise eachcategory. But how are the partitioning categories derived?State-based partitioningcategorizes class operations based on their ability tochange the state of the class. Again considering the Account class, state operations include deposit()and withdraw(),whereas nonstate operations include balance(),summarize(),and creditLimit().Tests are designed in a way that exercises operationsthat change state and those that do not change state separately. Therefore,
Test case p1:open•setup•deposit•deposit•withdraw•withdraw•closeTest case p
2:open•setup•deposit•summarize•creditLimit•withdraw•close
Test case p1changes state, while test case p2exercises operations that do not change state (other than those in the minimum test sequence).Attribute-based partitioningcategorizes class operations based on the attributesthat they use. For the Accountclass, the attributes balanceand creditLimitcan be used to define partitions. Operations are divided into three partitions: (1) operations thatuse creditLimit,(2) operations that modify creditLimit
,and (3) operations that do not use or modify creditLimit.Test sequences are then designed for each partition.Category-based partitioningcategorizes class operations based on the generic func-tion that each performs. For example, operations in the Accountclass can be catego- rized in initialization operations (open, setup ), computational operations (deposit, withdraw), queries (balance, summarize, creditLimit ), and termination operations (close).
19.6 I NTERCLASS TEST-CASEDESIGN
Test-case design becomes more complicated as integration of the object-orientedsystem begins. It is at this stage that testing of collaborations between classes mustbegin. To illustrate “interclass test-case generation” [Kir94], we expand the bankingexample introduced in Section 19.5 to include the classes and collaborations notedin Figure 19.2. The direction of the arrows in the figure indicates the direction of mes-sages, and the labeling indicates the operations that are invoked as a consequenceof the collaborations implied by the messages.Like the testing of individual classes, class collaboration testing can be accom-plished by applying random and partitioning methods, as well as scenario-basedtesting and behavioral testing.
19.6.1 Multiple Class Testing
Kirani and Tsai [Kir94] suggest the following sequence of steps to generate multipleclass random test cases:1.For each client class, use the list of class operations to generate a series of ran-dom test sequences. The operations will send messages to other server classes.524 PART THREEQUALITY MANAGEMENT
What testingoptions areavailable at theclass level??
uote:
“The boundary thatdefines the scope ofunit and integrationtesting is differentfor object-orienteddevelopment. Testscan be designedand exercised atmany points in theprocess. Thus‘design a little, codea little’ becomes‘design a little,code a little, testa little.’”Robert Binderpre75977_ch19.qxd  11/27/08  6:13 PM  Page 5242.For each message that is generated, determine the collaborator class and thecorresponding operation in the server object.3.For each operation in the server object (that has been invoked by messagessent from the client object), determine the messages that it transmits.4.For each of the messages, determine the next level of operations that areinvoked and incorporate these into the test sequence.To illustrate [Kir94], consider a sequence of operations for the Bank class relative to an ATMclass (Figure 19.2):
verifyAcct•verifyPIN•[[verifyPolicy•withdrawReq]|depositReq|acctInfoREQ]n
A random test case for the Bankclass might be
Test case r3/H11005verifyAcct•verifyPIN•depositReq
In order to consider the collaborators involved in this test, the messages associ-ated with each of the operations noted in test case r
3are considered. Bankmust col- laborate with ValidationInfoto execute the verifyAcct()and verifyPIN().Bankmust collaborate with Accountto execute depositReq().Hence, a new test case that exer- cises these collaborations is
Test case r4/H11005verifyAcct [Bank:validAcctValidationInfo]•verifyPIN[Bank: validPinValidationInfo]•depositReq [Bank: depositaccount]
The approach for multiple class partition testing is similar to the approach usedfor partition testing of individual classes. A single class is partitioned as discussed inSection 19.5.2. However, the test sequence is expanded to include those operationsthat are invoked via messages to collaborating classes. An alternative approachpartitions tests based on the interfaces to a particular class. Referring to Figure 19.2,CHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 525
ATMATMUserInterface  cardInsertedpassworddepositwithdrawaccntStatusterminate    verifyStatusdepositStatus dispenseCash printAccntStat readCardInfo getCashAmnt BankverifyAcctverifyPINverifyPolicywithdrawReqdepositReqacctInfo 
creditLimitaccntType balance withdraw deposit closeAccount
ValidationInfo  validPINvalidAcct
CashieropenAcctinitialDeposit authorizeCard deauthorize closeAcctFIGURE 19.2
Class collabo-ration diagramfor bankingapplicationSource:Adapted from[Kir94].pre75977_ch19.qxd  11/27/08  6:13 PM  Page 525the Bankclass receives messages from the ATM and Cashierclasses. The methods within Bankcan therefore be tested by partitioning them into those that serve ATMand those that serve Cashier.State-based partitioning (Section 19.5.2) can be usedto refine the partitions further.
19.6.2 Tests Derived from Behavior Models
The use of the state diagram as a model that represents the dynamic behavior ofa class is discussed in Chapter 7. The state diagram for a class can be used to helpderive a sequence of tests that will exercise the dynamic behavior of the class (andthose classes that collaborate with it). Figure 19.3 [Kir94] illustrates a state diagramfor the Accountclass discussed earlier. Referring to the figure, initial transitionsmove through the empty acctand setup acctstates. The majority of all behavior for instances of the class occurs while in the working acct state. A final withdrawal and account closure cause the account class to make transitions to the nonworking acctand dead acctstates, respectively.The tests to be designed should achieve coverage of every state. That is, theoperation sequences should cause the Account class to make transition through all allowable states:
Test case s1:open•setupAccnt•deposit (initial)•withdraw (final)•close
It should be noted that this sequence is identical to the minimum test sequencediscussed in Section 19.5.2. Adding additional test sequences to the minimumsequence,
Test case s2:open•setupAccnt•deposit(initial)•deposit•balance• credit•withdraw (final)•closeTest case s
3:open•setupAccnt•deposit(initial)•deposit•withdraw•accntInfo•withdraw (final)•close526PART THREEQUALITY MANAGEMENT
OpenEmptyacct Set upacct
Workingacct
Nonworkingacct DeadacctSetup AccntDeposit (initial)BalancecreditaccntInfoDepositWithdrawWithdrawal (final)CloseFIGURE 19.3
State diagramfor theAccount classSource:Adapted from[Kir94].pre75977_ch19.qxd  11/27/08  6:13 PM  Page 526Still more test cases could be derived to ensure that all behaviors for the classhave been adequately exercised. In situations in which the class behavior results ina collaboration with one or more classes, multiple state diagrams are used to trackthe behavioral flow of the system.The state model can be traversed in a “breadth-first” [McG94] manner. In this con-text, breadth-first implies that a test case exercises a single transition and that whena new transition is to be tested only previously tested transitions are used.Consider a CreditCardobject that is part of the banking system. The initial stateof CreditCardis undefined(i.e., no credit card number has been provided). Uponreading the credit card during a sale, the object takes on a defined state; that is, the attributes card numberand expiration date,along with bank-specific identifiers are defined. The credit card issubmittedwhen it is sent for authorization, and it is approvedwhen authorization is received. The transition of CreditCardfrom one state to another can be tested by deriving test cases that cause the transition to oc-cur. A breadth-first approach to this type of testing would not exercise submittedbe- fore it exercisedundefinedanddefined.If it did, it would make use of transitions that had not been previously tested and would therefore violate the breadth-first criterion.
19.7 S UMMARY
The overall objective of object-oriented testing—to find the maximum number oferrors with a minimum amount of effort is identical to the objective of conventionalsoftware testing. But the strategy and tactics for OO testing differ significantly. Theview of testing broadens to include the review of both the requirements and designmodel. In addition, the focus of testing moves away from the procedural component(the module) and toward the class.Because the OO requirements and design models and the resulting source codeare semantically coupled, testing (in the form of technical reviews) begins during themodeling activity. For this reason, the review of CRC, object-relationship, and object-behavior models can be viewed as first-stage testing.Once code is available, unit testing is applied for each class. The design of testsfor a class uses a variety of methods: fault-based testing, random testing, and parti-tion testing. Each of these methods exercise the operations encapsulated by theclass. Test sequences are designed to ensure that relevant operations are exercised.The state of the class, represented by the values of its attributes, is examined todetermine if errors exist.Integration testing can be accomplished using a thread-based or use-based strat-egy. Thread-based testing integrates the set of classes that collaborate to respond toone input or event. Use-based testing constructs the system in layers, beginning withthose classes that do not make use of server classes. Integration test-case designmethods can also make use of random and partition tests. In addition, scenario-based testing and tests derived from behavioral models can be used to test a classCHAPTER 19TESTING OBJECT-ORIENTED APPLICATIONS 527pre75977_ch19.qxd  11/27/08  6:13 PM  Page 527and its collaborators. A test sequence tracks the flow of operations across classcollaborations.OO system validation testing is black-box oriented and can be accomplished byapplying the same black-box methods discussed for conventional software. How-ever, scenario-based testing dominates the validation of OO systems, making theuse case a primary driver for validation testing.
PROBLEMS AND POINTS TO PONDER
19.1.In your own words, describe why the class is the smallest reasonable unit for testingwithin an OO system.19.2.Why do we have to retest subclasses that are instantiated from an existing class, if theexisting class has already been thoroughly tested? Can we use the test-case design for theexisting class?19.3.Why should “testing” begin with object-oriented analysis and design?19.4.Derive a set of CRC index cards for SafeHome, and conduct the steps noted in Sec- tion 19.2.2 to determine if inconsistencies exist.19.5.What is the difference between thread-based and use-based strategies for integrationtesting? How does cluster testing fit in?19.6.Apply random testing and partitioning to three classes defined in the design for theSafeHomesystem. Produce test cases that indicate the operation sequences that will be invoked.19.7.Apply multiple class testing and tests derived from the behavioral model for the SafeHomedesign.19.8.Derive four additional tests using random testing and partitioning methods as well asmultiple class testing and tests derived from the behavioral model for the banking applicationpresented in Sections 19.5 and 19.6.
FURTHER READINGS AND INFORMATION SOURCES
Many books on testing noted in the Further Readings sections of Chapters 17 and 18 discuss test- ing of OO systems to some extent. Schach (Object-Oriented and Classical Software Engineering,McGraw-Hill, 6th ed., 2004) considers OO testing within the context of broader softwareengineering practice. Sykes and McGregor (Practical Guide to Testing Object-Oriented Software,Addison-Wesley, 2001), Bashir and Goel (Testing Object-Oriented Software, Springer 2000), Binder (Testing Object-Oriented Systems, Addison-Wesley, 1999), and Kung and his colleagues (Testing Object-Oriented Software,Wiley-IEEE Computer Society Press, 1998) treat OO testing insignificant detail.A wide variety of information sources on object-oriented testing methods is available on theInternet. An up-to-date list of World Wide Web references that are relevant to testing techniquescan be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.528 PART THREEQUALITY MANAGEMENTpre75977_ch19.qxd  11/27/08  6:13 PM  Page 528There is an urgency that always pervades a WebApp project. Stakeholders—concerned about competition from other WebApps, coerced by customerdemands, and worried that they’ll miss a market window—press to get theWebApp online. As a consequence, technical activities that often occur late in theprocess, such as WebApp testing, are sometimes given short shrift. This can be acatastrophic mistake. To avoid it, you and other team members must ensure thateach work product exhibits high quality. Wallace and his colleagues {Wal03] notethis when they state:
Testing shouldn’t wait until the project is finished. Start testing before you write oneline of code. Test constantly and effectively, and you will develop a much more durableWeb site.
Since requirements and design models cannot be tested in the classical sense,you and your team should conduct technical reviews (Chapter 15) as well asexecutable tests. The intent is to uncover and correct errors before the WebApp ismade available to its end users.
529CHAPTER
20TESTING WEB
APPLICATIONS
What is it? WebApp testing is acollection of related activities witha single goal: to uncover errors inWebApp content, function, usability,navigability, performance, capacity,and security.To accomplish this, a testing strategy that en-compasses both reviews and executable testingis applied.
Who does it? Web engineers and other projectstakeholders (managers, customers, end users)all participate in WebApp testing.
Why is it important? If end users encounter errorsthat shake their faith in the WebApp, they will goelsewhere for the content and function theyneed, and the WebApp will fail. For this reason,you must work to eliminate as many errors aspossible before the WebApp goes online.
What are the steps? The WebApp testing processbegins by focusing on user-visible aspects of theQUICK
LOOKWebApp and proceeds to tests that exercisetechnology and infrastructure. Seven testingsteps are performed: content testing, interfacetesting, navigation testing, component testing,configuration testing, performance testing, andsecurity testing.
What is the work product? In some instances aWebApp test plan is produced. In every in-stance, a suite of test cases is developed forevery testing step and an archive of test results ismaintained for future use.
How do I ensure that I’ve done it right?
Although you can never be sure that you’veperformed every test that is needed, you can becertain that testing has uncovered errors (andthat those errors have been corrected). In addi-tion, if you’ve established a test plan, you cancheck to ensure that all planned tests have beenconducted.KEY
CONCEPTS
compatibility tests  . . . . . . . .542component-leveltesting  . . . . . . .543configuration testing  . . . . . . .547content testing  . . . . . . .534database testing  . . . . . . .535dimensions ofquality  . . . . . . .530interface testing  . . . . . . .537load testing  . . .551pre75977_ch20.qxd  11/28/08  10:22 AM  Page 52920.1 T ESTING CONCEPTS FOR WEBAPPS
Testing is the process of exercising software with the intent of finding (and ultimatelycorrecting) errors. This fundamental philosophy, first presented in Chapter 17, doesnot change for WebApps. In fact, because Web-based systems and applicationsreside on a network and interoperate with many different operating systems,browsers (residing on a variety of devices), hardware platforms, communicationsprotocols, and “backroom” applications, the search for errors represents a significantchallenge.To understand the objectives of testing within a Web engineering context, youshould consider the many dimensions of WebApp quality.
1In the context of this dis- cussion, I consider quality dimensions that are particularly relevant in any discussionof WebApp testing. I also consider the nature of the errors that are encountered as aconsequence of testing, and the testing strategy that is applied to uncover theseerrors.
20.1.1 Dimensions of Quality
Quality is incorporated into a Web application as a consequence of good design. It isevaluated by applying a series of technical reviews that assess various elements ofthe design model and by applying a testing process that is discussed throughout thischapter. Both reviews and testing examine one or more of the following qualitydimensions [Mil00a]:
•Contentis evaluated at both a syntactic and semantic level. At the syntacticlevel, spelling, punctuation, and grammar are assessed for text-baseddocuments. At a semantic level, correctness (of information presented),consistency (across the entire content object and related objects), and lack ofambiguity are all assessed.
•Functionis tested to uncover errors that indicate lack of conformance tocustomer requirements. Each WebApp function is assessed for correctness,instability, and general conformance to appropriate implementationstandards (e.g., Java or AJAX language standards).
•Structureis assessed to ensure that it properly delivers WebApp content andfunction, that it is extensible, and that it can be supported as new content orfunctionality is added.
•Usabilityis tested to ensure that each category of user is supported by theinterface and can learn and apply all required navigation syntax and semantics.
•Navigabilityis tested to ensure that all navigation syntax and semantics areexercised to uncover any navigation errors (e.g., dead links, improper links,erroneous links).530 PART THREEQUALITY MANAGEMENT
1 Generic software quality dimensions, equally applicable for WebApps, were discussed in Chapter 14.How do weassessquality within thecontext of aWebApp and itsenvironment??navigation testing  . . . . . . .545performance testing  . . . . . . .550planning . . . . . .532security testing  . . . . . . .548strategy . . . . . .532stress testing  . .552usability tests . .540pre75977_ch20.qxd  11/28/08  10:22 AM  Page 530•Performanceis tested under a variety of operating conditions, configurations,and loading to ensure that the system is responsive to user interaction andhandles extreme loading without unacceptable operational degradation.
•Compatibilityis tested by executing the WebApp in a variety of different hostconfigurations on both the client and server sides. The intent is to find errorsthat are specific to a unique host configuration.
•Interoperabilityis tested to ensure that the WebApp properly interfaces withother applications and/or databases.
•Securityis tested by assessing potential vulnerabilities and attempting toexploit each. Any successful penetration attempt is deemed a security failure.Strategy and tactics for WebApp testing have been developed to exercise each ofthese quality dimensions and are discussed later in this chapter.
20.1.2 Errors within a WebApp Environment
Errors encountered as a consequence of successful WebApp testing have a numberof unique characteristics [Ngu00]:1.Because many types of WebApp tests uncover problems that are firstevidenced on the client side (i.e., via an interface implemented on a specificbrowser or a personal communication device), you often see a symptom ofthe error, not the error itself.2.Because a WebApp is implemented in a number of different configurationsand within different environments, it may be difficult or impossible to repro-duce an error outside the environment in which the error was originallyencountered.3.Although some errors are the result of incorrect design or improper HTML(or other programming language) coding, many errors can be traced to theWebApp configuration.4.Because WebApps reside within a client-server architecture, errors can bedifficult to trace across three architectural layers: the client, the server, or thenetwork itself.5.Some errors are due to the static operating environment (i.e., the specific con- figuration in which testing is conducted), while others are attributable to thedynamic operating environment (i.e., instantaneous resource loading ortime-related errors).These five error attributes suggest that environment plays an important role in thediagnosis of all errors uncovered during the WebApp testing. In some situations (e.g.,content testing), the site of the error is obvious, but in many other types of WebApptesting (e.g., navigation testing, performance testing, security testing) the underlyingcause of the error may be considerably more difficult to determine.CHAPTER 20TESTING WEB APPLICATIONS 531
uote:
“Innovation is abittersweet deal forsoftware testers.Just when it seemsthat we know howto test a particulartechnology, a newone [WebApps]comes along andall bets are off.”James Bach
What makeserrorsencounteredduring WebAppexecutionsomewhatdifferent fromthose encounteredfor conventionalsoftware??pre75977_ch20.qxd  11/28/08  10:22 AM  Page 53120.1.3 Testing Strategy
The strategy for WebApp testing adopts the basic principles for all software testing(Chapter 17) and applies a strategy and tactics that have been recommendedfor object-oriented systems (Chapter 19). The following steps summarize theapproach:1.The content model for the WebApp is reviewed to uncover errors.2.The interface model is reviewed to ensure that all use cases can be accom-modated.3.The design model for the WebApp is reviewed to uncover navigation errors.4.The user interface is tested to uncover errors in presentation and/or naviga-tion mechanics.5.Functional components are unit tested.6.Navigation throughout the architecture is tested.7.The WebApp is implemented in a variety of different environmental configu-rations and is tested for compatibility with each configuration.8.Security tests are conducted in an attempt to exploit vulnerabilities in theWebApp or within its environment.9.Performance tests are conducted.10.The WebApp is tested by a controlled and monitored population of end users;the results of their interaction with the system are evaluated for content andnavigation errors, usability concerns, compatibility concerns, and WebAppsecurity, reliability, and performance.Because many WebApps evolve continuously, the testing process is an ongoing ac-tivity, conducted by Web support staff who use regression tests derived from the testsdeveloped when the WebApp was first engineered.
20.1.4 Test Planning
The use of the word planning(in any context) is anathema to some Web developers.These developers don’t plan; they just start—hoping that a killer WebApp willemerge. A more disciplined approach recognizes that planning establishes a roadmap for all work that follows. It’s worth the effort. In their book on WebApp testing,Splaine and Jaskiel [Spl01] state:
Except for the simplest of Web sites, it quickly becomes apparent that some sort of testplanning is needed. All too often, the initial number of bugs found from ad hoc testing islarge enough that not all of them are fixed the first time they’re detected. This puts anadditional burden on people who test Web sites and applications. Not only must theyconjure up imaginative new tests, but they must also remember how previous tests wereexecuted in order to reliably re-test the Web site/application, and ensure that knownbugs have been removed and that no new bugs have been introduced.532 PART THREEQUALITY MANAGEMENT
The overall strategy forWebApp testing canbe summarized in the10 steps noted here.
WebRef
Excellent articles onWebApp testing canbe found at www.stickyminds.com/testing.asppre75977_ch20.qxd  11/28/08  10:22 AM  Page 532The questions you should ask are: How do we “conjure up imaginative new tests,”and what should those tests focus on? The answers to these questions are containedwithin a test plan.A WebApp test plan identifies (1) the task set
2to be applied as testing commences, (2) the work products to be produced as each testing task is executed, and (3) themanner in which the results of testing are evaluated, recorded, and reused whenregression testing is conducted. In some cases, the test plan is integrated with theproject plan. In others, the test plan is a separate document.
20.2 T HETESTING PROCESS —A NOVERVIEW
You begin the WebApp testing process with tests that exercise content and interfacefunctionality that are immediately visible to end users. As testing proceeds, aspectsof the design architecture and navigation are exercised. Finally, the focus shifts totests that examine technological capabilities that are not always apparent to endusers—WebApp infrastructure and installation/implementation issues.Figure 20.1 juxtaposes the WebApp testing process with the design pyramid forWebApps (Chapter 13). Note that as the testing flow proceeds from left to right andCHAPTER 20TESTING WEB APPLICATIONS 533
The test plan identifiesthe testing task set, thework products to bedeveloped, and theway in which resultsare to be evaluated,recorded, and reused.
2 Task sets are discussed in Chapter 2. A related term— workflow—is also used to describe a series of tasks required to accomplish a software engineering activity.ContentTesting
InterfaceTesting
NavigationTesting
ComponentTestingConfigurationTestingPerformanceTestingSecurityTestingInterfacedesignAesthetic designContent designNavigation designArchitecture designComponent designuser
technologyFIGURE 20.1
The testingprocesspre75977_ch20.qxd  11/28/08  10:22 AM  Page 533top to bottom, user-visible elements of the WebApp design (top elements of thepyramid) are tested first, followed by infrastructure design elements.
20.3 C ONTENT TESTING
Errors in WebApp content can be as trivial as minor typographical errors or as sig-nificant as incorrect information, improper organization, or violation of intellectualproperty laws. Content testingattempts to uncover these and many other problemsbefore the user encounters them.Content testing combines both reviews and the generation of executable testcases. Reviews are applied to uncover semantic errors in content (discussed in Sec-tion 20.3.1). Executable testing is used to uncover content errors that can be tracedto dynamically derived content that is driven by data acquired from one or moredatabases.
20.3.1 Content Testing Objectives
Content testing has three important objectives: (1) to uncover syntactic errors (e.g.,typos, grammar mistakes) in text-based documents, graphical representations, andother media; (2) to uncover semantic errors (i.e., errors in the accuracy or com-pleteness of information) in any content object presented as navigation occurs, and(3) to find errors in the organization or structure of content that is presented to theend user.To accomplish the first objective, automated spelling and grammar checkers maybe used. However, many syntactic errors evade detection by such tools and must bediscovered by a human reviewer (tester). In fact, a large website might enlist theservices of a professional copy editor to uncover typographical errors, grammaticalmistakes, errors in content consistency, errors in graphical representations, andcross-referencing errors.Semantic testing focuses on the information presented within each contentobject. The reviewer (tester) must answer the following questions:
•Is the information factually accurate?
•Is the information concise and to the point?
•Is the layout of the content object easy for the user to understand?
•Can information embedded within a content object be found easily?
•Have proper references been provided for all information derived from othersources?
•Is the information presented consistent internally and consistent with infor-mation presented in other content objects?
•Is the content offensive, misleading, or does it open the door to litigation?
•Does the content infringe on existing copyrights or trademarks?534 PART THREEQUALITY MANAGEMENT
Content testingobjectives are: (1) touncover syntactic errorsin content, (2) touncover semanticerrors, and (3) to findstructural errors.Although technicalreviews are not a partof testing, contentreview should beperformed to ensurethat content has quality.
Whatquestionsshould be askedand answered touncover semanticerrors in content??pre75977_ch20.qxd  11/28/08  10:22 AM  Page 534•Does the content contain internal links that supplement existing content? Arethe links correct?
•Does the aesthetic style of the content conflict with the aesthetic style of theinterface?Obtaining answers to each of these questions for a large WebApp (containinghundreds of content objects) can be a daunting task. However, failure to uncoversemantic errors will shake the user’s faith in the WebApp and can lead to failure ofthe Web-based application.Content objects exist within an architecture that has a specific style (Chapter 13).During content testing, the structure and organization of the content architecture istested to ensure that required content is presented to the end user in the properorder and relationships. For example, the SafeHomeAssured.com WebApp presents a variety of information about sensors that are used as part of security andsurveillance products. Content objects provide descriptive information, technicalspecifications, a photographic representation, and related information. Tests of theSafeHomeAssured.comcontent architecture strive to uncover errors in the presen-tation of this information (e.g., a description of Sensor X is presented with a photoof Sensor Y).
20.3.2 Database Testing
Modern WebApps do much more than present static content objects. In many appli-cation domains, WebApps interface with sophisticated database managementsystems and build dynamic content objects that are created in real time using thedata acquired from a database.For example, a financial services WebApp can produce complex text-based, tab-ular, and graphical information about a specific equity (e.g., a stock or mutual fund).The composite content object that presents this information is created dynamicallyafter the user has made a request for information about a specific equity. To accom-plish this, the following steps are required: (1) a large equities database is queried,(2) relevant data are extracted from the database, (3) the extracted data must beorganized as a content object, and (4) this content object (representing customizedinformation requested by an end user) is transmitted to the client environment fordisplay. Errors can and do occur as a consequence of each of these steps. Theobjective of database testing is to uncover these errors, but database testing is com-plicated by a variety of factors:1.The original client-side request for information is rarely presented in the form[e.g., structured query language (SQL)] that can be input to a database manage-ment system (DBMS).Therefore, tests should be designed to uncover errorsmade in translating the user’s request into a form that can be processed bythe DBMS.CHAPTER 20TESTING WEB APPLICATIONS 535
What issuescomplicatedatabase testingfor WebApps??uote:
“In general, thesoftware testingtechniques that areapplied to otherapplications arethe same as thoseapplied to Web-basedapplications. . . .The difference . . . isthat the technologyvariables in theWeb environmentmultiply.”Hung Nguyenpre75977_ch20.qxd  11/28/08  10:22 AM  Page 5352.The database may be remote to the server that houses the WebApp. Therefore, tests that uncover errors in communication between the WebApp and theremote database must be developed.
3
3.Raw data acquired from the database must be transmitted to the WebApp serverand properly formatted for subsequent transmittal to the client. Therefore, tests that demonstrate the validity of the raw data received by the WebApp servermust be developed, and additional tests that demonstrate the validity of thetransformations applied to the raw data to create valid content objects mustalso be created.4.The dynamic content object(s) must be transmitted to the client in a form thatcan be displayed to the end user.Therefore, a series of tests must be designedto (1) uncover errors in the content object format and (2) test compatibilitywith different client environment configurations.Considering these four factors, test-case design methods should be applied for eachof the “layers of interaction” [Ngu01] noted in Figure 20.2. Testing should ensure that(1) valid information is passed between the client and server from the interface layer,(2) the WebApp processes scripts correctly and properly extracts or formats user data,(3) user data are passed correctly to a server-side data transformation function thatformats appropriate queries (e.g., SQL), (4) queries are passed to a data management536 PART THREEQUALITY MANAGEMENT
3 These tests can become complex when distributed databases are encountered or when access to adata warehouse (Chapter 1) is required.Client layer - user interface
HTML scriptsUser dataUser dataRaw dataSQLSQLServer layer - WebAppServer layer - data transformationServer layer - data managmentDatabase layer - data access
DatabaseFIGURE 20.2
Layers of inter-actionpre75977_ch20.qxd  11/28/08  10:22 AM  Page 536layer4that communicates with database access routines (potentially located onanother machine).The data transformation, data management, and database access layers shownin Figure 20.2 are often constructed with reusable components that have been vali-dated separately and as a package. If this is the case, WebApp testing focuses on thedesign of test cases to exercise the interactions between the client layer and the firsttwo server layers (WebApp and data transformation) shown in the figure.The user interface layer is tested to ensure that scripts are properly constructedfor each user query and properly transmitted to the server side. The WebApp layeron the server side is tested to ensure that user data are properly extracted fromscripts and properly transmitted to the data transformation layer on the server side.The data transformation functions are tested to ensure that the correct SQL is cre-ated and passed to appropriate data management components.A detailed discussion of the underlying technology that must be understood toadequately design these database tests is beyond the scope of this book. If you haveadditional interest, see [Sce02], [Ngu01], and [Bro01].
20.4 U SERINTERFACE TESTING
Verification and validation of a WebApp user interface occurs at three distinct points.During requirements analysis, the interface model is reviewed to ensure that it con-forms to stakeholder requirements and to other elements of the requirements model.During design the interface design model is reviewed to ensure that generic qualitycriteria established for all user interfaces (Chapter 11) have been achieved and thatapplication-specific interface design issues have been properly addressed. Duringtesting, the focus shifts to the execution of application-specific aspects of user inter-action as they are manifested by interface syntax and semantics. In addition, testingprovides a final assessment of usability.
20.4.1 Interface Testing Strategy
Interface testingexercises interaction mechanisms and validates aesthetic aspects ofthe user interface. The overall strategy for interface testing is to (1) uncover errorsrelated to specific interface mechanisms (e.g., errors in the proper execution of amenu link or the way data are entered in a form) and (2) uncover errors in the waythe interface implements the semantics of navigation, WebApp functionality, or con-tent display. To accomplish this strategy, a number of tactical steps are initiated:
•Interface features are tested to ensure that design rules, aesthetics, and relatedvisual content are available for the user without error. Features include typeCHAPTER 20TESTING WEB APPLICATIONS 537
4 The data management layer typically incorporates an SQL call-level interface (SQL-CLI) such asMicrosoft OLE/ADO or Java Database Connectivity (JDBC).uote:
“… we areunlikely to haveconfidence in aWeb site thatsuffers frequentdowntime, hangs inthe middle of atransaction, or hasa poor sense ofusability. Testing,therefore, has acrucial role in theoveralldevelopmentprocess.”Wing Lam
With the exception ofWebApp-orientedspecifics, the interfacestrategy noted hereis applicable to alltypes of client-serversoftware.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 537fonts, the use of color, frames, images, borders, tables, and related interfacefeatures that are generated as WebApp execution proceeds.
•Individual interface mechanisms are tested in a manner that is analogous to unittesting.For example, tests are designed to exercise all forms, client-sidescripting, dynamic HTML, scripts, streaming content, and application-specificinterface mechanisms (e.g., a shopping cart for an e-commerce application).In many cases, testing can focus exclusively on one of these mechanisms(the “unit”) to the exclusion of other interface features and functions.
•Each interface mechanism is tested within the context of a use case or NSU(Chapter 13)for a specific user category.This testing approach is analogous to integration testing in that tests are conducted as interface mechanisms areintegrated to allow a use case or NSU to be executed.
•The complete interface is tested against selected use cases and NSUs to uncovererrors in the semantics of the interface.This testing approach is analogous tovalidation testing because the purpose is to demonstrate conformance tospecific use-case or NSU semantics. It is at this stage that a series of usabilitytests are conducted.
•The interface is tested within a variety of environments (e.g., browsers) to ensurethat it will be compatible.In actuality, this series of tests can also be consid-ered to be part of configuration testing.
20.4.2 Testing Interface Mechanisms
When a user interacts with a WebApp, the interaction occurs through one or moreinterface mechanisms. A brief overview of testing considerations for each interfacemechanism is presented in the paragraphs that follow [Spl01].Links.Each navigation link is tested to ensure that the proper content object orfunction is reached.
5You build a list of all links associated with the interface layout(e.g., menu bars, index items) and then execute each individually. In addition, linkswithin each content object must be exercised to uncover bad URLs or links toimproper content objects or functions. Finally, links to external WebApps should betested for accuracy and also evaluated to determine the risk that they will becomeinvalid over time.Forms.At a macroscopic level, tests are performed to ensure that (1) labels cor-rectly identify fields within the form and that mandatory fields are identified visuallyfor the user, (2) the server receives all information contained within the form andthat no data are lost in the transmission between client and server, (3) appropriatedefaults are used when the user does not select from a pull-down menu or set ofbuttons, (4) browser functions (e.g., the “back” arrow) do not corrupt data entered in538 PART THREEQUALITY MANAGEMENT
External link testingshould occurthroughout the life ofthe WebApp. Part of asupport strategy shouldbe regularly scheduledlink tests.
5 These tests can be performed as part of either interface or navigation testing.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 538a form, and (5) scripts that perform error checking on data entered work properly andprovide meaningful error messages.At a more targeted level, tests should ensure that (1) form fields have proper widthand data types, (2) the form establishes appropriate safeguards that preclude the userfrom entering text strings longer than some predefined maximum, (3) all appropri-ate options for pull-down menus are specified and ordered in a way that is mean-ingful to the end user, (4) browser “auto-fill” features do not lead to data input errors,and (5) tab key (or some other key) initiates proper movement between form fields.Client-side scripting.Black-box tests are conducted to uncover any errors inprocessing as the script is executed. These tests are often coupled with forms test-ing, because script input is often derived from data provided as part of forms pro-cessing. A compatibility test should be conducted to ensure that the scriptinglanguage that has been chosen will work properly in the environmental configura-tions that support the WebApp. In addition to testing the script itself, Splaine andJaskiel [Spl01] suggest that “you should ensure that your company’s [WebApp] stan-dards state the preferred language and version of scripting language to be used forclient-side (and server-side) scripting.”Dynamic HTML.Each Web page that contains dynamic HTML is executed toensure that the dynamic display is correct. In addition, a compatibility test should beconducted to ensure that the dynamic HTML works properly in the environmentalconfigurations that support the WebApp.Pop-up windows.A series of tests ensure that (1) the pop-up is properly sized andpositioned, (2) the pop-up does not cover the original WebApp window, (3) the aes-thetic design of the pop-up is consistent with the aesthetic design of the interface,and (4) scroll bars and other control mechanisms appended to the pop-up are prop-erly located and function as required.CGI scripts.Black-box tests are conducted with an emphasis on data integrity(as data are passed to the CGI script) and script processing (once validated data havebeen received). In addition, performance testing can be conducted to ensure that theserver-side configuration can accommodate the processing demands of multipleinvocations of CGI scripts [Spl01].Streaming content.Tests should demonstrate that streaming data are up-to-date,properly displayed, and can be suspended without error and restarted without difficulty.Cookies.Both server-side and client-side testing are required. On the server side,tests should ensure that a cookie is properly constructed (contains correct data) andproperly transmitted to the client side when specific content or functionality isrequested. In addition, the proper persistence of the cookie is tested to ensure thatits expiration date is correct. On the client side, tests determine whether the WebAppproperly attaches existing cookies to a specific request (sent to the server).CHAPTER 20TESTING WEB APPLICATIONS 539
Client-side scriptingtests and tests associ-ated with dynamicHTML should berepeated whenever anew version of apopular browser isreleased.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 539Application-specific interface mechanisms. Tests conform to a checklist of functionality and features that are defined by the interface mechanism. For example,Splaine and Jaskiel [Spl01] suggest the following checklist for shopping cart func-tionality defined for an e-commerce application:
•Boundary-test (Chapter 18) the minimum and maximum number of itemsthat can be placed in the shopping cart.
•Test a “check out” request for an empty shopping cart.
•Test proper deletion of an item from the shopping cart.
•Test to determine whether a purchase empties the cart of its contents.
•Test to determine the persistence of shopping cart contents (this should bespecified as part of customer requirements).
•Test to determine whether the WebApp can recall shopping cart contents atsome future date (assuming that no purchase was made).
20.4.3 Testing Interface Semantics
Once each interface mechanism has been “unit” tested, the focus of interface testingchanges to a consideration of interface semantics. Interface semantics testing “eval-uates how well the design takes care of users, offers clear direction, delivers feed-back, and maintains consistency of language and approach” [Ngu00].A thorough review of the interface design model can provide partial answers tothe questions implied by the preceding paragraph. However, each use-case scenario(for each user category) should be tested once the WebApp has been implemented.In essence, a use case becomes the input for the design of a testing sequence. Theintent of the testing sequence is to uncover errors that will preclude a user fromachieving the objective associated with the use case.As each use case is tested, it’s a good idea to maintain a checklist to ensure thatevery menu item has been exercised at least one time and that every embedded linkwithin a content object has been used. In addition, the test series should includeimproper menu selection and link usage. The intent is to determine whether theWebApp provides effective error handling and recovery.
20.4.4 Usability Tests
Usability testing is similar to interface semantics testing (Section 20.4.3) in the sensethat it also evaluates the degree to which users can interact effectively with the WebAppand the degree to which the WebApp guides users’ actions, provides meaningful feed-back, and enforces a consistent interaction approach. Rather than focusing intently onthe semantics of some interactive objective, usability reviews and tests are designed todetermine the degree to which the WebApp interface makes the user’s life easy.
6540 PART THREEQUALITY MANAGEMENT
WebRef
A worthwhile guideto usability testing canbe found atwww.ahref.com/guides/design/199806/0615jef.html.
6 The term user-friendlinesshas been used in this context. The problem, of course, is that one user’sperception of a “friendly” interface may be radically different from another’s.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 540You will invariably contribute to the design of usability tests, but the tests them-selves are conducted by end users. The following sequence of steps is applied[Spl01]:1.Define a set of usability testing categories and identify goals for each.2.Design tests that will enable each goal to be evaluated.3.Select participants who will conduct the tests.4.Instrument participants’ interaction with the WebApp while testing isconducted.5.Develop a mechanism for assessing the usability of the WebApp.Usability testing can occur at a variety of different levels of abstraction: (1) the usabilityof a specific interface mechanism (e.g., a form) can be assessed, (2) the usability of a com-plete Web page (encompassing interface mechanisms, data objects, and related func-tions) can be evaluated, or (3) the usability of the complete WebApp can be considered.The first step in usability testing is to identify a set of usability categories andestablish testing objectives for each category. The following test categories andobjectives (written in the form of a question) illustrate this approach:
7
Interactivity—Are interaction mechanisms (e.g., pull-down menus, buttons,pointers) easy to understand and use?Layout—Are navigation mechanisms, content, and functions placed in a mannerthat allows the user to find them quickly?Readability—Is text well written and understandable?
8Are graphic representa- tions easy to understand?Aesthetics—Do layout, color, typeface, and related characteristics lead to ease ofuse? Do users “feel comfortable” with the look and feel of the WebApp?Display characteristics—Does the WebApp make optimal use of screen size andresolution?Time sensitivity—Can important features, functions, and content be used oracquired in a timely manner?Personalization—Does the WebApp tailor itself to the specific needs of differentuser categories or individual users?Accessibility—Is the WebApp accessible to people who have disabilities?A series of tests is designed within each of these categories. In some cases, the “test”may be a visual review of a Web page. In other cases interface semantics tests maybe executed again, but in this instance usability concerns are paramount.CHAPTER 20TESTING WEB APPLICATIONS 541
Whatcharacter-istics of usabilitybecome the focusof testing andwhat specificobjectives areaddressed??
7 For additional information on usability, see Chapter 11.8 The FOG Readability Index and others may be used to provide a quantitative assessment of read-ability See http://developer.gnome.org/documents/usability/usability-readability.htmlfor more details.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 541As an example, we consider usability assessment for interaction and interfacemechanisms. Constantine and Lockwood [Con99] suggest that the following list ofinterface features should be reviewed and tested for usability: animation, buttons,color, control, dialogue, fields, forms, frames, graphics, labels, links, menus, mes-sages, navigation, pages, selectors, text, and tool bars. As each feature is assessed,it is graded on a qualitative scale by the users who are doing the testing. Figure 20.3depicts a possible set of assessment “grades” that can be selected by users. Thesegrades are applied to each feature individually, to a complete Web page, or to theWebApp as a whole.
20.4.5 Compatibility Tests
Different computers, display devices, operating systems, browsers, and networkconnection speeds can have a significant influence on WebApp operation. Eachcomputing configuration can result in differences in client-side processing speeds,display resolution, and connection speeds. Operating system vagaries may causeWebApp processing issues. Different browsers sometimes produce slightly differentresults, regardless of the degree of HTML standardization within the WebApp. Re-quired plug-ins may or may not be readily available for a particular configuration.In some cases, small compatibility issues present no significant problems, but inothers, serious errors can be encountered. For example, download speeds may be-come unacceptable, lack of a required plug-in may make content unavailable,browser differences can change page layout dramatically, font styles may be alteredand become illegible, or forms may be improperly organized. Compatibility testingstrives to uncover these problems before the WebApp goes online.The first step in compatibility testing is to define a set of “commonly encountered”client-side computing configurations and their variants. In essence, a tree structureis created, identifying each computing platform, typical display devices, the operat-ing systems supported on the platform, the browsers available, likely Internet542 PART THREEQUALITY MANAGEMENT
Ease of useEasy to learnEffectiveSimple
Somewhat ambiguousConfusingGenerally uniformPredictablePredictabilityEase of understandingAwkwardDifficult to learnInformativeClearMisleadingInconsistentLacking uniformityFIGURE 20.3
Qualitativeassessment ofusability
WebApps executewithin a variety ofclient-sideenvironments. Theobjective ofcompatibility testing touncover errorsassociated with aspecific environment(e.g., browser).pre75977_ch20.qxd  11/28/08  10:22 AM  Page 542connection speeds, and similar information. Next, a series of compatibility validationtests are derived, often adapted from existing interface tests, navigation tests, per-formance tests, and security tests. The intent of these tests is to uncover errors orexecution problems that can be traced to configuration differences.CHAPTER 20TESTING WEB APPLICATIONS 543
WebApp Testing
The scene:Doug Miller’s office.The players:Doug Miller (manager of the SafeHome software engineering group) and Vinod Raman (amember of the product software engineering team).The conversation:Doug:What do you think of theSafeHomeAssured.come-commerce WebApp V0.0?Vinod:The outsourcing vendor’s done a good job.Sharon [development manager for the vendor] tells methey’re testing as we speak.Doug:I’d like you and the rest of the team to do a littleinformal testing on the e-commerce site.Vinod (grimacing):I thought we were going to hire athird-party testing company to validate the WebApp.We’re still killing ourselves trying to get the productsoftware out the door.Doug:We’re going to hire a testing vendor forperformance and security testing, and our outsourcingvendor is already testing. Just thought another point ofview would be helpful, and besides, we’d like to keepcosts in line, so . . .Vinod (sighs):What are you looking for?Doug:I want to be sure that the interface and allnavigation are solid.Vinod:I suppose we can start with the use cases foreach of the major interface functions:Learn aboutSafeHome.Specify theSafeHomesystem you need.Purchase aSafeHomesystem.Get technical support.Doug:Good. But take the navigation paths all the wayto their conclusion.Vinod (looking through a notebook of usecases):Yeah, when you select Specify theSafeHome system you need,that’ll take you to:Select SafeHome components.GetSafeHomecomponent recommendations.We can exercise the semantics of each path.Doug:While you’re there, check out the content thatappears at each navigation node.Vinod:Of course. . . and the functional elements aswell. Who’s testing usability?Doug:Oh . . . the testing vendor will coordinateusability testing. We’ve hired a market research firm toline up 20 typical users for the usability study, but if youguys uncover any usability issues . . .Vinod:I know, pass them along.Doug:Thanks, Vinod.SAFEHOME
20.5 C OMPONENT -LEVEL TESTING
Component-level testing,also called function testing,focuses on a set of tests that attempt to uncover errors in WebApp functions. Each WebApp function is a softwarecomponent (implemented in one of a variety of programming or scripting languages)and can be tested using black-box (and in some cases, white-box) techniques asdiscussed in Chapter 18.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 543Component-level test cases are often driven by forms-level input. Once formsdata are defined, the user selects a button or other control mechanism to initiateexecution. The following test-case design methods (Chapter 18) are typical:
•Equivalence partitioning—The input domain of the function is divided intoinput categories or classes from which test cases are derived. The input formis assessed to determine what classes of data are relevant for the function.Test cases for each class of input are derived and executed, while otherclasses of input are held constant. For example, an e-commerce applicationmay implement a function that computes shipping charges. Among a varietyof shipping information provided via a form is the user’s postal code. Testcases are designed in an attempt to uncover errors in postal code processingby specifying postal code values that might uncover different classes of errors(e.g., an incomplete postal code, a correct postal code, a nonexistent postalcode, an erroneous postal code format).
•Boundary value analysis—Forms data are tested at their boundaries. Forexample, the shipping calculation function noted previously requests themaximum number of days required for product delivery. A minimum of2 days and a maximum of 14 are noted on the form. However, boundaryvalue tests might input values of 0, 1, 2, 13, 14, and 15 to determine how thefunction reacts to data at and outside the boundaries of valid input.
9
•Path testing—If the logical complexity of the function is high,10path testing (a white-box test-case design method) can be used to ensure that every inde-pendent path in the program has been exercised.In addition to these test-case design methods, a technique called forced error testing[Ngu01] is used to derive test cases that purposely drive the WebApp component intoan error condition. The purpose is to uncover errors that occur during error handling(e.g., incorrect or nonexistent error messages, WebApp failure as a consequence ofthe error, erroneous output driven by erroneous input, side effects that are related tocomponent processing).Each component-level test case specifies all input values and the expected outputto be provided by the component. The actual output produced as a consequence ofthe test is recorded for future reference during support and maintenance.In many situations, the correct execution of a WebApp function is tied to properinterfacing with a database that may be external to the WebApp. Therefore, databasetesting becomes an integral part of the component-testing regime.544 PART THREEQUALITY MANAGEMENT
9 In this case, a better input design might eliminate potential errors. The maximum number of dayscould be selected from a pull-down menu, precluding the user from specifying out-of-bounds input.10 Logical complexity can be determined by computing cyclomatic complexity of the algorithm. SeeChapter 18 for additional details.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 54420.6 N AVIGATION TESTING
A user travels through a WebApp in much the same way as a visitor walks througha store or museum. There are many pathways that can be taken, many stops thatcan be made, many things to learn and look at, activities to initiate, and decisionsto make. This navigation process is predictable in the sense that every visitor hasa set of objectives when he arrives. At the same time, the navigation process canbe unpredictable because the visitor, influenced by something he sees or learns,may choose a path or initiate an action that is not typical for the original objec-tive. The job of navigation testing is (1) to ensure that the mechanisms that allowthe WebApp user to travel through the WebApp are all functional and (2) to vali-date that each navigation semantic unit (NSU) can be achieved by the appropriateuser category.
20.6.1 Testing Navigation Syntax
The first phase of navigation testing actually begins during interface testing.Navigation mechanisms are tested to ensure that each performs its intended func-tion. Splaine and Jaskiel [Spl01] suggest that each of the following navigation mech-anisms should be tested:
•Navigation links—these mechanisms include internal links within theWebApp, external links to other WebApps, and anchors within a specific Webpage. Each link should be tested to ensure that proper content or function-ality is reached when the link is chosen.
•Redirects—these links come into play when a user requests a nonexistentURL or selects a link whose content has been removed or whose name haschanged. A message is displayed for the user and navigation is redirected toanother page (e.g., the home page). Redirects should be tested by requestingincorrect internal links or external URLs and assessing how the WebApphandles these requests.
•Bookmarks—although bookmarks are a browser function, the WebAppshould be tested to ensure that a meaningful page title can be extracted asthe bookmark is created.
•Frames and framesets—each frame contains the content of a specific Webpage, and a frameset contains multiple frames and enables the display ofmultiple Web pages at the same time. Because it is possible to nest framesand framesets within one another, these navigation and display mechanismsshould be tested for correct content, proper layout and sizing, downloadperformance, and browser compatibility.
•Site maps—a site map provides a complete table of contents for all Webpages. Each site map entry should be tested to ensure that the links take theuser to the proper content or functionality.CHAPTER 20TESTING WEB APPLICATIONS 545
uote:
“We’re not lost.We’re locationallychallenged.”John M. Fordpre75977_ch20.qxd  11/28/08  10:22 AM  Page 545•Internal search engines—complex WebApps often contain hundreds or eventhousands of content objects. An internal search engine allows the user toperform a keyword search within the WebApp to find needed content. Searchengine testing validates the accuracy and completeness of the search, theerror-handling properties of the search engine, and advanced search features(e.g., the use of Boolean operators in the search field).Some of the tests noted can be performed by automated tools (e.g., link checking),while others are designed and executed manually. The intent throughout is to ensurethat errors in navigation mechanics are found before the WebApp goes online.
20.6.2 Testing Navigation Semantics
In Chapter 13 a navigation semantic unit (NSU) is defined as “a set of informationand related navigation structures that collaborate in the fulfillment of a subset ofrelated user requirements” [Cac02]. Each NSU is defined by a set of navigation paths(called “ways of navigating”) that connect navigation nodes (e.g., Web pages, con-tent objects, or functionality). Taken as a whole, each NSU allows a user to achievespecific requirements defined by one or more use cases for a user category. Naviga-tion testing exercises each NSU to ensure that these requirements can be achieved.You should answer the following questions as each NSU is tested:
•Is the NSU achieved in its entirety without error?
•Is every navigation node (defined for an NSU) reachable within the context ofthe navigation paths defined for the NSU?
•If the NSU can be achieved using more than one navigation path, has everyrelevant path been tested?
•If guidance is provided by the user interface to assist in navigation, are direc-tions correct and understandable as navigation proceeds?
•Is there a mechanism (other than the browser “back” arrow) for returning tothe preceding navigation node and to the beginning of the navigation path?
•Do mechanisms for navigation within a large navigation node (i.e., a longWeb page) work properly?
•If a function is to be executed at a node and the user chooses not to provideinput, can the remainder of the NSU be completed?
•If a function is executed at a node and an error in function processing occurs,can the NSU be completed?
•Is there a way to discontinue the navigation before all nodes have beenreached, but then return to where the navigation was discontinued andproceed from there?
•Is every node reachable from the site map? Are node names meaningful toend users?546 PART THREEQUALITY MANAGEMENT
Whatquestionsmust be askedand answered aseach NSU istested??
If NSUs have not beencreated as part ofWebApp analysis ordesign, you can applyuse cases for thedesign of navigationtest cases. The sameset of questions areasked and answered.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 546•If a node within an NSU is reached from some external source, is it possibleto process to the next node on the navigation path? Is it possible to return tothe previous node on the navigation path?
•Does the user understand his location within the content architecture as theNSU is executed?Navigation testing, like interface and usability testing, should be conducted by asmany different constituencies as possible. You have responsibility for early stages ofnavigation testing, but later stages should be conducted by other project stakehold-ers, an independent testing team, and ultimately, by nontechnical users. The intentis to exercise WebApp navigation thoroughly.
20.7 C ONFIGURATION TESTING
Configuration variability and instability are important factors that make WebApptesting a challenge. Hardware, operating system(s), browsers, storage capacity, net-work communication speeds, and a variety of other client-side factors are difficult topredict for each user. In addition, the configuration for a given user can change [e.g.,operating system (OS) updates, new ISP and connection speeds] on a regular basis.The result can be a client-side environment that is prone to errors that are both sub-tle and significant. One user’s impression of the WebApp and the manner in whichshe interacts with it can differ significantly from another user’s experience, if bothusers are not working within the same client-side configuration.The job of configuration testing is not to exercise every possible client-side con-figuration. Rather, it is to test a set of probable client-side and server-side configu-rations to ensure that the user experience will be the same on all of them and toisolate errors that may be specific to a particular configuration.
20.7.1 Server-Side Issues
On the server side, configuration test cases are designed to verify that the projectedserver configuration [i.e., WebApp server, database server, operating system(s), fire-wall software, concurrent applications] can support the WebApp without error. Inessence, the WebApp is installed within the server-side environment and tested toensure that it operates without error.As server-side configuration tests are designed, you should consider each com-ponent of the server configuration. Among the questions that need to be asked andanswered during server-side configuration testing are:
•Is the WebApp fully compatible with the server OS?
•Are system files, directories, and related system data created correctly whenthe WebApp is operational?
•Do system security measures (e.g., firewalls or encryption) allow the WebAppto execute and service users without interference or performance degradation?CHAPTER 20TESTING WEB APPLICATIONS 547
Whatquestionsmust be askedand answered asserver-sideconfigurationtesting isconducted??pre75977_ch20.qxd  11/28/08  10:22 AM  Page 547•Has the WebApp been tested with the distributed server configuration11
(if one exists) that has been chosen?
•Is the WebApp properly integrated with database software? Is the WebAppsensitive to different versions of database software?
•Do server-side WebApp scripts execute properly?
•Have system administrator errors been examined for their effect on WebAppoperations?
•If proxy servers are used, have differences in their configuration beenaddressed with on-site testing?
20.7.2 Client-Side Issues
On the client side, configuration tests focus more heavily on WebApp compatibilitywith configurations that contain one or more permutations of the following compo-nents [Ngu01]:
•Hardware—CPU, memory, storage, and printing devices
•Operating systems—Linux, Macintosh OS, Microsoft Windows, a mobile-basedOS
•Browser software—Firefox, Safari, Internet Explorer, Opera, Chrome, and others
•User interface components—Active X, Java applets, and others
•Plug-ins—QuickTime, RealPlayer, and many others
•Connectivity—cable, DSL, regular modem, T1, WiFiIn addition to these components, other variables include networking software, thevagaries of the ISP, and applications running concurrently.To design client-side configuration tests, you must reduce the number of configu-ration variables to a manageable number.
12To accomplish this, each user category is assessed to determine the likely configurations to be encountered within the cate-gory. In addition, industry market share data may be used to predict the most likelycombinations of components. The WebApp is then tested within these environments.
20.8 S ECURITY TESTING
WebApp security is a complex subject that must be fully understood before effectivesecurity testing can be accomplished.
13WebApps and the client-side and server-side environments in which they are housed represent an attractive target for externalhackers, disgruntled employees, dishonest competitors, and anyone else who548 PART THREEQUALITY MANAGEMENT
11 For example, a separate application server and database server may be used. Communicationbetween the two machines occurs across a network connection.12 Running tests on every possible combination of configuration components is far too time consuming.13 Books by Cross and Fisher [Cro07], Andrews and Whittaker [And06], and Trivedi [Tri03] provideuseful information about the subject.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 548wishes to steal sensitive information, maliciously modify content, degrade perform-ance, disable functionality, or embarrass a person, organization, or business.Security tests are designed to probe vulnerabilities of the client-side environment,the network communications that occur as data are passed from client to server andback again, and the server-side environment. Each of these domains can be attacked,and it is the job of the security tester to uncover weaknesses that can be exploited bythose with the intent to do so.On the client side, vulnerabilities can often be traced to preexisting bugs inbrowsers, e-mail programs, or communication software. Nguyen [Ngu01] describesa typical security hole:
One of the commonly mentioned bugs is Buffer Overflow, which allows malicious codeto be executed on the client machine. For example, entering a URL into a browser that ismuch longer than the buffer size allocated for the URL will cause a memory overwrite(buffer overflow) error if the browser does not have error detection code to validate thelength of the input URL. A seasoned hacker can cleverly exploit this bug by writing a longURL with code to be executed that can cause the browser to crash or alter securitysettings (from high to low), or, at worst, to corrupt user data.
Another potential vulnerability on the client side is unauthorized access to cook-ies placed within the browser. Websites created with malicious intent can acquireinformation contained within legitimate cookies and use this information in waysthat jeopardize the user’s privacy, or worse, set the stage for identity theft.Data communicated between the client and server are vulnerable to spoofing. Spoofing occurs when one end of the communication pathway is subverted by anentity with malicious intent. For example, a user can be spoofed by a maliciouswebsite that acts as if it is the legitimate WebApp server (identical look and feel). Theintent is to steal passwords, proprietary information, or credit data.On the server side, vulnerabilities include denial-of-service attacks and maliciousscripts that can be passed along to the client side or used to disable server operations.In addition, server-side databases can be accessed without authorization (data theft).To protect against these (and many other) vulnerabilities, one or more of thefollowing security elements is implemented [Ngu01]:
•Firewall—a filtering mechanism that is a combination of hardware andsoftware that examines each incoming packet of information to ensure that itis coming from a legitimate source, blocking any data that are suspect.
•Authentication—a verification mechanism that validates the identity of allclients and servers, allowing communication to occur only when both sidesare verified.
•Encryption—an encoding mechanism that protects sensitive data bymodifying it in a way that makes it impossible to read by those withmalicious intent. Encryption is strengthened by using digital certificates that allow the client to verify the destination to which the data are transmitted.CHAPTER 20TESTING WEB APPLICATIONS 549
uote:
“The Internet is arisky place toconduct businessor store assets.Hackers, crackers,snoops, spoofers,. . . vandals, viruslaunchers, androgue programpurveyors runloose.”Dorothy andPeter Denning
If the WebApp isbusiness critical,maintains sensitivedata, or is a likelytarget of hackers, it’s agood idea to outsourcesecurity testing to avendor who specializesin it.
Security tests shouldbe designed toexercise firewalls,authentication,encryption, andauthorization.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 549•Authorization—a filtering mechanism that allows access to the client orserver environment only by those individuals with appropriate authorizationcodes (e.g., userID and password).Security tests should be designed to probe each of these security technologies in aneffort to uncover security holes.The actual design of security tests requires in-depth knowledge of the inner work-ings of each security element and a comprehensive understanding of a full range ofnetworking technologies. In many cases, security testing is outsourced to firms thatspecialize in these technologies.
20.9 P ERFORMANCE TESTING
Nothing is more frustrating than a WebApp that takes minutes to load content whencompetitive sites download similar content in seconds. Nothing is more aggravatingthan trying to log on to a WebApp and receiving a “server-busy” message, with thesuggestion that you try again later. Nothing is more disconcerting than a WebAppthat responds instantly in some situations, and then seems to go into an infinite waitstate in other situations. All of these occurrences happen on the Web every day, andall of them are performance related.Performance testingis used to uncover performance problems that can result fromlack of server-side resources, inappropriate network bandwidth, inadequate data-base capabilities, faulty or weak operating system capabilities, poorly designedWebApp functionality, and other hardware or software issues that can lead todegraded client-server performance. The intent is twofold: (1) to understand how thesystem responds as loading(i.e., number of users, number of transactions, or over-all data volume) increases and (2) to collect metrics that will lead to design modifi-cations to improve performance.
20.9.1 Performance Testing Objectives
Performance tests are designed to simulate real-world loading situations. As thenumber of simultaneous WebApp users grows, or the number of online transactionsincreases, or the amount of data (downloaded or uploaded) increases, performancetesting will help answer the following questions:
•Does the server response time degrade to a point where it is noticeable andunacceptable?
•At what point (in terms of users, transactions, or data loading) does perform-ance become unacceptable?
•What system components are responsible for performance degradation?
•What is the average response time for users under a variety of loadingconditions?550 PART THREEQUALITY MANAGEMENT
Some aspects ofWebApp performance,at least as it isperceived by the enduser, are difficult totest. Network loading,the vagaries ofnetwork interfacinghardware, and similarissues are not easilytested at the WebApplevel.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 550•Does performance degradation have an impact on system security?
•Is WebApp reliability or accuracy affected as the load on the system grows?
•What happens when loads that are greater than maximum server capacityare applied?
•Does performance degradation have an impact on company revenues?To develop answers to these questions, two different performance tests areconducted: (1) load testingexamines real-world loading at a variety of load levelsand in a variety of combinations, and (2) stress testingforces loading to be in- creased to the breaking point to determine how much capacity the WebApp envi-ronment can handle. Each of these testing strategies is considered in the sectionsthat follow.
20.9.2 Load Testing
The intent of load testing is to determine how the WebApp and its server-sideenvironment will respond to various loading conditions. As testing proceeds,permutations to the following variables define a set of test conditions:N,number of concurrent usersT,number of online transactions per unit of timeD,data load processed by the server per transactionIn every case, these variables are defined within normal operating bounds of thesystem. As each test condition is run, one or more of the following measures arecollected: average user response, average time to download a standardized unit ofdata, or average time to process a transaction. You should examine these measuresto determine whether a precipitous decrease in performance can be traced to aspecific combination of N, T,andD.Load testing can also be used to assess recommended connection speedsfor users of the WebApp. Overall throughput, P, is computed in the following manner:P/H11005N/H11003T/H11003DAs an example, consider a popular sports news site. At a given moment, 20,000 con-current users submit a request (a transaction, T ) once every 2 minutes on average. Each transaction requires the WebApp to download a new article that averages 3Kbytes in length. Therefore, throughput can be calculated as:P/H11005[20,000 /H11003 0.5 /H110033Kb]/60 /H11005500 Kbytes/sec/H110054 megabits per secondThe network connection for the server would therefore have to support this data rateand should be tested to ensure that it does.CHAPTER 20TESTING WEB APPLICATIONS 551
If a WebApp usesmultiple servers toprovide significantcapacity, load testingmust be performed ina multiserverenvironment.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 55120.9.3 Stress Testing
Stress testingis a continuation of load testing, but in this instance the variables, N, T,andDare forced to meet and then exceed operational limits. The intent of these testsis to answer each of the following questions:
•Does the system degrade “gently,” or does the server shut down as capacityis exceeded?
•Does server software generate “server not available” messages? Moregenerally, are users aware that they cannot reach the server?
•Does the server queue resource requests and empty the queue once capacitydemands diminish?
•Are transactions lost as capacity is exceeded?
•Is data integrity affected as capacity is exceeded?
•What values of N, T,andDforce the server environment to fail? How doesfailure manifest itself? Are automated notifications sent to technical supportstaff at the server site?
•If the system does fail, how long will it take to come back online?
•Are certain WebApp functions (e.g., compute intensive functionality, datastreaming capabilities) discontinued as capacity reaches the 80 or 90 percentlevel?A variation of stress testing is sometimes referred to as spike/bounce testing[Spl01]. In this testing regime, load is spiked to capacity, then lowered quickly to nor-mal operating conditions, and then spiked again. By bouncing system loading, youcan determine how well the server can marshal resources to meet very high demandand then release them when normal conditions reappear (so that they are ready forthe next spike).552 PART THREEQUALITY MANAGEMENT
The intent of stresstesting is to betterunderstand how asystem fails as it isstressed beyond itsoperational limits.
Tools Taxonomy for WebApp Testing
In his paper on the testing of e-commercesystems, Lam [Lam01] presents a usefultaxonomy of automated tools that have direct applicabilityfor testing in a Web engineering context. We haveappended representative tools in each category.
14
Configuration and content management toolsmanage version and change control of WebApp contentobjects and functional component.Representative tool(s):Comprehensive list at www.daveeaton.com/scm/CMTools.htmlDatabase performance toolsmeasure databaseperformance, such as the time to perform selecteddatabase queries. These tools facilitate databaseoptimization.Representative tool(s):BMC Software(www.bmc.com)TOOLS
14 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In addition, tool names are registered trademarks of the companies noted.pre75977_ch20.qxd  11/28/08  10:22 AM  Page 552CHAPTER 20TESTING WEB APPLICATIONS 553
Debuggersare typical programming tools that findand resolve software defects in the code. They are partof most modern application development environments.Representative tool(s):Accelerated Technology(www.acceleratedtechnology.com ) Apple Debugging Tools(developer.apple.com/tools/performance/ ) IBM VisualAge Environment (www.ibm.com)Microsoft Debugging Tools (www.microsoft.com)Defect management systemsrecord defects andtrack their status and resolution. Some includereporting tools to provide management information ondefect spread and defect resolution rates.Representative tool(s):EXCEL Quickbigs (www.excelsoftware.com)ForeSoft BugTrack (www.bugtrack.net)McCabe TRUETrack (www.mccabe.com)Network monitoring toolswatch the level of networktraffic. They are useful for identifying networkbottlenecks and testing the link between front- andback-end systems.Representative tool(s):Comprehensive list atwww.slac.stanford.edu/xorg/nmtf/nmtf-tools.htmlRegression testing toolsstore test cases and testdata and can reapply the test cases after successivesoftware changes.Representative tool(s):Compuware QARun(www.compuware.com/products/qacenter/qarun)Rational VisualTest (www.rational.com)Seque Software (www.seque.com)Site monitoring toolsmonitor a site’s performance,often from a user perspective. Use them to compilestatistics such as end-to-end response time andthroughput and to periodically check a site’savailability.Representative tool(s):Keynote Systems(www.keynote.com)Stress toolshelp developers explore system behaviorunder high levels of operational usage and find asystem’s breakpoints.Representative tool(s):Mercury Interactive (www.merc-int.com)Open-source testing tools(www.opensourcetesting.org/performance.php)Web Performance Load Tester(www.webperformanceinc.com)System resource monitorsare part of most OSserver and Web server software; they monitorresources such as disk space, CPU usage, andmemory.Representative tool(s):Successful Hosting.com(www.successfulhosting.com)Quest Software Foglight (www.quest.com)Test data generation toolsassist users ingenerating test data.Representative tool(s):Comprehensive list atwww.softwareqatest.com/qatweb1.htmlTest result comparatorshelp compare the results ofone set of testing to that of another set. Use them tocheck that code changes have not introduced adversechanges in system behavior.Representative tool(s):Useful list at www.aptest.com/resources.htmlTransaction monitorsmeasure the performance ofhigh-volume transaction processing systems.Representative tool(s):QuotiumPro (www.quotium.com)Software Research eValid(www.soft.com/eValid/index.html )Website security toolshelp detect potential securityproblems. You can often set up security probing andmonitoring tools to run on a scheduled basis.Representative tool(s):Comprehensive list atwww
.timberlinetechnologies.com/products/www.html
20.10 S UMMARY
The goal of WebApp testing is to exercise each of the many dimensions of WebAppquality with the intent of finding errors or uncovering issues that may lead to qual-ity failures. Testing focuses on content, function, structure, usability, navigability,pre75977_ch20.qxd  11/28/08  10:22 AM  Page 553performance, compatibility, interoperability, capacity, and security. It incorporatesreviews that occur as the WebApp is designed, and tests that are conducted once theWebApp has been implemented.The WebApp testing strategy exercises each quality dimension by initially ex-amining “units” of content, functionality, or navigation. Once individual units havebeen validated, the focus shifts to tests that exercise the WebApp as a whole. Toaccomplish this, many tests are derived from the user’s perspective and are drivenby information contained in use cases. A WebApp test plan is developed and iden-tifies testing steps, work products (e.g., test cases), and mechanisms for the eval-uation of test results. The testing process encompasses seven different types oftesting.Content testing (and reviews) focus on various categories of content. The intentis to uncover both semantic and syntactic errors that affect the accuracy of contentor the manner in which it is presented to the end user. Interface testing exercises the interaction mechanisms that enable a user to communicate with the WebApp andvalidates aesthetic aspects of the interface. The intent is to uncover errors that resultfrom poorly implemented interaction mechanisms or from omissions, inconsisten-cies, or ambiguities in interface semantics.Navigation testing applies use cases, derived as part of the modeling activity, inthe design of test cases that exercise each usage scenario against the navigation de-sign. Navigation mechanisms are tested to ensure that any errors impeding comple-tion of a use case are identified and corrected. Component testing exercises contentand functional units within the WebApp.Configuration testing attempts to uncover errors and/or compatibility problemsthat are specific to a particular client or server environment. Tests are then con-ducted to uncover errors associated with each possible configuration. Security test-ing incorporates a series of tests designed to exploit vulnerabilities in the WebAppand its environment. The intent is to find security holes. Performance testingencompasses a series of tests that are designed to assess WebApp response time andreliability as demands on server-side resource capacity increase.
PROBLEMS AND POINTS TO PONDER
20.1.Are there any situations in which WebApp testing should be totally disregarded?20.2.In your own words, discuss the objectives of testing in a WebApp context.20.3.Compatibility is an important quality dimension. What must be tested to ensure thatcompatibility exists for a WebApp?20.4.Which errors tend to be more serious—client-side errors or server-side errors? Why?20.5.What elements of the WebApp can be “unit tested”? What types of tests must beconducted only after the WebApp elements are integrated?20.6.Is it always necessary to develop a formal written test plan? Explain.554 PART THREEQUALITY MANAGEMENTpre75977_ch20.qxd  11/28/08  10:22 AM  Page 55420.7.Is it fair to say that the overall WebApp testing strategy begins with user-visible elementsand moves toward technology elements? Are there exceptions to this strategy?20.8.Is content testing reallytesting in a conventional sense? Explain.20.9.Describe the steps associated with database testing for a WebApp. Is database testingpredominantly a client-side or server-side activity?20.10.What is the difference between testing that is associated with interface mechanismsand testing that addresses interface semantics?20.11.Assume that you are developing an online pharmacy (YourCornerPharmacy.com)that caters to senior citizens. The pharmacy provides typical functions, but also maintains adatabase for each customer so that it can provide drug information and warn of potential druginteractions. Discuss any special usability tests for this WebApp.20.12.Assume that you have implemented a drug interaction checking function forYourCornerPharmacy.com(Problem 20.11). Discuss the types of component-level tests thatwould have to be conducted to ensure that this function works properly. [Note: A databasewould have to be used to implement this function.]20.13.What is the difference between testing for navigation syntax and navigation semantics?20.14.Is it possible to test every configuration that a WebApp is likely to encounter on theserver side? On the client side? If it is not, how do you select a meaningful set of configurationtests?20.15.What is the objective of security testing? Who performs this testing activity?20.16. YourCornerPharmacy.com (Problem 20.11) has become wildly successful, and the number of users has increased dramatically in the first two months of operation. Draw a graphthat depicts probable response time as a function of number of users for a fixed set of server-side resources. Label the graph to indicate points of interest on the “response curve.”20.17.In response to it success YourCornerPharmacy.com(Problem 20.11) has imple- mented a special server solely to handle prescription refills. On average, 1000 concurrentusers submit a refill request once every two minutes. The WebApp downloads a 500-byteblock of data in response. What is the approximate required throughput for this server inmegabits per second?20.18.What is the difference between load testing and stress testing?
FURTHER READINGS AND INFORMATION SOURCES
The literature for WebApp testing continues to evolve. Books by Andrews and Whittaker (Howto Break Web Software,Addison-Wesley, 2006), Ash (The Web Testing Companion,Wiley, 2003), Nguyen and his colleagues (Testing Applications for the Web, 2d ed., Wiley, 2003), Dustin and his colleagues (Quality Web Systems, Addison-Wesley, 2002), and Splaine and Jaskiel [Spl01] are among the most complete treatments of the subject published to date. Mosley ( Client-Server Soft- ware Testing on the Desktop and the Web, Prentice Hall, 1999) addresses both client-side and server-side testing issues.Useful information on WebApp testing strategies and methods, as well as a worthwhilediscussion of automated testing tools is presented by Stottlemeyer (Automated Web TestingToolkit,Wiley, 2001). Graham and her colleagues (Software Test Automation, Addison-Wesley, 1999) present additional material on automated tools.Microsoft (Performance Testing Guidance for Web Applications, Microsoft Press, 2008) and Subraya (Integrated Approach to Web Performance Testing, IRM Press, 2006) present detailed treatments of performance testing for WebApps. Chirillo (Hack Attacks Revealed, 2d ed., Wiley, 2003), Splaine (Testing Web Security,Wiley, 2002), Klevinsky and his colleagues (Hack I.T.:CHAPTER 20TESTING WEB APPLICATIONS 555pre75977_ch20.qxd  11/28/08  10:22 AM  Page 555Security through Penetration Testing, Addison-Wesley, 2002), and Skoudis (Counter Hack, Prentice Hall, 2001) provide much useful information for those who must design security tests. In addi-tion, books that address security testing for software in general can provide important guidancefor those who must test WebApps. Representative titles include: Basta and Halton ( Computer Security and Penetration Testing,Thomson Delmar Learning, 2007), Wysopal and his colleagues(The Art of Software Security Testing, Addison-Wesley, 2006), and Gallagher and his colleagues (Hunting Security Bugs,Microsoft Press, 2006).A wide variety of information sources on WebApp testing is available on the Internet. Anup-to-date list of World Wide Web references relevant to WebApp testing can be found at theSEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.556 PART THREEQUALITY MANAGEMENTpre75977_ch20.qxd  11/28/08  10:22 AM  Page 556Unlike reviews and testing that begin once software models and code havebeen developed, formal modeling and verification incorporate specializedmodeling methods that are integrated with prescribed verificationapproaches. Without the appropriate modeling approach, verification cannot beaccomplished.In this chapter I discuss two formal modeling and verification methods—cleanroom software engineeringand formal methods. Both demand a specializedspecification approach and each applies a unique verification method. Both arequite rigorous and neither is used widely by the software engineering community.But if you intend to build bulletproof software, these methods can help youimmeasurably. They’re worth learning about.
557CHAPTER
21FORMAL MODELINGAND
VERIFICATION
What is it? How many times haveyou heard someone say, “Do it rightthe first time”? If we achieved thatin software, there’d be considerablyless effort expended on unnecessary softwarerework. Two advanced software engineeringmethods—cleanroom software engineering andformal methods—help a software team to “do itright the first time” by providing a mathemati-cally based approach to program modeling andthe ability to verify that the model is correct.Cleanroom software engineering emphasizesmathematical verification of correctness beforeprogram construction commences and certifica-tion of software reliability as part of the testingactivity. Formal methods use set theory and logicnotation to create a clear statement of facts(requirements) that can be analyzed to improve(or even prove) correctness and consistency. Thebottom line for both methods is the creation of soft-ware with extremely low failure rates.
Who does it? A specially trained software engineer.
Why is it important? Mistakes create rework.Rework takes time and increases costs. Wouldn’tit be nice if you could dramatically reduce thenumber of mistakes (bugs) introduced as theQUICK
LOOKsoftware is designed and built? That’s the prem-ise of formal modeling and verification.
What are the steps? Requirements and designmodels are created using specialized notationthat is amenable to mathematical verification.Cleanroom software engineering uses box struc-ture representation that encapsulates the system(or some aspect of the system) at a specific levelof abstraction. Correctness verification is ap-plied once the box structure design is complete.Once correctness has been verified for each boxstructure, statistical usage testing commences.Formal methods translate software requirementsinto a more formal representation by applyingthe notation and heuristics of sets to define thedata invariant, states, and operations for asystem function.
What is the work product? A specialized, for-mal model of requirements is developed. Theresults of correctness proofs and statistical usetests are recorded.
How do I ensure that I’ve done it right? Formalproof of correctness is applied to the require-ments model. Statistical use testing exercisesusage scenarios to ensure that errors in userfunctionality are uncovered and corrected.KEY
CONCEPTS
box structurespecification  . . .558certification  . . .567cleanroom design  . . . . . . .563cleanroom processmodel  . . . . . . .559correctnessverification . . . .559pre75977_ch21.qxd  11/27/08  6:18 PM  Page 557Cleanroom software engineeringis an approach that emphasizes the need to buildcorrectness into software as it is being developed. Instead of the classic analysis, de-sign, code, test, and debug cycle, the cleanroom approach suggests a different pointof view [Lin94b]: 
The philosophy behind cleanroom software engineering is to avoid dependence on costlydefect removal processes by writing code increments right the first time and verifyingtheir correctness before testing. Its process model incorporates the statistical qualitycertification of code increments as they accumulate into a system.
In many ways, the cleanroom approach elevates software engineering to anotherlevel by emphasizing the need to prove correctness.Models developed using formal methods are described using a formal syntax and semantics that specify system function and behavior. The specification is mathe-matical in form (e.g., predicate calculus can be used as the basis for a formal speci-fication language). In his introduction to formal methods, Anthony Hall [Hal90]makes a comment that applies equally to cleanroom methods:
Formal methods [and cleanroom software engineering] are controversial. Their advo-cates claim that they can revolutionize [software] development. Their detractors thinkthey are impossibly difficult. Meanwhile, for most people, formal methods [and clean-room software engineering] are so unfamiliar that it is difficult to judge the competingclaims.
In this chapter, I explore formal modeling and verification methods and examinetheir potential impact on software engineering in the years to come.
21.1 T HECLEANROOM STRATEGY
Cleanroom software engineering makes use of a specialized version of the incre-mental software model introduced in Chapter 2. A “pipeline of software increments”[Lin94b] is developed by small independent software teams. As each increment iscertified, it is integrated into the whole. Hence, functionality of the system growswith time.The sequence of cleanroom tasks for each increment is illustrated in Figure 21.1.Within the pipeline for cleanroom increments, the following tasks occur:Increment planning.A project plan that adopts the incremental strategy isdeveloped. The functionality of each increment, its projected size, and acleanroom development schedule are created. Special care must be taken toensure that certified increments will be integrated in a timely manner.Requirements gathering.Using techniques similar to those introduced inChapter 5, a more-detailed description of customer-level requirements (foreach increment) is developed.Box structure specification.A specification method that makes use ofbox structuresis used to describe the functional specification. Box structures558 PART THREEQUALITY MANAGEMENT
design refinement  . . . .563formal specificationlanguages  . . . .573functionalspecification  . . .560object constraintlanguage(OCL) . . . . . . . .574Z specificationlanguage  . . . . .577
uote:
“The only way forerrors to occur ina program is bybeing put there bythe author. Noother mechanismsare known. . . .Right practice aimsat preventinginsertion of errorsand, failing that,removing thembefore testing orany other runningof the program.”Harlan Millspre75977_ch21.qxd  11/27/08  6:18 PM  Page 558“isolate and separate the creative definition of behavior, data, and proce-dures at each level of refinement” [Hev93].Formal design.Using the box structure approach, cleanroom design is anatural and seamless extension of specification. Although it is possible tomake a clear distinction between the two activities, specifications (calledblack boxes) are iteratively refined (within an increment) to become analo-gous to architectural and component-level designs (called state boxes and clear boxes,respectively).Correctness verification.The cleanroom team conducts a series ofrigorous correctness verification activities on the design and then the code.Verification (Section 21.3.2) begins with the highest-level box structure(specification) and moves toward design detail and code. The first level ofcorrectness verification occurs by applying a set of “correctness questions”[Lin88]. If these do not demonstrate that the specification is correct, moreformal (mathematical) methods for verification are used.Code generation, inspection, and verification. The box structure speci- fications, represented in a specialized language, are translated into theappropriate programming language. Technical reviews (Chapter 15) are thenused to ensure semantic conformance of the code and box structures andsyntactic correctness of the code. Then correctness verification is conductedfor the source code.CHAPTER 21FORMAL MODELING AND VERIFICATION 559
BSSRGIncrement 1
SEFD CVTPCG CI
SUT C
BSSRGIncrement 2 FD CVTPCG CI
SUT C
BSSRGIncrement 3
SE — system engineeringRG — requirements gatheringBSS — box structure specificationFD — formal designCV — correctness verificationCG — code generationCI — code inspectionSUT — statistical use testingC — certificationTP — test planningFD CVTPCG CI
SUT CFIGURE 21.1
The cleanroomprocess model
WebRef
An excellent sourceof information andresources forcleanroom softwareengineering can befound at www.cleansoft.com.
uote:
”Cleanroomsoftwareengineeringachieves statisticalquality controlover softwaredevelopment bystrictly separatingthe design processfrom the testingprocess in apipeline ofincrementalsoftwaredevelopment.”Harlan Millspre75977_ch21.qxd  11/27/08  6:18 PM  Page 559Statistical test planning.The projected usage of the software is analyzed,and a suite of test cases that exercise a “probability distribution” of usage isplanned and designed (Section 21.4). Referring to Figure 21.1, this cleanroomactivity is conducted in parallel with specification, verification, and codegeneration.Statistical use testing.Recalling that exhaustive testing of computer soft-ware is impossible (Chapter 18), it is always necessary to design a finite num-ber of test cases. Statistical use techniques [Poo88] execute a series of testsderived from a statistical sample (the probability distribution noted earlier)of all possible program executions by all users from a targeted population(Section 21.4).Certification.Once verification, inspection, and usage testing have beencompleted (and all errors are corrected), the increment is certified as readyfor integration.The first four activities in the cleanroom process set the stage for the formal verifi-cation activities that follow. For this reason, I begin the discussion of the cleanroomapproach with the modeling activities that are essential for formal verification to beapplied.
21.2 F UNCTIONAL SPECIFICATION
The modeling approach in cleanroom software engineering uses a method calledbox structure specification.A “box” encapsulates the system (or some aspect of thesystem) at some level of detail. Through a process of elaboration or stepwise refine-ment, boxes are refined into a hierarchy where each box has referential trans-parency. That is, “the information content of each box specification is sufficient todefine its refinement, without depending on the implementation of any other box”[Lin94b]. This enables the analyst to partition a system hierarchically, moving fromessential representation at the top to implementation-specific detail at the bottom.Three types of boxes are used:Black box.The black box specifies the behavior of a system or a part of asystem. The system (or part) responds to specific stimuli (events) by applyinga set of transition rules that map the stimulus into a response.State box.The state box encapsulates state data and services (operations)in a manner that is analogous to objects. In this specification view, inputsto the state box (stimuli) and outputs (responses) are represented. The statebox also represents the “stimulus history” of the black box, that is, the dataencapsulated in the state box that must be retained between the transitionsimplied.Clear box.The transition functions that are implied by the state box aredefined in the clear box. Stated simply, a clear box contains the proceduraldesign for the state box.560 PART THREEQUALITY MANAGEMENT
Cleanroom emphasizestests that exercise theway software is reallyused. Use casesprovide input to thetest planning process.
uote:
“It’s a funny thingabout life: If yourefuse to acceptanything but thebest, you may veryoften get it.”W. SomersetMaugham
How isrefinementaccomplished aspart of a boxstructurespecification??pre75977_ch21.qxd  11/27/08  6:18 PM  Page 560Figure 21.2 illustrates the refinement approach using box structure specification.A black box (BB
1) defines responses for a complete set of stimuli. BB1can be refined into a set of black boxes, BB
1.1to BB1.n, each of which addresses a class of behavior.Refinement continues until a cohesive class of behavior is identified (e.g., BB
1.1.1). A state box (SB
1.1.1) is then defined for the black box (BB1.1.1). In this case, SB1.1.1contains all data and services required to implement the behavior defined by BB
1.1.1. Finally, SB
1.1.1is refined into clear boxes (CB1.1.1.n) and procedural design details are specified.As each of these refinement steps occurs, verification of correctness also occurs.State-box specifications are verified to ensure that each conforms to the behaviordefined by the parent black-box specification. Similarly, clear-box specifications areverified against the parent state box.
21.2.1 Black-Box Specification
A black-boxspecification describes an abstraction, stimuli, and response using thenotation shown in Figure 21.3 [Mil88]. The function f is applied to a sequence S*of inputs (stimuli) Sand transforms them into an output (response) R. For simple soft- ware components, fmay be a mathematical function, but in general, fis described using natural language (or a formal specification language).CHAPTER 21FORMAL MODELING AND VERIFICATION 561
BB1CB1.1.1.1
CB1.1.1.2
CB1.1.1.3SB1.1.1BB1.1.1
BB1.1.2
BB1.1.3BB1.1
BB1.2
BB1.nFIGURE 21.2
Box structurerefinement
Box structurerefinement andcorrectness verificationoccur simultaneously.f : S*          R S RFIGURE 21.3
A black-boxspecificationpre75977_ch21.qxd  11/27/08  6:18 PM  Page 561Many of the concepts introduced for object-oriented systems are also applicablefor the black box. Data abstractions and the operations that manipulate those ab-stractions are encapsulated by the black box. Like a class hierarchy, the black-boxspecification can exhibit usage hierarchies in which low-level boxes inherit the prop-erties of those boxes higher in the tree structure.
21.2.2 State-Box Specification
The state boxis “a simple generalization of a state machine” [Mil88]. Recalling thediscussion of behavioral modeling and state diagrams in Chapter 7, a state is someobservable mode of system behavior. As processing occurs, a system responds toevents (stimuli) by making a transition from the current state to some new state. Asthe transition is made, an action may occur. The state box uses a data abstraction todetermine the transition to the next state and the action (response) that will occur asa consequence of the transition.Referring to Figure 21.4 , the state box incorporates a black box g.The stimulus S that is input to the black box arrives from some external source and a set of internalsystem states T.Mills [Mil88] provides a mathematical description of the function fof the black box contained within the state box:g: S*/H11003T*→R/H11003Twhere gis a subfunction that is tied to a specific state t. When considered collectively,the state-subfunction pairs (t, g) define the black-box function f.
21.2.3 Clear-Box Specification
The clear-box specification is closely aligned with procedural design and structuredprogramming. In essence, the subfunction g within the state box is replaced by the structured programming constructs that implement g.As an example, consider the clear box shown in Figure 21.5. The black box g, shown in Figure 21.3, is replaced by a sequence construct that incorporates a conditional.562 PART THREEQUALITY MANAGEMENT
S R Black box, gTStateFIGURE 21.4
A state-boxspecificationpre75977_ch21.qxd  11/27/08  6:18 PM  Page 562These, in turn, can be refined into lower-level clear boxes as stepwise refinementproceeds.It is important to note that the procedural specification described in the clear-boxhierarchy can be proved to be correct. This topic is considered in Section 21.3.
21.3 C LEANROOM DESIGN
Cleanroom software engineering makes heavy use of the structured programmingphilosophy (Chapter 10). But in this case, structured programming is applied far morerigorously.Basic processing functions (described during earlier refinements of the specifica-tion) are refined using a “stepwise expansion of mathematical functions intostructures of logical connectives [e.g., if-then-else] and subfunctions, where theexpansion [is] carried out until all identified subfunctions could be directly stated inthe programming language used for implementation” [Dye92].The structured programming approach can be used effectively to refine function,but what about data design? Here a number of fundamental design concepts(Chapter 8) come into play. Program data are encapsulated as a set of abstractionsthat are serviced by subfunctions. The concepts of data encapsulation, informationhiding, and data typing are used to create the data design.
29.3.1 Design Refinement
Each clear-box specification represents the design of a procedure (subfunction)required to accomplish a state-box transition. Within the clear box, structured pro-gramming constructs and stepwise refinement are used to represent procedural de-tail. For example, a program function f is refined into a sequence of subfunctions g and h.These in turn are refined into conditional constructs (e.g., if-then-else and do-while). Further refinement continues until there is enough procedural detail to createthe component in question.CHAPTER 21FORMAL MODELING AND VERIFICATION 563
S RTState
g11cg1g12
g13FIGURE 21.5
A clear-boxspecificationpre75977_ch21.qxd  11/27/08  6:18 PM  Page 563At each level of refinement, the cleanroom team1performs a formal correctness verification.To accomplish this, a set of generic correctness conditions are attachedto the structured programming constructs. If a function f is expanded into a sequence gand h,the correctness condition for all input to f is
•Doesgfollowed byhdof?When a function pis refined into a conditional of the form, if < c> then q, else r, the correctness condition for all input to p is 
•Whenever condition/H11021c/H11022is true, doesqdop; and whenever /H11021c/H11022is false, doesrdop?When function mis refined as a loop, the correctness conditions for all input to mare 
•Is termination guaranteed?
•Whenever /H11021c/H11022is true, doesnfollowed bymdom; and whenever /H11021c/H11022is false, does skipping the loop still dom? Each time a clear box is refined to the next level of detail, these correctness condi-tions are applied.
21.3.2 Design Verification
You should note that the use of the structured programming constructs constrains thenumber of correctness tests that must be conducted. A single condition is checkedfor sequences; two conditions are tested for if-then-else, and three conditions areverified for loops.To illustrate correctness verification for a procedural design, we use a simpleexample first introduced by Linger, Mills, and Witt [Lin79]. The intent is to design andverify a small program that finds the integer part y of a square root of a given inte- ger x.The procedural design is represented using the flowchart in Figure 21.6.
2
To verify the correctness of this design, entry and exit conditions are added asshown in Figure 21.6. The entry condition notes that xmust be greater than or equal to 0. The exit condition requires that x remain unchanged and that ysatisfy the ex- pression noted in the figure. To prove the design to be correct, it is necessary to provethe conditions init, loop, cont, yes,and exitshown in Figure 21.6 are true in all cases. These are sometimes called subproofs.1.The condition initdemands that [x/H113500 and y/H110050]. Based on the requirements of the problem, the entry condition is assumed correct.
3Therefore, the first part of the initcondition, x/H113500, is satisfied. Referring to the flowchart, the564 PART THREEQUALITY MANAGEMENT
Whatconditionsare applied toprove structuredconstructscorrect??
If you limit yourself tojust the structuredconstructs as youdevelop a proceduraldesign, proof ofcorrectness is straight-forward. If you violatethe constructs, correct-ness proofs are difficultor impossible.
1 Because the entire team is involved in the verification process, it is less likely that an error will bemade in conducting the verification itself.2 Figure 21.6 has been adapted from [Lin94]. Used with permission.3 A negative value for the square root has no meaning in this context.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 564statement immediately preceding the init condition, sets y/H110050. Therefore, the second part of the initcondition is also satisfied. Hence, initis true. 2.The loopcondition may be encountered in one of two ways: (1) directly frominit(in this case, the loopcondition is satisfied directly) or via control flowthat passes through the condition cont. Since the contcondition is identical to the loopcondition, loopis true regardless of the flow path that leads to it.3.Thecontcondition is encountered only after the value of yis incremented by 1. In addition, the control flow path that leads to contcan be invoked only if the yescondition is also true. Hence, if (y/H110011)
2/H11349x, it follows that y2/H11349x. The contcondition is satisfied.4.The yescondition is tested in the conditional logic shown. Hence, the yescondition must be true when control flow moves along the path shown.5.Theexitcondition first demands thatxremain unchanged. An examination ofthe design indicates thatxappears nowhere to the left of an assignment oper-ator. There are no function calls that use x.Hence, it is unchanged. Since the conditional test (y/H110011)
2/H11349xmust fail to reach theexitcondition, it follows that (y/H110011)
2/H11349x. In addition, theloopcondition must still be true (i.e.,y2/H11349x). Therefore, (y/H110011)
2/H11022xandy2/H11349xcan be combined to satisfy the exit condition. You must further ensure that the loop terminates. An examination of the loop condition indicates that, because yis incremented and x/H113500, the loop must eventually terminate. The five steps just noted are a proof of the correctness of the design of the algo-rithm noted in Figure 21.6. You are now certain that the design will, in fact, computethe integer part of a square root.CHAPTER 21FORMAL MODELING AND VERIFICATION 565
y := y + 1 (y + 1)2 ≤ xy := 0sqrt
exit: x unchanged and y2 ≤ x ≤ (y + 1)2yes: (y + 1)2 ≤ xloop: [y2 ≤ x]cont: [y2 ≤ x]init:  [x ≥ 0, and y = 0]entry:  [x ≥ 0]FIGURE 21.6
Computing theinteger part ofa square rootSource: [Lin79].
To prove a design correct,you must first identify allconditions and then provethat each takes on theappropriate Booleanvalue. These are calledsubproofs.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 565A more rigorous mathematical approach to design verification is possible. How-ever, a discussion of this topic is beyond the scope of this book. If you have interest,refer to [Lin79].
21.4 C LEANROOM TESTING
The strategy and tactics of cleanroom testing are fundamentally different fromconventional testing approaches (Chapters 17 through 20). Conventional methodsderive a set of test cases to uncover design and coding errors. The goal of cleanroomtesting is to validate software requirements by demonstrating that a statistical sam-ple of use cases (Chapter 5) have been executed successfully.
21.4.1 Statistical Use Testing
The user of a computer program rarely needs to understand the technical details ofthe design. The user-visible behavior of the program is driven by inputs and eventsthat are often produced by the user. But in complex systems, the possible spectrumof input and events (i.e., the use cases) can be extremely broad. What subset of usecases will adequately verify the behavior of the program? This is the first questionaddressed by statistical use testing.Statistical use testing “amounts to testing software the way users intend to use it”[Lin94b]. To accomplish this, cleanroom testing teams (also called certification teams) must determine a usage probability distribution for the software. The specification(black box) for each increment of the software is analyzed to define a set of stimuli(inputs or events) that cause the software to change its behavior. Based on inter-views with potential users, the creation of usage scenarios, and a general under-standing of the application domain, a probability of use is assigned to each stimuli.Test cases are generated for each set of stimuli
4according to the usage probability distribution. To illustrate, consider the SafeHome system discussed earlier in this book. Cleanroom software engineering is being used to develop a software increment thatmanages user interaction with the security system keypad. Five stimuli have been iden-tified for this increment. Analysis indicates the percent probability distribution of eachstimulus. To make selection of test cases easier, these probabilities are mapped intointervals numbered between 1 and 99 [Lin94] and illustrated in the following table:
Program Stimulus Probability IntervalArm/disarm (AD)50%1–49 Zone set (ZS)15% 50–63Query (Q)15% 64–78Test (T)15% 79–94
Panic alarm5% 95–99566PART THREEQUALITY MANAGEMENT
uote:
“Quality is not anact, it is a habit.”Aristotle
Even if you decideagainst the cleanroomapproach, it’s worthconsidering statisticaluse testing as anintegral part of yourtest strategy.
4 Automated tools may be used to accomplish this. For further information, see [Dye92].pre75977_ch21.qxd  11/27/08  6:18 PM  Page 566To generate a sequence of usage test cases that conform to the usage probabilitydistribution, random numbers between 1 and 99 are generated. Each random num-ber corresponds to an interval on the preceding probability distribution. Hence, thesequence of usage test cases is defined randomly but corresponds to the appropri-ate probability of stimuli occurrence. For example, assume the following random-number sequences are generated: 13-94-22-24-45-5681-19-31-69-45-938-21-52-84-86-4Selecting the appropriate stimuli based on the distribution interval shown in thetable, the following use cases are derived:AD–T–AD–AD–AD–ZST–AD–AD–AD–Q–AD–ADAD–AD–ZS–T–T–ADThe testing team executes these use cases and verifies software behavior against thespecification for the system. Timing for tests is recorded so that interval times maybe determined. Using interval times, the certification team can compute mean-time-to-failure. If a long sequence of tests is conducted without failure, the MTTF is lowand software reliability may be assumed high.
21.4.2 Certification
The verification and testing techniques discussed earlier in this chapter lead to soft-ware components (and entire increments) that can be certified. Within the context ofthe cleanroom software engineering approach, certification implies that the reliabil- ity [measured by mean-time-to-failure (MTTF)] can be specified for each component.The potential impact of certifiable software components goes far beyond asingle cleanroom project. Reusable software components can be stored alongwith their usage scenarios, program stimuli, and probability distributions. Eachcomponent would have a certified reliability under the usage scenario and testingregime described. This information is invaluable to others who intend to use thecomponents.The certification approach involves five steps [Woh94]: (1) usage scenarios mustbe created, (2) a usage profile is specified, (3) test cases are generated from the pro-file, (4) tests are executed and failure data are recorded and analyzed, and (5) relia-bility is computed and certified. Steps 1 through 4 have been discussed in an earliersection. Certification for cleanroom software engineering requires the creation ofthree models [Poo93]: Sampling model.Software testing executes mrandom test cases and is certified if no failures or a specified numbers of failures occur. The value of mis derived mathematically to ensure that required reliability is achieved.CHAPTER 21FORMAL MODELING AND VERIFICATION 567
How do wecertify asoftwarecomponent??pre75977_ch21.qxd  11/27/08  6:18 PM  Page 567Component model.A system composed of ncomponents is to be certi- fied. The component model enables the analyst to determine the probabilitythat component iwill fail prior to completion.Certification model.The overall reliability of the system is projected andcertified.At the completion of statistical use testing, the certification team has the informationrequired to deliver software that has a certified MTTF computed using each of thesemodels. If you have further interest, see [Cur86], [Mus87], or [Poo93] for additionaldetail.
21.5 F ORMAL METHODS CONCEPTS
The Encyclopedia of Software Engineering [Mar01] defines formal methods in the following manner: 
Formal methods used in developing computer systems are mathematically based tech-niques for describing system properties. Such formal methods provide frameworks withinwhich people can specify, develop, and verify systems in a systematic, rather than ad hocmanner.
The desired properties of a formal specification—consistency, completeness, andlack of ambiguity—are the objectives of all specification methods. However, themathematically based specification language used for formal methods results in amuch higher likelihood of achieving these properties. The formal syntax of a speci-fication language (Section 21.7) enables requirements or design to be interpreted inonly one way, eliminating ambiguity that often occurs when a natural language(e.g., English) or a graphical notation (e.g., UML) must be interpreted by a reader. Thedescriptive facilities of set theory and logic notation enable a clear statement ofrequirements. To be consistent, requirements stated in one place in a specificationshould not be contradicted in another place. Consistency is achieved
5by mathemat- ically proving that initial facts can be formally mapped (using inference rules) intolater statements within the specification.To introduce basic formal methods concepts, let’s consider a few simple exam-ples to illustrate the use of mathematical specification, without getting bogged downin too much mathematical detail.Example 1: A symbol table.A program is used to maintain a symbol table. Sucha table is used frequently in many different types of applications. It consists of a col-lection of items without any duplication. An example of a typical symbol table is568 PART THREEQUALITY MANAGEMENT
uote:
“Formal methodshave tremendouspotential forimproving theclarity andprecision ofrequirementsspecifications,and in findingimportant andsubtle errors.”SteveEasterbrooket al.
5 In reality, completeness is difficult to ensure, even when formal methods are used. Some aspectsof a system may be left undefined as the specification is being created; other characteristics may bepurposely omitted to allow designers some freedom in choosing an implementation approach; andfinally, it is impossible to consider every operational scenario in a large, complex system. Thingsmay simply be omitted by mistake.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 568shown in Figure 21.7. It represents the table used by an operating system to hold thenames of the users of the system. Other examples of tables include the collection ofnames of staff in a payroll system, the collection of names of computers in a networkcommunications system, and the collection of destinations in a system for produc-ing transportation timetables.Assume that the table presented in this example consists of no more than MaxIdsnames. This statement, which places a constraint on the table, is a component of acondition known as a data invariant. A data invariant is a condition that is truethroughout the execution of the system that contains a collection of data. The datainvariant that holds for the symbol table just discussed has two components: (1) thatthe table will contain no more than MaxIds names and (2) that there will be no du- plicate names in the table. In the case of the symbol table program, this means thatno matter when the symbol table is examined during execution of the system, it willalways contain no more than MaxIdsnames and will contain no duplicates.Another important concept is that of a state. Many formal languages, such as OCL (Section 21.7.1), use the notion of states as they were discussed in Chapter 7; that is,a system can be in one of several states, each representing an externally observablemode of behavior. However, a different definition for the term state is used in the Z language (Section 21.7.2). In Z (and related languages), the state of a system is rep-resented by the system’s stored data (hence, Z suggests a much larger number ofstates, representing each possible configuration of the data). Using the latter defini-tion in the example of the symbol table program, the state is the symbol table.The final concept is that of an operation. This is an action that takes place within a system and reads or writes data. If the symbol table program is concerned with addingand removing names from the symbol table, then it will be associated with two oper-ations: an operation to add()a specified name to the symbol table and an operationto remove()an existing name from the table.
6If the program provides the facility toCHAPTER 21FORMAL MODELING AND VERIFICATION 569
1.2.3.4.5.6.7.8.9.10.WilsonSimpsonAbelFernandez
MaxIds = 10FIGURE 21.7
A symbol table
A data invariant is aset of conditions thatare true throughout theexecution of thesystem that containsa collection of data.
Another way of lookingat the notion of thestate is to say thatdata determines state.That is, you canexamine data to seewhat state the systemis in.
6 It should be noted that adding a name cannot occur in the full state and deleting a name is impos- sible in the emptystate.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 569check whether a specific name is contained in the table, then there would be anoperation that would return some indication of whether the name is in the table.Three types of conditions can be associated with operations: invariants, precon-ditions, and postconditions. An invariant defines what is guaranteed not to change. For example, the symbol table has an invariant that states that the number ofelements is always less than or equal to MaxIds. A preconditiondefines the circum- stances in which a particular operation is valid. For example, the precondition for anoperation that adds a name to a staff identifier symbol table is valid only if the namethat is to be added is not contained in the table and also if there are fewer thanMaxIdsstaff identifiers in the table. The postcondition of an operation defines what is guaranteed to be true upon completion of an operation. This is defined by its effecton the data. For the add()operation, the postcondition would specify mathematicallythat the table has been augmented with the new identifier.Example 2: A block handler.One of the more important parts of a simple oper-ating system is the subsystem that maintains files created by users. Part of the filingsubsystem is the block handler.Files in the file store are composed of blocks of stor-age that are held on a file storage device. During the operation of the computer, fileswill be created and deleted, requiring the acquisition and release of blocks of storage.In order to cope with this, the filing subsystem will maintain a reservoir of unused(free) blocks and keep track of blocks that are currently in use. When blocks are re-leased from a deleted file, they are normally added to a queue of blocks waiting to beadded to the reservoir of unused blocks. This is shown in Figure 21.8. In this figure, anumber of components are shown: the reservoir of unused blocks, the blocks thatcurrently make up the files administered by the operating system, and those blocksthat are waiting to be added to the reservoir. The waiting blocks are held in a queue,with each element of the queue containing a set of blocks from a deleted file.570 PART THREEQUALITY MANAGEMENT
1  3  4  6  9
File #15  8  11File #27File #3 Block queue containing blocks from deleted filesUnused blocks
2Queued for entry into unused blocks2  5  7  8  1011  12Used blocks
Blocks are releasedto queue when filesare deletedFIGURE 21.8
A blockhandlerpre75977_ch21.qxd  11/27/08  6:18 PM  Page 570For this subsystem the state is the collection of free blocks, the collection of usedblocks, and the queue of returned blocks. The data invariant, expressed in naturallanguage, is 
•No block will be marked as both unused and used.
•All the sets of blocks held in the queue will be subsets of the collection ofcurrently used blocks.
•No elements of the queue will contain the same block numbers.
•The collection of used blocks and blocks that are unused will be the totalcollection of blocks that make up files.
•The collection of unused blocks will have no duplicate block numbers.
•The collection of used blocks will have no duplicate block numbers.Some of the operations associated with this data are: add() a collection of blocks to the end of the queue, remove()a collection of used blocks from the front of the queueand place them in the collection of unused blocks, and check()whether the queue of blocks is empty.The precondition of add()is that the blocks to be added must be in the collectionof used blocks. The postcondition is that the collection of blocks is now found at theend of the queue. The precondition of remove() is that the queue must have at least one item in it. The postcondition is that the blocks must be added to the collectionof unused blocks. The check()operation has no precondition. This means that the op-eration is always defined, regardless of what value the state is. The postcondition de-livers the value trueif the queue is empty and falseotherwise. In the examples noted in this section, I introduce the key concepts of formal spec-ification but without emphasizing the mathematics that are required to make thespecification formal. In Section 21.6, I consider how mathematical notation can beused to formally specify some element of a system.
21.6 A PPLYING MATHEMATICAL NOTATION7FOR
FORMAL SPECIFICATION
To illustrate the use of mathematical notation in the formal specification of a soft-ware component, we revisit the block handler example presented in Section 21.5. Toreview, an important component of a computer’s operating system maintains filesthat have been created by users. The block handler maintains a reservoir of unusedblocks and will also keep track of blocks that are currently in use. When blocks arereleased from a deleted file, they are normally added to a queue of blocks waiting toCHAPTER 21FORMAL MODELING AND VERIFICATION 571
Brain storming tech-niques can work wellwhen you mustdevelop a datainvariant for a reason-ably complex function.Have members of thesoftware team writebounds, restrictions,and limitations for thefunction and thencombine and edit.
7 I have written this section making the assumption that you are familiar with the mathematical no-tation associated with sets and sequences and the logical notation used in predicate calculus. If youneed a review, a brief overview is presented as a supplementary resource at the 7th edition web-site. For more detailed information, see [Jec06] or [Pot04].pre75977_ch21.qxd  11/27/08  6:18 PM  Page 571be added to the reservoir of unused blocks. This has been depicted schematically inFigure 21.8.A set named BLOCKSwill consist of every block number. AllBlocks is a set of blocks that lie between 1 and MaxBlocks. The state will be modeled by two sets and a sequence. The two sets are usedand free. Both contain blocks—the usedset con- tains the blocks that are currently used in files, and the free set contains blocks that are available for new files. The sequence will contain sets of blocks that are ready tobe released from files that have been deleted. The state can be described asused, free: /H11936BLOCKSBlockQueue: seq/H11936BLOCKSThis is very much like the declaration of program variables. It states that used and freewill be sets of blocks and that BlockQueue will be a sequence, each element of which will be a set of blocks. The data invariant can be written asused/H20669free/H11005∅/H11625used/H20668free/H11005AllBlocks/H11625/H7001i:dom BlockQueue• BlockQueue i/H20661used/H11625 /H7001i, j: dom BlockQueue• i/HS11005j/H11005BlockQueue i/H20669BlockQueue j/H11005∅ The mathematical components of the data invariant match four of the bulleted,natural-language components described earlier. The first line of the data invariantstates that there will be no common blocks in the used collection and free collectionsof blocks. The second line states that the collection of used blocks and free blockswill always be equal to the whole collection of blocks in the system. The third lineindicates the ith element in the block queue will always be a subset of the usedblocks. The final line states that, for any two elements of the block queue that arenot the same, there will be no common blocks in these two elements. The final twonatural language components of the data invariant are implemented by virtue of thefact that usedand freeare sets and therefore will not contain duplicates.The first operation to be defined is one that removes an element from the head ofthe block queue. The precondition is that there must be at least one item in the queue:#BlockQueue /H110220,The postcondition is that the head of the queue must be removed and placed in thecollection of free blocks and the queue adjusted to show the removal:used′/H11005used\ head BlockQueue/H11625free′/H11005free/H20668head BlockQueue/H11625BlockQueue
′/H11005tail BlockQueueA convention used in many formal methods is that the value of a variable after an op-eration is primed. Hence, the first component of the preceding expression states thatthe new used blocks (used’) will be equal to the old used blocks minus the blocks thathave been removed. The second component states that the new free blocks ( free’)572 PART THREEQUALITY MANAGEMENT
WebRef
Extensive informationof formal methodscan be found atwww.afm.sbu.ac.uk.How can Irepresentstates and datainvariants using aset and logicoperators??pre75977_ch21.qxd  11/27/08  6:18 PM  Page 572will be the old free blocks with the head of the block queue added to it. The third com-ponent states that the new block queue will be equal to the tail of the old value of theblock queue, that is, all elements in the queue apart from the first one. A secondoperation adds a collection of blocks,Ablocks,to the block queue. The precondition is thatAblocksis currently a set of used blocks:Ablocks/H20661usedThe postcondition is that the set of blocks is added to the end of the block queue andthe set of used and free blocks remains unchanged: BlockQueue′/H11005BlockQueue/H6114/H20855Ablocks/H20856/H11625 used′/H11005used/H11625free′/H11005freeThere is no question that the mathematical specification of the block queue isconsiderably more rigorous than a natural language narrative or a graphical model.The additional rigor requires effort, but the benefits gained from improved consis-tency and completeness can be justified for some application domains.
21.7 F ORMAL SPECIFICATION LANGUAGES
A formal specification language is usually composed of three primary components:(1) a syntax that defines the specific notation with which the specification is repre-sented, (2) semantics to help define a ”universe of objects” [Win90] that will be usedto describe the system, and (3) a set of relations that define the rules that indicatewhich objects properly satisfy the specification.The syntactic domain of a formal specification language is often based on a syn-tax that is derived from standard set theory notation and predicate calculus. Thesemantic domainof a specification language indicates how the language representssystem requirements.It is possible to use different semantic abstractions to describe the same system indifferent ways. We did this in a less formal fashion in Chapters 6 and 7. Information,function, and behavior were each represented. Different modeling notation can beused to represent the same system. The semantics of each representation providescomplementary views of the system. To illustrate this approach when formal meth-ods are used, assume that a formal specification language is used to describe the setof events that cause a particular state to occur in a system. Another formal relationdepicts all functions that occur within a given state. The intersection of these two re-lations provides an indication of the events that will cause specific functions to occur.A variety of formal specification languages are in use today. OCL [OMG03b], Z[ISO02], LARCH [Gut93], and VDM [Jon91] are representative formal specificationlanguages that exhibit the characteristics noted previously. In this chapter, I presenta brief discussion of OCL and Z.CHAPTER 21FORMAL MODELING AND VERIFICATION 573
How do Irepresentpre- andpostconditions??pre75977_ch21.qxd  11/27/08  6:18 PM  Page 573574 PART THREEQUALITY MANAGEMENT
8 This section has been contributed by Professor Timothy Lethbridge of The University of Ottawa andis presented here with permission.TABLE 21.1 SUMMARY OF KEY OCL NOTATION
x.yObtain the property y of object x. A property can be anattribute, the set of objects at the end of an association, theresult of evaluating an operation, or other things depending onthe type of UML diagram. If x is a Set, then y is applied toevery element of x; the results are collected into a new Set.c/H11002/H11022f()Apply the built-in OCL operation f to Collection c itself (asopposed to each of the objects in c). Examples of built-inoperations are listed below.and, or, /H11005, /H11021/H11022Logical and, logical or, equals, not-equals.p implies qTrue if either q is true or p is false.
Sample of Operations on Collections (including Sets and Sequences)C/H11002/H11022size()The number of elements in Collection c.C/H11002/H11022isEmpty()True if c has no elements, false otherwise.c1/H11002/H11022includesAll(c2)True if every element of c2 is found in c1.c1/H11002/H11022excludesAll(c2)True if no element of c2 is found in c1.C/H11002/H11022forAll(elem | boolexpr)True if boolexpr is true when applied to every element of c. Asan element is being evaluated, it is bound to the variable elem,which can be used in boolexpr. This implements universalquantification, discussed earlier.C/H11002/H11022forAll(elem1, elem2 | boolexpr) Same as above, except that boolexpr is evaluated for everypossible pairof elements taken from c, including cases wherethe pair consists of the same element.C/H11002/H11022isUnique(elem | expr)True if expr evaluates to a different value when applied toevery element of c.
Sample of Operations Specific to Setss1/H11002/H11022intersection(s2)The set of those elements found s1 and also in s2.s1/H11002/H11022union(s2)The set of those elements found in either s1 or s2.s1/H11002/H11022excluding(x)The set s1 with object x omitted.
Sample Operation Specific to Sequences
Seq/H11002/H11022first()The object that is the first element in the sequence seq.
21.7.1 Object Constraint Language (OCL)8
Object Constraint Language(OCL) is a formal notation developed so that users of UMLcan add more precision to their specifications. All of the power of logic and discretemathematics is available in the language. However, the designers of OCL decidedthat only ASCII characters (rather than conventional mathematical notation) shouldpre75977_ch21.qxd  11/27/08  6:18 PM  Page 574be used in OCL statements. This makes the language more friendly to people whoare less mathematically inclined, and more easily processed by computer. But it alsomakes OCL a little wordy in places.To use OCL, you start with one or more UML diagrams—most commonly class, state,or activity diagrams (Appendix 1). OCL expressions are added and state facts aboutelements of the diagrams. These expressions are called constraints; any implementa- tion derived from the model must ensure each of the constraints always remains true.Like an object-oriented programming language, an OCL expression involvesoperators operating on objects. However, the result of a complete expression mustalways be a Boolean, that is, true or false. The objects can be instances of the OCLCollectionclass, of which Setand Sequenceare two subclasses. The object selfis the element of the UML diagram in the context of which the OCLexpression is being evaluated. Other objects can be obtained by navigating using the . (dot) symbol from the selfobject. For example: 
•If selfis class C, with attribute a, then self.aevaluates to the object stored in a.
•If Chas a one-to-many association called assocto another class D, then self.assocevaluates to a Setwhose elements are of type D.
•Finally (and a little more subtly), if Dhas attribute b, then the expression self.assoc.bevaluates to the set of all the b’s belonging to all D’s. OCL provides built-in operations implementing set and logic operators, constructivespecification, and related mathematics. A small sample of these is presented inTable 21.1.To illustrate the use of OCL in specification, we reexamine the block handlerexample, introduced in Section 21.5. The first step is to develop a UML model(Figure 21.9). This class diagram specifies many relationships among the objectsinvolved. However, OCL expressions are added to allow implementers of the systemto know more precisely what must remain true as the system runs.CHAPTER 21FORMAL MODELING AND VERIFICATION 575
11BlockBlockSet
BlockHandler*****1
11blockQueue{orderd}freeallBlocks{subset}{subset}usedelements
addBlock( )removeBlock( )numberFIGURE 21.9
Class diagramfor a blockhandlerpre75977_ch21.qxd  11/27/08  6:18 PM  Page 575The OCL expressions that supplement the class diagram correspond to the sixparts of the invariant discussed in Section 21.5. In the example that follows, the in-variant is repeated in English and then the corresponding OCL expression is written.It is considered good practice to provide natural language text along with the formallogic; doing so helps you to understand the logic, and also helps reviewers to un-cover mistakes, e.g., situations where English and the logic do not correspond.1.No block will be marked as both unused and used.
context BlockHandler inv:
(self.used/H11002/H11022intersection(self.free)) /H11002/H11022isEmpty()Note that each expression starts with the key word context. This indicates the element of the UML diagram that the expression constrains. Alternatively,you could place the constraint directly on the UML diagram, surrounded bybraces {}. The keyword selfhere refers to the instance of BlockHandler; in the following, as is permissible in OCL, we will omit the self.2.All the sets of blocks held in the queue will be subsets of the collection ofcurrently used blocks.
context BlockHandler inv:
blockQueue/H11002/H11022forAll(aBlockSet | used/H11002/H11022includesAll(aBlockSet ))3.No elements of the queue will contain the same block numbers.
context BlockHandler inv:
blockQueue/H11002/H11022forAll(blockSet1, blockSet2 |blockSet1 /H11021/H11022blockSet2 impliesblockSet1.elements.number/H11002/H11022excludesAll(blockSet2elements.number))The expression before impliesis needed to ensure we ignore pairs where bothelements are the same block.4.The collection of used blocks and blocks that are unused will be the total collec-tion of blocks that make up files.
context BlockHandler inv:
allBlocks /H11005used/H11002/H11022union(free)5.The collection of unused blocks will have no duplicate block numbers.
context BlockHandler inv:
free/H11002/H11022isUnique(aBlock | aBlock.number)6.The collection of used blocks will have no duplicate block numbers.
context BlockHandler inv:
used/H11002/H11022isUnique(aBlock | aBlock.number)OCL can also be used to specify preconditions and postconditions of operations. Forexample, the following describes operations that remove and add sets of blocks to576 PART THREEQUALITY MANAGEMENTpre75977_ch21.qxd  11/27/08  6:18 PM  Page 576the queue. Note that the notation x@pre indicates the object xas it existed priorto the operation; this is opposite to mathematical notation discussed earlier, where it is the xafterthe operation that is specially designated (as x’).
context BlockHandler::removeBlocks()
pre: blockQueue /H11002/H11022size() /H110220post: used /H11005used
@pre-blockQueue @pre/H11002/H11022first() andfree = free
@pre/H11002/H11022union(blockQueue @pre/H11002/H11022first()) andblockQueue /H11005blockQueue
@pre/H11002/H11022excluding(blockQueue @pre/H11002/H11022first)
context BlockHandler::addBlocks(aBlockSet :BlockSet)
pre: used/H11002/H11022includesAll(aBlockSet.elements)post: (blockQueue.elements /H11005blockQueue.elements
@pre /H11002/H11022append (aBlockSet.elements) andused /H11005used
@pre andfree /H11005free
@preOCL is a modeling language, but it has all of the attributes of a formal language. OCLallows the expression of various constraints, pre- and postconditions, guards, andother characteristics that relate to the objects represented in various UML models.
21.7.2 The Z Specification Language
Z (properly pronounced as “zed”) is a specification language that is widely usedwithin the formal methods community. The Z language applies typed sets, relations,and functions within the context of first-order predicate logic to build schemas—ameans for structuring the formal specification.Z specifications are organized as a set of schemas—a language structure that in-troduces variables and specifies the relationship between these variables. A schemais essentially the formal specification analog of the programming language compo-nent. Schemas are used to structure a formal specification in the same way that com-ponents are used to structure a system.A schema describes the stored data that a system accesses and alters. In the con-text of Z, this is called the “state.” This usage of the term state in Z is slightly differ- ent from the use of the word in the rest of this book.
9In addition, the schema identifies the operations that are applied to change state and the relationships thatoccur within the system. The generic structure of a schema takes the form:——— schemaName——————————————declarations———————————————————————invariant————————————————————————CHAPTER 21FORMAL MODELING AND VERIFICATION 577
WebRef
Detailed informationabout the Z languagecan be found atwww.users.cs.york.ac.uk/~susan/abs/z.htm.
9 Recall that in other chapters state has been used to identify an externally observable mode of be- havior for a system.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 577where declarations identify the variables that comprise the system state and theinvariant imposes constraints on the manner in which the state can evolve. A sum-mary of Z language notation is presented in Table 21.2.578 PART THREEQUALITY MANAGEMENT
TABLE 21.2 SUMMARY OF Z NOTATION
Z notation is based on typed set theory and first-order logic. Z provides a construct, called a schema, todescribe a specification’s state space and operations. A schema groups variable declarations with a listof predicates that constrain the possible value of a variable. In Z, the schema X is defined by the form———X–––––––––––—————————————declarations——————————————————————predicates——————————————————————Global functions and constants are defined by the formdeclarations——————————————————————predicatesThe declaration gives the type of the function or constant, while the predicate gives it value. Only anabbreviated set of Z symbols is presented in this table.Sets:S: /H11936XSis declared as a set of Xs.X/H33528Sx is a member of S.x
/HV20678Sx is not a member of S.S
/H20661TSis a subset of T: Every member of Sis also in T. S
/H20668TThe union of Sand T: It contains every member of Sor Tor both. S
/H20669TThe intersection of Sand T: It contains every member of both Sand T. S\ TThe difference of Sand T: It contains every member of Sexcept those also in T.
/H11083 Empty set: It contains no members.{x} Singleton set: It contains just x./H11934The set of natural numbers 0, 1, 2, ....S: /H11926XSis declared as a finite set of Xs. max (S) The maximum of the nonempty set of numbers S.Functions:f:X
>→Yfis declared as a partial injection from Xto Y. dom fThe domain of f: the set of values xfor which f(x) is defined. ran fThe range of f: the set of values taken by f(x) as x varies over the domain of f. f/H17053{xı→y} A function that agrees with fexcept that xis mapped to y. {x} /H17008
–fA function like f, except that xis removed from its domain.Logic:P/H11625 QPand Q: It is true if both Pand Qare true. P⇒QPimplies Q: It is true if either Qis true or Pis false.
/H9258S’ /H11005/H9258SNo components of schema Schange in an operation.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 578The following example of a schema describes the state of the block handler andthe data invariant:——— BlockHandler ————————————— ——— —— — — —— —— —used, free: /H11936BLOCKSBlockQueue: seq /H11936BLOCKSused/H20669free/H11005/H11632/H11625used/H20668free/H11005AllBlocks/H11625/H7001i: domBlockQueue• BlockQueue i/H20661used/H11625 /H7001i, j: dom BlockQueue• i/HS11005j/H11005/H11022BlockQueue i/H20669BlockQueue j/H11005/H11632 ————————————————————————————————As we have noted, the schema consists of two parts. The part above the central linerepresents the variables of the state, while the part below the central line describesthe data invariant. Whenever the schema specifies operations that change the state,it is preceded by the /H9004symbol. The following example of a schema describes theoperation that removes an element from the block queue:——— RemoveBlocks ———————————————/H9004BlockHandler————————————————————————— ——#BlockQueue /H110220,used′/H11005used\ head BlockQueue/H11625free′/H11005free/H20668head BlockQueue/H11625BlockQueue′/H11005tail BlockQueue————————————————————————— ——The inclusion of /H9004BlockHandlerresults in all variables that make up the state beingavailable for the RemoveBlocksschema and ensures that the data invariant will holdbefore and after the operation has been executed.The second operation, which adds a collection of blocks to the end of the queue,is represented as———AddBlocks——————————————————/H9004BlockHandlerAblocks? : BLOCKS———————————————————————— ———Ablocks?/H20661usedBloc
kQueue′/H11005BlockQueue/H6114/H20855Ablocks?/H20856/H11625 used′/H11005used/H11625free′/H11005free—————————————————————————— —By convention in Z, an input variable that is read, but does not form part of the state,is terminated by a question mark. Thus, Ablocks?, which acts as an input parameter,is terminated by a question mark.CHAPTER 21FORMAL MODELING AND VERIFICATION 579pre75977_ch21.qxd  11/27/08  6:18 PM  Page 57921.8 S UMMARY
Cleanroom software engineering is a formal approach to software development thatcan lead to software that has remarkably high quality. It uses box structure specifi-cation for analysis and design modeling and emphasizes correctness verification,rather than testing, as the primary mechanism for finding and removing errors.Statistical use testing is applied to develop the failure rate information necessary tocertify the reliability of delivered software.The cleanroom approach begins with analysis and design models that use a boxstructure representation. A “box” encapsulates the system (or some aspect of thesystem) at a specific level of abstraction. Black boxes are used to represent theexternally observable behavior of a system. State boxes encapsulate state data andoperations. A clear box is used to model the procedural design that is implied by thedata and operations of a state box.Correctness verification is applied once the box structure design is complete. Theprocedural design for a software component is partitioned into a series of subfunc-tions. To prove the correctness of the subfunctions, exit conditions are defined foreach subfunction and a set of subproofs is applied. If each exit condition is satisfied,the design must be correct.Once correctness verification is complete, statistical use testing commences.Unlike conventional testing, cleanroom software engineering does not emphasizeunit or integration testing. Rather, the software is tested by defining a set of usagescenarios, determining the probability of use for each scenario, and then definingrandom tests that conform to the probabilities. The error records that result are580 PART THREEQUALITY MANAGEMENT
Formal Methods
Objective:The objective of formal methodstools is to assist a software team in specificationand correctness verification.Mechanics:Tools mechanics vary. In general, tools assistin specification and automating correctness proving,usually by defined a specialized language for theoremproving. Many tools are not commercialized and havebeen developed for research purposes.Representative Tools:
10
ACL2,developed at the University of Texas(www.cs.utexas.edu/users/moore/acl2/), isSOFTWARE TOOLS
“both a programming language in which you canmodel computer systems and a tool to help you proveproperties of those models.”EVES,developed by ORA Canada(www.ora.on.ca/eves.html), implements theVerdi language for formal specification and anautomated proof generator.An extensive list of over 90 formal methods tools can befound at http://vl.fmnet.info/.
10 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch21.qxd  11/27/08  6:18 PM  Page 580combined with sampling, component, and certification models to enable mathe-matical computation of projected reliability for the software component.Formal methods use the descriptive facilities of set theory and logic notation to en-able a software engineer to create a clear statement of facts (requirements). The un-derlying concepts that govern formal methods are: (1) the data invariant, a conditiontrue throughout the execution of the system that contains a collection of data; (2) thestate, a representation of a system’s externally observable mode of behavior, or (in Zand related languages) the stored data that a system accesses and alters; and (3) theoperation, an action that takes place in a system and reads or writes data to a state.An operation is associated with two conditions: a precondition and a postcondition.Will cleanroom software engineering or formal methods ever be widely used? Theanswer is “probably not.” They are more difficult to learn than conventional softwareengineering methods and represent significant “culture shock” for some softwarepractitioners. But the next time you hear someone lament, “Why can’t we get thissoftware right the first time?” you’ll know that there are techniques that can help youto do exactly that.
PROBLEMS AND POINTS TO PONDER
21.1.If you had to pick one aspect of cleanroom software engineering that makes it radicallydifferent from conventional or object-oriented software engineering approaches, what would itbe?21.2.How do an incremental process model and certification work together to produce high-quality software?21.3.Using box structure specification, develop “first-pass” analysis and design models for theSafeHomesystem.21.4.A bubble-sort algorithm is defined in the following manner:
procedure bubblesort;var i, t, integer;beginrepeat until t/H11005a[1]t:/H11005a[1];for j:/H110052 to n doif a[j-1] /H11022a[j] then begint:/H11005a[j-1];a[j-1]:/H11005a[j];a[j]:/H11005t;endendrepend
Partition the design into subfunctions, and define a set of conditions that would enable you toprove that this algorithm is correct.21.5.Document a correctness verification proof for the bubble sort discussed in Problem 21.4.21.6.Select a program that you use regularly (e.g., an e-mail handler, a word processor, aspreadsheet program). Create a set of usage scenarios for the program. Define the probability ofCHAPTER 21FORMAL MODELING AND VERIFICATION 581pre75977_ch21.qxd  11/27/08  6:18 PM  Page 581use for each scenario, and then develop a program stimuli and probability distribution tablesimilar to the one shown in Section 21.4.1.21.7.For the program stimuli and probability distribution table developed in Problem 21.6, usea random-number generator to develop a set of test cases for use in statistical use testing.21.8.In your own words, describe the intent of certification in the cleanroom software engi-neering context.21.9.You have been assigned to a team that is developing software for a fax modem. Your jobis to develop the “phone book” portion of the application. The phone book function enables upto MaxNamespeople to be stored along with associated company names, fax numbers, andother related information. Using natural language, definea. The data invariant.b. The state.c. The operations that are likely.21.10.You have been assigned to a software team that is developing software, called Memo-ryDoubler, that provides greater apparent memory for a PC than physical memory. This isaccomplished by identifying, collecting, and reassigning blocks of memory that have beenassigned to an existing application but are not being used. The unused blocks are reassigned toapplications that require additional memory. Making appropriate assumptions and using naturallanguage, definea. The data invariant.b. The state.c. The operations that are likely.21.11.Using the OCL or Z notation presented in Table 21.1 or 21.2, select some part of theSafeHomesecurity system described earlier in this book and attempt to specify it with OCL or Z.21.12.Using one or more of the information sources noted in the references to this chapter orFurther Readings and Information Sources, develop a half-hour presentation on the basic syntax and semantics of a formal specification language other than OCL or Z.
FURTHER READINGS AND INFORMATION SOURCES
Relatively few books on advanced specification and verification techniques have been pub-lished in recent years. However, some new additions to the literature are worth considering. Abook edited by Gabbar (Modern Formal Methods and Applications, Springer, 2006) presents both fundamentals, new developments, and advanced applications. Jackson ( Software Abstractions, The MIT Press, 2006) presents all of the basics and an approach that he calls “lightweight for-mal methods.” Monin and Hinchey (Understanding Formal Methods, Springer, 2003) provide an excellent introduction to the subject. Butler and other editors (Integrated Formal Methods,Springer, 2002) present a variety of papers on formal methods topics.In addition to books referenced in this chapter, Prowell and his colleagues ( Cleanroom Software Engineering: Technology and Process, Addison-Wesley, 1999) provide an in-depth treatment of all important aspects of the cleanroom approach. Useful discussions of clean-room topics have been edited by Poore and Trammell (Cleanroom Software Engineering:A Reader,Blackwell Publishing, 1996). Becker and Whittaker ( Cleanroom Software Engineering Practices,Idea Group Publishing, 1996) present an excellent overview for those who are unfa-miliar with cleanroom practices.The Cleanroom Pamphlet (Software Technology Support Center, Hill AF Base, April 1995)contains reprints of a number of important articles. The Data and Analysis Center for Software(DACS) (www.dacs.dtic.mil) provides many useful papers, guidebooks, and other informationsources on cleanroom software engineering.Design verification via proof of correctness lies at the heart of the cleanroom approach.Books by Cupillari (The Nuts and Bolts of Proofs, 3d ed., Academic Press, 2005), Solow (How to582 PART THREEQUALITY MANAGEMENTpre75977_ch21.qxd  11/27/08  6:18 PM  Page 582Read and Do Proofs,4th ed., Wiley, 2004), Eccles (An Introduction to Mathematical Reasoning,Cambridge University Press, 1998), provide excellent introductions into the mathematicalbasics. Stavely (Toward Zero-Defect Software, Addison-Wesley, 1998), Baber (Error-Free Software, Wiley, 1991), and Schulmeyer (Zero Defect Software, McGraw-Hill, 1990) discuss proof of cor- rectness in considerable detail.In the formal methods domain, books by Casey ( A Programming Approach to Formal Methods, McGraw-Hill, 2000), Hinchey and Bowan ( Industrial Strength Formal Methods, Springer-Verlag, 1999), Hussmann (Formal Foundations for Software Engineering Methods, Springer-Verlag, 1997), and Sheppard (An Introduction to Formal Specification with Z and VDM, McGraw-Hill, 1995) provide useful guidance. In addition, language-specific books such as Warmer and Kleppe ( Object Con- straint Language,Addison-Wesley, 1998), Jacky (The Way of Z: Practical Programming with Formal Methods,Cambridge University Press, 1997), Harry (Formal Methods Fact File: VDM and Z, Wiley, 1997), and Cooper and Barden (Z in Practice,Prentice-Hall, 1995) provide useful introductions to formal methods as well as a variety of modeling languages.A wide variety of information sources on cleanroom software engineering and formal meth-ods is available on the Internet. An up-to-date list of World Wide Web references relevant toformal modeling and verification can be found at the SEPA website: www.mhhe.com/engcs/ compsci/pressman/professional/olc/ser.htm .CHAPTER 21FORMAL MODELING AND VERIFICATION 583pre75977_ch21.qxd  11/27/08  6:18 PM  Page 583Change is inevitable when computer software is built. And change in-creases the level of confusion when you and other members of a softwareteam are working on a project. Confusion arises when changes are notanalyzed before they are made, recorded before they are implemented, reportedto those with a need to know, or controlled in a manner that will improve qualityand reduce error. Babich [Bab86] discusses this when he states:
The art of coordinating software development to minimize . . . confusion is calledconfiguration management. Configuration management is the art of identifying,organizing, and controlling modifications to the software being built by a program-ming team. The goal is to maximize productivity by minimizing mistakes.
Software configuration management (SCM) is an umbrella activity that isapplied throughout the software process. Because change can occur at any time,
584CHAPTER
22SOFTWARE CONFIGURATION
MANAGEMENT
KEY
CONCEPTS
baselines  . . . . .587change control . .596configuration audit  . . . . . . . .599configuration object  . . . . . . .589content management . . .603identification . . .594repository  . . . .590SCM process . . .593
What is it? When you build com-puter software, change happens.And because it happens, you need tomanage it effectively. Software con-figuration management (SCM), also calledchange management, is a set of activities de-signed to manage change by identifying thework products that are likely to change, estab-lishing relationships among them, definingmechanisms for managing different versions ofthese work products, controlling the changesimposed, and auditing and reporting on thechanges made.
Who does it? Everyone involved in the softwareprocess is involved with change management tosome extent, but specialized support positions aresometimes created to manage the SCM process.
Why is it important? If you don’t controlchange, it controls you. And that’s never good.It’s very easy for a stream of uncontrolledchanges to turn a well-run software project intochaos. As a consequence, software quality suf-fers and delivery is delayed. For that reason,QUICK
LOOKchange management is an essential part ofquality management.
What are the steps? Because many work prod-ucts are produced when software is built, eachmust be uniquely identified. Once this is accom-plished, mechanisms for version and changecontrol can be established. To ensure that qual-ity is maintained as changes are made, theprocess is audited; and to ensure that those witha need to know are informed about changes,reporting is conducted.
What is the work product? A Software Configu-ration Management Plan defines the projectstrategy for change management. In addition,when formal SCM is invoked, the change controlprocess produces software change requests,reports, and engineering change orders.
How do I ensure that I’ve done it right? Whenevery work product can be accounted for,traced, and controlled; when every change canbe tracked and analyzed; when everyonewho needs to know about a change has beeninformed—you’ve done it right.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 584SCM activities are developed to (1) identify change, (2) control change, (3) ensurethat change is being properly implemented, and (4) report changes to others whomay have an interest.It is important to make a clear distinction between software support and softwareconfiguration management. Support is a set of software engineering activities thatoccur after software has been delivered to the customer and put into operation.Software configuration management is a set of tracking and control activities thatare initiated when a software engineering project begins and terminates only whenthe software is taken out of operation.A primary goal of software engineering is to improve the ease with which changescan be accommodated and reduce the amount of effort expended when changesmust be made. In this chapter, I discuss the specific activities that enable you to man-age change.
22.1 S OFTWARE CONFIGURATION MANAGEMENT
The output of the software process is information that may be divided into threebroad categories: (1) computer programs (both source level and executable forms),(2) work products that describe the computer programs (targeted at various stake-holders), and (3) data or content (contained within the program or external to it). Theitems that comprise all information produced as part of the software process arecollectively called a software configuration.As software engineering work progresses, a hierarchy of software configurationitems(SCIs)—a named element of information that can be as small as a single UMLdiagram or as large as the complete design document—is created. If each SCI simplyled to other SCIs, little confusion would result. Unfortunately, another variable en-ters the process—change.Change may occur at any time, for any reason. In fact, theFirst Law of System Engineering[Ber80] states: “No matter where you are in the sys-tem life cycle, the system will change, and the desire to change it will persistthroughout the life cycle.”What is the origin of these changes? The answer to this question is as varied asthe changes themselves. However, there are four fundamental sources of change:
•New business or market conditions dictate changes in product requirementsor business rules.
•New stakeholder needs demand modification of data produced by informa-tion systems, functionality delivered by products, or services delivered by acomputer-based system.
•Reorganization or business growth/downsizing causes changes in projectpriorities or software engineering team structure.
•Budgetary or scheduling constraints cause a redefinition of the system orproduct.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 585softwareconfiguration items(SCIs)  . . . . . . .589status reporting  . . . . .600version control  . . . . . . .595WebAppconfiguration objects . . . . . . .603WebApps  . . . . .601
uote:
“There is nothingpermanent exceptchange.”Heraclitus,500
B.C.
What is theorigin ofchanges that arerequested forsoftware??pre75977_ch22.qxd  11/27/08  6:20 PM  Page 585Software configuration management is a set of activities that have been devel-oped to manage change throughout the life cycle of computer software. SCM can beviewed as a software quality assurance activity that is applied throughout the soft-ware process. In the sections that follow, I describe major SCM tasks and importantconcepts that can help you to manage change.
22.1.1 An SCM Scenario1
A typical CM operational scenario involves a project manager who is in charge of asoftware group, a configuration manager who is in charge of the CM procedures andpolicies, the software engineers who are responsible for developing and maintain-ing the software product, and the customer who uses the product. In the scenario,assume that the product is a small one involving about 15,000 lines of code being de-veloped by a team of six people. (Note that other scenarios of smaller or larger teamsare possible, but, in essence, there are generic issues that each of these projects faceconcerning CM.)At the operational level, the scenario involves various roles and tasks. For theproject manager, the goal is to ensure that the product is developed within a certaintime frame. Hence, the manager monitors the progress of development and recog-nizes and reacts to problems. This is done by generating and analyzing reports aboutthe status of the software system and by performing reviews on the system.The goals of the configuration manager are to ensure that procedures and poli-cies for creating, changing, and testing of code are followed, as well as to makeinformation about the project accessible. To implement techniques for maintainingcontrol over code changes, this manager introduces mechanisms for making officialrequests for changes, for evaluating them (via a Change Control Board that isresponsible for approving changes to the software system), and for authorizingchanges. The manager creates and disseminates task lists for the engineers andbasically creates the project context. Also, the manager collects statistics about com-ponents in the software system, such as information determining which componentsin the system are problematic.For the software engineers, the goal is to work effectively. This means engineersdo not unnecessarily interfere with each other in the creation and testing of code andin the production of supporting work products. But, at the same time, they try to com-municate and coordinate efficiently. Specifically, engineers use tools that help builda consistent software product. They communicate and coordinate by notifying oneanother about tasks required and tasks completed. Changes are propagated acrosseach other’s work by merging files. Mechanisms exist to ensure that, for componentsthat undergo simultaneous changes, there is some way of resolving conflicts and586 PART THREEQUALITY MANAGEMENT
1 This section is extracted from [Dar01]. Special permission to reproduce “Spectrum of Functionalityin CM System” by Susan Dart [Dar01], © 2001 by Carnegie Mellon University is granted by the Soft-ware Engineering Institute.What are thegoals of andthe activitiesperformed byeach of theconstituenciesinvolved in changemanagement??
There must be amechanism to ensurethat simultaneouschanges to the samecomponent areproperly tracked,managed, andexecuted.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 586merging changes. A history is kept of the evolution of all components of the systemalong with a log with reasons for changes and a record of what actually changed.The engineers have their own workspace for creating, changing, testing, and inte-grating code. At a certain point, the code is made into a baseline from which furtherdevelopment continues and from which variants for other target machines are made.The customer uses the product. Since the product is under CM control, the cus-tomer follows formal procedures for requesting changes and for indicating bugs inthe product.Ideally, a CM system used in this scenario should support all these roles and tasks;that is, the roles determine the functionality required of a CM system. The projectmanager sees CM as an auditing mechanism; the configuration manager sees it as acontrolling, tracking, and policy making mechanism; the software engineer sees itas a changing, building, and access control mechanism; and the customer sees it asa quality assurance mechanism.
22.1.2 Elements of a Configuration Management System
In her comprehensive white paper on software configuration management, SusanDart [Dar01] identifies four important elements that should exist when a configura-tion management system is developed:
•Component elements—a set of tools coupled within a file management system(e.g., a database) that enables access to and management of each softwareconfiguration item.
•Process elements—a collection of actions and tasks that define an effectiveapproach to change management (and related activities) for all constituencies involved in the management, engineering, and use ofcomputer software.
•Construction elements—a set of tools that automate the construction ofsoftware by ensuring that the proper set of validated components (i.e., thecorrect version) have been assembled.
•Human elements—a set of tools and process features (encompassing otherCM elements) used by the software team to implement effective SCM.These elements (to be discussed in more detail in later sections) are not mutuallyexclusive. For example, component elements work in conjunction with constructionelements as the software process evolves. Process elements guide many humanactivities that are related to SCM and might therefore be considered human elementsas well.
22.1.3 Baselines
Change is a fact of life in software development. Customers want to modify require-ments. Developers want to modify the technical approach. Managers want to mod-ify the project strategy. Why all this modification? The answer is really quite simple.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 587pre75977_ch22.qxd  11/27/08  6:20 PM  Page 587As time passes, all constituencies know more (about what they need, which ap-proach would be best, and how to get it done and still make money). This additionalknowledge is the driving force behind most changes and leads to a statement of factthat is difficult for many software engineering practitioners to accept: Most changesare justified!A baselineis a software configuration management concept that helps you to con-trol change without seriously impeding justifiable change. The IEEE (IEEE Std. No.610.12-1990) defines a baseline as:
A specification or product that has been formally reviewed and agreed upon, that there-after serves as the basis for further development, and that can be changed only throughformal change control procedures.
Before a software configuration item becomes a baseline, changes may be madequickly and informally. However, once a baseline is established, changes can bemade, but a specific, formal procedure must be applied to evaluate and verify eachchange.In the context of software engineering, a baseline is a milestone in the developmentof software. A baseline is marked by the delivery of one or more software configurationitems that have been approved as a consequence of a technical review (Chapter 15).For example, the elements of a design model have been documented and reviewed.Errors are found and corrected. Once all parts of the model have been reviewed,corrected, and then approved, the design model becomes a baseline. Further changesto the program architecture (documented in the design model) can be made only aftereach has been evaluated and approved. Although baselines can be defined at any levelof detail, the most common software baselines are shown in Figure 22.1.588 PART THREEQUALITY MANAGEMENT
SCIs
SCIsModified
SoftwareengineeringtasksTechnicalreviewsSCIsApproved
SCIsExtractedSCMcontrolsSCIsStoredProject database
System SpecificationSoftware RequirementsDesign Specification Source CodeTest Plans/Procedures/DataOperational System   BASELINES:FIGURE 22.1
Baselined SCIsand theprojectdatabaseMost software changesare justified, so there’sno point incomplaining aboutthem. Rather, becertain that you havemechanisms in placeto handle them.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 588The progression of events that lead to a baseline is also illustrated in Fig-ure 22.1. Software engineering tasks produce one or more SCIs. After SCIs are re-viewed and approved, they are placed in a project database (also called a project libraryor software repositoryand discussed in Section 22.2). When a member of asoftware engineering team wants to make a modification to a baselined SCI, it iscopied from the project database into the engineer’s private workspace. However,this extracted SCI can be modified only if SCM controls (discussed later in thischapter) are followed. The arrows in Figure 22.1 illustrate the modification pathfor a baselined SCI.
22.1.4 Software Configuration Items
I have already defined a software configuration item as information that is createdas part of the software engineering process. In the extreme, a SCI could be consid-ered to be a single section of a large specification or one test case in a large suite oftests. More realistically, an SCI is all or part of a work product (e.g., a document, anentire suite of test cases, or a named program component).In addition to the SCIs that are derived from software work products, many soft-ware engineering organizations also place software tools under configuration con-trol. That is, specific versions of editors, compilers, browsers, and other automatedtools are “frozen” as part of the software configuration. Because these tools wereused to produce documentation, source code, and data, they must be available whenchanges to the software configuration are to be made. Although problems are rare,it is possible that a new version of a tool (e.g., a compiler) might produce differentresults than the original version. For this reason, tools, like the software that theyhelp to produce, can be baselined as part of a comprehensive configuration man-agement process.In reality, SCIs are organized to form configuration objects that may be cata-loged in the project database with a single name. A configuration object has a name, attributes, and is “connected” to other objects by relationships. Referring toFigure 22.2, the configuration objects, DesignSpecification, DataModel,ComponentN, SourceCode,and TestSpecificationare each defined sepa- rately. However, each of the objects is related to the others as shown by thearrows. A curved arrow indicates a compositional relation. That is, DataModel and ComponentNare part of the object DesignSpecification.A double-headed straight arrow indicates an interrelationship. If a change were made to theSourceCodeobject, the interrelationships enable you to determine what otherobjects (and SCIs) might be affected.
2CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 589
Be sure that theproject database ismaintained in acentralized, controlledlocation.
2 These relationships are defined within the database. The structure of the database (repository) isdiscussed in greater detail in Section 22.2.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 58922.2 T HESCM R EPOSITORY
In the early days of software engineering, software configuration items were main-tained as paper documents (or punched computer cards!), placed in file folders orthree-ring binders, and stored in metal cabinets. This approach was problematic formany reasons: (1) finding a configuration item when it was needed was often diffi-cult, (2) determining which items were changed, when and by whom was often chal-lenging, (3) constructing a new version of an existing program was time consumingand error prone, and (4) describing detailed or complex relationships between con-figuration items was virtually impossible.Today, SCIs are maintained in a project database or repository. Webster’s Dictio-narydefines the word repositoryas “any thing or person thought of as a center ofaccumulation or storage.” During the early history of software engineering, therepository was indeed a person—the programmer who had to remember the loca-tion of all information relevant to a software project, who had to recall informationthat was never written down and reconstruct information that had been lost. Sadly,using a person as “the center for accumulation and storage” (although it conformsto Webster’s definition) does not work very well. Today, the repository is a “thing”—a database that acts as the center for both accumulation and storage of software en-gineering information. The role of the person (the software engineer) is to interactwith the repository using tools that are integrated with it.
22.2.1 The Role of the Repository
The SCM repository is the set of mechanisms and data structures that allow asoftware team to manage change in an effective manner. It provides the obvious590 PART THREEQUALITY MANAGEMENT
DesignSpecificationdata designarchitectural designmodule designinterface design
ComponentNinterface descriptionalgorithm descriptionPDL DataModel
TestSpecification
test plantest proceduretest cases
SourceCodeFIGURE 22.2
Configurationobjectspre75977_ch22.qxd  11/27/08  6:20 PM  Page 590functions of a modern database management system by ensuring data integrity,sharing, and integration. In addition, the SCM repository provides a hub for the inte-gration of software tools, is central to the flow of the software process, and can en-force uniform structure and format for software engineering work products.To achieve these capabilities, the repository is defined in terms of a meta-model.The meta-modeldetermines how information is stored in the repository, how datacan be accessed by tools and viewed by software engineers, how well data securityand integrity can be maintained, and how easily the existing model can be extendedto accommodate new needs.
22.2.2 General Features and Content
The features and content of the repository are best understood by looking at it from twoperspectives: what is to be stored in the repository and what specific services are pro-vided by the repository. A detailed breakdown of types of representations, documents,and other work products that are stored in the repository is presented in Figure 22.3.A robust repository provides two different classes of services: (1) the same typesof services that might be expected from any sophisticated database managementsystem and (2) services that are specific to the software engineering environment.A repository that serves a software engineering team should also (1) integrate withor directly support process management functions, (2) support specific rules thatgovern the SCM function and the data maintained within the repository, (3) providean interface to other software engineering tools, and (4) accommodate storage ofsophisticated data objects (e.g., text, graphics, video, audio).CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 591
Business rulesBusiness functionsOrganization structureInformation architecture
Project estimatesProject scheduleSCM requirements Change requests Change reportsSQA requirementsProject reports/audit reportsProject metricsUse casesAnalysis model Scenario-based diagrams Flow-oriented diagrams Class-based diagrams Behavioral diagramsDesign model Architectural diagrams Interface diagrams Component-level diagramsTechnical metricsSource codeObject codeSystem build instructionsTest casesTest scriptsTest resultsQuality metrics
Project planSCM/SQA planSystem specRequirements specDesign documentTest plan and procedureSupport documentsUser manualProjectmanagementcontentDocumentsModelcontentConstructioncontent
V & VcontentBusinesscontentFIGURE 22.3
Content of therepositoryWebRef
An example of acommercially availablerepository can beobtained atwww.oracle.com/technology/products/repository/index.html.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 59122.2.3 SCM Features
To support SCM, the repository must have a tool set that provides support for the fol-lowing features:Versioning.As a project progresses, many versions (Section 22.3.2) of individualwork products will be created. The repository must be able to save all of these ver-sions to enable effective management of product releases and to permit developersto go back to previous versions during testing and debugging.The repository must be able to control a wide variety of object types, includingtext, graphics, bit maps, complex documents, and unique objects like screen and re-port definitions, object files, test data, and results. A mature repository tracks ver-sions of objects with arbitrary levels of granularity; for example, a single datadefinition or a cluster of modules can be tracked.Dependency tracking and change management. The repository manages a wide variety of relationships among the data elements stored in it. These includerelationships between enterprise entities and processes, among the parts of an appli-cation design, between design components and the enterprise information architec-ture, between design elements and deliverables, and so on. Some of these relationshipsare merely associations, and some are dependencies or mandatory relationships.The ability to keep track of all of these relationships is crucial to the integrity ofthe information stored in the repository and to the generation of deliverables basedon it, and it is one of the most important contributions of the repository concept tothe improvement of the software process. For example, if a UML class diagram ismodified, the repository can detect whether related classes, interface descriptions,and code components also require modification and can bring affected SCIs to thedeveloper’s attention.Requirements tracing.This special function depends on link management andprovides the ability to track all the design and construction components and deliv-erables that result from a specific requirements specification (forward tracing). Inaddition, it provides the ability to identify which requirement generated any givenwork product (backward tracing).Configuration management.A configuration management facility keeps trackof a series of configurations representing specific project milestones or productionreleases.Audit trails.An audit trail establishes additional information about when, why,and by whom changes are made. Information about the source of changes can beentered as attributes of specific objects in the repository. A repository trigger mech-anism is helpful for prompting the developer or the tool that is being used to initiateentry of audit information (such as the reason for a change) whenever a design ele-ment is modified.592 PART THREEQUALITY MANAGEMENT
The repository must becapable of maintainingSCIs related to manydifferent versions ofthe software. Moreimportant, it mustprovide themechanisms forassembling these SCIsinto a version-specificconfiguration.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 59222.3 T HESCM P ROCESS
The software configuration management process defines a series of tasks that havefour primary objectives: (1) to identify all items that collectively define the softwareconfiguration, (2) to manage changes to one or more of these items, (3) to facilitatethe construction of different versions of an application, and (4) to ensure that soft-ware quality is maintained as the configuration evolves over time.A process that achieves these objectives need not be bureaucratic or ponderous,but it must be characterized in a manner that enables a software team to develop an-swers to a set of complex questions:
•How does a software team identify the discrete elements of a softwareconfiguration?
•How does an organization manage the many existing versions of a program(and its documentation) in a manner that will enable change to be accommo-dated efficiently?
•How does an organization control changes before and after software isreleased to a customer?
•Who has responsibility for approving and ranking requested changes?
•How can we ensure that changes have been made properly?
•What mechanism is used to apprise others of changes that are made?These questions lead to the definition of five SCM tasks—identification, version con-trol, change control, configuration auditing, and reporting—illustrated in Figure 22.4.Referring to the figure, SCM tasks can viewed as concentric layers. SCIs flowoutward through these layers throughout their useful life, ultimately becoming partCHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 593
uote:
“Any change, evena change for thebetter, isaccompanied bydrawbacks anddiscomforts.”Arnold Bennett
Whatquestionsshould the SCMprocess bedesigned toanswer??
SoftwareVm.nReportingVersion controlChange controlIdentificationConfiguration auditing
SCIsFIGURE 22.4
Layers of theSCM processpre75977_ch22.qxd  11/27/08  6:20 PM  Page 593of the software configuration of one or more versions of an application or system.As an SCI moves through a layer, the actions implied by each SCM task may or maynot be applicable. For example, when a new SCI is created, it must be identified.However, if no changes are requested for the SCI, the change control layer does notapply. The SCI is assigned to a specific version of the software (version control mech-anisms come into play). A record of the SCI (its name, creation date, version desig-nation, etc.) is maintained for configuration auditing purposes and reported to thosewith a need to know. In the sections that follow, we examine each of these SCMprocess layers in more detail.
22.3.1 Identification of Objects in the Software Configuration
To control and manage software configuration items, each should be separatelynamed and then organized using an object-oriented approach. Two types of objectscan be identified [Cho89]: basic objects and aggregate objects.
3A basic objectis a unit of information that you create during analysis, design, code, or test. For example, abasic object might be a section of a requirements specification, part of a designmodel, source code for a component, or a suite of test cases that are used to exer-cise the code. An aggregate objectis a collection of basic objects and other aggregateobjects. For example, a DesignSpecification is an aggregate object. Conceptually, it can be viewed as a named (identified) list of pointers that specify aggregate objectssuch as ArchitecturalModeland DataModel,and basic objectssuch asCompo- nentNandUMLClassDiagramN.Each object has a set of distinct features that identify it uniquely: a name, adescription, a list of resources, and a “realization.” The object name is a characterstring that identifies the object unambiguously. The object description is a list of dataitems that identify the SCI type (e.g., model element, program, data) represented bythe object, a project identifier, and change and/or version information. Resourcesare “entities that are provided, processed, referenced or otherwise required by theobject” [Cho89]. For example, data types, specific functions, or even variable namesmay be considered to be object resources. The realization is a pointer to the “unit oftext” for a basic object and null for an aggregate object.Configuration object identification can also consider the relationships that existbetween named objects. For example, using the simple notation
Class diagram/H11021part-of/H11022requirements model;Requirements model/H11021part-of/H11022requirements specification;
you can create a hierarchy of SCIs.594 PART THREEQUALITY MANAGEMENT
The interrelationshipsestablished forconfiguration objectsallow you to assess theimpact of change.
3 The concept of an aggregate object [Gus89] has been proposed as a mechanism for representing acomplete version of a software configuration.pre75977_ch22.qxd  11/27/08  6:20 PM  Page 594In many cases, objects are interrelated across branches of the object hierarchy.These cross-structural relationships can be represented in the following manner:
DataModel/H11021interrelated/H11022DataFlowModelDataModel/H11021interrelated/H11022TestCaseClassM
In the first case, the interrelationship is between a composite object, while the sec-ond relationship is between an aggregate object (DataModel) and a basic object(TestCaseClassM).The identification scheme for software objects must recognize that objects evolvethroughout the software process. Before an object is baselined, it may change manytimes, and even after a baseline has been established, changes may be quite frequent.
22.3.2 Version Control
Version control combines procedures and tools to manage different versions of con-figuration objects that are created during the software process. A version control sys-tem implements or is directly integrated with four major capabilities: (1) a projectdatabase (repository) that stores all relevant configuration objects, (2) a version man- agementcapability that stores all versions of a configuration object (or enables anyversion to be constructed using differences from past versions), (3) a make facilitythat enables you to collect all relevant configuration objects and construct a specificversion of the software. In addition, version control and change control systems of-ten implement an issues tracking(also called bug tracking) capability that enables theteam to record and track the status of all outstanding issues associated with eachconfiguration object.A number of version control systems establish a change set—a collection of allchanges (to some baseline configuration) that are required to create a specific ver-sion of the software. Dart [Dar91] notes that a change set “captures all changes to allfiles in the configuration along with the reason for changes and details of who madethe changes and when.”A number of named change sets can be identified for an application or system. Thisenables you to construct a version of the software by specifying the change sets (byname) that must be applied to the baseline configuration. To accomplish this, a system modelingapproach is applied. The system model contains: (1) a templatethat includes a component hierarchy and a “build order” for the components that describes how thesystem must be constructed, (2) construction rules, and (3) verification rules.
4
A number of different automated approaches to version control have been pro-posed over the last few decades. The primary difference in approaches is the sophis-tication of the attributes that are used to construct specific versions and variants of asystem and the mechanics of the process for construction.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 595
Even if the projectdatabase provides theability to establishthese relationships,they are time consum-ing to establish anddifficult to keep up-to-date. Although veryuseful for impactanalysis, they are notessential for overallchange management.
4 It is also possible to query the system model to assess how a change in one component will impactother components.pre75977_ch22.qxd  11/27/08  6:21 PM  Page 59522.3.3 Change Control
The reality of change control in a modern software engineering context has beensummed up beautifully by James Bach [Bac98]:
Change control is vital. But the forces that make it necessary also make it annoying. Weworry about change because a tiny perturbation in the code can create a big failure in theproduct. But it can also fix a big failure or enable wonderful new capabilities. We worryabout change because a single rogue developer could sink the project; yet brilliant ideasoriginate in the minds of those rogues, and a burdensome change control process couldeffectively discourage them from doing creative work.
Bach recognizes that we face a balancing act. Too much change control and wecreate problems. Too little, and we create other problems.For a large software project, uncontrolled change rapidly leads to chaos. For suchprojects, change control combines human procedures and automated tools to pro-vide a mechanism for the control of change. The change control process is illustratedschematically in Figure 22.5. A change request is submitted and evaluated to assess technical merit, potential side effects, overall impact on other configuration objectsand system functions, and the projected cost of the change. The results of the eval-uation are presented as a change report, which is used by a change control authority (CCA)—a person or group that makes a final decision on the status and priority of thechange. An engineering change order(ECO) is generated for each approved change.The ECO describes the change to be made, the constraints that must be respected,and the criteria for review and audit.The object(s) to be changed can be placed in a directory that is controlled solelyby the software engineer making the change. A version control system (see the CVSsidebar) updates the original file once the change has been made. As an alternative,596 PART THREEQUALITY MANAGEMENT
The Concurrent Versions System (CVS)
The use of tools to achieve version control isessential for effective change management. TheConcurrent Versions System(CVS) is a widely used tool forversion control. Originally designed for source code, butuseful for any text-based file, the CVS system (1) establishesa simple repository, (2) maintains all versions of a file in asingle named file by storing only the differences betweenprogressive versions of the original file, and (3) protectsagainst simultaneous changes to a file by establishingdifferent directories for each developer, thus insulating onefrom another. CVS merges changes when each developercompletes her work.It is important to note that CVS is not a “build” system;that is, it does not construct a specific version of thesoftware. Other tools (e.g.,Makefile) must be integratedwith CVS to accomplish this. CVS does not implement achange control process (e.g., change requests, changereports, bug tracking).Even with these limitations, CVS “is a dominant open-source network-transparent version control system [that] isuseful for everyone from individual developers to large,distributed teams” [CVS07]. Its client-server architectureallows users to access files via Internet connections, and itsopen-source philosophy makes it available on mostpopular platforms.CVS is available at no cost for Windows, Mac OS,LINUX, and UNIX environments. See [CVS07] for furtherdetails.SOFTWARE TOOLS
uote:
“The art ofprogress is topreserve orderamid change andto preserve changeamid order.”Alfred NorthWhitehead
It should be noted thata number of changerequests may becombined to result in asingle ECO and thatECOs typically result inchanges to multipleconfiguration objects.pre75977_ch22.qxd  11/27/08  6:21 PM  Page 596the object(s) to be changed can be “checked out” of the project database (repository),the change is made, and appropriate SQA activities are applied. The object(s) is(are) then “checked in” to the database and appropriate version control mechanisms(Section 22.3.2) are used to create the next version of the software.These version control mechanisms, integrated within the change control process,implement two important elements of change management—access control andsynchronization control. Access control governs which software engineers have the authority to access and modify a particular configuration object. Synchronization controlhelps to ensure that parallel changes, performed by two different people,don’t overwrite one another.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 597
Need for change is recognized
Change request from user
Developer evaluates
Change report is generated
Change control authority decides
Request is queued for action, ECO generated
Assign individuals to configuration objects
“Check out” configuration objects (items)
Make the change
Review (audit) the change
“Check in” the configuration items that have been changed
Establish a baseline for testing
Perform quality assurance and testing activities
“Promote” changes for inclusion in next release (revision)
Rebuild appropriate version of software
Review (audit) the change to all configuration items
Include changes in new versionDistribute the new versionChange request is deniedUser is informedFIGURE 22.5
The changecontrol processpre75977_ch22.qxd  11/27/08  6:21 PM  Page 597You may feel uncomfortable with the level of bureaucracy implied by the changecontrol process description shown in Figure 22.5. This feeling is not uncommon.Without proper safeguards, change control can retard progress and create unneces-sary red tape. Most software developers who have change control mechanisms (un-fortunately, many have none) have created a number of layers of control to helpavoid the problems alluded to here.Prior to an SCI becoming a baseline, only informal change control need be applied. The developer of the configuration object (SCI) in question may make whateverchanges are justified by project and technical requirements (as long as changes donot affect broader system requirements that lie outside the developer’s scope ofwork). Once the object has undergone technical review and has been approved, abaseline can be created.
5Once an SCI becomes a baseline, project level changecontrolis implemented. Now, to make a change, the developer must gain approvalfrom the project manager (if the change is “local”) or from the CCA if the changeaffects other SCIs. In some cases, formal generation of change requests, changereports, and ECOs is dispensed with. However, assessment of each change is con-ducted and all changes are tracked and reviewed.When the software product is released to customers, formal change control is instituted. The formal change control procedure has been outlined in Figure 22.5.The change control authority plays an active role in the second and third layers ofcontrol. Depending on the size and character of a software project, the CCA may becomposed of one person—the project manager—or a number of people (e.g., repre-sentatives from software, hardware, database engineering, support, marketing). Therole of the CCA is to take a global view, that is, to assess the impact of change be-yond the SCI in question. How will the change affect hardware? How will the changeaffect performance? How will the change modify customers’ perception of the prod-uct? How will the change affect product quality and reliability? These and many otherquestions are addressed by the CCA.598 PART THREEQUALITY MANAGEMENT
Opt for a bit morechange control thanyou think you’ll need.It’s likely that toomuch will be the rightamount.
5 A baseline can be created for other reasons as well. For example, when “daily builds” are created,all components checked in by a given time become the baseline for the next day’s work.uote:
“Change isinevitable, exceptfor vendingmachines.”Bumper sticker
SCM Issues
The scene:Doug Miller’s office asthe SafeHomesoftware project begins.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman, JamieLazar, and other members of the product softwareengineering team.The conversation:Doug:I know it’s early, but we’ve got to talk aboutchange management.Vinod (laughing):Hardly. Marketing called thismorning with a few “second thoughts.” Nothing major,but it’s just the beginning.SAFEHOMEpre75977_ch22.qxd  11/27/08  6:21 PM  Page 598CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 599
Jamie:We’ve been pretty informal about changemanagement on past projects.Doug:I know, but this is bigger and more visible, andas I recall . . .Vinod (nodding):We got killed by uncontrolledchanges on the home lighting control project . . . rememberthe delays that . . .Doug (frowning):A nightmare that I’d prefer not torelive.Jamie:So what do we do?Doug:As I see it, three things. First we have todevelop—or borrow—a change control process.Jamie:You mean how people request changes?Vinod:Yeah, but also how we evaluate the change,decide when to do it (if that’s what we decide), and howwe keep records of what’s affected by the change.Doug:Second, we’ve got to get a really good SCM toolfor change and version control.Jamie:We can build a database for all of our workproducts.Vinod:They’re called SCIs in this context, and mostgood tools provide some support for that.Doug:That’s a good start, now we have to . . .Jamie:Uh, Doug, you said there were three things . . .Doug (smiling):Third—we’ve all got to commit tofollow the change management process and use thetools—no matter what, okay?
22.3.4 Configuration Audit
Identification, version control, and change control help you to maintain order inwhat would otherwise be a chaotic and fluid situation. However, even the most suc-cessful control mechanisms track a change only until an ECO is generated. How cana software team ensure that the change has been properly implemented? The an-swer is twofold: (1) technical reviews and (2) the software configuration audit.The technical review (Chapter 15) focuses on the technical correctness of the con-figuration object that has been modified. The reviewers assess the SCI to determineconsistency with other SCIs, omissions, or potential side effects. A technical reviewshould be conducted for all but the most trivial changes.A software configuration auditcomplements the technical review by assessing aconfiguration object for characteristics that are generally not considered during re-view. The audit asks and answers the following questions:1.Has the change specified in the ECO been made? Have any additional modifi-cations been incorporated?2.Has a technical review been conducted to assess technical correctness?3.Has the software process been followed and have software engineeringstandards been properly applied?4.Has the change been “highlighted” in the SCI? Have the change date andchange author been specified? Do the attributes of the configuration objectreflect the change?5.Have SCM procedures for noting the change, recording it, and reporting itbeen followed?6.Have all related SCIs been properly updated?
What are theprimaryquestions that weask during aconfigurationaudit??pre75977_ch22.qxd  11/27/08  6:21 PM  Page 599In some cases, the audit questions are asked as part of a technical review. How-ever, when SCM is a formal activity, the configuration audit is conducted sepa-rately by the quality assurance group. Such formal configuration audits alsoensure that the correct SCIs (by version) have been incorporated into a specificbuild and that all documentation is up-to-date and consistent with the version thathas been built.
22.3.5 Status Reporting
Configuration status reporting(sometimes called status accounting) is an SCM taskthat answers the following questions: (1) What happened? (2) Who did it? (3) Whendid it happen? (4) What else will be affected?The flow of information for configuration status reporting (CSR) is illustratedin Figure 22.5. Each time an SCI is assigned new or updated identification, a CSRentry is made. Each time a change is approved by the CCA (i.e., an ECO is issued),a CSR entry is made. Each time a configuration audit is conducted, the results arereported as part of the CSR task. Output from CSR may be placed in an online data-base or website, so that software developers or support staff can access change in-formation by keyword category. In addition, a CSR report is generated on a regularbasis and is intended to keep management and practitioners appraised of importantchanges.600 PART THREEQUALITY MANAGEMENT
Develop a “need toknow” list for everyconfiguration objectand keep it up-to-date.When a change ismade, be sure thateveryone on the list isnotified.
SCM Support
Objective:SCM tools provide support to oneor more of the process activities discussed inSection 22.3.Mechanics:Most modern SCM tools work in conjunctionwith a repository (a database system) and providemechanisms for identification, version and change control,auditing, and reporting.Representative Tools:
6
CCC/Harvest,distributed by Computer Associates(www.cai.com), is a multiplatform SCM system.ClearCase,developed by Rational, provides a family ofSCM functions (www-306.ibm.com/software/awdtools/clearcase/index.html). Serena ChangeMan ZMF ,distributed by Serena(www.serena.com/US/products/zmf/index.aspx), provides a full set of SCM tools that are applicable for both conventional software andWebApps.SourceForge,distributed by VA Software(sourceforge.net), provides version management,build capabilities, issue/bug tracking, and many othermanagement features.SurroundSCM,developed by Seapine Software, providescomplete change management capabilities(www.seapine.com).Vesta,distributed by Compac, is a public domain SCMsystem that can support both small (/H1102110 KLOC) andlarge (10,000 KLOC) projects(www.vestasys.org).A comprehensive list of commercial SCM tools andenvironments can be found atwww.cmtoday.com/yp/commercial.html .SOFTWARE TOOLS
6 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch22.qxd  12/3/08  2:00 PM  Page 60022.4 C ONFIGURATION MANAGEMENT FOR WEBAPPS
Earlier in this book, I discussed the special nature of Web applications and the spe-cialized methods (called Web engineering methods
7) that are required to build them. Among the many characteristics that differentiate WebApps from traditional soft-ware is the ubiquitous nature of change.WebApp developers often use an iterative, incremental process model thatapplies many principles derived from agile software development (Chapter 3). Usingthis approach, an engineering team often develops a WebApp increment in a veryshort time period using a customer-driven approach. Subsequent increments addadditional content and functionality, and each is likely to implement changes thatlead to enhanced content, better usability, improved aesthetics, better navigation,enhanced performance, and stronger security. Therefore, in the agile world ofWebApps, change is viewed somewhat differently.If you’re a member of a WebApp team, you must embrace change. And yet, a typ-ical agile team eschews all things that appear to be process-heavy, bureaucratic, andformal. Software configuration management is often viewed (albeit incorrectly) tohave these characteristics. This seeming contradiction is remedied not by rejectingSCM principles, practices, and tools, but rather, by molding them to meet the specialneeds of WebApp projects.
22.4.1 Dominant Issues
As WebApps become increasing important to business survival and growth, the needfor configuration management grows. Why? Because without effective controls,improper changes to a WebApp (recall that immediacy and continuous evolution arethe dominant attributes of many WebApps) can lead to: unauthorized posting of newproduct information, erroneous or poorly tested functionality that frustrates visitorsto a website, security holes that jeopardize internal company systems, and other eco-nomically unpleasant or even disastrous consequences.The general strategies for software configuration management (SCM) describedin this chapter are applicable, but tactics and tools must be adapted to conform tothe unique nature of WebApps. Four issues [Dar99] should be considered whendeveloping tactics for WebApp configuration management.Content.A typical WebApp contains a vast array of content—text, graphics,applets, scripts, audio/video files, forms, active page elements, tables, streamingdata, and many others. The challenge is to organize this sea of content into a rationalset of configuration objects (Section 22.1.4) and then establish appropriate configu-ration control mechanisms for these objects. One approach is to model the WebAppcontent using conventional data modeling techniques (Chapter 6), attaching a set ofCHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 601
7 See [Pre08] for a comprehensive discussion of Web engineering methods.What impactdoesuncontrolledchange have on aWebApp??pre75977_ch22.qxd  11/27/08  6:21 PM  Page 601specialized properties to each object. The static/dynamic nature of each object andits projected longevity (e.g., temporary, fixed existence, or permanent object) areexamples of properties that are required to establish an effective SCM approach. Forexample, if a content item is changed hourly, it has temporary longevity. The controlmechanisms for this item would be different (less formal) than those applied for aforms component that is a permanent object.People.Because a significant percentage of WebApp development continues tobe conducted in an ad hoc manner, any person involved in the WebApp can (andoften does) create content. Many content creators have no software engineeringbackground and are completely unaware of the need for configuration manage-ment. As a consequence, the application grows and changes in an uncontrolledfashion.Scalability.The techniques and controls applied to a small WebApp do not scaleupward well. It is not uncommon for a simple WebApp to grow significantly asinterconnections with existing information systems, databases, data warehouses,and portal gateways are implemented. As size and complexity grow, small changescan have far-reaching and unintended effects that can be problematic. Therefore, therigor of configuration control mechanisms should be directly proportional to appli-cation scale.Politics.Who “owns” a WebApp? This question is argued in companies large andsmall, and its answer has a significant impact on the management and controlactivities. In some instances Web developers are housed outside the IT organization,creating potential communication difficulties. Dart [Dar99] suggests the followingquestions to help understand the politics associated with Web engineering:
•Who assumes responsibility for the accuracy of the information on thewebsite?
•Who ensures that quality control processes have been followed before infor-mation is published to the site?
•Who is responsible for making changes?
•Who assumes the cost of change?The answers to these questions help determine the people within an organizationwho must adopt a configuration management process for WebApps.Configuration management for WebApps continues to evolve (e.g., [Ngu06]). Aconventional SCM process may be too cumbersome, but a new generation of contentmanagement toolsthat are specifically designed for Web engineering has emergedover the past few years. These tools establish a process that acquires existing infor-mation (from a broad array of WebApp objects), manages changes to the objects,structures it in a way that enables it to be presented to an end user, and then pro-vides it to the client-side environment for display.602 PART THREEQUALITY MANAGEMENT
How do Ideterminewho hasresponsibility forWebApp CM??pre75977_ch22.qxd  11/27/08  6:21 PM  Page 60222.4.2 WebApp Configuration Objects
WebApps encompass a broad range of configuration objects—content objects (e.g.,text, graphics, images, video, audio), functional components (e.g., scripts, applets),and interface objects (e.g., COM or CORBA). WebApp objects can be identified (as-signed file names) in any manner that is appropriate for the organization. However,the following conventions are recommended to ensure that cross-platform compat-ibility is maintained: filenames should be limited to 32 characters in length, mixed-case or all-caps names should be avoided, and the use of underscores in file namesshould be avoided. In addition, URL references (links) within a configuration objectshould always use relative paths (e.g., ../products/alarmsensors.html).All WebApp content has format and structure. Internal file formats are dictated bythe computing environment in which the content is stored. However, rendering for- mat(often called display format) is defined by the aesthetic style and design rulesestablished for the WebApp. Content structure defines a content architecture; that is, it defines the way in which content objects are assembled to present meaningfulinformation to an end user. Boiko [Boi04] defines structure as “maps that you layover a set of content chunks [objects] to organize them and make them accessibleto the people who need them.”
22.4.3 Content Management
Content managementis related to configuration management in the sense that a con-tent management system (CMS) establishes a process (supported by appropriatetools) that acquires existing content (from a broad array of WebApp configurationobjects), structures it in a way that enables it to be presented to an end user, and thenprovides it to the client-side environment for display.The most common use of a content management system occurs when a dynamicWebApp is built. Dynamic WebApps create Web pages “on-the-fly.” That is, the usertypically queries the WebApp requesting specific information. The WebApp queriesa database, formats the information accordingly, and presents it to the user. Forexample, a music company provides a library of CDs for sale. When a user requests aCD or its e-music equivalent, a database is queried and a variety of information aboutthe artist, the CD (e.g., its cover image or graphics), the musical content, and sampleaudio are all downloaded and configured into a standard content template. The re-sultant Web page is built on the server side and passed to the client-side browser forexamination by the end user. A generic representation of this is shown in Figure 22.6.In the most general sense, a CMS “configures” content for the end user by invok-ing three integrated subsystems: a collection subsystem, a management subsystem,and a publishing subsystem [Boi04].The collection subsystem.Content is derived from data and information thatmust be created or acquired by a content developer. The collection subsystem encompasses all actions required to create and/or acquire content, and the technicalCHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 603
uote:
“Contentmanagement is anantidote to today’sinformationfrenzy.”Bob Boikopre75977_ch22.qxd  11/27/08  6:21 PM  Page 603functions that are necessary to (1) convert content into a form that can be repre-sented by a mark-up language (e.g., HTML, XML), and (2) organize content intopackets that can be displayed effectively on the client side.Content creation and acquisition (often called authoring) commonly occurs in par- allel with other WebApp development activities and is often conducted by nontech-nical content developers. This activity combines elements of creativity and researchand is supported by tools that enable the content author to characterize content in amanner that can be standardized for use within the WebApp.Once content exists, it must be converted to conform to the requirements ofa CMS. This implies stripping raw content of any unnecessary information (e.g.,redundant graphical representations), formatting the content to conform to therequirements of the CMS, and mapping the results into an information structure thatwill enable it to be managed and published.The management subsystem.Once content exists, it must be stored in a reposi-tory, cataloged for subsequent acquisition and use, and labeled to define (1) current sta-tus (e.g., is the content object complete or in development?), (2) the appropriate versionof the content object, and (3) related content objects. Therefore, the management sub-systemimplements a repository that encompasses the following elements:
•Content database—the information structure that has been established tostore all content objects
•Database capabilities—functions that enable the CMS to search forspecific content objects (or categories of objects), store and retrieve604 PART THREEQUALITY MANAGEMENT
Database
Templates
Server-sideHTML code+ scriptsClient-side browserConfiguration objectsContentmanagementsystemFIGURE 22.6
Contentmanagementsystem
The collectionsubsystemencompasses allactions required tocreate, acquire, and/orconvert content into aform that can bepresented on theclient side.
The managementsubsystem implementsa repository for allcontent. Configurationmanagement isperformed within thissubsystem.pre75977_ch22.qxd  11/27/08  6:21 PM  Page 604objects, and manage the file structure that has been established for thecontent
•Configuration management functions—the functional elements and associatedworkflow that support content object identification, version control, changemanagement, change auditing, and reportingIn addition to these elements, the management subsystem implements an adminis-tration function that encompasses the metadata and rules that control the overallstructure of the content and the manner in which it is supported.The publishing subsystem.Content must be extracted from the repository, con-verted to a form that is amenable to publication, and formatted so that it can betransmitted to client-side browsers. The publishing subsystem accomplishes thesetasks using a series of templates. Each template is a function that builds a publica- tion using one of three different components [Boi04]:
•Static elements—text, graphics, media, and scripts that require no furtherprocessing are transmitted directly to the client side.
•Publication services—function calls to specific retrieval and formattingservices that personalize content (using predefined rules), perform dataconversion, and build appropriate navigation links.
•External services—access to external corporate information infrastructuresuch as enterprise data or “back-room” applications.A content management system that encompasses each of these subsystems isapplicable for major WebApp projects. However, the basic philosophy and function-ality associated with a CMS are applicable to all dynamic WebApps.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 605
The publishingsubsystem extractscontent from therepository and deliversit to client-sidebrowsers.
Content Management
Objective:To assist software engineers andcontent developers in managing content that isincorporated into WebApps.Mechanics:Tools in this category enable Web engineersand content providers to update WebApp content in acontrolled manner. Most establish a simple file managementsystem that assigns page-by-page update and editingpermissions for various types of WebApp content. Somemaintain a versioning system so that a previous version ofcontent can be archived for historical purposes.Representative Tools:8
Vignette Content Management,developed by Vignette(www.vignette.com/us/Products), is a suite ofenterprise content management tools.ektron-CMS300,developed by ektron(www.ektron.com), is a suite of tools that providecontent management capabilities as well as Webdevelopment tools.OmniUpdate, developed by WebsiteASP, Inc.(www.omniupdate.com), is a tool that allowsSOFTWARE TOOLS
8 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch22.qxd  11/27/08  6:21 PM  Page 60522.4.4 Change Management
The workflow associated with change control for conventional software (Sec-tion 22.3.3) is generally too ponderous for WebApp development. It is unlikely thatthe change request, change report, and engineering change order sequence can beachieved in an agile manner that is acceptable for most WebApp developmentprojects. How then do we manage a continuous stream of changes requested forWebApp content and functionality?To implement effective change management within the “code and go” philosophythat continues to dominate WebApp development, the conventional change controlprocess must be modified. Each change should be categorized into one of fourclasses:Class 1— a content or function change that corrects an error or enhances localcontent or functionalityClass 2—a content or function change that has an impact on other contentobjects or functional componentsClass 3—a content or function change that has a broad impact across a WebApp(e.g., major extension of functionality, significant enhancement or reduction incontent, major required changes in navigation)Class 4—a major design change (e.g., a change in interface design or naviga-tion approach) that will be immediately noticeable to one or more categoriesof userOnce the requested change has been categorized, it can be processed according tothe algorithm shown in Figure 22.7.Referring to the figure, class 1 and 2 changes are treated informally and are han-dled in an agile manner. For a class 1 change, you would evaluate the impact of thechange, but no external review or documentation is required. As the change is made,standard check-in and check-out procedures are enforced by configuration reposi-tory tools. For class 2 changes, you should review the impact of the change onrelated objects (or ask other developers responsible for those objects to do so). If the606 PART THREEQUALITY MANAGEMENT
authorized content providers to develop controlledupdates to specified WebApp content.Additional information on SCM and content managementtools for Web engineering can be found at one or moreof the following websites: Web Developer’s VirtualEncyclopedia(www.wdlv.com),WebDeveloper(www.webdeveloper.com), Developer Shed(www.devshed.com), webknowhow.net(www.webknowhow.net), or WebReference(www.webreference.com).pre75977_ch22.qxd  11/27/08  6:21 PM  Page 606change can be made without requiring significant changes to other objects, modifi-cation occurs without additional review or documentation. If substantive changesare required, further evaluation and planning are necessary.Class 3 and 4 changes are also treated in an agile manner, but some descriptivedocumentation and more formal review procedures are required. A change description—describing the change and providing a brief assessment of the impactof the change—is developed for class 3 changes. The description is distributed to allmembers of the team who review it to better assess its impact. A change descrip-tion is also developed for class 4 changes, but in this case, the review is conductedby all stakeholders.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 607
Classify therequested change
Acquire related objects andassess impact of change Develop brief writtendescription of change
Transmit to all teammembers for review
Check out object(s)to be changedDevelop brief writtendescription of change
Make changesdesign, construct, test
Check in object(s)that were changed
Publish to WebAppTransmit to all stake-holders for review
Changesrequiredin relatedobjectsFurtherevaluationis requiredFurtherevaluationis requiredOK to makeOK to makeClass 1 change Class 4 changeClass 3 changeClass 2 changeFIGURE 22.7
Managingchanges forWebAppspre75977_ch22.qxd  11/27/08  6:21 PM  Page 60722.4.5 Version Control
As a WebApp evolves through a series of increments, a number of different versionsmay exist at the same time. One version (the current operational WebApp) is avail-able via the Internet for end users; another version (the next WebApp increment)may be in the final stages of testing prior to deployment; a third version is in devel-opment and represents a major update in content, interface aesthetics, and func-tionality. Configuration objects must be clearly defined so that each can beassociated with the appropriate version. In addition, control mechanisms must beestablished. Dreilinger [Dre99] discusses the importance of version (and change)control when he writes:
In an uncontrolledsite where multiple authors have access to edit and contribute, thepotential for conflict and problems arises—more so when these authors work from dif-ferent offices at different times of day and night. You may spend the day improving thefile index.htmlfor a customer. After you’ve made your changes, another developer whoworks at home after hours, or in another office, may spend the night uploading their ownnewly revised version of the file index.html, completely overwriting your work with noway to get it back!
It’s likely that you’ve experienced a similar situation. To avoid it, a version controlprocess is required.1.A central repository for the WebApp project should be established. The reposi- tory will hold current versions of all WebApp configuration objects (content,functional components, and others).2.Each Web engineer creates his or her own working folder. The folder contains those objects that are being created or changed at any given time.608 PART THREEQUALITY MANAGEMENT
9 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Change Management
Objective:To assist Web engineers andcontent developers in managing changes asthey are made to WebApp configuration objects.Mechanics:Tools in this category were originallydeveloped for conventional software, but can be adaptedfor use by Web engineers and content developers to makecontrolled changes to WebApps. They support automatedcheck-in and check-out, version control and rollback,reporting, and other SCM functions.Representative Tools:9
ChangeMan WCM,developed by Serena (www.serena.com), is one of a suite of change management toolsthat provide complete SCM capabilities.ClearCase,developed by Rational (www-306.ibm.com/software/rational/sw-atoz/indexC.html), is a suite of tools that provide fullconfiguration management capabilities for WebApps.Source Integrity, developed by mks (www.mks.com),is a SCM tool that can be integrated with selecteddevelopment environments.SOFTWARE TOOLSpre75977_ch22.qxd  11/27/08  6:21 PM  Page 6083.The clocks on all developer workstations should be synchronized. This is done to avoid overwriting conflicts when two developers make updates that arevery close to one another in time.4.As new configuration objects are developed or existing objects are changed, theyare imported into the central repository. The version control tool (see discus- sion of CVS in the sidebar) will manage all check-in and check-out functionsfrom the working folders of each WebApp developer. The tool will also pro-vide automatic e-mail updates to all interested parties when changes to therepository are made.5.As objects are imported or exported from the repository, an automatic, time-stamped log message is made.This provides useful information for auditingand can become part of an effective reporting scheme.The version control tool maintains different versions of the WebApp and can revertto an older version if required.
22.4.6 Auditing and Reporting
In the interest of agility, the auditing and reporting functions are deemphasized inWeb engineering work.
10However, they are not eliminated altogether. All objectsthat are checked into or out of the repository are recorded in a log that can bereviewed at any point in time. A complete log report can be created so that all mem-bers of the WebApp team have a chronology of changes over a defined period oftime. In addition, an automated e-mail notification (addressed to those developersand stakeholders who have interest) can be sent every time an object is checked inor out of the repository.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 609
10 This is beginning to change. There is an increasing emphasis on SCM as one element of WebAppsecurity [Sar06]. By providing a mechanism for tracking and reporting every change made to everyWebApp object, a change management tool can provide valuable protection against maliciouschanges.SCM Standards
The following list of SCM standards (extractedin part from www.12207.com) is reasonablycomprehensive:IEEE Standards standards.ieee.org/catalog/olis/IEEE 828 Software Configuration Management PlansIEEE 1042 Software Configuration ManagementISO Standards www.iso.ch/iso/en/ISOOnline.frontpageISO 10007-1995 Quality Management, Guidancefor CMISO/IEC 12207 Information Technology-SoftwareLife Cycle ProcessesISO/IEC TR 15271 Guide for ISO/IEC 12207INFOpre75977_ch22.qxd  11/27/08  6:21 PM  Page 60922.5 S UMMARY
Software configuration management is an umbrella activity that is applied through-out the software process. SCM identifies, controls, audits, and reports modificationsthat invariably occur while software is being developed and after it has been releasedto a customer. All work products created as part of software engineering becomepart of a software configuration. The configuration is organized in a manner thatenables orderly control of change.The software configuration is composed of a set of interrelated objects, also calledsoftware configuration items, that are produced as a result of some software engi-neering activity. In addition to documents, programs, and data, the developmentenvironment that is used to create software can also be placed under configurationcontrol. All SCIs are stored within a repository that implements a set of mechanismsand data structures to ensure data integrity, provide integration support for othersoftware tools, support information sharing among all members of the softwareteam, and implement functions in support of version and change control.Once a configuration object has been developed and reviewed, it becomes abaseline. Changes to a baselined object result in the creation of a new version of that610 PART THREEQUALITY MANAGEMENT
ISO/IEC TR 15846 Software Engineering-Software LifeCycle Process-ConfigurationManagement for Software OrderEIA Standards www.eia.org/EIA 649 National Consensus Standard forConfiguration ManagementEIA CMB4-1A Configuration ManagementDefinitions for Digital ComputerProgramsEIA CMB4-2 Configuration Identification forDigital Computer Programs EIA CMB4-3 Computer Software LibrariesEIA CMB4-4 Configuration Change Control forDigital Computer Programs EIA CMB6-1C Configuration and DataManagement References OrderEIA CMB6-3 Configuration IdentificationEIA CMB6-4 Configuration ControlEIA CMB6-5 Textbook for Configuration StatusAccountingEIA CMB7-1 Electronic Interchange ofConfiguration Management DataU.S. Military Information of MIL standards:Standards www-library.itsi.disa.milDoD MIL STD-973 Configuration ManagementMIL-HDBK-61 Configuration ManagementGuidanceOther StandardsDO-178B Guidelines for the Developmentof Aviation SoftwareESA PSS-05-09 Guide to Software ConfigurationManagementAECL CE-1001-STD Standard for Software Engineeringrev.1 of Safety Critical SoftwareDOE SCM checklist: http://cio.doe.gov/ITReform/sqse/download/cmcklst.docBS-6488 British Std., ConfigurationManagement of Computer-BasedSystemsBest Practice—UK Office of Government Commerce:www.ogc.gov.ukCMII Institute of CM Best Practices:www.icmhq.comA Configuration Management Resource Guide provides complementary information for those interested in CMprocesses and practice. It is available at www.quality.org/config/cm-guide.html.pre75977_ch22.qxd  11/27/08  6:21 PM  Page 610object. The evolution of a program can be tracked by examining the revision historyof all configuration objects. Version control is the set of procedures and tools formanaging the use of these objects.Change control is a procedural activity that ensures quality and consistency aschanges are made to a configuration object. The change control process begins witha change request, leads to a decision to make or reject the request for change, andculminates with a controlled update of the SCI that is to be changed.The configuration audit is an SQA activity that helps to ensure that quality ismaintained as changes are made. Status reporting provides information about eachchange to those with a need to know.Configuration management for WebApps is similar in most respects to SCM forconventional software. However, each of the core SCM tasks should be streamlinedto make it as lean as possible, and special provisions for content management mustbe implemented.
PROBLEMS AND POINTS TO PONDER
22.1.Why is the First Law of System Engineering true? Provide specific examples for each ofthe four fundamental reasons for change.22.2.What are the four elements that exist when an effective SCM system is implemented?Discuss each briefly.22.3.Discuss the reasons for baselines in your own words.22.4.Assume that you’re the manager of a small project. What baselines would you define forthe project and how would you control them?22.5.Design a project database (repository) system that would enable a software engineerto store, cross reference, trace, update, and change all important software configuration items.How would the database handle different versions of the same program? Would source code behandled differently than documentation? How will two developers be precluded from makingdifferent changes to the same SCI at the same time?22.6.Research an existing SCM tool and describe how it implements control for versions,variants, and configuration objects in general.22.7.The relations <part-of> and <interrelated> represent simple relationships between con-figuration objects. Describe five additional relationships that might be useful in the context ofan SCM repository.22.8.Research an existing SCM tool and describe how it implements the mechanics of versioncontrol. Alternatively, read two or three papers on SCM and describe the different data struc-tures and referencing mechanisms that are used for version control.22.9.Develop a checklist for use during configuration audits.22.10.What is the difference between an SCM audit and a technical review? Can their func-tion be folded into one review? What are the pros and cons?22.11.Briefly describe the differences between SCM for conventional software and SCM forWebApps.22.12.What is content management? Use the Web to research the features of a contentmanagement tool and provide a brief summary.CHAPTER 22SOFTWARE CONFIGURATION MANAGEMENT 611pre75977_ch22.qxd  11/27/08  6:21 PM  Page 611FURTHER READINGS AND INFORMATION SOURCES
Among the more recent SCM offerings are Leon (Software Configuration Management Handbook,2d ed., Artech House Publishers, 2005), Maraia (The Build Master: Microsoft’s Software Configu-ration Management Best Practices, Addison-Wesley, 2005), Keyes (Software Configuration Man- agement,Auerbach, 2004), and Hass (Configuration Management Principles and Practice,Addison-Wesley, 2002). Each of these books presents the entire SCM process in substantialdetail. Maraia (Software Configuration Management Implementation Roadmap, Wiley, 2004) pres- ents a unique how-to guide for those who must implement SCM within an organization. Lyon(Practical CM,Raven Publishing, 2003, available at www.configuration.org) has written a comprehensive guide for the CM professional that includes pragmatic guidelines for imple-menting every aspect of a configuration management system (updated yearly). White andClemm (Software Configuration Management Strategies and Rational ClearCase, Addison-Wesley, 2000) present SCM within the context of one of the more popular SCM tools.Berczuk and Appleton (Software Configuration Management Patterns, Addison-Wesley, 2002) present a variety of useful patterns that assist in understanding SCM and implementing effec-tive SCM systems. Brown et al. (Anti-Patterns and Patterns in Software Configuration Management,Wiley, 1999) discuss the things not to do (anti-patterns) when implementing an SCM process andthen consider their remedies. Bays (Software Release Methodology, Prentice Hall, 1999) focuses on the mechanics of “successful product release,” an important complement to effective SCM.As WebApps have become more dynamic, content management has become an essentialtopic for Web engineers. Books by White (The Content Management Handbook, Curtin University Books, 2005), Jenkins and his colleagues (Enterprise Content Management Methods, Open Text Corporation, 2005), Boiko [Boi04], Mauthe and Thomas ( Professional Content Management Sys- tems,Wiley, 2004), Addey and his colleagues ( Content Management Systems,Glasshaus, 2003), Rockley (Managing Enterprise Content, New Riders Press, 2002), Hackos (Content Management for Dynamic Web Delivery,Wiley, 2002), and Nakano (Web Content Management,Addison-Wesley, 2001) present worthwhile treatments of the subject.In addition to generic discussions of the topic, Lim and his colleagues (Enhancing MicrosoftContent Management Server with ASP.NET 2.0, Packt Publishing, 2006), Ferguson ( Creating Content Management Systems in Java, Charles River Media, 2006), IBM Redbooks (IBM Workplace Web Content Management for Portal 5.1 and IBM Workplace Web Content Management 2.5,Vivante, 2006), Fritz and his colleagues (Typo3: Enterprise Content Management, Packt Publish- ing, 2005), and Forta (Reality ColdFusion: Intranets and Content Management, Pearson Education, 2002) present content management within the context of specific tools and languages.A wide variety of information sources on software configuration management and contentmanagement is available on the Internet. An up-to-date list of World Wide Web referencesrelevant to software configuration management can be found at the SEPA website:www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm .612 PART THREEQUALITY MANAGEMENTpre75977_ch22.qxd  11/27/08  6:21 PM  Page 612Akey element of any engineering process is measurement. You can usemeasures to better understand the attributes of the models that you cre-ate and to assess the quality of the engineered products or systems thatyou build. But unlike other engineering disciplines, software engineering is notgrounded in the basic quantitative laws of physics. Direct measures, such asvoltage, mass, velocity, or temperature, are uncommon in the software world.Because software measures and metrics are often indirect, they are open todebate. Fenton [Fen91] addresses this issue when he states:
Measurement is the process by which numbers or symbols are assigned to the attrib-utes of entities in the real world in such a way as to define them according to clearlydefined rules....I nt h ephysical sciences, medicine, economics, and more recently thesocial sciences, we are now able to measure attributes that were previously thought to
613CHAPTER
23PRODUCT
METRICS
What is it? By its nature, engineer-ing is a quantitative discipline. Prod-uct metrics help software engineersgain insight into the design and con-struction of the software they build by focusingon specific, measurable attributes of softwareengineering work products.
Who does it? Software engineers use product met-rics to help them build higher-quality software.
Why is it important? There will always be a qual-itative element to the creation of computer soft-ware. The problem is that qualitative assessmentmay not be enough. You need objective criteriato help guide the design of data, architecture,interfaces, and components. When testing, youneed quantitative guidance that will help in theselection of test cases and their targets. Productmetrics provide a basis from which analysis, de-sign, coding, and testing can be conducted moreobjectively and assessed more quantitatively.
What are the steps? The first step in the meas-urement process is to derive the softwaremeasures and metrics that are appropriate forQUICK
LOOKthe representation of software that is beingconsidered. Next, data required to derive theformulated metrics are collected. Once com-puted, appropriate metrics are analyzedbased on preestablished guidelines and pastdata. The results of the analysis are interpretedto gain insight into the quality of the software,and the results of the interpretation lead tomodification of requirements and designmodels, source code, or test cases. In someinstances, it may also lead to modification ofthe software process itself.
What is the work product? Product metrics thatare computed from data collected from therequirements and design models, source code,and test cases.
How do I ensure that I’ve done it right? Youshould establish the objectives of measurementbefore data collection begins, defining eachproduct metric in an unambiguous manner.Define only a few metrics and then use them togain insight into the quality of a software engi-neering work product.KEY
CONCEPTS
function point (FP) . . . . .620Goal/Question/Metric (GQM) . .617indicator . . . . . .615measure . . . . . .614measurement  . .614measurementprinciples  . . . . .616metrics, attributes of . .618pre75977_ch23.qxd  11/27/08  6:22 PM  Page 613be unmeasurable. . . . Of course, such measurements are not as refined as many meas-urements in the physical sciences . . . , but they exist [and important decisions are madebased on them]. We feel that the obligation to attempt to “measure the unmeasurable” inorder to improve our understanding of particular entities is as powerful in software engi-neering as in any discipline.
But some members of the software community continue to argue that software is“unmeasurable” or that attempts at measurement should be postponed until we bet-ter understand software and the attributes that should be used to describe it. This isa mistake.Although product metrics for computer software are imperfect, they can provideyou with a systematic way to assess quality based on a set of clearly defined rules.They also provide you with on-the-spot, rather than after-the-fact, insight. Thisenables you to discover and correct potential problems before they become cata-strophic defects.In this chapter, I present measures that can be used to assess the quality of theproduct as it is being engineered. These measures of internal product attributes pro-vide you with a real-time indication of the efficacy of the requirements, design, andcode models; the effectiveness of test cases; and the overall quality of the softwareto be built.
23.1 A F RAMEWORK FOR PRODUCT METRICS
As I noted in the introduction, measurement assigns numbers or symbols to attributesof entities in the real word. To accomplish this, a measurement model encompassing aconsistent set of rules is required. Although the theory of measurement (e.g., [Kyb84])and its application to computer software (e.g., [Zus97]) are topics that are beyond thescope of this book, it is worthwhile to establish a fundamental framework and a set ofbasic principles that guide the definition of product metrics for software.
23.1.1 Measures, Metrics, and Indicators
Although the terms measure, measurement, and metricsare often used interchangeably, it is important to note the subtle differences between them. Because measure can be used either as a noun or a verb, definitions of the term can become confusing. Withinthe software engineering context, a measure provides a quantitative indication of the extent, amount, dimension, capacity, or size of some attribute of a product or process.Measurementis the act of determining a measure. The IEEE Standard Glossary of Soft-ware Engineering Terminology[IEE93b] defines metricas “a quantitative measure of the degree to which a system, component, or process possesses a given attribute.”When a single data point has been collected (e.g., the number of errors uncoveredwithin a single software component), a measure has been established. Measurementoccurs as the result of the collection of one or more data points (e.g., a number ofcomponent reviews and unit tests are investigated to collect measures of the number614 PART THREEQUALITY MANAGEMENT
metrics (continued)architectural design  . . . . . .624class-oriented . .628OO design  . . .627requirements model  . . . . . .619source code  . .638testing . . . . . .639user interfacedesign  . . . . . .635WebApp design  . . . . . .636
uote:
“A science is asmature as itsmeasurementtools.”Louis Pasteur
What’s thedifferencebetween ameasure anda metric??pre75977_ch23.qxd  11/27/08  6:22 PM  Page 614of errors for each). A software metric relates the individual measures in some way(e.g., the average number of errors found per review or the average number of errorsfound per unit test).A software engineer collects measures and develops metrics so that indicatorswill be obtained. An indicatoris a metric or combination of metrics that providesinsight into the software process, a software project, or the product itself. An indica-tor provides insight that enables the project manager or software engineers to adjustthe process, the project, or the product to make things better.
23.1.2 The Challenge of Product Metrics
Over the past four decades, many researchers have attempted to develop a singlemetric that provides a comprehensive measure of software complexity. Fenton[Fen94] characterizes this research as a search for “the impossible holy grail.”Although dozens of complexity measures have been proposed [Zus90], each takes asomewhat different view of what complexity is and what attributes of a system leadto complexity. By analogy, consider a metric for evaluating an attractive car. Someobservers might emphasize body design; others might consider mechanical charac-teristics; still others might tout cost, or performance, or the use of alternative fuels,or the ability to recycle when the car is junked. Since any one of these characteris-tics may be at odds with others, it is difficult to derive a single value for “attractive-ness.” The same problem occurs with computer software.Yet there is a need to measure and control software complexity. And if a singlevalue of this quality metric is difficult to derive, it should be possible to developmeasures of different internal program attributes (e.g., effective modularity, func-tional independence, and other attributes discussed in Chapter 8). These measuresand the metrics derived from them can be used as independent indicators of thequality of requirements and design models. But here again, problems arise. Fenton[Fen94] notes this when he states: “The danger of attempting to find measureswhich characterize so many different attributes is that inevitably the measureshave to satisfy conflicting aims. This is counter to the representational theory ofmeasurement.” Although Fenton’s statement is correct, many people argue thatproduct measurement conducted during the early stages of the software processprovides software engineers with a consistent and objective mechanism forassessing quality.It is fair to ask, however, just how valid product metrics are. That is, how closelyaligned are product metrics to the long-term reliability and quality of a computer-based system? Fenton [Fen91] addresses this question in the following way:
In spite of the intuitive connections between the internal structure of software products[product metrics] and its external product and process attributes, there have actuallybeen very few scientific attempts to establish specific relationships. There are a numberof reasons why this is so; the most commonly cited is the impracticality of conducting rel-evant experiments.CHAPTER 23PRODUCT METRICS 615
An indicator is a metricor metrics that provideinsight into theprocess, the product,or the project.
WebRef
Voluminousinformation onproduct metrics hasbeen compiled byHorst Zuse atirb.cs.tu-berlin.de/~zuse/.uote:
“Just astemperaturemeasurementbegan with anindex finger . . .and grew tosophisticatedscales, tools andtechniques, so toois softwaremeasurementmaturing.”Shari Pfleegerpre75977_ch23.qxd  11/27/08  6:22 PM  Page 615Each of the “challenges” noted here is a cause for caution, but it is no reason todismiss product metrics.
1Measurement is essential if quality is to be achieved.
23.1.3 Measurement Principles
Before I introduce a series of product metrics that (1) assist in the evaluation of theanalysis and design models, (2) provide an indication of the complexity of proceduraldesigns and source code, and (3) facilitate the design of more effective testing, it isimportant for you to understand basic measurement principles. Roche [Roc94] sug-gests a measurement process that can be characterized by five activities:
•Formulation.The derivation of software measures and metrics appropriate forthe representation of the software that is being considered.
•Collection.The mechanism used to accumulate data required to derive theformulated metrics.
•Analysis.The computation of metrics and the application of mathematicaltools.
•Interpretation.The evaluation of metrics resulting in insight into the quality ofthe representation.
•Feedback.Recommendations derived from the interpretation of productmetrics transmitted to the software team.Software metrics will be useful only if they are characterized effectively and vali-dated so that their worth is proven. The following principles [Let03b] are represen-tative of many that can be proposed for metrics characterization and validation:
•A metric should have desirable mathematical properties. That is, the metric’s value should be in a meaningful range (e.g., 0 to 1, where 0 truly meansabsence, 1 indicates the maximum value, and 0.5 represents the “halfwaypoint”). Also, a metric that purports to be on a rational scale should not becomposed of components that are only measured on an ordinal scale.
•When a metric represents a software characteristic that increases when positivetraits occur or decreases when undesirable traits are encountered, the value ofthe metric should increase or decrease in the same manner.
•Each metric should be validated empirically in a wide variety of contexts beforebeing published or used to make decisions. A metric should measure the factor of interest, independently of other factors. It should “scale up” to largesystems and work in a variety of programming languages and systemdomains.616 PART THREEQUALITY MANAGEMENT
1 Although criticism of specific metrics is common in the literature, many critiques focus on esotericissues and miss the primary objective of metrics in the real world: to help the software engineerestablish a systematic and objective way to gain insight into his or her work and to improve prod-uct quality as a result.What are thesteps of aneffectivemeasurementprocess??
In reality, manyproduct metrics in usetoday do not conformto these principles aswell as they should.But that doesn’t meanthat they have novalue—just be carefulwhen you use them,understanding thatthey are intended toprovide insight, nothard scientificverification.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 616Although formulation, characterization, and validation are critical, collection andanalysis are the activities that drive the measurement process. Roche [Roc94] sug-gests the following principles for these activities: (1) whenever possible, data collec-tion and analysis should be automated; (2) valid statistical techniques should beapplied to establish relationships between internal product attributes and externalquality characteristics (e.g., whether the level of architectural complexity correlateswith the number of defects reported in production use); and (3) interpretative guide-lines and recommendations should be established for each metric.
23.1.4 Goal-Oriented Software Measurement
The Goal/Question/Metric(GQM) paradigm has been developed by Basili and Weiss[Bas84] as a technique for identifying meaningful metrics for any part of the softwareprocess. GQM emphasizes the need to (1) establish an explicit measurement goalthat is specific to the process activity or product characteristic that is to be assessed,(2) define a set of questionsthat must be answered in order to achieve the goal, and(3) identify well-formulated metricsthat help to answer these questions.A goal definition template[Bas94] can be used to define each measurement goal.The template takes the form:
Analyze{the name of activity or attribute to be measured} for the purpose of {the over- all objective of the analysis
2} with respect to{the aspect of the activity or attribute that is considered} from the viewpoint of {the people who have an interest in the measure- ment} in the context of{the environment in which the measurement takes place}.
As an example, consider a goal definition template for SafeHome:
Analyzethe SafeHomesoftware architecture for the purpose of evaluating architec- tural components with respect to the ability to make SafeHomemore extensible from the viewpoint ofthe software engineers performing the work in the context of prod- uct enhancement over the next three years.
With a measurement goal explicitly defined, a set of questions is developed. Answersto these questions help the software team (or other stakeholders) to determinewhether the measurement goal has been achieved. Among the questions that mightbe asked are:Q
1: Are architectural components characterized in a manner that compart-mentalizes function and related data?Q
2: Is the complexity of each component within bounds that will facilitatemodification and extension?Each of these questions should be answered quantitatively, using one or more meas-ures and metrics. For example, a metric that provides an indication of the cohesionCHAPTER 23PRODUCT METRICS 617
WebRef
A useful discussion ofGQM can be found at www.thedacs.com/GoldPractices/practices/gqma.html.
2 van Solingen and Berghout [Sol99] suggest that the objective is almost always “understanding,controlling or improving” the process activity or product attribute.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 617(Chapter 8) of an architectural component might be useful in answering Q1. Metrics discussed later in this chapter might provide insight for Q
2. In every case, the metrics that are chosen (or derived) should conform to the measurement principles dis-cussed in Section 23.1.3 and the measurement attributes discussed in Section 23.1.5.
23.1.5 The Attributes of Effective Software Metrics
Hundreds of metrics have been proposed for computer software, but not all providepractical support to the software engineer. Some demand measurement that is toocomplex, others are so esoteric that few real-world professionals have any hopeof understanding them, and others violate the basic intuitive notions of what high-quality software really is.Ejiogu [Eji91] defines a set of attributes that should be encompassed by effectivesoftware metrics. The derived metric and the measures that lead to it should be:
•Simple and computable.It should be relatively easy to learn how to derive themetric, and its computation should not demand inordinate effort or time.
•Empirically and intuitively persuasive.The metric should satisfy the engineer’sintuitive notions about the product attribute under consideration (e.g., ametric that measures module cohesion should increase in value as the levelof cohesion increases).
•Consistent and objective.The metric should always yield results that areunambiguous. An independent third party should be able to derive the samemetric value using the same information about the software. 
•Consistent in its use of units and dimensions. The mathematical computation of the metric should use measures that do not lead to bizarre combinationsof units. For example, multiplying people on the project teams by program-ming language variables in the program results in a suspicious mix of unitsthat are not intuitively persuasive.
•Programming language independent.Metrics should be based on the require-ments model, the design model, or the structure of the program itself. Theyshould not be dependent on the vagaries of programming language syntax orsemantics.
•An effective mechanism for high-quality feedback. That is, the metric should provide you with information that can lead to a higher-quality end product.Although most software metrics satisfy these attributes, some commonly used met-rics may fail to satisfy one or two of them. An example is the function point (discussedin Section 23.2.1)—a measure of the “functionality” delivered by the software. It canbe argued
3that the consistent and objective attribute fails because an independentthird party may not be able to derive the same function point value as a colleague618 PART THREEQUALITY MANAGEMENT
How shouldwe assessthe quality of aproposedsoftware metric??
Experience indicatesthat a product metricwill be used only if it isintuitive and easy tocompute. If dozens of“counts” have to bemade, and complexcomputations arerequired, it is unlikelythat the metric will bewidely adopted.
3 An equally vigorous counterargument can be made. Such is the nature of software metrics.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 618using the same information about the software. Should we therefore reject the FPmeasure? The answer is “Of course not!” FP provides useful insight and therefore pro-vides distinct value, even if it fails to satisfy one attribute perfectly.CHAPTER 23PRODUCT METRICS 619
Debating Product Metrics
The scene:Vinod’s cubicle.The players:Vinod, Jamie, and Ed—members of theSafeHomesoftware engineering team who are continuingwork of component-level design and test-case design.The conversation:Vinod:Doug [Doug Miller, software engineeringmanager] told me that we should all use product metrics,but he was kind of vague. He also said that he wouldn’tpush the matter . . . that using them was up to us.Jamie:That’s good, ’cause there’s no way I have time tostart measuring stuff. We’re fighting to maintain theschedule as it is.Ed:I agree with Jamie. We’re up against it, here . . . notime.Vinod:Yeah, I know, but there’s probably some merit tousing them.Jamie:I’m not arguing that, Vinod, it’s a time thing . . .and I for one don’t have any to spare.Vinod:But what if measuring saves you time?Ed:Wrong, it takes time and like Jamie said . . . Vinod:No, wait. . . what it saves us is time?Jamie:How?Vinod:Rework . . . that’s how. If a measure we use helpsus to avoid one major or even moderate problem, andthat saves us from having to rework a part of the system,we save time. No?Ed:It’s possible, I suppose, but can you guarantee thatsome product metric will help us find a problem?Vinod:Can you guarantee that it won’t?Jamie:So what are you proposing?”Vinod:I think we should select a few design metrics,probably class-oriented, and use them as part of ourreview process for every component we develop.Ed:I’m not real familiar with class-oriented metrics.Vinod:I’ll spend some time checking them out and makea recommendation. . . okay with you guys?[Ed and Jamie nod without much enthusiasm.]SAFEHOME
23.2 M ETRICS FOR THE REQUIREMENTS MODEL
Technical work in software engineering begins with the creation of the requirementsmodel. It is at this stage that requirements are derived and a foundation for design isestablished. Therefore, product metrics that provide insight into the quality of theanalysis model are desirable.Although relatively few analysis and specification metrics have appeared in theliterature, it is possible to adapt metrics that are often used for project estimation andapply them in this context. These metrics examine the requirements model with theintent of predicting the “size” of the resultant system. Size is sometimes (but notalways) an indicator of design complexity and is almost always an indicator ofincreased coding, integration, and testing effort.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 61923.2.1 Function-Based Metrics
The function point(FP) metriccan be used effectively as a means for measuring thefunctionality delivered by a system.
4Using historical data, the FP metric can then beused to (1) estimate the cost or effort required to design, code, and test the software;(2) predict the number of errors that will be encountered during testing; and (3) fore-cast the number of components and/or the number of projected source lines in theimplemented system.Function points are derived using an empirical relationship based on countable(direct) measures of software’s information domain and qualitative assessments ofsoftware complexity. Information domain values are defined in the following manner:
5
Number of external inputs (EIs).Each external inputoriginates from a user or is transmitted from another application and provides distinctapplication-oriented data or control information. Inputs are often used toupdate internal logical files(ILFs). Inputs should be distinguished frominquiries, which are counted separately.Number of external outputs (EOs). Each external outputis derived data within the application that provides information to the user. In this contextexternal output refers to reports, screens, error messages, etc. Individual dataitems within a report are not counted separately.Number of external inquiries (EQs). An external inquiryis defined as an online input that results in the generation of some immediate softwareresponse in the form of an online output (often retrieved from an ILF).Number of internal logical files (ILFs). Each internal logical fileis a logi- cal grouping of data that resides within the application’s boundary and ismaintained via external inputs.Number of external interface files (EIFs). Each external interface fileis a logical grouping of data that resides external to the application but providesinformation that may be of use to the application.Once these data have been collected, the table in Figure 23.1 is completed and a com-plexity value is associated with each count. Organizations that use function pointmethods develop criteria for determining whether a particular entry is simple, average,or complex. Nonetheless, the determination of complexity is somewhat subjective.To compute function points (FP), the following relationship is used:FP /H11005count total /H11003[0.65 /H110010.01 /H11003/H20858(F
i)](23.1) where count total is the sum of all FP entries obtained from Figure 23.1.620 PART THREEQUALITY MANAGEMENT
WebRef
Much usefulinformation aboutfunction points canbe obtained at www.ifpug.organdwww.functionpoints.com.
4 Hundreds of books, papers, and articles have been written on FP metrics. A worthwhile bibliographycan be found at [IFP05].5 In actuality, the definition of information domain values and the manner in which they are countedare a bit more complex. The interested reader should see [IFP01] for more details.pre75977_ch23.qxd  12/1/08  3:25 PM  Page 620The Fi (i/H110051 to 14) are value adjustment factors(VAF) based on responses to the following questions [Lon02]:1.Does the system require reliable backup and recovery?2.Are specialized data communications required to transfer information to orfrom the application?3.Are there distributed processing functions?4.Is performance critical?5.Will the system run in an existing, heavily utilized operational environment?6.Does the system require online data entry?7.Does the online data entry require the input transaction to be built over mul-tiple screens or operations?8.Are the ILFs updated online?9.Are the inputs, outputs, files, or inquiries complex?10.Is the internal processing complex?11.Is the code designed to be reusable?12.Are conversion and installation included in the design?13.Is the system designed for multiple installations in different organizations?14.Is the application designed to facilitate change and ease of use by the user?Each of these questions is answered using a scale that ranges from 0 (not importantor applicable) to 5 (absolutely essential). The constant values in Equation (23.1) andthe weighting factors that are applied to information domain counts are determinedempirically.To illustrate the use of the FP metric in this context, we consider a simple analy-sis model representation, illustrated in Figure 23.2. Referring to the figure, a dataflow diagram (Chapter 7) for a function within the SafeHome software is represented.CHAPTER 23PRODUCT METRICS 621
External Inputs (EIs) /H11003 External Outputs (EOs) /H11003 External Inquiries (EQs) /H11003External Interface Files (EIFs) /H11003 Count totalInternal Logical Files (ILFs) /H1100334357=====4547106761015InformationDomain Value Weighting factorCountSimple Average ComplexFIGURE 23.1
Computingfunction points
Value adjustmentfactors are used toprovide an indicationof problem complexity.
WebRef
An online FP calculatorcan be found at irb.cs.uni-magdeburg.de/sw-eng/us/java/fp/.pre75977_ch23.qxd  12/1/08  3:25 PM  Page 621The function manages user interaction, accepting a user password to activate ordeactivate the system, and allows inquiries on the status of security zones and var-ious security sensors. The function displays a series of prompting messages andsends appropriate control signals to various components of the security system.The data flow diagram is evaluated to determine a set of key information domainmeasures required for computation of the function point metric. Three externalinputs—password, panic button, andactivate/deactivate—are shown in the fig- ure along with two external inquiries—zone inquiryand sensor inquiry. One ILF (system configuration file) is shown. Two external outputs (messages and sensor status) and four EIFs (test sensor, zone setting, activate/deactivate,and alarm alert) are also present. These data, along with the appropriate complex-ity, are shown in Figure 23.3.The count total shown in Figure 23.3 must be adjusted using Equation (23.1). Forthe purposes of this example, we assume that /H9018(F
i) is 46 (a moderately complex product). Therefore,FP /H1100550 /H11003[0.65 /H11001(0.01 /H1100346)] /H1100556 Based on the projected FP value derived from the requirements model, the projectteam can estimate the overall implemented size of the SafeHomeuser interaction622 PART THREEQUALITY MANAGEMENT
UserSafeHomeuserinteractionfunctionMessages
System configuration dataPassword, sensors . . .Sensor statusSensors
Monitoring& responsesubsystemAlarmalertActivate/deactivateZone settingTest sensorUserSensor inquiryPanic buttonActivate/deactivateZone inquiryPasswordFIGURE 23.2
A data flowmodel forSafeHomesoftware
External Inputs (EIs) /H11003 External Outputs (EOs) /H11003 External Inquiries (EQs) /H11003External Interface Files (EIFs) /H11003 Count totalInternal Logical Files (ILFs) /H1100334357=====4547106761015InformationDomain Value Weighting factorCountSimple Average Complex 9862050732241FIGURE 23.3
Computingfunction pointspre75977_ch23.qxd  11/27/08  6:22 PM  Page 622function. Assume that past data indicates that one FP translates into 60 lines of code(an object-oriented language is to be used) and that 12 FPs are produced for eachperson-month of effort. These historical data provide the project manager withimportant planning information that is based on the requirements model rather thanpreliminary estimates. Assume further that past projects have found an average ofthree errors per function point during requirements and design reviews and fourerrors per function point during unit and integration testing. These data can ulti-mately help you assess the completeness of your review and testing activities.Uemura and his colleagues [Uem99] suggest that function points can also be com-puted from UML class and sequence diagrams. If you have further interest, see[Uem99] for details.
23.2.2 Metrics for Specification Quality
Davis and his colleagues [Dav93] propose a list of characteristics that can be used toassess the quality of the requirements model and the corresponding requirementsspecification: specificity(lack of ambiguity), completeness, correctness, understandabil- ity, verifiability, internal and external consistency, achievability, concision, traceability,modifiability, precision,and reusability.In addition, the authors note that high-qualityspecifications are electronically stored; executable or at least interpretable; annotatedby relative importance; and stable, versioned, organized, cross-referenced, and spec-ified at the right level of detail.Although many of these characteristics appear to be qualitative in nature, Daviset al. [Dav93] suggest that each can be represented using one or more metrics. Forexample, we assume that there are n
rrequirements in a specification, such thatn
r/H11005nf/H11001nnf
where nfis the number of functional requirements and nnfis the number of non- functional (e.g., performance) requirements.To determine the specificity(lack of ambiguity) of requirements, Davis et al. sug-gest a metric that is based on the consistency of the reviewers’ interpretation of eachrequirement:Q
1/H11005where n
uiis the number of requirements for which all reviewers had identicalinterpretations. The closer the value of Q to 1, the lower is the ambiguity of the specification.The completenessof functional requirements can be determined by computing theratioQ
2/H11005where n
uis the number of unique functional requirements, niis the number of inputs (stimuli) defined or implied by the specification, and n
sis the number of statesnu
ni/H11003nsnui
nrCHAPTER 23PRODUCT METRICS 623
uote:
“Rather than justmusing on what’new metric’ mightapply . . . weshould also beasking ourselvesthe more basicquestion, ’Whatwill we do withmetrics?”Michael MahandLarry Putnam
By measuringcharacteristics of thespecification, it ispossible to gainquantitative insightinto specificity andcompleteness.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 623specified. The Q2ratio measures the percentage of necessary functions that havebeen specified for a system. However, it does not address nonfunctional require-ments. To incorporate these into an overall metric for completeness, you must con-sider the degree to which requirements have been validated:Q
3/H11005where n
cis the number of requirements that have been validated as correct and nnv
is the number of requirements that have not yet been validated.
23.3 M ETRICS FOR THE DESIGN MODEL
It is inconceivable that the design of a new aircraft, a new computer chip, or a newoffice building would be conducted without defining design measures, determiningmetrics for various aspects of design quality, and using them as indicators to guidethe manner in which the design evolves. And yet, the design of complex software-based systems often proceeds with virtually no measurement. The irony of this is thatdesign metrics for software are available, but the vast majority of software engineerscontinue to be unaware of their existence.Design metrics for computer software, like all other software metrics, are not per-fect. Debate continues over their efficacy and the manner in which they should beapplied. Many experts argue that further experimentation is required before designmeasures can be used. And yet, design without measurement is an unacceptablealternative.In the sections that follow, I examine some of the more common design metricsfor computer software. Each can provide you with improved insight, and all can helpthe design to evolve to a higher level of quality. 
23.3.1 Architectural Design Metrics
Architectural design metrics focus on characteristics of the program architecture(Chapter 9) with an emphasis on the architectural structure and the effectiveness ofmodules or components within the architecture. These metrics are “black box” in thesense that they do not require any knowledge of the inner workings of a particularsoftware component.Card and Glass [Car90] define three software design complexity measures: struc-tural complexity, data complexity, and system complexity.For hierarchical architectures (e.g., call-and-return architectures), structural complexityof a module iis defined in the following manner:S(i) /H11005f
2out(i)where f
out(i) is the fan-out6of module i.nc
nc+ nnv624 PART THREEQUALITY MANAGEMENT
uote:
“Measure what ismeasurable, andwhat is notmeasurable, makemeasurable.”Galileo
Metrics can provideinsight into structuraldata and systemcomplexity associatedwith architecturaldesign.
6Fan-outis defined as the number of modules immediately subordinate to module i; that is, thenumber of modules that are directly invoked by module i.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 624Data complexityprovides an indication of the complexity in the internal interfacefor a module iand is defined asD(i)/H11005where v(i) is the number of input and output variables that are passed to and frommodule i.Finally, system complexityis defined as the sum of structural and data complexity,specified asC(i) /H11005S(i) /H11001D(i)As each of these complexity values increases, the overall architectural complexity ofthe system also increases. This leads to a greater likelihood that integration andtesting effort will also increase.Fenton [Fen91] suggests a number of simple morphology (i.e., shape) metrics thatenable different program architectures to be compared using a set of straightforwarddimensions. Referring to the call-and-return architecture in Figure 23.4, the follow-ing metrics can be defined:Size /H11005n + awhere nis the number of nodes and ais the number of arcs. For the architecture shown in Figure 23.4, Size /H1100517 /H1100118 /H1100535Depth /H11005longest path from the root (top) node to a leaf node. For the architec-ture shown in Figure 23.4, depth /H110054. Width /H11005maximum number of nodes at any one level of the architecture. Forthe architecture shown in Figure 23.4, width /H11005 6. The arc-to-node ratio, r /H11005a/H20862n,measures the connectivity density of the architectureand may provide a simple indication of the coupling of the architecture. For thearchitecture shown in Figure 23.4, r/H1100518/H2086217/H110051.06.v(i)f
out(i)/H110011CHAPTER 23PRODUCT METRICS 625
je
n qpk l
rid
mhb
gfca
Width
DepthNode
ArcFIGURE 23.4
Morphologymetricspre75977_ch23.qxd  11/27/08  6:22 PM  Page 625The U.S. Air Force Systems Command [USA87] has developed a number of soft-ware quality indicators that are based on measurable design characteristics of acomputer program. Using concepts similar to those proposed in IEEE Std. 982.1-1988[IEE94], the Air Force uses information obtained from data and architectural designto derive a design structure quality index (DSQI) that ranges from 0 to 1. The follow- ing values must be ascertained to compute the DSQI [Cha89]:S
1/H11005total number of modules defined in the program architectureS
2/H11005number of modules whose correct function depends on the source of datainput or that produce data to be used elsewhere (in general, control mod-ules, among others, would not be counted as part of S
2) S
3/H11005number of modules whose correct function depends on prior processingS
4/H11005number of database items (includes data objects and all attributes thatdefine objects)S
5/H11005total number of unique database itemsS
6/H11005number of database segments (different records or individual objects)S
7/H11005number of modules with a single entry and exit (exception processing isnot considered to be a multiple exit)Once values S
1through S7are determined for a computer program, the followingintermediate values can be computed:Program structure: D
1, where D1is defined as follows: If the architectural designwas developed using a distinct method (e.g., data flow-oriented design or object-oriented design), then D
1/H110051, otherwise D1/H110050.Module independence: D
2/H110051/H11002Modules not dependent on prior processing: D
3/H110051/H11002Database size: D
4/H110051/H11002Database compartmentalization: D
5/H110051/H11002Module entrance/exit characteristic: D
6/H110051/H11002With these intermediate values determined, the DSQI is computed in the followingmanner:DSQI /H11005/H20858w
iDi
where i/H110051 to 6, wiis the relative weighting of the importance of each of the inter-mediate values, and /H20858w
i/H110051 (if all Diare weighted equally, then wi/H110050.167). The value of DSQI for past designs can be determined and compared to a designthat is currently under development. If the DSQI is significantly lower than average,S7
S1S6
S4S5
S4S3
S1S2
S1626 PART THREEQUALITY MANAGEMENT
uote:
“Measurement canbe seen as adetour. This detouris necessarybecause humansmostly are not ableto make clear andobjective decisions[withoutquantitativesupport].”Horst Zusepre75977_ch23.qxd  11/27/08  6:22 PM  Page 626further design work and review are indicated. Similarly, if major changes are to bemade to an existing design, the effect of those changes on DSQI can be calculated.
23.3.2 Metrics for Object-Oriented Design
There is much about object-oriented design that is subjective—an experienceddesigner “knows” how to characterize an OO system so that it will effectively imple-ment customer requirements. But, as an OO design model grows in size and com-plexity, a more objective view of the characteristics of the design can benefit both theexperienced designer (who gains additional insight) and the novice (who obtains anindication of quality that would otherwise be unavailable).In a detailed treatment of software metrics for OO systems, Whitmire [Whi97]describes nine distinct and measurable characteristics of an OO design:Size.Size is defined in terms of four views: population, volume, length, andfunctionality. Populationis measured by taking a static count of OO entitiessuch as classes or operations. Volumemeasures are identical to populationmeasures but are collected dynamically—at a given instant of time. Length is a measure of a chain of interconnected design elements (e.g., the depth of aninheritance tree is a measure of length). Functionality metrics provide an indi- rect indication of the value delivered to the customer by an OO application.Complexity.Like size, there are many differing views of software complex-ity [Zus97]. Whitmire views complexity in terms of structural characteristicsby examining how classes of an OO design are interrelated to one another.Coupling.The physical connections between elements of the OO design(e.g., the number of collaborations between classes or the number of mes-sages passed between objects) represent coupling within an OO system.Sufficiency.Whitmire defines sufficiencyas “the degree to which an abstrac- tion possesses the features required of it, or the degree to which a designcomponent possesses features in its abstraction, from the point of view ofthe current application.” Stated another way, we ask: “What properties doesthis abstraction (class) need to possess to be useful to me?” [Whi97]. Inessence, a design component (e.g., a class) is sufficient if it fully reflects all properties of the application domain object that it is modeling—that is, thatthe abstraction (class) possesses the features required of it.Completeness.The only difference between completeness and sufficiencyis “the feature set against which we compare the abstraction or design com-ponent” [Whi97]. Sufficiency compares the abstraction from the point of viewof the current application. Completeness considers multiple points of view, asking the question: “What properties are required to fully represent theproblem domain object?” Because the criterion for completeness considersdifferent points of view, it has an indirect implication about the degree towhich the abstraction or design component can be reused.CHAPTER 23PRODUCT METRICS 627
Whatcharacter-istics can bemeasured whenwe assess an OOdesign??
uote:
“Many of thedecisions for whichI had to rely onfolklore and mythcan now be madeusing quantitativedata.”Scott Whitmirepre75977_ch23.qxd  11/27/08  6:22 PM  Page 627Cohesion.Like its counterpart in conventional software, an OO componentshould be designed in a manner that has all operations working together toachieve a single, well-defined purpose. The cohesiveness of a class is deter-mined by examining the degree to which “the set of properties it possesses ispart of the problem or design domain” [Whi97].Primitiveness.A characteristic that is similar to simplicity, primitiveness(applied to both operations and classes) is the degree to which an operationis atomic—that is, the operation cannot be constructed out of a sequence ofother operations contained within a class. A class that exhibits a high degreeof primitiveness encapsulates only primitive operations.Similarity.The degree to which two or more classes are similar in termsof their structure, function, behavior, or purpose is indicated by this measure.Volatility.As I have noted many times throughout this book, design changescan occur when requirements are modified or when modifications occur inother parts of an application, resulting in mandatory adaptation of the designcomponent in question. Volatility of an OO design component measures thelikelihood that a change will occur.In reality, product metrics for OO systems can be applied not only to the designmodel, but also the requirements model. In the sections that follow, I discuss met-rics that provide an indication of quality at the OO class level and the operationlevel. In addition, metrics applicable for project management and testing are alsoexplored.
23.3.3 Class-Oriented Metrics—The CK Metrics Suite
The class is the fundamental unit of an OO system. Therefore, measures and metricsfor an individual class, the class hierarchy, and class collaborations will be invalu-able when you are required to assess OO design quality. A class encapsulates dataand the function that manipulate the data. It is often the “parent” for subclasses(sometimes called children) that inherit its attributes and operations. It often collab-orates with other classes. Each of these characteristics can be used as the basis formeasurement.
7
Chidamber and Kemerer have proposed one of the most widely referenced sets ofOO software metrics [Chi94]. Often referred to as the CK metrics suite, the authors have proposed six class-based design metrics for OO systems.
8
Weighted methods per class (WMC). Assume that nmethods of complexity c1, c
2,...,  cnare defined for a class C. The specific complexity metric that is chosen628 PART THREEQUALITY MANAGEMENT
7 It should be noted that the validity of some of the metrics discussed in this chapter is currentlydebated in the technical literature. Those who champion measurement theory demand a degree offormalism that some OO metrics do not provide. However, it is reasonable to state that the metricsnoted provide useful insight for the software engineer.8 Chidamber, Darcy, and Kemerer use the term methodsrather than operations. Their usage of the term is reflected in this section.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 628(e.g., cyclomatic complexity) should be normalized so that nominal complexity for amethod takes on a value of 1.0.WMC /H11005/H20858c
i
for i/H110051 to n. The number of methods and their complexity are reasonable indicatorsof the amount of effort required to implement and test a class. In addition, the largerthe number of methods, the more complex is the inheritance tree (all subclassesinherit the methods of their parents). Finally, as the number of methods grows for agiven class, it is likely to become more and more application specific, thereby limitingpotential reuse. For all of these reasons, WMC should be kept as low as is reasonable.Although it would seem relatively straightforward to develop a count for the num-ber of methods in a class, the problem is actually more complex than it seems. A con-sistent counting approach [Chu95] should be developed.Depth of the inheritance tree (DIT). This metric is “the maximum length from the node to the root of the tree” [Chi94]. Referring to Figure 23.5, the value of DIT forthe class hierarchy shown is 4. As DIT grows, it is likely that lower-level classes willinherit many methods. This leads to potential difficulties when attempting to predictthe behavior of a class. A deep class hierarchy (DIT is large) also leads to greaterdesign complexity. On the positive side, large DIT values imply that many methodsmay be reused.Number of children (NOC).The subclasses that are immediately subordinate toa class in the class hierarchy are termed its children. Referring to Figure 23.5, classC
2has three children—subclasses C21,C22, and C23. As the number of children grows, reuse increases, but also, as NOC increases, the abstraction represented bythe parent class can be diluted if some of the children are not appropriate membersof the parent class. As NOC increases, the amount of testing (required to exerciseeach child in its operational context) will also increase.CHAPTER 23PRODUCT METRICS 629
C
C1
C11
C211C21 C22 C23C2FIGURE 23.5
A classhierarchypre75977_ch23.qxd  11/27/08  6:22 PM  Page 629Coupling between object classes (CBO). The CRC model (Chapter 6) may be used to determine the value for CBO. In essence, CBO is the number of collabora-tions listed for a class on its CRC index card.
9As CBO increases, it is likely that the reusability of a class will decrease. High values of CBO also complicate modificationsand the testing that ensues when modifications are made. In general, the CBO val-ues for each class should be kept as low as is reasonable. This is consistent with thegeneral guideline to reduce coupling in conventional software.Response for a class (RFC).The response set of a class is “a set of methods thatcan potentially be executed in response to a message received by an object of thatclass” [Chi94]. RFC is the number of methods in the response set. As RFC increases,the effort required for testing also increases because the test sequence (Chapter 19)grows. It also follows that, as RFC increases, the overall design complexity of theclass increases.Lack of cohesion in methods (LCOM). Each method within a class C accesses one or more attributes (also called instance variables). LCOM is the number of meth-ods that access one or more of the same attributes.
10If no methods access the same attributes, then LCOM/H110050. To illustrate the case where LCOM /HS110050, consider a class with six methods. Four of the methods have one or more attributes in common (i.e.,they access common attributes). Therefore, LCOM /H11005 4. If LCOM is high, methods may be coupled to one another via attributes. This increases the complexity of the classdesign. Although there are cases in which a high value for LCOM is justifiable, it isdesirable to keep cohesion high; that is, keep LCOM low.
11630 PART THREEQUALITY MANAGEMENT
The concepts ofcoupling and cohesionapply to both conven-tional and OOsoftware. Keep classcoupling low and classand operation cohesionhigh.
9 If CRC index cards are developed manually, completeness and consistency must be assessed beforeCBO can be determined reliably.10 The formal definition is a bit more complex. See [Chi94] for details.11 The LCOM metric provides useful insight in some situations, but it can be misleading in others. Forexample, keeping coupling encapsulated within a class increases the cohesion of the system as awhole. Therefore in at least one important sense, higher LCOM actually suggests that a class mayhave higher cohesion, not lower.Applying CK Metrics
The scene:Vinod’s cubicle.The players:Vinod, Jamie, Shakira, and Ed—members of the SafeHomesoftware engineering teamwho are continuing to work on component-level designand test-case design.The conversation:Vinod:Did you guys get a chance to read thedescription of the CK metrics suite I sent you onWednesday and make those measurements?Shakira:Wasn’t too complicated. I went back to myUML class and sequence diagrams, like you suggested,and got rough counts for DIT, RFC, and LCOM. I couldn’tfind the CRC model, so I didn’t count CBO.Jamie (smiling):You couldn’t find the CRC modelbecause I had it.Shakira:That’s what I love about this team, superbcommunication.SAFEHOMEpre75977_ch23.qxd  11/27/08  6:22 PM  Page 63023.3.4 Class-Oriented Metrics—The MOOD Metrics Suite
Harrison, Counsell, and Nithi [Har98b] propose a set of metrics for object-orienteddesign that provide quantitative indicators for OO design characteristics. A samplingof MOOD metrics follows.Method inheritance factor (MIF). The degree to which the class architecture of an OO system makes use of inheritance for both methods (operations) and attributesis defined asMIF/H11005where the summation occurs over i /H110051 to TC. TC is defined as the total number of classes in the architecture, C
iis a class within the architecture, andM
a(Ci) /H11005Md(Ci) + Mi(Ci)whereM
a(Ci) /H11005number of methods that can be invoked in association with Ci
Md(Ci) /H11005number of methods declared in the class Ci
Mi(Ci) /H11005number of methods inherited (and not overridden) in Ci
The value of MIF [the attribute inheritance factor (AIF) is defined in an analogousmanner] provides an indication of the impact of inheritance on the OO software.Coupling factor (CF).Earlier in this chapter I noted that coupling is an indicationof the connections between elements of the OO design. The MOOD metrics suitedefines coupling in the following way:CF/H11005∑
i∑jis_clientwhere the summations occur over i /H110051 to T
cand j/H110051 to Tc. The function(Ci, Cj)T
c2/H11002Tc/H20858Mi(Ci)/H20858M
a(Ci)CHAPTER 23PRODUCT METRICS 631
Vinod:I did my counts . . . did you guys developnumbers for the CK metrics?[Jamie and Ed nod in the affirmative.]Jamie:Since I had the CRC cards, I took a look at CBOand it looked pretty uniform across most of the classes.There was one exception, which I noted.Ed:There are a few classes where RFC is pretty high,compared with the averages . . . maybe we should take alook at simplifying them.Jamie:Maybe yes, maybe no. I’m still concerned abouttime, and I don’t want to fix stuff that isn’t really broken.Vinod:I agree with that. Maybe we should look forclasses that have bad numbers in at least two or moreof the CK metrics. Kind of two strikes and you’remodified.Shakira (looking over Ed’s list of classes withhigh RFC):Look, see this class, it’s got a high LCOM aswell as a high RFC. Two strikes?Vinod:Yeah I think so . . . it’ll be difficult to implementbecause of complexity and difficult to test for the samereason. Probably worth designing two separate classes toachieve the same behavior.Jamie:You think modifying it’ll save us time?Vinod:Over the long haul, yes.
uote:
“Analyzing OOsoftware in orderto evaluate itsquality is becomingincreasinglyimportant as the[OO] paradigmcontinues toincrease inpopularity.”RachelHarrison et al.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 631is_client/H110051, if and only if a relationship exists between the client class Ccand the server class C
s, and Cc/HS11005Cs
/H110050, otherwiseAlthough many factors affect software complexity, understandability, and maintain-ability, it is reasonable to conclude that as the value for CF increases, the complex-ity of the OO software will also increase and understandability, maintainability, andthe potential for reuse may suffer as a result.Harrison and her colleagues [Har98b] present a detailed analysis of MIF and CFalong with other metrics and examine their validity for use in the assessment ofdesign quality.
23.3.5 OO Metrics Proposed by Lorenz and Kidd
In their book on OO metrics, Lorenz and Kidd [Lor94] divide class-based metricsinto four broad categories that each have a bearing on component-level design:size, inheritance, internals, and externals. Size-oriented metrics for an OO designclass focus on counts of attributes and operations for an individual class and aver-age values for the OO system as a whole. Inheritance-based metrics focus on themanner in which operations are reused through the class hierarchy. Metrics forclass internals look at cohesion (Section 23.3.3) and code-oriented issues, andexternal metrics examine coupling and reuse. One example of the metrics proposedby Lorenz and Kidd is:Class size (CS).The overall size of a class can be determined using the followingmeasures: 
•The total number of operations (both inherited and private instance opera-tions) that are encapsulated within the class
•The number of attributes (both inherited and private instance attributes) thatare encapsulated by the classThe WMC metric proposed by Chidamber and Kemerer (Section 23.3.3) is also aweighted measure of class size. As I noted earlier, large values for CS indicate that aclass may have too much responsibility. This will reduce the reusability of the classand complicate implementation and testing. In general, inherited or public opera-tions and attributes should be weighted more heavily in determining class size[Lor94]. Private operations and attributes enable specialization and are more local-ized in the design. Averages for the number of class attributes and operations mayalso be computed. The lower the average values for size, the more likely that classeswithin the system can be reused widely.
23.3.6 Component-Level Design Metrics
Component-level design metrics for conventional software components focus oninternal characteristics of a software component and include measures of the632 PART THREEQUALITY MANAGEMENT
During review of theanalysis model, CRCindex cards will providea reasonable indicationof expected values forCS. If you encounter aclass with a largenumber of responsibili-ties, considerpartitioning it.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 632“three Cs”—module cohesion, coupling, and complexity. These measures can helpyou judge the quality of a component-level design.Component-level design metrics may be applied once a procedural design hasbeen developed and are “glass box” in the sense that they require knowledge of theinner workings of the module under consideration. Alternatively, they may bedelayed until source code is available.Cohesion metrics.Bieman and Ott [Bie94] define a collection of metrics thatprovide an indication of the cohesiveness (Chapter 8) of a module. The metrics aredefined in terms of five concepts and measures:Data slice.Stated simply, a data slice is a backward walk through a module thatlooks for data values that affect the module location at which the walk began. Itshould be noted that both program slices (which focus on statements and con-ditions) and data slices can be defined.Data tokens.The variables defined for a module can be defined as data tokensfor the module.Glue tokens.This set of data tokens lies on one or more data slice.Superglue tokens.These data tokens are common to every data slice in a module.Stickiness.The relative stickiness of a glue token is directly proportional to thenumber of data slices that it binds.Bieman and Ott develop metrics for strong functional cohesion (SFC), weak functional cohesion(WFC), and adhesiveness(the relative degree to which glue tokens bind dataslices together). A detailed discussion of the Bieman and Ott metrics is best left tothe authors [Bie94].Coupling metrics.Module coupling provides an indication of the “connected-ness” of a module to other modules, global data, and the outside environment. InChapter 9, coupling was discussed in qualitative terms.Dhama [Dha95] has proposed a metric for module coupling that encompassesdata and control flow coupling, global coupling, and environmental coupling. Themeasures required to compute module coupling are defined in terms of each of thethree coupling types noted previously.For data and control flow coupling,d
i/H11005number of input data parametersc
i/H11005number of input control parametersd
o/H11005number of output data parametersc
o/H11005number of output control parametersFor global coupling,g
d/H11005number of global variables used as datag
c/H11005number of global variables used as controlCHAPTER 23PRODUCT METRICS 633
It is possible tocompute measuresof the functionalindependence—coupling andcohesion—of acomponent and to usethese to assess thequality of a design.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 633For environmental coupling,w/H11005number of modules called (fan-out)r/H11005number of modules calling the module under consideration (fan-in)Using these measures, a module coupling indicator m
cis defined in the following way:m
c/H11005where kis a proportionality constant andM/H11005d
i/H11001(a/H11003ci) /H11001do/H11001(b/H11003co) /H11001gd/H11001(c/H11003gc) /H11001w/H11001r Values for k, a , b,and cmust be derived empirically.As the value for m
cincreases, the overall module coupling decreases. In order tohave the coupling metric move upward as the degree of coupling increases, a revisedcoupling metric may be defined asC/H110051 /H11002m
c
where the degree of coupling increases as the value of M increases. Complexity metrics.A variety of software metrics can be computed to deter-mine the complexity of program control flow. Many of these are based on the flowgraph. A graph (Chapter 18) is a representation composed of nodes and links (alsocalled edges). When the links (edges) are directed, the flow graph is a directedgraph.McCabe and Watson [McC94] identify a number of important uses for complexitymetrics: 
Complexity metrics can be used to predict critical information about reliability and main-tainability of software systems from automatic analysis of source code [or proceduraldesign information]. Complexity metrics also provide feedback during the software proj-ect to help control the [design activity]. During testing and maintenance, they provide de-tailed information about software modules to help pinpoint areas of potential instability.
The most widely used (and debated) complexity metric for computer software iscyclomatic complexity, originally developed by Thomas McCabe [McC76] and dis-cussed in detail in Chapter 18.Zuse ([Zus90], [Zus97]) presents an encyclopedic discussion of no fewer than 18different categories of software complexity metrics. The author presents the basicdefinitions for metrics in each category (e.g., there are a number of variations on thecyclomatic complexity metric) and then analyzes and critiques each. Zuse’s work isthe most comprehensive published to date.
23.3.7 Operation-Oriented Metrics
Because the class is the dominant unit in OO systems, fewer metrics have beenproposed for operations that reside within a class. Churcher and Shepperd [Chu95]kM634 PART THREEQUALITY MANAGEMENT
Cyclomatic complexityis only one of a largenumber of complexitymetrics.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 634discuss this when they state: “Results of recent studies indicate that methods tend tobe small, both in terms of number of statements and in logical complexity [Wil93],suggesting that connectivity structure of a system may be more important than thecontent of individual modules.” However, some insights can be gained by examin-ing average characteristics for methods (operations). Three simple metrics, proposedby Lorenz and Kidd [Lor94], are appropriate:Average operation size (OS
avg).Size can be determined by counting thenumber of lines of code or the number of messages sent by the operation. Asthe number of messages sent by a single operation increases, it is likely thatresponsibilities have not been well allocated within a class.Operation complexity (OC).The complexity of an operation can be com-puted using any of the complexity metrics proposed for conventional software[Zus90]. Because operations should be limited to a specific responsibility, thedesigner should strive to keep OC as low as possible.Average number of parameters per operation (NP
avg).The larger the number of operation parameters, the more complex the collaborationbetween objects. In general, NP
avgshould be kept as low as possible.
23.3.8 User Interface Design Metrics
Although there is significant literature on the design of human/computer interfaces(Chapter 11), relatively little information has been published on metrics that wouldprovide insight into the quality and usability of the interface.Sears [Sea93] suggests that layout appropriateness(LA) is a worthwhile design metric for human/computer interfaces. A typical GUI uses layout entities—graphicicons, text, menus, windows, and the like—to assist the user in completing tasks. Toaccomplish a given task using a GUI, the user must move from one layout entity tothe next. The absolute and relative position of each layout entity, the frequency withwhich it is used, and the “cost” of the transition from one layout entity to the next allcontribute to the appropriateness of the interface.A study of Web page metrics [Ivo01] indicates that simple characteristics of theelements of the layout can also have a significant impact on the perceived quality ofthe GUI design. The number of words, links, graphics, colors, and fonts (among othercharacteristics) contained within a Web page affect the perceived complexity andquality of that page.It is important to note that the selection of a GUI design can be guided with met-rics such as LA, but the final arbiter should be user input based on GUI prototypes.Nielsen and Levy [Nie94] report that “one has a reasonably large chance of suc-cess if one chooses between interface [designs] based solely on users’ opinions.Users’ average task performance and their subjective satisfaction with a GUI arehighly correlated.”CHAPTER 23PRODUCT METRICS 635
uote:
“You can learn atleast one principleof user interfacedesign by loading adishwasher. If youcrowd a lot inthere, nothing getsvery clean.”Author unknownpre75977_ch23.qxd  11/27/08  6:22 PM  Page 63523.4 D ESIGN METRICS FOR WEBAPPS
A useful set of measures and metrics for WebApps provides quantitative answers tothe following questions: 
•Does the user interface promote usability?
•Are the aesthetics of the WebApp appropriate for the application domain andpleasing to the user?
•Is the content designed in a manner that imparts the most information withthe least effort?
•Is navigation efficient and straightforward?
•Has the WebApp architecture been designed to accommodate the specialgoals and objectives of WebApp users, the structure of content and function-ality, and the flow of navigation required to use the system effectively?
•Are components designed in a manner that reduces procedural complexityand enhances correctness, reliability, and performance?Today, each of these questions can be addressed only qualitatively because a vali-dated suite of metrics that would provide quantitative answers does not yet exist.In the paragraphs that follow, I present a representative sampling of WebAppdesign metrics that have been proposed in the literature. It is important to note thatmany of these metrics have not as yet been validated and should be used judiciously.Interface metrics.For WebApps, the following interface measures can beconsidered:
Suggested MetricDescriptionLayout appropriateness See Section 23.3.8.Layout complexityNumber of distinct regions
12defined for an interface Layout region complexity Average number of distinct links per regionRecognition complexity Average number of distinct items the user must look at before making anavigation or data input decisionRecognition time Average time (in seconds) that it takes a user to select the appropriateaction for a given taskTyping effort Average number of key strokes required for a specific functionMouse pick effort Average number of mouse picks per functionSelection complexity Average number of links that can be selected per pageContent acquisition time Average number of words of text per Web pageMemory load Average number of distinct data items that the user must remember to
achieve a specific objective636PART THREEQUALITY MANAGEMENT
Many of these metricsare applicable to alluser interfaces andshould be consideredin conjunction withthose presented inSection 23.3.8.
12 A distinct region is an area within the layout display that accomplishes some specific set of relatedfunctions (e.g., a menu bar, a static graphical display, a content area, an animated display).pre75977_ch23.qxd  11/27/08  6:22 PM  Page 636Aesthetic (graphic design) metrics. By its nature, aesthetic design relies on qualitative judgment and is not generally amenable to measurement and metrics.However, Ivory and her colleagues [Ivo01] propose a set of measures that may beuseful in assessing the impact of aesthetic design:
Suggested MetricDescriptionWord count Total number of words that appear on a pageBody text percentage Percentage of words that are body versus display text (i.e., headers)Emphasized body text % Portion of body text that is emphasized (e.g., bold, capitalized)Text positioning count Changes in text position from flush leftText cluster countText areas highlighted with color, bordered regions, rules, or listsLink countTotal links on a pagePage sizeTotal bytes for the page as well as elements, graphics, and style sheetsGraphic percentage Percentage of page bytes that are for graphicsGraphics countTotal graphics on a page (not including graphics specified in scripts,applets, and objects)Color countTotal colors employed
Font countTotal fonts employed (i.e., face /H11001size /H11001bold /H11001italic)
Content metrics.Metrics in this category focus on content complexity and onclusters of content objects that are organized into pages [Men01].
Suggested MetricDescriptionPage waitAverage time required for a page to download at different connection speedsPage complexity Average number of different types of media used on page, notincluding text  Graphic complexity Average number of graphics media per pageAudio complexity Average number of audio media per page  Video complexity Average number of video media per page  Animation complexity Average number of animations per page  
Scanned image complexity Average number of scanned images per page
Navigation metrics.Metrics in this category address the complexity of the navi-gational flow [Men01]. In general, they are applicable only for static Web applica-tions, which don’t include dynamically generated links and pages.
Suggested MetricDescriptionPage-linking complexity Number of links per pageConnectivity Total number of internal links, not including dynamically generated links
Connectivity densityConnectivity divided by page count  CHAPTER 23PRODUCT METRICS 637pre75977_ch23.qxd  11/27/08  6:22 PM  Page 637Using a subset of the metrics suggested, it may be possible to derive empirical rela-tions that allow a WebApp development team to assess technical quality and predicteffort based on projected estimates of complexity. Further work remains to beaccomplished in this area.638 PART THREEQUALITY MANAGEMENT
Technical Metrics for WebApps
Objective:To assist Web engineers indeveloping meaningful WebApp metrics thatprovide insight into the overall quality of an application.Mechanics:Tool mechanics vary.Representative Tools:
13Netmechanic Tools,developed by Netmechanic (www.netmechanic.com),is a collection of tools that help to improve websiteperformance, focusing on implementation-specific issues.NIST Web Metrics Testbed, developed by TheNational Institute of Standards and Technology(zing.ncsl.nist.gov/WebTools/) encompasses thefollowing collection of useful tools that are available fordownload:Web Static Analyzer Tool (WebSAT)—checks Web pageHTML against typical usability guidelines.Web Category Analysis Tool (WebCAT)—lets the usabilityengineer construct and conduct a Web category analysis.Web Variable Instrumenter Program (WebVIP)—instruments a website to capture a log of user interaction.Framework for Logging Usability Data (FLUD) — implements a file formatter and parser for representationof user interaction logs.VisVIP Tool—produces a 3D visualization of usernavigation paths through a website.TreeDec—adds navigation aids to the pages of a website.SOFTWARE TOOLS
13 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.14 It should be noted that Halstead’s “laws” have generated substantial controversy, and many believethat the underlying theory has flaws. However, experimental verification for selected programminglanguages has been performed (e.g., [Fel89]).23.5 M ETRICS FOR SOURCE CODE
Halstead’s theory of “software science” [Hal77] proposed the first analytical “laws”for computer software.
14Halstead assigned quantitative laws to the development ofcomputer software, using a set of primitive measures that may be derived after codeis generated or estimated once design is complete. The measures are:n
1/H11005number of distinct operators that appear in a programn
2 /H11005number of distinct operands that appear in a programN
1/H11005total number of operator occurrencesN
2/H11005total number of operand occurrencesHalstead uses these primitive measures to develop expressions for the overall pro-gram length, potential minimum volume for an algorithm, the actual volume (num-ber of bits required to specify a program), the program level (a measure of softwarecomplexity), the language level (a constant for a given language), and other featuressuch as development effort, development time, and even the projected number offaults in the software.uote:
“The human brainfollows a more rigidset of rules [fordevelopingalgorithms] than ithas been aware of.”MauriceHalsteadpre75977_ch23.qxd  11/27/08  6:22 PM  Page 638Halstead shows that length Ncan be estimatedN/H11005n
1log2n1/H11001n2log2n2
and program volume may be definedV/H11005Nlog
2(n1/H11001n2)It should be noted that Vwill vary with programming language and represents thevolume of information (in bits) required to specify a program.Theoretically, a minimum volume must exist for a particular algorithm. Halsteaddefines a volume ratio Las the ratio of volume of the most compact form of a pro-gram to the volume of the actual program. In actuality, Lmust always be less than 1. In terms of primitive measures, the volume ratio may be expressed asL/H11005/H11003Halstead’s work is amenable to experimental verification and a large body of researchhas been conducted to investigate software science. A discussion of this work is be-yond the scope of this book. For further information, see [Zus90], [Fen91], and [Zus97].
23.6 M ETRICS FOR TESTING
Although much has been written on software metrics for testing (e.g., [Het93]), themajority of metrics proposed focus on the process of testing, not the technical char-acteristics of the tests themselves. In general, testers must rely on analysis, design,and code metrics to guide them in the design and execution of test cases.Architectural design metrics provide information on the ease or difficulty associ-ated with integration testing (Section 23.3) and the need for specialized testingsoftware (e.g., stubs and drivers). Cyclomatic complexity (a component-level designmetric) lies at the core of basis path testing, a test-case design method presented inChapter 18. In addition, cyclomatic complexity can be used to target modules as can-didates for extensive unit testing. Modules with high cyclomatic complexity are morelikely to be error prone than modules whose cyclomatic complexity is lower. For thisreason, you should expend above average effort to uncover errors in such modulesbefore they are integrated in a system.
23.6.1 Halstead Metrics Applied to Testing
Testing effort can be estimated using metrics derived from Halstead measures (Sec-tion 23.5). Using the definitions for program volume Vand program level PL, Halstead effort ecan be computed as PL/H11005 (23.2a)e/H11005 (23.2b)
VPL1(n
1/H208622)/H11003 (N2/n2)n2
N22n
1CHAPTER 23PRODUCT METRICS 639
Testing metrics fall intotwo broad categories:(1) metrics thatattempt to predict thelikely number of testsrequired at varioustesting levels, and (2) metrics that focuson test coverage for agiven component.Operators include allflow of controlconstructs, condi-tionals, and mathoperations. Operandsencompass all programvariables andconstants.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 639The percentage of overall testing effort to be allocated to a module k can be esti- mated using the following relationship:Percentage of testing effort (k) /H11005 (23.3) where e(k) is computed for module kusing Equations (23.2) and the summation inthe denominator of Equation (23.3) is the sum of Halstead effort across all modulesof the system.
23.6.2 Metrics for Object-Oriented Testing
The OO design metrics noted in Section 23.3 provide an indication of design quality.They also provide a general indication of the amount of testing effort required to ex-ercise an OO system. Binder [Bin94b] suggests a broad array of design metrics thathave a direct influence on the “testability” of an OO system. The metrics consideraspects of encapsulation and inheritance.Lack of cohesion in methods (LCOM).
15The higher the value of LCOM, the more states must be tested to ensure that methods do not generate side effects.Percent public and protected (PAP). Public attributes are inherited from other classes and therefore are visible to those classes. Protected attributesare accessible to methods in subclasses. This metric indicates the percentageof class attributes that are public or protected. High values for PAP increasethe likelihood of side effects among classes because public and protectedattributes lead to high potential for coupling.
16Tests must be designed to ensure that such side effects are uncovered.Public access to data members (PAD). This metric indicates the number of classes (or methods) that can access another class’s attributes, a violation ofencapsulation. High values for PAD lead to the potential for side effects amongclasses. Tests must be designed to ensure that such side effects are uncovered.Number of root classes (NOR).This metric is a count of the distinct classhierarchies that are described in the design model. Test suites for each rootclass and the corresponding class hierarchy must be developed. As NORincreases, testing effort also increases.Fan-in (FIN).When used in the OO context, fan-in in the inheritance hierar-chy is an indication of multiple inheritance. FIN /H11022 1 indicates that a class inherits its attributes and operations from more than one root class. FIN /H11022 1 should be avoided when possible.Number of children (NOC) and depth of the inheritance tree (DIT).
17
As I mentioned in Chapter 19, superclass methods will have to be retested foreach subclass.e(k)/H20858e(i)640 PART THREEQUALITY MANAGEMENT
15 See Section 23.3.3 for a description of LCOM.16 Some people promote designs with none of the attributes being public or private, that is, PAP /H110050. This implies that all attributes must be accessed in other classes via methods.17 See Section 23.3.3 for a description of NOC and DIT.OO testing can bequite complex. Metricscan assist you intargeting testingresources at threads,scenarios, andpackages of classesthat are “suspect”based on measuredcharacteristics. Usethem.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 64023.7 M ETRICS FOR MAINTENANCE
All of the software metrics introduced in this chapter can be used for the develop-ment of new software and the maintenance of existing software. However, metricsdesigned explicitly for maintenance activities have been proposed.IEEE Std. 982.1-1988 [IEE93] suggests a software maturity index(SMI) that provides an indication of the stability of a software product (based on changes that occur foreach release of the product). The following information is determined:M
T/H11005number of modules in the current releaseF
c/H11005number of modules in the current release that have been changedF
a/H11005number of modules in the current release that have been addedF
d/H11005number of modules from the preceding release that were deleted in thecurrent releaseThe software maturity index is computed in the following manner:SMI /H11005As SMI approaches 1.0, the product begins to stabilize. SMI may also be used asa metric for planning software maintenance activities. The mean time to produce arelease of a software product can be correlated with SMI, and empirical models formaintenance effort can be developed.
MT– (Fa/H11001Fc/H11001Fd)M
TCHAPTER 23PRODUCT METRICS 641
Product Metrics
Objective:To assist software engineers indeveloping meaningful metrics that assess thework products produced during analysis and designmodeling, source code generation, and testing.Mechanics:Tools in this category span a broad array ofmetrics and are implemented either as a stand-aloneapplication or (more commonly) as functionality that existswithin tools for analysis and design, coding, or testing. Inmost cases, the metrics tool analyzes a representation ofthe software (e.g., a UML model or source code) anddevelops one or more metrics as a result.Representative Tools:
18Krakatau Metrics,developed by Power Software (www.powersoftware.com/products), computes complexity, Halstead, and relatedmetrics for C/C++ and Java.Metrics4C—developed by +1 Software Engineering(www.plus-one.com/Metrics4C_fact_sheet.html), computes a variety of architectural, design, andcode-oriented metrics as well as project-oriented metrics.Rational Rose,distributed by IBM(www-304.ibm.com/jct03001c/software/awdtools/developer/rose/), is a comprehensivetool set for UML modeling that incorporates a numberof metrics analysis features.RSM, developed by M-Squared Technologies(msquaredtechnologies.com/m2rsm/index.html), computes a wide variety of code-orientedmetrics for C, C++, and Java.Understand,developed by Scientific Toolworks, Inc.(www.scitools.com), calculates code-orientedmetrics for a variety of programming languages.SOFTWARE TOOLS
18 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch23.qxd  11/27/08  6:22 PM  Page 64123.8 S UMMARY
Software metrics provide a quantitative way to assess the quality of internal productattributes, thereby enabling you to assess quality before the product is built. Metricsprovide the insight necessary to create effective requirements and design models,solid code, and thorough tests.To be useful in a real-world context, a software metric must be simple and com-putable, persuasive, consistent, and objective. It should be programming languageindependent and provide you with effective feedback.Metrics for the requirements model focus on function, data, and behavior—thethree components of the model. Metrics for design consider architecture, compo-nent-level design, and interface design issues. Architectural design metrics considerthe structural aspects of the design model. Component-level design metrics providean indication of module quality by establishing indirect measures for cohesion, cou-pling, and complexity. User interface design metrics provide an indication of the easewith which a GUI can be used. WebApp metrics consider aspects of the user inter-face as well as WebApp aesthetics, content, and navigation.Metrics for OO systems focus on measurement that can be applied to the classand the design characteristics—localization, encapsulation, information hiding,inheritance, and object abstraction techniques—that make the class unique. The CKmetrics suite defines six class-oriented software metrics that focus on the class andthe class hierarchy. The metrics suite also develops metrics to assess the collabora-tions between classes and the cohesion of methods that reside within a class. At aclass-oriented level, the CK metrics suite can be augmented with metrics proposedby Lorenz and Kidd and the MOOD metrics suite.Halstead provides an intriguing set of metrics at the source code level. Using thenumber of operators and operands present in the code, software science provides avariety of metrics that can be used to assess program quality.Few product metrics have been proposed for direct use in software testing and main-tenance. However, many other product metrics can be used to guide the testing processand as a mechanism for assessing the maintainability of a computer program. A widevariety of OO metrics have been proposed to assess the testability of an OO system.
PROBLEMS AND POINTS TO PONDER
23.1.Measurement theory is an advanced topic that has a strong bearing on software metrics.Using [Zus97], [Fen91], [Zus90], or Web-based sources, write a brief paper that outlines the maintenets of measurement theory. Individual project: Develop a presentation on the subject andpresent it to your class.23.2.Why is it that a single, all-encompassing metric cannot be developed for program com-plexity or program quality? Try to come up with a measure or metric from everyday life thatviolates the attributes of effective software metrics defined in Section 23.1.5.23.3.A system has 12 external inputs, 24 external outputs, fields 30 different external queries,manages 4 internal logical files, and interfaces with 6 different legacy systems (6 EIFs). All of642 PART THREEQUALITY MANAGEMENTpre75977_ch23.qxd  11/27/08  6:22 PM  Page 642these data are of average complexity and the overall system is relatively simple. Compute FP forthe system.23.4.Software for System X has 24 individual functional requirements and 14 nonfunctionalrequirements. What is the specificity of the requirements? The completeness?23.5.A major information system has 1140 modules. There are 96 modules that perform con-trol and coordination functions and 490 modules whose function depends on prior processing.The system processes approximately 220 data objects that each have an average of threeattributes. There are 140 unique database items and 90 different database segments. Finally,600 modules have single entry and exit points. Compute the DSQI for this system.23.6.A class Xhas 12 operations. Cyclomatic complexity has been computed for all operationsin the OO system, and the average value of module complexity is 4. For class X, the complexityfor operations 1 to 12 is 5, 4, 3, 3, 6, 8, 2, 2, 5, 5, 4, 4, respectively. Compute the weighted meth-ods per class.23.7.Develop a software tool that will compute cyclomatic complexity for a programminglanguage module. You may choose the language.23.8.Develop a small software tool that will perform a Halstead analysis on programminglanguage source code of your choosing. 23.9.A legacy system has 940 modules. The latest release required that 90 of these modulesbe changed. In addition, 40 new modules were added and 12 old modules were removed.Compute the software maturity index for the system.
FURTHER READINGS AND INFORMATION SOURCES
There is a surprisingly large number of books that are dedicated to software metrics, althoughthe majority focus on process and project metrics to the exclusion of product metrics. Lanza andher colleagues (Object-Oriented Metrics in Practice, Springer, 2006) discuss OO metrics and their use for assessing the quality of a design. Genero (Metrics for Software Conceptual Models, Imper- ial College Press, 2005) and Ejiogu ( Software Metrics,BookSurge Publishing, 2005) present a wide variety of technical metrics for use cases, UML models, and other modeling representations.Hutcheson (Software Testing Fundamentals: Methods and Metrics, Wiley, 2003) presents a set of metrics for testing. Kan (Metrics and Models in Software Quality Engineering, Addison-Wesley, 2d ed., 2002), Fenton and Pfleeger ( Software Metrics: A Rigorous and Practical Approach, Brooks- Cole Publishing, 1998), and Zuse [Zus97] have written thorough treatments of product metrics.Books by Card and Glass [Car90], Zuse [Zus90], Fenton [Fen91], Ejiogu [Eji91], Moeller andPaulish (Software Metrics,Chapman and Hall, 1993), and Hetzel [Het93] all address product met-rics in some detail. Oman and Pfleeger (Applying Software Metrics, IEEE Computer Society Press, 1997) have edited an anthology of important papers on software metrics.Methods for establishing a metrics program and the underlying principles for software meas-urement are considered by Ebert and his colleagues ( Best Practices in Software Measurement, Springer, 2004). Shepperd (Foundations of Software Measurement, Prentice-Hall, 1996) also ad- dresses measurement theory in some detail. Current research is presented in the Proceedings of the Symposium on Software Metrics (IEEE, published annually).A comprehensive summary of dozens of useful software metrics is presented in [IEE93]. Ingeneral, a discussion of each metric has been distilled to the essential “primitives” (measures)required to compute the metric and the appropriate relationships to effect the computation. Anappendix provides discussion and many references.Whitmire [Whi97] presents a comprehensive and mathematically sophisticated treatment ofOO metrics. Lorenz and Kidd [Lor94] and Hendersen-Sellers (Object-Oriented Metrics: Measuresof Complexity,Prentice-Hall, 1996) provide treatments that are dedicated to OO metrics.A wide variety of information sources on software metrics is available on the Internet. An up-to-date list of World Wide Web references that are relevant to software metrics can be found at theSEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 23PRODUCT METRICS 643pre75977_ch23.qxd  11/27/08  6:22 PM  Page 643pre75977_ch23.qxd  11/27/08  6:22 PM  Page 644MANAGING SOFTWARE
PROJECTS
645PART
Four
In this part of Software Engineering: A Practitioner's Approachyou’ll learn the management techniques required to plan,organize, monitor, and control software projects. These ques-tions are addressed in the chapters that follow:•How must people, process, and problem be managed duringa software project?•How can software metrics be used to manage a softwareproject and the software process?•How does a software team generate reliable estimates ofeffort, cost, and project duration?•What techniques can be used to assess the risks that can havean impact on project success?•How does a software project manager select a set of softwareengineering work tasks?•How is a project schedule created?•Why are maintenance and reengineering so important forboth software engineering managers and practitioners?Once these questions are answered, you’ll be better prepared tomanage software projects in a way that will lead to timely deliveryof a high-quality product.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 645In the preface to his book on software project management, Meiler Page-Jones[Pag85] makes a statement that can be echoed by many software engineeringconsultants:
I’ve visited dozens of commercial shops, both good and bad, and I’ve observed scoresof data processing managers, again, both good and bad. Too often, I’ve watched inhorror as these managers futilely struggled through nightmarish projects, squirmedunder impossible deadlines, or delivered systems that outraged their users and wenton to devour huge chunks of maintenance time.
What Page-Jones describes are symptoms that result from an array of manage-ment and technical problems. However, if a post mortem were to be conducted
646CHAPTER
24PROJECT MANAGEMENT
CONCEPTS
KEY
CONCEPTS
agile teams  . . .654coordination andcommunication . .655criticalpractices  . . . . .662people  . . . . . . .649problemdecomposition . .656product  . . . . . .656
What is it? Although many ofus (in our darker moments) takeDilbert’s view of “management,” itremains a very necessary activitywhen computer-based systems and products arebuilt. Project management involves the planning,monitoring, and control of the people, process,and events that occur as software evolves froma preliminary concept to full operationaldeployment.
Who does it? Everyone “manages” to some extent,but the scope of management activities variesamong people involved in a software project. Asoftware engineer manages her day-to-dayactivities, planning, monitoring, and controllingtechnical tasks. Project managers plan, monitor,and control the work of a team of software engi-neers. Senior managers coordinate the interfacebetween the business and software professionals.
Why is it important? Building computer softwareis a complex undertaking, particularly if it in-volves many people working over a relativelylong time. That’s why software projects need tobe managed.
What are the steps? Understand the four P’s—people, product, process, and project. PeopleQUICK
LOOKmust be organized to perform software work ef-fectively. Communication with the customer andother stakeholders must occur so that productscope and requirements are understood. Aprocess that is appropriate for the people andthe product should be selected. The project mustbe planned by estimating effort and calendartime to accomplish work tasks: defining workproducts, establishing quality checkpoints, andidentifying mechanisms to monitor and controlwork defined by the plan.
What is the work product? A project plan is pro-duced as management activities commence. Theplan defines the process and tasks to be con-ducted, the people who will do the work, and themechanisms for assessing risks, controllingchange, and evaluating quality.
How do I ensure that I’ve done it right? You’renever completely sure that the project plan isright until you’ve delivered a high-quality prod-uct on time and within budget. However, a proj-ect manager does it right when he encouragessoftware people to work together as an effectiveteam, focusing their attention on customer needsand product quality.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 646for every project, it is very likely that a consistent theme would be encountered: proj-ect management was weak.In this chapter and Chapters 25 through 29, I’ll present the key concepts thatlead to effective software project management. This chapter considers basic soft-ware project management concepts and principles. Chapter 25 presents processand project metrics, the basis for effective management decision making. Thetechniques that are used to estimate cost are discussed in Chapter 26. Chapter 27will help you to define a realistic project schedule. The management activitiesthat lead to effective risk monitoring, mitigation, and management are presentedin Chapter 28. Finally, Chapter 29 considers maintenance and reengineering anddiscusses the management issues that you’ll encounter when you must deal withlegacy systems.
24.1 T HEMANAGEMENT SPECTRUM
Effective software project management focuses on the four P’s: people, product,process, and project. The order is not arbitrary. The manager who forgets that soft-ware engineering work is an intensely human endeavor will never have success inproject management. A manager who fails to encourage comprehensive stake-holder communication early in the evolution of a product risks building an elegantsolution for the wrong problem. The manager who pays little attention to theprocess runs the risk of inserting competent technical methods and tools into avacuum. The manager who embarks without a solid project plan jeopardizes thesuccess of the project.
24.1.1 The People
The cultivation of motivated, highly skilled software people has been discussed sincethe 1960s. In fact, the “people factor” is so important that the Software EngineeringInstitute has developed a People Capability Maturity Model (People-CMM), in recogni- tion of the fact that “every organization needs to continually improve its ability toattract, develop, motivate, organize, and retain the workforce needed to accomplishits strategic business objectives” [Cur01].The people capability maturity model defines the following key practice areasfor software people: staffing, communication and coordination, work environment,performance management, training, compensation, competency analysis anddevelopment, career development, workgroup development, team/culture develop-ment, and others. Organizations that achieve high levels of People-CMM maturityhave a higher likelihood of implementing effective software project managementpractices.The People-CMM is a companion to the Software Capability Maturity Model–Integration(Chapter 30) that guides organizations in the creation of a matureCHAPTER 24PROJECT MANAGEMENT CONCEPTS 647
project  . . . . . . .660softwarescope  . . . . . . . .656softwareteam  . . . . . . . .651stakeholders  . .649team leaders  . .650W
5HHprinciple  . . . . . .661pre75977_ch24.qxd  11/27/08  6:23 PM  Page 647software process. Issues associated with people management and structure for soft-ware projects are considered later in this chapter.
24.1.2 The Product
Before a project can be planned, product objectives and scope should be established,alternative solutions should be considered, and technical and management con-straints should be identified. Without this information, it is impossible to define rea-sonable (and accurate) estimates of the cost, an effective assessment of risk, arealistic breakdown of project tasks, or a manageable project schedule that providesa meaningful indication of progress.As a software developer, you and other stakeholders must meet to define productobjectives and scope. In many cases, this activity begins as part of the system engi-neering or business process engineering and continues as the first step in softwarerequirements engineering (Chapter 5). Objectives identify the overall goals for theproduct (from the stakeholders’ points of view) without considering how these goalswill be achieved. Scope identifies the primary data, functions, and behaviors thatcharacterize the product, and more important, attempts to bound these characteris-tics in a quantitative manner.Once the product objectives and scope are understood, alternative solutions areconsidered. Although very little detail is discussed, the alternatives enable managersand practitioners to select a “best” approach, given the constraints imposed by de-livery deadlines, budgetary restrictions, personnel availability, technical interfaces,and myriad other factors.
24.1.3 The Process
A software process (Chapters 2 and 3) provides the framework from which a com-prehensive plan for software development can be established. A small number offramework activities are applicable to all software projects, regardless of their sizeor complexity. A number of different task sets—tasks, milestones, work products,and quality assurance points—enable the framework activities to be adapted tothe characteristics of the software project and the requirements of the projectteam. Finally, umbrella activities—such as software quality assurance, softwareconfiguration management, and measurement—overlay the process model. Um-brella activities are independent of any one framework activity and occurthroughout the process.
24.1.4 The Project
We conduct planned and controlled software projects for one primary reason—it isthe only known way to manage complexity. And yet, software teams still struggle.In a study of 250 large software projects between 1998 and 2004, Capers Jones[Jon04] found that “about 25 were deemed successful in that they achieved theirschedule, cost, and quality objectives. About 50 had delays or overruns below648 PART FOURMANAGING SOFTWARE PROJECTS
Those who adhere tothe agile processphilosophy (Chapter 3)argue that theirprocess is leaner thanothers. That may betrue, but they still havea process, and agilesoftware engineeringstill requires discipline.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 64835 percent, while about 175 experienced major delays and overruns, or were ter-minated without completion.” Although the success rate for present-day softwareprojects may have improved somewhat, our project failure rate remains muchhigher than it should be.
1
To avoid project failure, a software project manager and the software engineerswho build the product must avoid a set of common warning signs, understand thecritical success factors that lead to good project management, and develop a com-monsense approach for planning, monitoring, and controlling the project. Each ofthese issues is discussed in Section 24.5 and in the chapters that follow.
24.2 P EOPLE
In a study published by the IEEE [Cur88], the engineering vice presidents of threemajor technology companies were asked what was the most important contributorto a successful software project. They answered in the following way:VP 1:I guess if you had to pick one thing out that is most important in ourenvironment, I’d say it’s not the tools that we use, it’s the people.VP 2:The most important ingredient that was successful on this project washaving smart people . . . very little else matters in my opinion. . . . The mostimportant thing you do for a project is selecting the staff. . . . The success ofthe software development organization is very, very much associated with theability to recruit good people.VP 3:The only rule I have in management is to ensure I have good people—realgood people—and that I grow good people—and that I provide an environmentin which good people can produce.Indeed, this is a compelling testimonial on the importance of people in the softwareengineering process. And yet, all of us, from senior engineering vice presidents to thelowliest practitioner, often take people for granted. Managers argue (as the preced-ing group had) that people are primary, but their actions sometimes belie their words.In this section I examine the stakeholders who participate in the software process andthe manner in which they are organized to perform effective software engineering.
24.2.1 The Stakeholders
The software process (and every software project) is populated by stakeholders whocan be categorized into one of five constituencies:1.Senior managerswho define the business issues that often have a significantinfluence on the project.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 649
1 Given these statistics, it’s reasonable to ask how the impact of computers continues to grow expo-nentially. Part of the answer, I think, is that a substantial number of these “failed” projects are illconceived in the first place. Customers lose interest quickly (because what they’ve requestedwasn’t really as important as they first thought), and the projects are cancelled.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 6492.Project (technical) managerswho must plan, motivate, organize, and controlthe practitioners who do software work.3.Practitionerswho deliver the technical skills that are necessary to engineer aproduct or application.4.Customerswho specify the requirements for the software to be engineeredand other stakeholders who have a peripheral interest in the outcome.5.End userswho interact with the software once it is released for production use.Every software project is populated by people who fall within this taxonomy.
2To be effective, the project team must be organized in a way that maximizes each person’sskills and abilities. And that’s the job of the team leader.
24.2.2 Team Leaders
Project management is a people-intensive activity, and for this reason, competentpractitioners often make poor team leaders. They simply don’t have the right mix ofpeople skills. And yet, as Edgemon states: “Unfortunately and all too frequently itseems, individuals just fall into a project manager role and become accidental proj-ect managers” [Edg95].In an excellent book of technical leadership, Jerry Weinberg [Wei86] suggests anMOI model of leadership:Motivation.The ability to encourage (by “push or pull”) technical people toproduce to their best ability.Organization.The ability to mold existing processes (or invent new ones)that will enable the initial concept to be translated into a final product.Ideas or innovation.The ability to encourage people to create and feelcreative even when they must work within bounds established for a particu-lar software product or application.Weinberg suggests that successful project leaders apply a problem-solving manage-ment style. That is, a software project manager should concentrate on understand-ing the problem to be solved, managing the flow of ideas, and at the same time,letting everyone on the team know (by words and, far more important, by actions)that quality counts and that it will not be compromised.Another view [Edg95] of the characteristics that define an effective project man-ager emphasizes four key traits:Problem solving.An effective software project manager can diagnose thetechnical and organizational issues that are most relevant, systematicallystructure a solution or properly motivate other practitioners to develop thesolution, apply lessons learned from past projects to new situations, and650 PART FOURMANAGING SOFTWARE PROJECTS
2 When WebApps are developed, other nontechnical people may be involved in content creation.What do welook forwhen choosingsomeone to lead asoftware project??
uote:
“In simplest terms,a leader is one whoknows where hewants to go, andgets up, and goes.”John Erskinepre75977_ch24.qxd  11/27/08  6:23 PM  Page 650remain flexible enough to change direction if initial attempts at problemsolution are fruitless.Managerial identity.A good project manager must take charge of theproject. She must have the confidence to assume control when necessaryand the assurance to allow good technical people to follow their instincts.Achievement.A competent manager must reward initiative and accom-plishment to optimize the productivity of a project team. She must demon-strate through her own actions that controlled risk taking will not bepunished.Influence and team building.An effective project manager must be ableto “read” people; she must be able to understand verbal and nonverbal sig-nals and react to the needs of the people sending these signals. The managermust remain under control in high-stress situations.
24.2.3 The Software Team
There are almost as many human organizational structures for software develop-ment as there are organizations that develop software. For better or worse, organi-zational structure cannot be easily modified. Concern with the practical and politicalconsequences of organizational change are not within the software project man-ager’s scope of responsibility. However, the organization of the people directly in-volved in a new software project is within the project manager’s purview.The “best” team structure depends on the management style of your organization,the number of people who will populate the team and their skill levels, and the over-all problem difficulty. Mantei [Man81] describes seven project factors that should beconsidered when planning the structure of software engineering teams:
•Difficulty of the problem to be solved
•“Size” of the resultant program(s) in lines of code or function points
•Time that the team will stay together (team lifetime)
•Degree to which the problem can be modularized
•Required quality and reliability of the system to be built
•Rigidity of the delivery date
•Degree of sociability (communication) required for the projectConstantine [Con93] suggests four “organizational paradigms” for softwareengineering teams:1.A closed paradigmstructures a team along a traditional hierarchy of authority.Such teams can work well when producing software that is quite similar topast efforts, but they will be less likely to be innovative when working withinthe closed paradigm.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 651
uote:
“Not every groupis a team, and notevery team iseffective.”Glenn Parker
What factorsshould beconsidered whenthe structure of asoftware team ischosen??
Whatoptions dowe have whendefining thestructure of asoftware team??pre75977_ch24.qxd  11/27/08  6:23 PM  Page 6512.A random paradigmstructures a team loosely and depends on individual ini-tiative of the team members. When innovation or technological breakthroughis required, teams following the random paradigm will excel. But such teamsmay struggle when “orderly performance” is required.3.An open paradigmattempts to structure a team in a manner that achievessome of the controls associated with the closed paradigm but also muchof the innovation that occurs when using the random paradigm. Work isperformed collaboratively, with heavy communication and consensus-baseddecision making the trademarks of open paradigm teams. Open paradigmteam structures are well suited to the solution of complex problems but maynot perform as efficiently as other teams.4.A synchronous paradigmrelies on the natural compartmentalization of aproblem and organizes team members to work on pieces of the problem withlittle active communication among themselves.As an historical footnote, one of the earliest software team organizations was aclosed paradigm structure originally called the chief programmer team. This struc- ture was first proposed by Harlan Mills and described by Baker [Bak72]. The nu-cleus of the team was composed of a senior engineer(the chief programmer), who plans, coordinates, and reviews all technical activities of the team; technical staff (normally two to five people), who conduct analysis and development activities;and a backup engineer,who supports the senior engineer in his or her activities andcan replace the senior engineer with minimum loss in project continuity. The chiefprogrammer may be served by one or more specialists (e.g., telecommunicationsexpert, database designer), support staff (e.g., technical writers, clerical personnel),and a software librarian.As a counterpoint to the chief programmer team structure, Constantine’s randomparadigm [Con93] suggests a software team with creative independence whoseapproach to work might best be termed innovative anarchy. Although the free-spirited approach to software work has appeal, channeling creative energy into a high-performance team must be a central goal of a software engineering organization.To achieve a high-performance team:
•Team members must have trust in one another.
•The distribution of skills must be appropriate to the problem.
•Mavericks may have to be excluded from the team, if team cohesiveness is tobe maintained.Regardless of team organization, the objective for every project manager is tohelp create a team that exhibits cohesiveness. In their book, Peopleware, DeMarco and Lister [DeM98] discuss this issue: 
We tend to use the word team fairly loosely in the business world, calling any group ofpeople assigned to work together a “team.” But many of these groups just don’t seem like652 PART FOURMANAGING SOFTWARE PROJECTS
uote:
“If you want to beincrementallybetter: Becompetitive. If youwant to beexponentiallybetter: Becooperative.”Author unknownpre75977_ch24.qxd  11/27/08  6:23 PM  Page 652teams. They don’t have a common definition of success or any identifiable team spirit.What is missing is a phenomenon that we call jell.A jelled team is a group of people so strongly knit that the whole is greater than thesum of the parts. . . .Once a team begins to jell, the probability of success goes way up. The team canbecome unstoppable, a juggernaut for success. . . . They don’t need to be managed in thetraditional way, and they certainly don’t need to be motivated. They’ve got momentum.
DeMarco and Lister contend that members of jelled teams are significantly more pro-ductive and more motivated than average. They share a common goal, a commonculture, and in many cases, a “sense of eliteness” that makes them unique.But not all teams jell. In fact, many teams suffer from what Jackman [Jac98] calls“team toxicity.” She defines five factors that “foster a potentially toxic team environ-ment”: (1) a frenzied work atmosphere, (2) high frustration that causes frictionamong team members, (3) a “fragmented or poorly coordinated” software process,(4) an unclear definition of roles on the software team, and (5) “continuous and re-peated exposure to failure.”To avoid a frenzied work environment, the project manager should be certain thatthe team has access to all information required to do the job and that major goals andobjectives, once defined, should not be modified unless absolutely necessary. A soft-ware team can avoid frustration if it is given as much responsibility for decision mak-ing as possible. An inappropriate process (e.g., unnecessary or burdensome worktasks or poorly chosen work products) can be avoided by understanding the productto be built, the people doing the work, and by allowing the team to select the processmodel. The team itself should establish its own mechanisms for accountability (tech-nical reviews
3are an excellent way to accomplish this) and define a series of correc-tive approaches when a member of the team fails to perform. And finally, the key toavoiding an atmosphere of failure is to establish team-based techniques for feedbackand problem solving.In addition to the five toxins described by Jackman, a software team often strug-gles with the differing human traits of its members. Some team members are extro-verts; others are introverts. Some people gather information intuitively, distillingbroad concepts from disparate facts. Others process information linearly, collectingand organizing minute details from the data provided. Some team members arecomfortable making decisions only when a logical, orderly argument is presented.Others are intuitive, willing to make a decision based on “feel.” Some practitionerswant a detailed schedule populated by organized tasks that enable them to achieveclosure for some element of a project. Others prefer a more spontaneous environ-ment in which open issues are okay. Some work hard to get things done long beforea milestone date, thereby avoiding stress as the date approaches, while others areCHAPTER 24PROJECT MANAGEMENT CONCEPTS 653
What is a“jelled“team??
Why is itthat teamsfail to jell??
uote:
“Do or do not.There is no try.”Yoda from StarWars
3 Technical reviews are discussed in detail in Chapter 15.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 653energized by the rush to make a last-minute deadline. A detailed discussion of thepsychology of these traits and the ways in which a skilled team leader can help peo-ple with opposing traits to work together is beyond the scope of this book.
4However, it is important to note that recognition of human differences is the first step towardcreating teams that jell.
24.2.4 Agile Teams
Over the past decade, agile software development (Chapter 3) has been suggestedas an antidote to many of the problems that have plagued software project work. Toreview, the agile philosophy encourages customer satisfaction and early incremen-tal delivery of software, small highly motivated project teams, informal methods,minimal software engineering work products, and overall development simplicity.The small, highly motivated project team, also called an agile team,adopts many of the characteristics of successful software project teams discussed in the preced-ing section and avoids many of the toxins that create problems. However, the agilephilosophy stresses individual (team member) competency coupled with group col-laboration as critical success factors for the team. Cockburn and Highsmith [Coc01a]note this when they write:
If the people on the project are good enough, they can use almost any process andaccomplish their assignment. If they are not good enough, no process will repair theirinadequacy—“people trump process” is one way to say this. However, lack of user andexecutive support can kill a project—“politics trump people.” Inadequate support cankeep even good people from accomplishing the job.
To make effective use of the competencies of each team member and to fostereffective collaboration through a software project, agile teams are self-organizing. A self-organizing team does not necessarily maintain a single team structure butinstead uses elements of Constantine’s random, open, and synchronous paradigmsdiscussed in Section 24.2.3.Many agile process models (e.g., Scrum) give the agile team significant autonomyto make the project management and technical decisions required to get the jobdone. Planning is kept to a minimum, and the team is allowed to select its ownapproach (e.g., process, methods, tools), constrained only by business requirementsand organizational standards. As the project proceeds, the team self-organizes tofocus individual competency in a way that is most beneficial to the project at a givenpoint in time. To accomplish this, an agile team might conduct daily team meetingsto coordinate and synchronize the work that must be accomplished for that day.Based on information obtained during these meetings, the team adapts its approachin a way that accomplishes an increment of work. As each day passes, continual self-organizationandcollaborationmovetheteamtowardacompletedsoftwareincrement.654 PART FOURMANAGING SOFTWARE PROJECTS
4 An excellent introduction to these issues as they relate to software project teams can be found in[Fer98].An agile team is a self-organizing team thathas autonomy to planand make technicaldecisions.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 65424.2.5 Coordination and Communication Issues
There are many reasons that software projects get into trouble. The scale of manydevelopment efforts is large, leading to complexity, confusion, and significant diffi-culties in coordinating team members. Uncertainty is common, resulting in a con-tinuing stream of changes that ratchets the project team. Interoperability hasbecome a key characteristic of many systems. New software must communicate withexisting software and conform to predefined constraints imposed by the system orproduct.These characteristics of modern software—scale, uncertainty, and interoperability—are facts of life. To deal with them effectively, you must establish effective methodsfor coordinating the people who do the work. To accomplish this, mechanisms forformal and informal communication among team members and between multipleteams must be established. Formal communication is accomplished through “writ-ing, structured meetings, and other relatively non-interactive and impersonal com-munication channels” [Kra95]. Informal communication is more personal. Membersof a software team share ideas on an ad hoc basis, ask for help as problems arise,and interact with one another on a daily basis.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 655
uote:
“Collectiveownership isnothing more thanan instantiation ofthe idea thatproducts should beattributable to the[agile] team, notindividuals whomake up theteam.”Jim Highsmith
Team Structure
The scene:Doug Miller’s office priorto the initiation of the SafeHomesoftware project.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman, JamieLazar, and other members of the product softwareengineering team.The conversation:Doug:Have you guys had a chance to look over thepreliminary info on SafeHomethat marketing hasprepared?Vinod (nodding and looking at histeammates):Yes. But we have a bunch of questions.Doug:Let’s hold on that for a moment. I’d like to talkabout how we’re going to structure the team, who’sresponsible for what . . .Jamie:I’m really into the agile philosophy, Doug. I thinkwe should be a self-organizing team.Vinod:I agree. Given the tight time line and some ofthe uncertainty, and that fact that we’re all reallycompetent [laughs], that seems like the right way to go.Doug:That’s okay with me, but you guys know the drill.Jamie (smiling and talking as if she wasreciting something):“We make tactical decisions,about who does what and when, but it’s our responsibilityto get product out the door on time.Vinod:And with quality.Doug:Exactly. But remember there are constraints.Marketing defines the software increments to beproduced—in consultation with us, of course.Jamie:And?Doug:And, we’re going to use UML as our modelingapproach.Vinod:But keep extraneous documentation to anabsolute minimum.Doug:Who is the liaison with me?Jamie:We decided that Vinod will be the tech lead—he’s got the most experience, so Vinod is your liaison, butfeel free to talk to any of us.Doug (laughing):Don’t worry, I will.SAFEHOMEpre75977_ch24.qxd  11/27/08  6:23 PM  Page 65524.3 T HEPRODUCT
A software project manager is confronted with a dilemma at the very beginning of asoftware project. Quantitative estimates and an organized plan are required, butsolid information is unavailable. A detailed analysis of software requirements wouldprovide necessary information for estimates, but analysis often takes weeks or evenmonths to complete. Worse, requirements may be fluid, changing regularly as theproject proceeds. Yet, a plan is needed “now!”Like it or not, you must examine the product and the problem it is intended tosolve at the very beginning of the project. At a minimum, the scope of the productmust be established and bounded.
24.3.1 Software Scope
The first software project management activity is the determination of softwarescope.Scope is defined by answering the following questions:Context.How does the software to be built fit into a larger system, product, orbusiness context, and what constraints are imposed as a result of the context?Information objectives.What customer-visible data objects are producedas output from the software? What data objects are required for input?Function and performance.What function does the software perform totransform input data into output? Are any special performance characteris-tics to be addressed?Software project scope must be unambiguous and understandable at the manage-ment and technical levels. A statement of software scope must be bounded. That is,quantitative data (e.g., number of simultaneous users, target environment, maxi-mum allowable response time) are stated explicitly, constraints and/or limitations(e.g., product cost restricts memory size) are noted, and mitigating factors (e.g.,desired algorithms are well understood and available in Java) are described.
24.3.2 Problem Decomposition
Problem decomposition, sometimes called partitioning or problem elaboration,is an activity that sits at the core of software requirements analysis (Chapters 6 and 7).During the scoping activity no attempt is made to fully decompose the problem.Rather, decomposition is applied in two major areas: (1) the functionality andcontent (information) that must be delivered and (2) the process that will be used todeliver it.Human beings tend to apply a divide-and-conquer strategy when they are con-fronted with a complex problem. Stated simply, a complex problem is partitionedinto smaller problems that are more manageable. This is the strategy that applies asproject planning begins. Software functions, described in the statement of scope, areevaluated and refined to provide more detail prior to the beginning of estimation(Chapter 26). Because both cost and schedule estimates are functionally oriented,656 PART FOURMANAGING SOFTWARE PROJECTS
If you can’t bound acharacteristic of thesoftware you intend tobuild, list the charac-teristic as a project risk(Chapter 25).
In order to develop areasonable projectplan, you mustdecompose theproblem. This can beaccomplished using alist of functions or withuse cases.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 656some degree of decomposition is often useful. Similarly, major content or dataobjects are decomposed into their constituent parts, providing a reasonable under-standing of the information to be produced by the software.As an example, consider a project that will build a new word-processing product.Among the unique features of the product are continuous voice as well as virtualkeyboard input via a multitouch screen, extremely sophisticated “automatic copyedit” features, page layout capability, automatic indexing and table of contents, andothers. The project manager must first establish a statement of scope that boundsthese features (as well as other more mundane functions such as editing, file man-agement, and document production). For example, will continuous voice input re-quire that the product be “trained” by the user? Specifically, what capabilities will thecopy edit feature provide? Just how sophisticated will the page layout capability beand will it encompass the capabilities implied by a multitouch screen?As the statement of scope evolves, a first level of partitioning naturally occurs.The project team learns that the marketing department has talked with potential cus-tomers and found that the following functions should be part of automatic copy ed-iting: (1) spell checking, (2) sentence grammar checking, (3) reference checking forlarge documents (e.g., Is a reference to a bibliography entry found in the list of en-tries in the bibliography?), (4) the implementation of a style sheet feature that im-posed consistency across a document, and (5) section and chapter referencevalidation for large documents. Each of these features represents a subfunction to beimplemented in software. Each can be further refined if the decomposition will makeplanning easier.
24.4 T HEPROCESS
The framework activities (Chapter 2) that characterize the software process areapplicable to all software projects. The problem is to select the process model that isappropriate for the software to be engineered by your project team.Your team must decide which process model is most appropriate for (1) the cus-tomers who have requested the product and the people who will do the work, (2) thecharacteristics of the product itself, and (3) the project environment in which thesoftware team works. When a process model has been selected, the team thendefines a preliminary project plan based on the set of process framework activities.Once the preliminary plan is established, process decomposition begins. That is, acomplete plan, reflecting the work tasks required to populate the framework activi-ties must be created. We explore these activities briefly in the sections that followand present a more detailed view in Chapter 26.
24.4.1 Melding the Product and the Process
Project planning begins with the melding of the product and the process. Each func-tion to be engineered by your team must pass through the set of framework activi-ties that have been defined for your software organization.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 657pre75977_ch24.qxd  11/27/08  6:23 PM  Page 657Assume that the organization has adopted the generic framework activities—communication, planning, modeling, construction, anddeployment— discussed in Chapter 2. The team members who work on a product function willapply each of the framework activities to it. In essence, a matrix similar to the oneshown in Figure 24.1 is created. Each major product function (the figure notes func-tions for the word-processing software discussed earlier) is listed in the left-handcolumn. Framework activities are listed in the top row. Software engineering worktasks (for each framework activity) would be entered in the following row.
5The job of the project manager (and other team members) is to estimate resource require-ments for each matrix cell, start and end dates for the tasks associated with each cell,and work products to be produced as a consequence of each task. These activitiesare considered in Chapter 26.
24.4.2 Process Decomposition
A software team should have a significant degree of flexibility in choosing the soft-ware process model that is best for the project and the software engineering tasksthat populate the process model once it is chosen. A relatively small project that issimilar to past efforts might be best accomplished using the linear sequentialapproach. If the deadline is so tight that full functionality cannot reasonably be de-livered, an incremental strategy might be best. Similarly, projects with other charac-teristics (e.g., uncertain requirements, breakthrough technology, difficult customers,significant reuse potential) will lead to the selection of other process models.
6658 PART FOURMANAGING SOFTWARE PROJECTS
5 It should be noted that work tasks must be adapted to the specific needs of the project based on anumber of adaptation criteria.6 Recall that project characteristics also have a strong bearing on the structure of the software team(Section 24.2.3).COMMON PROCESSFRAMEWORK ACTIVITIES
Software Engineering TasksProduct Functions  Text input  Editing and formatting  Automatic copy edit  Page layout capability  Automatic indexing and TOC  File management  Document productioncommunicationplanningmodelingconstructiondeploymentFIGURE 24.1
Melding theproblem andthe process
The process frameworkestablishes a skeletonfor project planning.It is adapted byallocating a task setthat is appropriate tothe project.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 658Once the process model has been chosen, the process framework is adapted toit. In every case, the generic process framework discussed earlier can be used. Itwill work for linear models, for iterative and incremental models, for evolutionarymodels, and even for concurrent or component assembly models. The processframework is invariant and serves as the basis for all work performed by a soft-ware organization.But actual work tasks do vary. Process decomposition commences when the proj-ect manager asks, “How do we accomplish this framework activity?” For example, asmall, relatively simple project might require the following work tasks for the com-munication activity:1.Develop list of clarification issues.2.Meet with stakeholders to address clarification issues.3.Jointly develop a statement of scope.4.Review the statement of scope with all concerned.5.Modify the statement of scope as required.These events might occur over a period of less than 48 hours. They represent aprocess decomposition that is appropriate for the small, relatively simple project.Now, consider a more complex project, which has a broader scope and more sig-nificant business impact. Such a project might require the following work tasks forthe communication:1.Review the customer request.2.Plan and schedule a formal, facilitated meeting with all stakeholders.3.Conduct research to specify the proposed solution and existing approaches.4.Prepare a “working document” and an agenda for the formal meeting.5.Conduct the meeting.6.Jointly develop mini-specs that reflect data, functional, and behavioralfeatures of the software. Alternatively, develop use cases that describe thesoftware from the user’s point of view.7.Review each mini-spec or use case for correctness, consistency, and lack ofambiguity.8.Assemble the mini-specs into a scoping document.9.Review the scoping document or collection of use cases with allconcerned.10.Modify the scoping document or use cases as required.Both projects perform the framework activity that we call communication, but thefirst project team performs half as many software engineering work tasks as thesecond.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 659pre75977_ch24.qxd  11/27/08  6:23 PM  Page 65924.5 T HEPROJECT
In order to manage a successful software project, you have to understand what cango wrong so that problems can be avoided. In an excellent paper on software proj-ects, John Reel [Ree99] defines 10 signs that indicate that an information systemsproject is in jeopardy:1.Software people don’t understand their customer’s needs.2.The product scope is poorly defined.3.Changes are managed poorly.4.The chosen technology changes.5.Business needs change [or are ill defined].6.Deadlines are unrealistic.7.Users are resistant.8.Sponsorship is lost [or was never properly obtained].9.The project team lacks people with appropriate skills.10.Managers [and practitioners] avoid best practices and lessons learned.Jaded industry professionals often refer to the 90–90 rule when discussing partic-ularly difficult software projects: The first 90 percent of a system absorbs 90 percentof the allotted effort and time. The last 10 percent takes another 90 percent of theallotted effort and time [Zah94]. The seeds that lead to the 90–90 rule are containedin the signs noted in the preceding list.But enough negativity! How does a manager act to avoid the problems just noted?Reel [Ree99] suggests a five-part commonsense approach to software projects:1.Start on the right foot.This is accomplished by working hard (very hard) tounderstand the problem that is to be solved and then setting realisticobjectives and expectations for everyone who will be involved in the project.It is reinforced by building the right team (Section 24.2.3) and giving the teamthe autonomy, authority, and technology needed to do the job.2.Maintain momentum.Many projects get off to a good start and then slowlydisintegrate. To maintain momentum, the project manager must provideincentives to keep turnover of personnel to an absolute minimum, the teamshould emphasize quality in every task it performs, and senior managementshould do everything possible to stay out of the team’s way.
7660 PART FOURMANAGING SOFTWARE PROJECTS
What are thesigns that asoftware projectis in jeopardy??
uote:
“We don’t havetime to stop forgas, we’re alreadylate.”M. Cleron
7 The implication of this statement is that bureaucracy is reduced to a minimum, extraneousmeetings are eliminated, and dogmatic adherence to process and project rules is deemphasized.The team should be self-organizing and autonomous.pre75977_ch24.qxd  11/27/08  6:23 PM  Page 6603.Track progress.For a software project, progress is tracked as work products(e.g., models, source code, sets of test cases) are produced and approved(using technical reviews) as part of a quality assurance activity. In addition,software process and project measures (Chapter 25) can be collected andused to assess progress against averages developed for the software devel-opment organization.4.Make smart decisions.In essence, the decisions of the project manager andthe software team should be to “keep it simple.” Whenever possible, decideto use commercial off-the-shelf software or existing software components orpatterns, decide to avoid custom interfaces when standard approaches areavailable, decide to identify and then avoid obvious risks, and decide toallocate more time than you think is needed to complex or risky tasks(you’ll need every minute).5.Conduct a postmortem analysis.Establish a consistent mechanism for extract-ing lessons learned for each project. Evaluate the planned and actual sched-ules, collect and analyze software project metrics, get feedback from teammembers and customers, and record findings in written form.
24.6 T HEW5HH P RINCIPLE
In an excellent paper on software process and projects, Barry Boehm [Boe96]states: “you need an organizing principle that scales down to provide simple [proj-ect] plans for simple projects.” Boehm suggests an approach that addresses proj-ect objectives, milestones and schedules, responsibilities, management andtechnical approaches, and required resources. He calls it the W
5HH Principle,after a series of questions that lead to a definition of key project characteristics and theresultant project plan:Why is the system being developed?All stakeholders should assess the validity ofbusiness reasons for the software work. Does the business purpose justify theexpenditure of people, time, and money?What will be done?The task set required for the project is defined.When will it be done?The team establishes a project schedule by identifyingwhen project tasks are to be conducted and when milestones are to bereached.Who is responsible for a function?The role and responsibility of each member ofthe software team is defined.Where are they located organizationally? Not all roles and responsibilities reside within software practitioners. The customer, users, and other stakeholders alsohave responsibilities.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 661
How dowe definekey projectcharacteristics??uote:
“A project is like aroad trip. Someprojects are simpleand routine, likedriving to the storein broad daylight.But most projectsworth doing aremore like drivinga truck off-road,in the mountains,at night.”Cem Kaner,James Bach, andBret Pettichordpre75977_ch24.qxd  11/27/08  6:23 PM  Page 661How will the job be done technically and managerially? Once product scope is established, a management and technical strategy for the project must bedefined.How much of each resource is needed?The answer to this question is derived bydeveloping estimates (Chapter 26) based on answers to earlier questions.Boehm’s W
5HH Principle is applicable regardless of the size or complexity of asoftware project. The questions noted provide you and your team with an excellentplanning outline.
24.7 C RITICAL PRACTICES
The Airlie Council8has developed a list of “critical software practices forperformance-based management.” These practices are “consistently used by, andconsidered critical by, highly successful software projects and organizations whose’bottom line’ performance is consistently much better than industry averages” [Air99].Critical practices
9include: metric-based project management (Chapter 25), empir-ical cost and schedule estimation (Chapters 26 and 27), earned value tracking (Chap-ter 27), defect tracking against quality targets (Chapters 14 though 16), and peopleaware management (Section 24.2). Each of these critical practices is addressedthroughout Parts 3 and 4 of this book.662 PART FOURMANAGING SOFTWARE PROJECTS
8 The Airlie Council was comprised of a team of software engineering experts chartered by the U.S.Department of Defense to help develop guidelines for best practices in software project manage-ment and software engineering. For more on best practices, see www.swqual.com/newsletter/ vol1/no3/vol1no3.html.9 Only those critical practices associated with “project integrity” are noted here.10 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Software Tools for Project Managers
The “tools” listed here are generic and apply toa broad range of activities performed byproject managers. Specific project management tools(e.g., scheduling tools, estimating tools, risk analysis tools)are considered in later chapters.Representative Tools:
10
The Software Program Manager’s Network(www.spmn.com) has developed a simple toolcalled Project Control Panel,which provides projectmanagers with an direct indication of project status.The tool has “gauges” much like a dashboard and isimplemented with Microsoft Excel. It is available fordownload at www.spmn.com/products_software.html.Ganthead.com(www.gantthead.com/) hasdeveloped a set of useful checklists for projectmanagers.Ittoolkit.com(www.ittoolkit.com) provides“a collection of planning guides, process templatesand smart worksheets” available on CD-ROM.SOFTWARE TOOLSpre75977_ch24.qxd  11/27/08  6:23 PM  Page 66224.8 S UMMARY
Software project management is an umbrella activity within software engineering. Itbegins before any technical activity is initiated and continues throughout the mod-eling, construction, and deployment of computer software.Four P’s have a substantial influence on software project management—people,product, process, and project. People must be organized into effective teams, mo-tivated to do high-quality software work, and coordinated to achieve effectivecommunication. Product requirements must be communicated from customer todeveloper, partitioned (decomposed) into their constituent parts, and positionedfor work by the software team. The process must be adapted to the people and theproduct. A common process framework is selected, an appropriate software engi-neering paradigm is applied, and a set of work tasks is chosen to get the job done.Finally, the project must be organized in a manner that enables the software teamto succeed.The pivotal element in all software projects is people. Software engineers can beorganized in a number of different team structures that range from traditionalcontrol hierarchies to “open paradigm” teams. A variety of coordination and com-munication techniques can be applied to support the work of the team. In general,technical reviews and informal person-to-person communication have the mostvalue for practitioners.The project management activity encompasses measurement and metrics, esti-mation and scheduling, risk analysis, tracking, and control. Each of these topics isconsidered in the chapters that follow.
PROBLEMS AND POINTS TO PONDER
24.1.Based on information contained in this chapter and your own experience, develop “tencommandments” for empowering software engineers. That is, make a list of 10 guidelines thatwill lead to software people who work to their full potential.24.2.The Software Engineering Institute’s People Capability Maturity Model (People-CMM)takes an organized look at “key practice areas” that cultivate good software people. Yourinstructor will assign you one KPA for analysis and summary.24.3.Describe three real-life situations in which the customer and the end user are the same.Describe three situations in which they are different.24.4.The decisions made by senior management can have a significant impact on the effec-tiveness of a software engineering team. Provide five examples to illustrate that this is true.24.5.Review a copy of Weinberg’s book [Wei86], and write a two- or three-page summary ofthe issues that should be considered in applying the MOI model.24.6.You have been appointed a project manager within an information systems organization.Your job is to build an application that is quite similar to others your team has built, althoughthis one is larger and more complex. Requirements have been thoroughly documented by thecustomer. What team structure would you choose and why? What software process model(s)would you choose and why?CHAPTER 24PROJECT MANAGEMENT CONCEPTS 663pre75977_ch24.qxd  11/27/08  6:23 PM  Page 66324.7.You have been appointed a project manager for a small software products company. Yourjob is to build a breakthrough product that combines virtual reality hardware with state-of-the-art software. Because competition for the home entertainment market is intense, there is sig-nificant pressure to get the job done. What team structure would you choose and why? Whatsoftware process model(s) would you choose and why?24.8.You have been appointed a project manager for a major software products company.Your job is to manage the development of the next-generation version of its widely used word-processing software. Because competition is intense, tight deadlines have been established andannounced. What team structure would you choose and why? What software process model(s)would you choose and why?24.9.You have been appointed a software project manager for a company that services the ge-netic engineering world. Your job is to manage the development of a new software product thatwill accelerate the pace of gene typing. The work is R&D oriented, but the goal is to produce aproduct within the next year. What team structure would you choose and why? What softwareprocess model(s) would you choose and why?24.10.You have been asked to develop a small application that analyzes each course offeredby a university and reports the average grade obtained in the course (for a given term). Write astatement of scope that bounds this problem.24.11.Do a first-level functional decomposition of the page layout function discussed brieflyin Section 24.3.2.
FURTHER READINGS AND INFORMATION SOURCES
The Project Management Institute (Guide to the Project Management Body of Knowledge, PMI, 2001) covers all important aspects of project management. Bechtold ( Essentials of Software Pro- ject Management,2d ed., Management Concepts, 2007), Wysocki ( Effective Software Project Man- agement,Wiley, 2006), Stellman and Greene ( Applied Software Project Management, O’Reilly, 2005), and Berkun (The Art of Project Management, O’Reilly, 2005) teach basic skills and provide detailed guidance for all software project management tasks. McConnell ( Professional Software Development,Addison-Wesley, 2004) offers pragmatic advice for achieving “shorter schedules,higher quality products, and more successful projects.” Henry (Software Project Management,Addison-Wesley, 2003) offers real-world advice that is useful for all project managers.Tom DeMarco and his colleagues (Adrenaline Junkies and Template Zombies, Dorset House, 2008) have written an insightful treatment of the human patterns that are encountered in everysoftware project. An excellent four-volume series written by Weinberg (Quality Software Manage-ment,Dorset House, 1992, 1993, 1994, 1996) introduces basic systems thinking and managementconcepts, explains how to use measurements effectively, and addresses “congruent action,” theability to establish “fit” between the manager’s needs, the needs of technical staff, and the needsof the business. It will provide both new and experienced managers with useful information.Futrell and his colleagues (Quality Software Project Management, Prentice-Hall, 2002) present a vo- luminous treatment of project management. Brown and his colleagues (Antipatterns in ProjectManagement,Wiley, 2000) discuss what not to do during the management of a software project.Brooks (The Mythical Man-Month,Anniversary Edition, Addison-Wesley, 1995) has updated his classic book to provide new insight into software project and management issues. McConnell(Software Project Survival Guide,Microsoft Press, 1997) presents excellent pragmatic guidance forthose who must manage software projects. Purba and Shah ( How to Manage a Successful Software Project,2d ed., Wiley, 2000) present a number of case studies that indicate why some projects suc-ceed and others fail. Bennatan (On Time Within Budget, 3d ed., Wiley, 2000) presents useful tips and guidelines for software project managers. Weigers (Practical Project Initiation, Microsoft Press, 2007) provides practical guidelines for getting a software project off the ground successfully.It can be argued that the most important aspect of software project management is peoplemanagement. Cockburn (Agile Software Development,Addison-Wesley, 2002) presents one of664 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch24.qxd  11/27/08  6:23 PM  Page 664the best discussions of software people written to date. DeMarco and Lister [DeM98] have writ-ten the definitive book on software people and software projects. In addition, the followingbooks on this subject have been published in recent years and are worth examining: Cantor, M., Software Leadership: A Guide to Successful Software Development, Addison- Wesley, 2001.Carmel, E., Global Software Teams: Collaborating Across Borders and Time Zones, Prentice Hall, 1999.Constantine, L., Peopleware Papers: Notes on the Human Side of Software, Prentice Hall, 2001. Garton, C., and K. Wegryn, Managing Without Walls, McPress, 2006. Humphrey, W. S., Managing Technical People: Innovation, Teamwork, and the Software Process,Addison-Wesley, 1997.Humphrey, W. S., TSP-Coaching Development Teams, Addison-Wesley, 2006. Jones, P. H., Handbook of Team Design: A Practitioner’s Guide to Team Systems Development,McGraw-Hill, 1997.Karolak, D. S., Global Software Development: Managing Virtual Teams and Environments, IEEE Computer Society, 1998.Peters, L., Getting Results from Software Development Teams, Microsoft Press, 2008. Whitehead, R., Leading a Software Development Team, Addison-Wesley, 2001. Even though they do not relate specifically to the software world and sometimes suffer fromoversimplification and broad generalization, best-selling “management” books by Kanter(Confidence,Three Rivers Press, 2006), Covy (The 8th Habit, Free Press, 2004), Bossidy (Execution: The Discipline of Getting Things Done, Crown Publishing, 2002), Drucker ( Management Challenges for the 21st Century,Harper Business, 1999), Buckingham and Coffman ( First, Break All the Rules: What the World’s Greatest Managers Do Differently, Simon and Schuster, 1999), and Christensen (The Innovator’s Dilemma,Harvard Business School Press, 1997) emphasize “new rules” definedby a rapidly changing economy. Older titles such as Who Moved My Cheese?, The One-Minute Manager,and In Search of Excellencecontinue to provide valuable insights that can help you to manage people and projects more effectively.A wide variety of information sources on the software project management are available onthe Internet. An up-to-date list of World Wide Web references relevant to software project man-agement can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 24PROJECT MANAGEMENT CONCEPTS 665pre75977_ch24.qxd  11/27/08  6:23 PM  Page 665Measurement enables us to gain insight into the process and the projectby providing a mechanism for objective evaluation. Lord Kelvin oncesaid:
When you can measure what you are speaking about and express it in numbers, youknow something about it; but when you cannot measure, when you cannot express itin numbers, your knowledge is of a meager and unsatisfactory kind: it may be thebeginning of knowledge, but you have scarcely, in your thoughts, advanced to thestage of a science.
The software engineering community has taken Lord Kelvin’s words to heart. Butnot without frustration and more than a little controversy!Measurement can be applied to the software process with the intent ofimproving it on a continuous basis. Measurement can be used throughout a soft-ware project to assist in estimation, quality control, productivity assessment, andproject control. Finally, measurement can be used by software engineers to helpassess the quality of work products and to assist in tactical decision making as aproject proceeds (Chapter 23).
666CHAPTER
25PROCESS AND
PROJECT METRICS
KEY
CONCEPTS
defect removalefficiency (DRE) . . . . . . . .681function point  . .673measurement  . .671metrics,  . . . . . .667argumentsfor . . . . . . . . .683baseline  . . . . .683establishing a program  . . .686function-oriented  . . . . .673LOC-based  . . .675object-oriented  . . . . .675
What is it? Software process andproject metrics are quantitative mea-sures that enable you to gain insightinto the efficacy of the softwareprocess and the projects that are conducted usingthe process as a framework. Basic quality andproductivity data are collected. These data arethen analyzed, compared against past averages,and assessed to determine whether quality andproductivity improvements have occurred. Met-rics are also used to pinpoint problem areas sothat remedies can be developed and the softwareprocess can be improved.
Who does it? Software metrics are analyzed andassessed by software managers. Measures areoften collected by software engineers.
Why is it important? If you don’t measure, judg-ment can be based only on subjective evaluation.QUICK
LOOKWith measurement, trends (either good or bad)can be spotted, better estimates can be made, andtrue improvement can be accomplished over time.
What are the steps? Begin by defining a limitedset of process, project, and product measuresthat are easy to collect. These measures areoften normalized using either size- or function-oriented metrics. The result is analyzed andcompared to past averages for similar projectsperformed within the organization. Trends areassessed and conclusions are generated.
What is the work product? A set of softwaremetrics that provide insight into the process andunderstanding of the project.
How do I ensure that I’ve done it right? Byapplying a consistent, yet simple measurementscheme that is never to be used to assess,reward, or punish individual performance.pre75977_ch25.qxd  11/27/08  6:24 PM  Page 666Within the context of the software process and the projects that are conductedusing the process, a software team is concerned primarily with productivity andquality metrics—measures of software development “output” as a function of effortand time applied and measures of the “fitness for use” of the work products that areproduced. For planning and estimating purposes, your interest is historical. Whatwas software development productivity on past projects? What was the quality of thesoftware that was produced? How can past productivity and quality data be extrap-olated to the present? How can it help you plan and estimate more accurately?In their guidebook on software measurement, Park, Goethert, and Florac [Par96b]note the reasons that we measure: (1) to characterize in an effort to gain an under- standing “of processes, products, resources, and environments, and to establishbaselines for comparisons with future assessments”; (2) to evaluate “to determine status with respect to plans”; (3) to predict by “gaining understandings of relation- ships among processes and products and building models of these relationships”;and (4) to improveby “identify[ing] roadblocks, root causes, inefficiencies, and otheropportunities for improving product quality and process performance.”Measurement is a management tool. If conducted properly, it provides a projectmanager with insight. And as a result, it assists the project manager and the softwareteam in making decisions that will lead to a successful project.
25.1 M ETRICS IN THE PROCESS AND PROJECT DOMAINS
Process metricsare collected across all projects and over long periods of time. Theirintent is to provide a set of process indicators that lead to long-term software processimprovement. Project metricsenable a software project manager to (1) assess the sta-tus of an ongoing project, (2) track potential risks, (3) uncover problem areas beforethey go “critical,” (4) adjust work flow or tasks, and (5) evaluate the project team’sability to control quality of software work products.Measures that are collected by a project team and converted into metrics for useduring a project can also be transmitted to those with responsibility for softwareprocess improvement (Chapter 30). For this reason, many of the same metrics areused in both the process and project domains.
25.1.1 Process Metrics and Software Process Improvement
The only rational way to improve any process is to measure specific attributes of theprocess, develop a set of meaningful metrics based on these attributes, and then use themetrics to provide indicators that will lead to a strategy for improvement (Chapter 30).But before I discuss software metrics and their impact on software process improve-ment, it is important to note that process is only one of a number of “controllable factorsin improving software quality and organizational performance” [Pau94].Referring to Figure 25.1, process sits at the center of a triangle connecting threefactors that have a profound influence on software quality and organizationalCHAPTER 25PROCESS AND PROJECT METRICS 667process  . . . . . .667productivity  . . .675project  . . . . . . .670public and private . . . . . . .668size-oriented . . .672software quality  . . . . . . .679use-case–oriented  . . . . . .676WebApp . . . . . .677
Process metrics havelong-term impact.Their intent is toimprove the processitself. Project metricsoften contribute to thedevelopment ofprocess metrics.pre75977_ch25.qxd  11/27/08  6:24 PM  Page 667668 PART FOURMANAGING SOFTWARE PROJECTS
performance. The skill and motivation of people has been shown [Boe81] to be thesingle most influential factor in quality and performance. The complexity of theproduct can have a substantial impact on quality and team performance. The tech-nology (i.e., the software engineering methods and tools) that populates the processalso has an impact.In addition, the process triangle exists within a circle of environmental conditionsthat include the development environment (e.g., integrated software tools), businessconditions (e.g., deadlines, business rules), and customer characteristics (e.g., easeof communication and collaboration).You can only measure the efficacy of a software process indirectly. That is, youderive a set of metrics based on the outcomes that can be derived from the process.Outcomes include measures of errors uncovered before release of the software,defects delivered to and reported by end users, work products delivered (productivity),human effort expended, calendar time expended, schedule conformance, and othermeasures. You can also derive process metrics by measuring the characteristics ofspecific software engineering tasks. For example, you might measure the effort andtime spent performing the umbrella activities and the generic software engineeringactivities described in Chapter 2.Grady [Gra92] argues that there are “private and public” uses for different types ofprocess data. Because it is natural that individual software engineers might besensitive to the use of metrics collected on an individual basis, these data shouldbe private to the individual and serve as an indicator for the individual only. Exam-ples of private metricsinclude defect rates (by individual), defect rates (by compo-nent), and errors found during development.ProcessProduct
TechnologyPeople
DevelopmentenvironmentCustomercharacteristics BusinessconditionsFIGURE 25.1
Determinantsfor softwarequality andorganizationaleffectiveness.Source: Adapted from[Pau94].
The skill andmotivation of thesoftware people doingthe work are the mostimportant factors thatinfluence softwarequality.
uote:
“Software metricslet you know whento laugh and whento cry.”Tom Gilbpre75977_ch25.qxd  11/27/08  6:24 PM  Page 668The “private process data” philosophy conforms well with the Personal SoftwareProcess approach (Chapter 2) proposed by Humphrey [Hum97]. Humphrey recog-nizes that software process improvement can and should begin at the individuallevel. Private process data can serve as an important driver as you work to improveyour software engineering approach.Some process metrics are private to the software project team but public to allteam members. Examples include defects reported for major software functions (thathave been developed by a number of practitioners), errors found during technicalreviews, and lines of code or function points per component or function.
1The team reviews these data to uncover indicators that can improve team performance.Public metrics generally assimilate information that originally was private to indi-viduals and teams. Project-level defect rates (absolutely not attributed to an individual),effort, calendar times, and related data are collected and evaluated in an attempt touncover indicators that can improve organizational process performance.Software process metrics can provide significant benefit as an organization worksto improve its overall level of process maturity. However, like all metrics, these canbe misused, creating more problems than they solve. Grady [Gra92] suggests a “soft-ware metrics etiquette” that is appropriate for both managers and practitioners asthey institute a process metrics program:
•Use common sense and organizational sensitivity when interpreting metricsdata.
•Provide regular feedback to the individuals and teams who collect measuresand metrics.
•Don’t use metrics to appraise individuals.
•Work with practitioners and teams to set clear goals and metrics that will beused to achieve them.
•Never use metrics to threaten individuals or teams.
•Metrics data that indicate a problem area should not be considered“negative.” These data are merely an indicator for process improvement.
•Don’t obsess on a single metric to the exclusion of other important metrics.As an organization becomes more comfortable with the collection and use ofprocess metrics, the derivation of simple indicators gives way to a more rigorousapproach called statistical software process improvement (SSPI). In essence, SSPI uses software failure analysis to collect information about all errors and defects
2encoun- tered as an application, system, or product is developed and used.CHAPTER 25PROCESS AND PROJECT METRICS 669
What is thedifferencebetween privateand public usesfor softwaremetrics??
Whatguidelinesshould be appliedwhen we collectsoftware metrics??
1 Lines of code and function point metrics are discussed in Sections 25.2.1 and 25.2.2.2 In this book, an erroris defined as some flaw in a software engineering work product that isuncovered beforethe software is delivered to the end user. A defect is a flaw that is uncovered after delivery to the end user. It should be noted that others do not make this distinction.pre75977_ch25.qxd  11/27/08  6:24 PM  Page 66925.1.2 Project Metrics
Unlike software process metrics that are used for strategic purposes, software proj-ect measures are tactical. That is, project metrics and the indicators derived fromthem are used by a project manager and a software team to adapt project workflowand technical activities.The first application of project metrics on most software projects occurs duringestimation. Metrics collected from past projects are used as a basis from which effortand time estimates are made for current software work. As a project proceeds, mea-sures of effort and calendar time expended are compared to original estimates (and theproject schedule). The project manager uses these data to monitor and control progress.As technical work commences, other project metrics begin to have significance.Production rates represented in terms of models created, review hours, functionpoints, and delivered source lines are measured. In addition, errors uncoveredduring each software engineering task are tracked. As the software evolves fromrequirements into design, technical metrics (Chapter 23) are collected to assessdesign quality and to provide indicators that will influence the approach taken tocode generation and testing.The intent of project metrics is twofold. First, these metrics are used to minimizethe development schedule by making the adjustments necessary to avoid delays andmitigate potential problems and risks. Second, project metrics are used to assess pro-duct quality on an ongoing basis and, when necessary, modify the technical approachto improve quality.As quality improves, defects are minimized, and as the defect count goes down,the amount of rework required during the project is also reduced. This leads to areduction in overall project cost.670 PART FOURMANAGING SOFTWARE PROJECTS
How shouldwe usemetrics during theproject itself??
The scene:Doug Miller’s office as theSafeHomesoftware project is aboutto begin.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman and JamieLazar, members of the product software engineering team.The conversation:Doug:Before we start work on this project, I’d like youguys to define and collect a set of simple metrics. To start,you’ll have to define your goals.Vinod (frowning):We’ve never done that before,and . . .Jamie (interrupting):And based on the time linemanagement has been talking about, we’ll never have thetime. What good are metrics anyway?Doug (raising his hand to stop the onslaught):Slow down and take a breath, guys. The fact that we’venever done it before is all the more reason to start now,and the metrics work I’m talking about shouldn’t takemuch time at all . . . in fact, it just might save us time.Vinod:How?Doug:Look, we’re going to be doing a lot morein-house software engineering as our products get moreintelligent, become Web enabled, all that . . . and weneed to understand the process we use to buildsoftware...  and improve it so we can build softwarebetter. The only way to do that is to measure.Jamie:But we’re under time pressure, Doug. I’m not infavor of more paper pushing...w e  n e e d  the time to doour work, not collect data.SAFEHOMEEstablishing a Metrics Approachpre75977_ch25.qxd  11/27/08  6:25 PM  Page 67025.2 S OFTWARE MEASUREMENT
In Chapter 23, I noted that measurements in the physical world can be categorizedin two ways: direct measures (e.g., the length of a bolt) and indirect measures (e.g.,the “quality” of bolts produced, measured by counting rejects). Software metrics canbe categorized similarly.Direct measuresof the software process include cost and effort applied. Directmeasures of the product include lines of code (LOC) produced, execution speed,memory size, and defects reported over some set period of time. Indirect measuresof the product include functionality, quality, complexity, efficiency, reliability, main-tainability, and many other “–abilities” that are discussed in Chapter 14.The cost and effort required to build software, the number of lines of code pro-duced, and other direct measures are relatively easy to collect, as long as specificconventions for measurement are established in advance. However, the quality andfunctionality of software or its efficiency or maintainability are more difficult to as-sess and can be measured only indirectly.I have partitioned the software metrics domain into process, project, and productmetrics and noted that product metrics that are private to an individual are oftencombined to develop project metrics that are public to a software team. Project met-rics are then consolidated to create process metrics that are public to the softwareorganization as a whole. But how does an organization combine metrics that comefrom different individuals or projects?To illustrate, consider a simple example. Individuals on two different projectteams record and categorize all errors that they find during the software process. In-dividual measures are then combined to develop team measures. Team A found 342errors during the software process prior to release. Team B found 184 errors. Allother things being equal, which team is more effective in uncovering errors through-out the process? Because you do not know the size or complexity of the projects,you cannot answer this question. However, if the measures are normalized, it isCHAPTER 25PROCESS AND PROJECT METRICS 671
Doug (calmly):Jamie, an engineer’s work involvescollecting data, evaluating it, and using the results toimprove the product and the process. Am I wrong?Jamie:No, but . . .Doug:What if we hold the number of measures we collectto no more than five or six and focus on quality?Vinod:No one can argue against high quality . . .Jamie:True . . . but, I don’t know. I still think this isn’tnecessary.Doug:I’m going to ask you to humor me on this one.How much do you guys know about software metrics?Jamie (looking at Vinod):Not much.Doug:Here are some Web refs . . . spend a few hoursgetting up to speed.Jamie (smiling):I thought you said this wouldn’t takeany time.Doug:Time you spend learning is never wasted...g o do it and then we’ll establish some goals, ask a fewquestions, and define the metrics we need to collect.
uote:
“Not everythingthat can becounted counts,and not everythingthat counts can becounted.”Albert Einstein
Because many factorsaffect software work,don’t use metrics tocompare individuals orteams.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 671possible to create software metrics that enable comparison to broader organiza-tional averages.
25.2.1 Size-Oriented Metrics
Size-oriented software metrics are derived by normalizing quality and/or productiv-ity measures by considering thesizeof the software that has been produced. If a soft-ware organization maintains simple records, a table of size-oriented measures, suchas the one shown in Figure 25.2, can be created. The table lists each software devel-opment project that has been completed over the past few years and correspondingmeasures for that project. Referring to the table entry (Figure 25.2) for project alpha:12,100 lines of code were developed with 24 person-months of effort at a cost of$168,000. It should be noted that the effort and cost recorded in the table representall software engineering activities (analysis, design, code, and test), not just coding.Further information for project alpha indicates that 365 pages of documentationwere developed, 134 errors were recorded before the software was released, and 29defects were encountered after release to the customer within the first year of oper-ation. Three people worked on the development of software for project alpha.In order to develop metrics that can be assimilated with similar metrics from otherprojects, you can choose lines of code as a normalization value. From the rudimen-tary data contained in the table, a set of simple size-oriented metrics can be devel-oped for each project:
•Errors per KLOC (thousand lines of code)
•Defects per KLOC
•$ per KLOC
•Pages of documentation per KLOC672 PART FOURMANAGING SOFTWARE PROJECTS
FIGURE 25.2
Size-orientedmetricsProject LOC Effort $(000) Pp. doc. Errors Defects People
alphabetagamma12,10027,20020,20024624316844031436512241050  134321256  298664356pre75977_ch25.qxd  11/27/08  6:25 PM  Page 672In addition, other interesting metrics can be computed:
•Errors per person-month
•KLOC per person-month
•$ per page of documentationSize-oriented metrics are not universally accepted as the best way to measure thesoftware process. Most of the controversy swirls around the use of lines of code as akey measure. Proponents of the LOC measure claim that LOC is an “artifact” of all soft-ware development projects that can be easily counted, that many existing softwareestimation models use LOC or KLOC as a key input, and that a large body of literatureand data predicated on LOC already exists. On the other hand, opponents argue thatLOC measures are programming language dependent, that when productivity is con-sidered, they penalize well-designed but shorter programs; that they cannot easilyaccommodate nonprocedural languages; and that their use in estimation requires alevel of detail that may be difficult to achieve (i.e., the planner must estimate the LOCto be produced long before analysis and design have been completed).
25.2.2 Function-Oriented Metrics
Function-oriented software metrics use a measure of the functionality delivered bythe application as a normalization value. The most widely used function-orientedmetric is the function point (FP). Computation of the function point is based on char-acteristics of the software’s information domain and complexity. The mechanics ofFP computation have been discussed in Chapter 23.
3
The function point, like the LOC measure, is controversial. Proponents claim thatFP is programming language independent, making it ideal for applications using con-ventional and nonprocedural languages, and that it is based on data that are morelikely to be known early in the evolution of a project, making FP more attractive as anestimation approach. Opponents claim that the method requires some “sleight ofhand” in that computation is based on subjective rather than objective data, thatcounts of the information domain (and other dimensions) can be difficult to collectafter the fact, and that FP has no direct physical meaning—it’s just a number.
25.2.3 Reconciling LOC and FP Metrics
The relationship between lines of code and function points depends upon the pro-gramming language that is used to implement the software and the quality of thedesign. A number of studies have attempted to relate FP and LOC measures. The fol-lowing table
4[QSM02] provides rough estimates of the average number of lines ofcode required to build one function point in various programming languages:CHAPTER 25PROCESS AND PROJECT METRICS 673
Size-oriented metricsare widely used,but debate abouttheir validity andapplicability continues.
3 See Section 23.2.1 for a detailed discussion of FP computation.4 Used with permission of Quantitative Software Management (www.qsm.com), copyright 2002.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 673LOC per Function Point
Programming Language Average Median Low HighAccess 35 38 15 47Ada 154 — 104 205APS 86 83 20 184ASP 69 62 — 32 127Assembler 337 315 91 694C 162 109 33 704C++ 66 53 29 178Clipper 38 39 27 70COBOL 77 77 14 400Cool:Gen/IEF 38 31 10 180Culprit 51 — — —DBase IV 52 — — —Easytrieve+ 33 34 25 41Excel47 46 — 31 63Focus 43 42 32 56FORTRAN — — — —FoxPro 32 35 25 35Ideal 66 52 34 203IEF/Cool:Gen 38 31 10 180Informix 42 31 24 57Java 63 53 77 —JavaScript 58 63 42 75JCL 91 123 26 150JSP 59 — — —Lotus Notes 21 22 15 25Mantis 71 27 22 250Mapper 118 81 16 245Natural 60 52 22 141Oracle 30 35 4 217PeopleSoft 33 32 30 40Perl 60 — — —PL/1 78 67 22 263Powerbuilder 32 31 11 105REXX 67 — — —RPG II/III 61 49 24 155SAS 40 41 33 49Smalltalk 26 19 10 55SQL 40 37 7 110VBScript36 34 27 50 —
Visual Basic474216158674PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch25.qxd  11/27/08  6:25 PM  Page 674A review of these data indicates that one LOC of C++ provides approximately2.4 times the “functionality” (on average) as one LOC of C. Furthermore, one LOC ofSmalltalk provides at least four times the functionality of an LOC for a conventionalprogramming language such as Ada, COBOL, or C. Using the information containedin the table, it is possible to “backfire” [Jon98] existing software to estimate the num-ber of function points, once the total number of programming language statementsare known.LOC and FP measures are often used to derive productivity metrics. This invari-ably leads to a debate about the use of such data. Should the LOC/person-month (orFP/person-month) of one group be compared to similar data from another? Shouldmanagers appraise the performance of individuals by using these metrics? The an-swer to these questions is an emphatic “No!” The reason for this response is thatmany factors influence productivity, making for “apples and oranges” comparisonsthat can be easily misinterpreted.Function points and LOC-based metrics have been found to be relatively accuratepredictors of software development effort and cost. However, in order to use LOCand FP for estimation (Chapter 26), an historical baseline of information must beestablished.Within the context of process and project metrics, you should be concernedprimarily with productivity and quality—measures of software development “output”as a function of effort and time applied and measures of the “fitness for use” of thework products that are produced. For process improvement and project planningpurposes, your interest is historical. What was software development productivity onpast projects? What was the quality of the software that was produced? How can pastproductivity and quality data be extrapolated to the present? How can it help usimprove the process and plan new projects more accurately?
25.2.4 Object-Oriented Metrics
Conventional software project metrics (LOC or FP) can be used to estimate object-oriented software projects. However, these metrics do not provide enough granular-ity for the schedule and effort adjustments that are required as you iterate throughan evolutionary or incremental process. Lorenz and Kidd [Lor94] suggest the fol-lowing set of metrics for OO projects:Number of scenario scripts.A scenario script (analogous to use cases discussedthroughout Part 2 of this book) is a detailed sequence of steps that describe theinteraction between the user and the application. Each script is organized intotriplets of the form {initiator,action,participant}where initiatoris the object that requests some service (that initiates a message),actionis the result of the request, and participant is the server object that satisfies the request. The number of scenario scripts is directly correlated to the size of theCHAPTER 25PROCESS AND PROJECT METRICS 675pre75977_ch25.qxd  11/27/08  6:25 PM  Page 675application and to the number of test cases that must be developed to exercise thesystem once it is constructed.Number of key classes.Key classesare the “highly independent components” [Lor94] that are defined early in object-oriented analysis (Chapter 6).
5Because key classes are central to the problem domain, the number of such classes is an indica-tion of the amount of effort required to develop the software and also an indicationof the potential amount of reuse to be applied during system development.Number of support classes.Support classesare required to implement the sys- tem but are not immediately related to the problem domain. Examples might be userinterface (GUI) classes, database access and manipulation classes, and computationclasses. In addition, support classes can be developed for each of the key classes.Support classes are defined iteratively throughout an evolutionary process. Thenumber of support classes is an indication of the amount of effort required to developthe software and also an indication of the potential amount of reuse to be appliedduring system development.Average number of support classes per key class. In general, key classes are known early in the project. Support classes are defined throughout. If the averagenumber of support classes per key class were known for a given problem domain,estimating (based on total number of classes) would be greatly simplified. Lorenzand Kidd suggest that applications with a GUI have between two and three times thenumber of support classes as key classes. Non-GUI applications have between oneand two times the number of support classes as key classes.Number of subsystems.A subsystemis an aggregation of classes that support a function that is visible to the end user of a system. Once subsystems are identified,it is easier to lay out a reasonable schedule in which work on subsystems is parti-tioned among project staff.To be used effectively in an object-oriented software engineering environment,metrics similar to those noted above should be collected along with project meas-ures such as effort expended, errors and defects uncovered, and models or docu-mentation pages produced. As the database grows (after a number of projects havebeen completed), relationships between the object-oriented measures and projectmeasures will provide metrics that can aid in project estimation.
25.2.5 Use-Case–Oriented Metrics
Use cases6are used widely as a method for describing customer-level or businessdomain requirements that imply software features and functions. It would seemreasonable to use the use case as a normalization measure similar to LOC or FP.676 PART FOURMANAGING SOFTWARE PROJECTS
It is not uncommon formultiple-scenarioscripts to mention thesame functionalityor data objects.Therefore, be carefulwhen using scriptcounts. Many scriptscan sometimes bereduced to a singleclass or set of code.
Classes can vary insize and complexity.Therefore, it’s worthconsidering classifyingclass counts by sizeand complexity.
5 We referred to key classes as analysis classes in Part 2 of this book. 6 Use cases are introduced in Chapters 5 and 6.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 676Like FP, the use case is defined early in the software process, allowing it to be usedfor estimation before significant modeling and construction activities are initiated.Use cases describe (indirectly, at least) user-visible functions and features that arebasic requirements for a system. The use case is independent of programminglanguage. In addition, the number of use cases is directly proportional to the size ofthe application in LOC and to the number of test cases that will have to be designedto fully exercise the application.Because use cases can be created at vastly different levels of abstraction, thereis no standard “size” for a use case. Without a standard measure of what a use caseis, its application as a normalization measure (e.g., effort expended per use case) issuspect.Researchers have suggested use-case points (UCPs) as a mechanism for estimat- ing project effort and other characteristics. The UCP is a function of the number ofactors and transactions implied by the use-case models and is analogous to the FPin some ways. If you have further interest, see [Cle06].
25.2.6 WebApp Project Metrics
The objective of all WebApp projects is to deliver a combination of content andfunctionality to the end user. Measures and metrics used for traditional softwareengineering projects are difficult to translate directly to WebApps. Yet, it is possi-ble to develop a database that allows access to internal productivity and qualitymeasures derived over a number of projects. Among the measures that can becollected are:Number of static Web pages.Web pages with static content (i.e., the enduser has no control over the content displayed on the page) are the mostcommon of all WebApp features. These pages represent low relative com-plexity and generally require less effort to construct than dynamic pages. Thismeasure provides an indication of the overall size of the application and theeffort required to develop it.Number of dynamic Web pages.Web pages with dynamic content (i.e.,end-user actions or other external factors result in customized content dis-played on the page) are essential in all e-commerce applications, searchengines, financial applications, and many other WebApp categories. Thesepages represent higher relative complexity and require more effort to con-struct than static pages. This measure provides an indication of the overallsize of the application and the effort required to develop it.Number of internal page links.Internal page links are pointers that pro-vide a hyperlink to some other Web page within the WebApp. This measureprovides an indication of the degree of architectural coupling within theWebApp. As the number of page links increases, the effort expended onnavigational design and construction also increases.CHAPTER 25PROCESS AND PROJECT METRICS 677pre75977_ch25.qxd  11/27/08  6:25 PM  Page 677Number of persistent data objects. One or more persistent data objects (e.g., a database or data file) may be accessed by a WebApp. As the numberof persistent data objects grows, the complexity of the WebApp also growsand the effort to implement it increases proportionally.Number of external systems interfaced. WebApps must often interface with “backroom” business applications. As the requirement for interfacinggrows, system complexity and development effort also increase.Number of static content objects.Static content objects encompass statictext-based, graphical, video, animation, and audio information that areincorporated within the WebApp. Multiple content objects may appear on asingle Web page.Number of dynamic content objects. Dynamic content objects are gener- ated based on end-user actions and encompass internally generated text-based, graphical, video, animation, and audio information that areincorporated within the WebApp. Multiple content objects may appear on asingle Web page.Number of executable functions.An executable function (e.g., a scriptor applet) provides some computational service to the end user. As thenumber of executable functions increases, modeling and construction effortalso increase.Each of the preceding measures can be determined at a relatively early stage. For ex-ample, you can define a metric that reflects the degree of end-user customizationthat is required for the WebApp and correlate it to the effort expended on the projectand/or the errors uncovered as reviews and testing are conducted. To accomplishthis, you define N
sp/H11005number of Static Web pagesN
dp/H11005number of Dynamic Web pagesThen,Customization index, C/H11005The value of Cranges from 0 to 1. As Cgrows larger, the level of WebApp cus- tomization becomes a significant technical issue.Similar WebApp metrics can be computed and correlated with project measuressuch as effort expended, errors and defects uncovered, and models or documenta-tion pages produced. As the database grows (after a number of projects have beencompleted), relationships between the WebApp measures and project measures willprovide indicators that can aid in project estimation.
Ndp
Ndp/H11001Nsp678 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch25.qxd  11/27/08  6:25 PM  Page 67825.3 M ETRICS FOR SOFTWARE QUALITY
The overriding goal of software engineering is to produce a high-quality system,application, or product within a time frame that satisfies a market need. To achievethis goal, you must apply effective methods coupled with modern tools within the con-text of a mature software process. In addition, a good software engineer (and goodsoftware engineering managers) must measure if high quality is to be realized.The quality of a system, application, or product is only as good as the require-ments that describe the problem, the design that models the solution, the code thatleads to an executable program, and the tests that exercise the software to uncovererrors. You can use measurement to assess the quality of the requirements and de-sign models, the source code, and the test cases that have been created as the soft-ware is engineered. To accomplish this real-time assessment, you apply productmetrics (Chapter 23) to evaluate the quality of software engineering work productsin objective, rather than subjective ways.A project manager must also evaluate quality as the project progresses. Privatemetrics collected by individual software engineers are combined to provide project-level results. Although many quality measures can be collected, the primary thrust atthe project level is to measure errors and defects. Metrics derived from these meas-ures provide an indication of the effectiveness of individual and group software qual-ity assurance and control activities.CHAPTER 25PROCESS AND PROJECT METRICS 679
Project and Process Metrics
Objective:To assist in the definition,collection, evaluation, and reporting ofsoftware measures and metrics.Mechanics:Each tool varies in its application, but allprovide mechanisms for collecting and evaluating datathat lead to the computation of software metrics.Representative Tools: 
7
Function Point WORKBENCH,developed by Charismatek(www.charismatek.com.au), offers a wide arrayof FP-oriented metrics.MetricCenter,developed by Distributive Software(www.distributive.com), supports automatingdata collection, analysis, chart formatting, reportgeneration, and other measurement tasks.PSM Insight,developed by Practical Software and SystemsMeasurement (www.psmsc.com), assists in thecreation and subsequent analysis of a projectmeasurement database.SLIM tool set,developed by QSM (www.qsm.com),provides a comprehensive set of metrics and estimationtools.SPR tool set,developed by Software Productivity Research(www.spr.com), offers a comprehensive collectionof FP-oriented tools.TychoMetrics,developed by Predicate Logic, Inc.(www.predicate.com), is a tool suite for manage-ment metrics collection and reporting.SOFTWARE TOOLS
7 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Software is a complexentity. Therefore, errorsare to be expected aswork products aredeveloped. Processmetrics are intended toimprove the softwareprocess so that errorsare uncovered in themost effective manner.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 679Metrics such as work product errors per function point, errors uncovered perreview hour, and errors uncovered per testing hour provide insight into the efficacyof each of the activities implied by the metric. Error data can also be used to com-pute the defect removal efficiency(DRE) for each process framework activity. DRE isdiscussed in Section 25.3.3.
25.3.1 Measuring Quality
Although there are many measures of software quality,8correctness, maintainabil- ity, integrity, and usability provide useful indicators for the project team. Gilb [Gil88]suggests definitions and measures for each.Correctness.A program must operate correctly or it provides little value toits users. Correctness is the degree to which the software performs its re-quired function. The most common measure for correctness is defects perKLOC, where a defect is defined as a verified lack of conformance to require-ments. When considering the overall quality of a software product, defectsare those problems reported by a user of the program after the program hasbeen released for general use. For quality assessment purposes, defects arecounted over a standard period of time, typically one year.Maintainability.Software maintenance and support accounts for more ef-fort than any other software engineering activity. Maintainability is the easewith which a program can be corrected if an error is encountered, adaptedif its environment changes, or enhanced if the customer desires a change inrequirements. There is no way to measure maintainability directly; there-fore, you must use indirect measures. A simple time-oriented metric ismean-time-to-change(MTTC), the time it takes to analyze the changerequest, design an appropriate modification, implement the change, test it,and distribute the change to all users. On average, programs that are main-tainable will have a lower MTTC (for equivalent types of changes) thanprograms that are not maintainable.Integrity.Software integrity has become increasingly important in the ageof cyber terrorists and hackers. This attribute measures a system’s abilityto withstand attacks (both accidental and intentional) to its security.Attacks can be made on all three components of software: programs, data,and documention.To measure integrity, two additional attributes must be defined: threat andsecurity. Threatis the probability (which can be estimated or derived fromempirical evidence) that an attack of a specific type will occur within a giventime. Securityis the probability (which can be estimated or derived from680 PART FOURMANAGING SOFTWARE PROJECTS
8 A detailed discussion of the factors that influence software quality and the metrics that can be usedto assess software quality has been presented in Chapter 23.WebRef
An excellent sourceof information onsoftware quality andrelated topics(including metrics) canbe found at www.qualityworld.com.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 680empirical evidence) that the attack of a specific type will be repelled. Theintegrity of a system can then be defined as:Integrity /H11005/H20858[1 /H11002(threat /H11003(1 /H11002security))]For example, if threat (the probability that an attack will occur) is 0.25 andsecurity (the likelihood of repelling an attack) is 0.95, the integrity of the sys-tem is 0.99 (very high). If, on the other hand, the threat probability is 0.50 andthe likelihood of repelling an attack is only 0.25, the integrity of the system is0.63 (unacceptably low).Usability.If a program is not easy to use, it is often doomed to failure, even ifthe functions that it performs are valuable. Usability is an attempt to quantifyease of use and can be measured in terms of the characteristics presented inChapter 11.The four factors just described are only a sampling of those that have been proposedas measures for software quality. Chapter 23 considers this topic in additional detail.
25.3.2 Defect Removal Efficiency
A quality metric that provides benefit at both the project and process level is defectremoval efficiency(DRE). In essence, DRE is a measure of the filtering ability of qual-ity assurance and control actions as they are applied throughout all process frame-work activities.When considered for a project as a whole, DRE is defined in the following manner: DRE /H11005where Eis the number of errors found before delivery of the software to the end userand Dis the number of defects found after delivery.The ideal value for DRE is 1. That is, no defects are found in the software. Realisti-cally, Dwill be greater than 0, but the value of DRE can still approach 1 as Eincreases for a given value ofD.In fact, as Eincreases, it is likely that the final value of D will decrease (errors are filtered out before they become defects). If used as a metric thatprovides an indicator of the filtering ability of quality control and assurance activities,DRE encourages a software project team to institute techniques for finding as manyerrors as possible before delivery.DRE can also be used within the project to assess a team’s ability to find errorsbefore they are passed to the next framework activity or software engineering action.For example, requirements analysis produces a requirements model that can bereviewed to find and correct errors. Those errors that are not found during the reviewof the requirements model are passed on to design (where they may or may not befound). When used in this context, we redefine DRE as DRE
i/H11005Ei
Ei/H11001Ei/H110011EE/H11001DCHAPTER 25PROCESS AND PROJECT METRICS 681
If DRE is low as youmove through analysisand design, spendsome time improvingthe way you conducttechnical reviews.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 681where Eiis the number of errors found during software engineering action i and Ei+ 1
is the number of errors found during software engineering action i + 1 that are trace- able to errors that were not discovered in software engineering action i. A quality objective for a software team (or an individual software engineer) is toachieve DRE
ithat approaches 1. That is, errors should be filtered out before they arepassed on to the next activity or action.682 PART FOURMANAGING SOFTWARE PROJECTS
The scene:Doug Miller’s office twodays after initial meeting on software metrics.The players:Doug Miller (manager of the SafeHomesoftware engineering team) and Vinod Raman and JamieLazar, members of the product software engineering team.The conversation:Doug:You both had a chance to learn a little aboutprocess and project metrics?Vinod and Jamie:[Both nod.]Doug:It’s always a good idea to establish goals whenyou adopt any metrics. What are yours?Vinod:Our metrics should focus on quality. In fact, ouroverall goal is to keep the number of errors we pass onfrom one software engineering activity to the next to anabsolute minimum.Doug:And be very sure you keep the number of defectsreleased with the product to as close to zero as possible.Vinod (nodding):Of course.Jamie:I like DRE as a metric, and I think we can use itfor the entire project, but also as we move from one framework activity to the next. It’ll encourage us to finderrors at each step.Vinod:I’d also like to collect the number of hours wespend on reviews.Jamie:And the overall effort we spend on eachsoftware engineering task.Doug:You can compute a review-to-developmentratio . . . might be interesting.Jamie:I’d like to track some use-case data as well. Likethe amount of effort required to develop a use case, theamount of effort required to build software to implementa use case, and . . . Doug (smiling):I thought we were going to keep thissimple.Vinod:We should, but once you get into this metricsstuff, there’s a lot of interesting things to look at.Doug:I agree, but let’s walk before we run and stick toour goal. Limit data to be collected to five or six items,and we’re ready to go.SAFEHOMEEstablishing a Metrics Approach
25.4 I NTEGRATING METRICS WITHIN THE SOFTWARE PROCESS
The majority of software developers still do not measure, and sadly, most have littledesire to begin. As I noted earlier in this chapter, the problem is cultural. Attemptingto collect measures where none have been collected in the past often precipitatesresistance. “Why do we need to do this?” asks a harried project manager. “I don’t seethe point,” complains an overworked practitioner.In this section, I consider some arguments for software metrics and present anapproach for instituting a metrics collection program within a software engineeringorganization. But before I begin, some words of wisdom (now more than twodecades old) are suggested by Grady and Caswell [Gra87]:pre75977_ch25.qxd  11/27/08  6:25 PM  Page 682Some of the things we describe here will sound quite easy. Realistically, though, estab-lishing a successful company-wide software metrics program is hard work. When we saythat you must wait at least three years before broad organizational trends are available,you get some idea of the scope of such an effort.
The caveat suggested by the authors is well worth heeding, but the benefits of meas-urement are so compelling that the hard work is worth it.
25.4.1 Arguments for Software Metrics
Why is it so important to measure the process of software engineering and the prod-uct (software) that it produces? The answer is relatively obvious. If you do not mea-sure, there no real way of determining whether you are improving. And if you are notimproving, you are lost.By requesting and evaluating productivity and quality measures, a software team(and its management) can establish meaningful goals for improvement of the soft-ware process. Early in this book, I noted that software is a strategic business issuefor many companies. If the process through which it is developed can be improved, adirect impact on the bottom line can result. But to establish goals for improvement,the current status of software development must be understood. Hence, measurementis used to establish a process baseline from which improvements can be assessed.The day-to-day rigors of software project work leave little time for strategic think-ing. Software project managers are concerned with more mundane (but equally impor-tant) issues: developing meaningful project estimates, producing higher-qualitysystems, getting product out the door on time. By using measurement to establish aproject baseline, each of these issues becomes more manageable. I have alreadynoted that the baseline serves as a basis for estimation. Additionally, the collection ofquality metrics enables an organization to “tune” its software process to remove the“vital few” causes of defects that have the greatest impact on software development.
9
25.4.2 Establishing a Baseline
By establishing a metrics baseline, benefits can be obtained at the process, project,and product (technical) levels. Yet the information that is collected need not be fun-damentally different. The same metrics can serve many masters. The metrics base-line consists of data collected from past software development projects and can beas simple as the table presented in Figure 25.2 or as complex as a comprehensivedatabase containing dozens of project measures and the metrics derived from them.To be an effective aid in process improvement and/or cost and effort estimation,baseline data must have the following attributes: (1) data must be reasonablyaccurate—“guestimates” about past projects are to be avoided, (2) data should becollected for as many projects as possible, (3) measures must be consistent (for ex-ample, a line of code must be interpreted consistently across all projects for whichCHAPTER 25PROCESS AND PROJECT METRICS 683
uote:
“We managethings by thenumbers in manyaspects of our lives. . . These numbersgive us insight andhelp steer ouractions.”Michael MahandLarry Putnam
9 These ideas have been formalized into an approach called statistical software quality assurance.What is ametricsbaseline and whatbenefit does itprovide to asoftwareengineer??pre75977_ch25.qxd  11/27/08  6:25 PM  Page 683data are collected), (4) applications should be similar to work that is to beestimated—it makes little sense to use a baseline for batch information systemswork to estimate a real-time, embedded application.
25.4.3 Metrics Collection, Computation, and Evaluation
The process for establishing a metrics baseline is illustrated in Figure 25.3. Ideally,data needed to establish a baseline have been collected in an ongoing manner.Sadly, this is rarely the case. Therefore, data collection requires an historical inves-tigation of past projects to reconstruct required data. Once measures have been col-lected (unquestionably the most difficult step), metrics computation is possible.Depending on the breadth of measures collected, metrics can span a broad rangeof application-oriented metrics (e.g., LOC, FP, object-oriented, WebApp) as well asother quality- and project-oriented metrics. Finally, metrics must be evaluated andapplied during estimation, technical work, project control, and process improve-ment. Metrics evaluation focuses on the underlying reasons for the results obtainedand produces a set of indicators that guide the project or process.
25.5 M ETRICS FOR SMALL ORGANIZATIONS
The vast majority of software development organizations have fewer than 20 soft-ware people. It is unreasonable, and in most cases unrealistic, to expect that suchorganizations will develop comprehensive software metrics programs. However, itis reasonable to suggest that software organizations of all sizes measure and thenuse the resultant metrics to help improve their local software process and the qual-ity and timeliness of the products they produce.A commonsense approach to the implementation of any software process-relatedactivity is: keep it simple, customize to meet local needs, and be sure it adds value.684 PART FOURMANAGING SOFTWARE PROJECTS
Softwareengineeringprocess
Softwareproject
SoftwareproductDatacollection
Metricscomputation
MetricsevaluationMeasures
Metrics
IndicatorsFIGURE 25.3
Softwaremetrics collec-tion process
If you’re just starting tocollect metrics data,remember to keep itsimple. If you buryyourself with data, yourmetrics effort will fail.Baseline metrics datashould be collectedfrom a largerepresentativesampling of pastsoftware projects.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 684In the paragraphs that follow, I examine how these guidelines relate to metrics forsmall shops.
10
“Keep it simple” is a guideline that works reasonably well in many activities. But howshould you derive a “simple” set of software metrics that still provides value, and howcan you be sure that these simple metrics will meet the specific needs of your softwareorganization? You can begin by focusing not on measurement but rather on results.The software group is polled to define a single objective that requires improvement. Forexample, “reduce the time to evaluate and implement change requests.” A smallorganization might select the following set of easily collected measures:
•Time (hours or days) elapsed from the time a request is made until evaluationis complete, t
queue.
•Effort (person-hours) to perform the evaluation, Weval.
•Time (hours or days) elapsed from completion of evaluation to assignment ofchange order to personnel, t
eval.
•Effort (person-hours) required to make the change, Wchange .
•Time required (hours or days) to make the change, tchange .
•Errors uncovered during work to make change, Echange .
•Defects uncovered after change is released to the customer base, Dchange . Once these measures have been collected for a number of change requests, it ispossible to compute the total elapsed time from change request to implementationof the change and the percentage of elapsed time absorbed by initial queuing, eval-uation and change assignment, and change implementation. Similarly, the percent-age of effort required for evaluation and implementation can be determined. Thesemetrics can be assessed in the context of quality data, E
change and Dchange . The per- centages provide insight into where the change request process slows down andmay lead to process improvement steps to reduce t
queue, Weval, teval, Wchange , and/or E
change . In addition, the defect removal efficiency can be computed as DRE/H11005DRE can be compared to elapsed time and total effort to determine the impact ofquality assurance activities on the time and effort required to make a change.For small groups, the cost of collecting measures and computing metrics rangesfrom 3 to 8 percent of project budget during the learning phase and then drops toless than 1 percent of project budget after software engineers and project managershave become familiar with the metrics program [Gra99]. These costs can show a
Echange
Echange/H11001DchangeCHAPTER 25PROCESS AND PROJECT METRICS 685
10 This discussion is equally relevant to software teams that have adopted an agile software develop-ment process (Chapter 3).How shouldwe derive aset of “simple”software metrics.?pre75977_ch25.qxd  11/27/08  6:25 PM  Page 685substantial return on investment if the insights derived from metrics data lead tomeaningful process improvement for the software organization.
25.6 E STABLISHING A SOFTWARE METRICS PROGRAM
The Software Engineering Institute has developed a comprehensive guidebook[Par96b] for establishing a “goal-driven” software metrics program. The guidebooksuggests the following steps:1.Identify your business goals.2.Identify what you want to know or learn.3.Identify your subgoals.4.Identify the entities and attributes related to your subgoals.5.Formalize your measurement goals.6.Identify quantifiable questions and the related indicators that you will use tohelp you achieve your measurement goals.7.Identify the data elements that you will collect to construct the indicators thathelp answer your questions.8.Define the measures to be used, and make these definitions operational.9.Identify the actions that you will take to implement the measures.10.Prepare a plan for implementing the measures.A detailed discussion of these steps is best left to the SEI’s guidebook. However, abrief overview of key points is worthwhile.Because software supports business functions, differentiates computer-basedsystems or products, or acts as a product in itself, goals defined for the business canalmost always be traced downward to specific goals at the software engineeringlevel. For example, consider the SafeHomeproduct. Working as a team, software engineering and business managers develop a list of prioritized business goals:1.Improve our customers’ satisfaction with our products.2.Make our products easier to use.3.Reduce the time it takes us to get a new product to market.4.Make support for our products easier.5.Improve our overall profitability.The software organization examines each business goal and asks: “What activi-ties do we manage, execute, or support and what do we want to improve withinthese activities?” To answer these questions the SEI recommends the creation of an“entity-question list” in which all things (entities) within the software process thatare managed or influenced by the software organization are noted. Examples of686 PART FOURMANAGING SOFTWARE PROJECTS
WebRef
A Guidebook for GoalDriven SoftwareMeasurementcan bedownloaded from
www.sei.cmu.edu .
The software metricsyou choose should bedriven by the businessand technical goalsyou wish toaccomplish.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 686entities include development resources, work products, source code, test cases,change requests, software engineering tasks, and schedules. For each entity listed,software people develop a set of questions that assess quantitative characteristicsof the entity (e.g., size, cost, time to develop). The questions derived as a conse-quence of the creation of an entity-question list lead to the derivation of a set of sub-goals that relate directly to the entities created and the activities performed as partof the software process.Consider the fourth goal: “Make support for our products easier.” The followinglist of questions might be derived for this goal [Par96b]:
•Do customer change requests contain the information we require toadequately evaluate the change and then implement it in a timely manner?
•How large is the change request backlog?
•Is our response time for fixing bugs acceptable based on customer need?
•Is our change control process (Chapter 22) followed?
•Are high-priority changes implemented in a timely manner?Based on these questions, the software organization can derive the following sub-goal: Improve the performance of the change management process. The software process entities and attributes that are relevant to the subgoal are identified, and themeasurement goals associated with them are delineated.The SEI [Par96b] provides detailed guidance for steps 6 through 10 of its goal-drivenmeasurement approach. In essence, you refine measurement goals into questions thatare further refined into entities and attributes that are then refined into metrics.CHAPTER 25PROCESS AND PROJECT METRICS 687
Establishing a Metrics Program
The Software Productivity Center(www.spc.ca) suggests an eight-stepapproach for establishing a metrics program within asoftware organization that can be used as an alternativeto the SEI approach described in Section 25.6. Theirapproach is summarized in this sidebar.1. Understand the existing software process. Framework activities (Chapter 2) are identified.Input information for each activity is described.Tasks associated with each activity are defined.Quality assurance functions are noted.Work products that are produced are listed.2. Define the goals to be achieved by establishing ametrics programExamples: improve accuracy of estimation,improve product quality.3. Identify metrics required to achieve goals.Questions to be answered are defined; forexample, How many errors found in oneframework activity can be traced to thepreceding framework activity?Create measures and metrics that will help answerthese questions.4. Identify the measures and metrics to be collected andcomputed.5. Establish a measurement collection process byanswering these questions:What is the source of the measurements?Can tools be used to collect the data?Who is responsible for collecting the data?When are data collected and recorded?How are data stored?INFOpre75977_ch25.qxd  11/27/08  6:25 PM  Page 68725.7 S UMMARY
Measurement enables managers and practitioners to improve the software process;assist in the planning, tracking, and control of software projects; and assess the qual-ity of the product (software) that is produced. Measures of specific attributes of theprocess, project, and product are used to compute software metrics. These metricscan be analyzed to provide indicators that guide management and technical actions.Process metrics enable an organization to take a strategic view by providinginsight into the effectiveness of a software process. Project metrics are tactical. Theyenable a project manager to adapt project workflow and technical approach in areal-time manner.Both size- and function-oriented metrics are used throughout the industry. Size-oriented metrics use the line of code as a normalizing factor for other measures suchas person-months or defects. The function point is derived from measures of the in-formation domain and a subjective assessment of problem complexity. In addition,object-oriented metrics and Web application metrics can be used.Software quality metrics, like productivity metrics, focus on the process, the proj-ect, and the product. By developing and analyzing a metrics baseline for quality, anorganization can correct those areas of the software process that are the cause ofsoftware defects.Measurement results in cultural change. Data collection, metrics computation,and metrics analysis are the three steps that must be implemented to begin a met-rics program. In general, a goal-driven approach helps an organization focus on theright metrics for its business. By creating a metrics baseline—a database containingprocess and product measurements—software engineers and their managers cangain better insight into the work that they do and the product that they produce.
PROBLEMS AND POINTS TO PONDER
25.1.Describe the difference between process and project metrics in your own words.25.2.Why should some software metrics be kept “private”? Provide examples of three metricsthat should be private. Provide examples of three metrics that should be public.688 PART FOURMANAGING SOFTWARE PROJECTS
What validation mechanisms are used to ensurethat the data are correct?6. Acquire appropriate tools to assist in collection andassessment.7. Establish a metrics database.The relative sophistication of the database isestablished.Use of related tools (e.g., an SCM repository,Chapter 26) is explored.Existing database products are evaluated.8. Define appropriate feedback mechanisms.Who requires ongoing metrics information?How is the information to be delivered?What is the format of the information?A considerably more detailed description of these eight stepscan be downloaded from www.spc.ca/resources/metrics/.pre75977_ch25.qxd  11/27/08  6:25 PM  Page 68825.3.What is an indirect measure, and why are such measures common in software metricswork?25.4.Grady suggests an etiquette for software metrics. Can you add three more rules to thosenoted in Section 25.1.1?25.5.Team A found 342 errors during the software engineering process prior to release. Team Bfound 184 errors. What additional measures would have to be made for projects A and B todetermine which of the teams eliminated errors more efficiently? What metrics would you pro-pose to help in making the determination? What historical data might be useful?25.6.Present an argument against lines of code as a measure for software productivity. Willyour case hold up when dozens or hundreds of projects are considered?25.7.Compute the function point value for a project with the following information domaincharacteristics:Number of user inputs: 32Number of user outputs: 60Number of user inquiries: 24Number of files: 8Number of external interfaces: 2Assume that all complexity adjustment values are average. Use the algorithm noted in Chapter 23.25.8.Using the table presented in Section 25.2.3, make an argument against the use of as-sembler language based on the functionality delivered per statement of code. Again referring tothe table, discuss why C++ would present a better alternative than C.25.9.The software used to control a photocopier requires 32,000 lines of C and 4,200 lines ofSmalltalk. Estimate the number of function points for the software inside the copier.25.10.A Web engineering team has built an e-commerce WebApp that contains 145 individ-ual pages. Of these pages, 65 are dynamic; that is, they are internally generated based on end-user input. What is the customization index for this application?25.11.A WebApp and its support environment have not been fully fortified against attack. Webengineers estimate that the likelihood of repelling an attack is only 30 percent. The system doesnot contain sensitive or controversial information, so the threat probability is 25 percent. Whatis the integrity of the WebApp?25.12.At the conclusion of a project, it has been determined that 30 errors were found dur-ing the modeling activity and 12 errors were found during the construction activity that weretraceable to errors that were not discovered in the modeling activity. What is the DRE for themodeling activity?25.13.A software team delivers a software increment to end users. The users uncover eightdefects during the first month of use. Prior to delivery, the software team found 242 errors dur-ing formal technical reviews and all testing tasks. What is the overall DRE for the project afterone month’s usage?
FURTHER READINGS AND INFORMATION SOURCES
Software process improvement (SPI) has received a significant amount of attention over the pasttwo decades. Since measurement and software metrics are key to successfully improving thesoftware process, many books on SPI also discuss metrics. Rico (ROI of Software ProcessImprovement,J. Ross Publishing, 2004) provides an in-depth discussion of SPI and the metricsthat can help an organization achieve it. Ebert and his colleagues (Best Practices in Software Mea-surement,Springer, 2004) address the use of measurement within the context of ISO and CMMIstandards. Kan (Metrics and Models in Software Quality Engineering, 2d ed., Addison-Wesley, 2002) presents a collection of relevant metrics.CHAPTER 25PROCESS AND PROJECT METRICS 689pre75977_ch25.qxd  11/27/08  6:25 PM  Page 689Ebert and Dumke (Software Measurement, Springer, 2007) provide a useful treatment of measurement and metrics as they should be applied for IT projects. McGarry and his colleagues(Practical Software Measurement,Addison-Wesley, 2001) present in-depth advice for assessingthe software process. A worthwhile collection of papers has been edited by Haug and his col-leagues (Software Process Improvement: Metrics, Measurement, and Process Modeling, Springer- Verlag, 2001). Florac and Carlton (Measuring the Software Process, Addison-Wesley, 1999) and Fenton and Pfleeger (Software Metrics: A Rigorous and Practical Approach, Revised, Brooks/ColePublishers, 1998) discuss how software metrics can be used to provide the indicators necessaryto improve the software process.Laird and Brennan (Software Measurement and Estimation, Wiley-IEEE Computer Society Press, 2006) and Goodman (Software Metrics: Best Practices for Successful IT Management,Rothstein Associates, Inc., 2004) discuss the use of software metrics for project managementand estimation. Putnam and Myers (Five Core Metrics, Dorset House, 2003) draw on a database of more the 6000 software projects to demonstrate how five core metrics—time, effort, size, re-liability, and process productivity—can be used to control software projects. Maxwell (AppliedStatistics for Software Managers,Prentice-Hall, 2003) presents techniques for analyzing softwareproject data. Munson (Software Engineering Measurement, Auerbach, 2003) discusses a broad ar- ray of software engineering measurement issues. Jones ( Software Assessments, Benchmarks and Best Practices, Addison-Wesley, 2000) describes both quantitative measurement and qualitativefactors that help an organization assess its software process and practices.Function point measurement has become a widely used technique in many areas of softwareengineering work. Parthasarathy (Practical Software Estimation: Function Point Methods forInsourced and Outsourced Projects, Addison-Wesley, 2007) provide a comprehensive guide. Garmus and Herron (Function Point Analysis: Measurement Practices for Successful SoftwareProjects,Addison-Wesley, 2000) discuss process metrics with an emphasis on function pointanalysis.Relatively little has been published on metrics for Web engineering work, However, Kaushik(Web Analytics: An Hour a Day,Sybex, 2007), Stern (Web Metrics: Proven Methods for MeasuringWeb Site Success,Wiley, 2002), Inan and Kean (Measuring the Success of Your Website, Longman, 2002), and Nobles and Grady (Web Site Analysis and Reporting,Premier Press, 2001) address Web metrics from a business and marketing perspective.The latest research in the metrics area is summarized by the IEEE ( Symposium on Software Metrics,published yearly). A wide variety of information sources on the process and projectmetrics is available on the Internet. An up-to-date list of World Wide Web references relevant toprocess and project metrics can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm .690 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch25.qxd  11/27/08  6:25 PM  Page 690Software project management begins with a set of activities that are collec-tively called project planning.Before the project can begin, the softwareteam should estimate the work to be done, the resources that will berequired, and the time that will elapse from start to finish. Once these activitiesare accomplished, the software team should establish a project schedule that de-fines software engineering tasks and milestones, identifies who is responsible forconducting each task, and specifies the intertask dependencies that may have astrong bearing on progress.In an excellent guide to “software project survival,” Steve McConnell [McC98]presents a real-world view of project planning:
Many technical workers would rather do technical work than spend time planning.Many technical managers do not have sufficient training in technical management to 
691CHAPTER
26ESTIMATION FOR
SOFTWARE PROJECTS
What is it? A real need for softwarehas been established; stakeholdersare onboard, software engineers areready to start, and the project isabout to begin. But how do you proceed? Soft-ware project planning encompasses five majoractivities—estimation, scheduling, risk analysis,quality management planning, and changemanagement planning. In the context of thischapter, we consider only estimation—yourattempt to determine how much money, effort,resources, and time it will take to build a specificsoftware-based system or product.
Who does it? Software project managers—usinginformation solicited from project stakeholdersand software metrics data collected from pastprojects.
Why is it important? Would you build a housewithout knowing how much you were about tospend, the tasks that you need to perform, andthe time line for the work to be conducted? Ofcourse not, and since most computer-basedsystems and products cost considerably moreto build than a large house, it would seemQUICK
LOOKreasonable to develop an estimate before youstart creating the software.
What are the steps? Estimation begins with adescription of the scope of the problem. Theproblem is then decomposed into a set of smallerproblems, and each of these is estimated usinghistorical data and experience as guides. Prob-lem complexity and risk are considered before afinal estimate is made.
What is the work product? A simple table delin-eating the tasks to be performed, the functions tobe implemented, and the cost, effort, and timeinvolved for each is generated.
How do I ensure that I’ve done it right? That’shard, because you won’t really know until theproject has been completed. However, if youhave experience and follow a systematicapproach, generate estimates using solid histor-ical data, create estimation data points using atleast two different methods, establish a realisticschedule, and continually adapt it as the projectmoves forward, you can feel confident thatyou’ve given it your best shot.KEY
CONCEPTS
estimation  . . . .692agile  . . . . . . .713empiricalmodels  . . . . . .708FP-based  . . . .702object-orientedprojects  . . . . .712problem-based . . . . . . .699process-based . . . . . . .703reconciling  . . .707pre75977_ch26.qxd  11/27/08  6:26 PM  Page 691692 PART FOURMANAGING SOFTWARE PROJECTS
feel confident that their planning will improve a project’s outcome. Since neither partywants to do planning, it often doesn’t get done.But failure to plan is one of the most critical mistakes a project can make . . . effective planning is needed to resolve problems upstream [early in the project] at low cost, ratherthan downstream [late in the project] at high cost. The average project spends 80 percent of its time on rework—fixing mistakes that were made earlier in the project.
McConnell argues that every team can find the time to plan (and to adapt the planthroughout the project) simply by taking a small percentage of the time that wouldhave been spent on rework that occurs because planning was not conducted.
26.1 O BSERVATIONS ON ESTIMATION
Planning requires you to make an initial commitment, even though it’s likely that this“commitment” will be proven wrong. Whenever estimates are made, you look intothe future and accept some degree of uncertainty as a matter of course. To quoteFrederick Brooks [Bro95]:
. . . our techniques of estimating are poorly developed. More seriously, they reflect anunvoiced assumption that is quite untrue, i.e., that all will go well. . . . because we areuncertain of our estimates, software managers often lack the courteous stubbornness tomake people wait for a good product.
Although estimating is as much art as it is science, this important action need not beconducted in a haphazard manner. Useful techniques for time and effort estimationdo exist. Process and project metrics can provide historical perspective and power-ful input for the generation of quantitative estimates. Past experience (of all peopleinvolved) can aid immeasurably as estimates are developed and reviewed. Becauseestimation lays a foundation for all other project planning actions, and project plan-ning provides the road map for successful software engineering, we would be illadvised to embark without it.Estimation of resources, cost, and schedule for a software engineering effortrequires experience, access to good historical information (metrics), and the courageto commit to quantitative predictions when qualitative information is all that exists.Estimation carries inherent risk,
1and this risk leads to uncertainty.Project complexityhas a strong effect on the uncertainty inherent in planning.Complexity, however, is a relative measure that is affected by familiarity with pasteffort. The first-time developer of a sophisticated e-commerce application might con-sider it to be exceedingly complex. However, a Web engineering team developing itstenth e-commerce WebApp would consider such work run-of-the-mill. A number ofquantitative software complexity measures have been proposed [Zus97]. Such mea-sures are applied at the design or code level and are therefore difficult to use duringuote:
“Good estimatingapproaches andsolid historical dataoffer the best hopethat reality will winout over impossibledemands.”Caper Jones
1 Systematic techniques for risk analysis are presented in Chapter 28.use cases  . . . .705WebApps  . . . .714feasibility . . . . .694projectplanning . . . . . .693software equation . . . . . .711software scope  . . . . . . . .694pre75977_ch26.qxd  11/27/08  6:26 PM  Page 692software planning (before a design and code exist). However, other, more subjectiveassessments of complexity (e.g., function point complexity adjustment factorsdescribed in Chapter 23) can be established early in the planning process.Project sizeis another important factor that can affect the accuracy and efficacy ofestimates. As size increases, the interdependency among various elements of thesoftware grows rapidly.
2Problem decomposition, an important approach to estimat-ing, becomes more difficult because the refinement of problem elements may still beformidable. To paraphrase Murphy’s law: “What can go wrong will go wrong”—andif there are more things that can fail, more things will fail.The degree of structural uncertaintyalso has an effect on estimation risk. In this context, structure refers to the degree to which requirements have been solidified,the ease with which functions can be compartmentalized, and the hierarchicalnature of the information that must be processed.The availability of historical information has a strong influence on estimation risk.By looking back, you can emulate things that worked and improve areas whereproblems arose. When comprehensive software metrics (Chapter 25) are availablefor past projects, estimates can be made with greater assurance, schedules canbe established to avoid past difficulties, and overall risk is reduced.Estimation risk is measured by the degree of uncertainty in the quantitativeestimates established for resources, cost, and schedule. If project scope is poorlyunderstood or project requirements are subject to change, uncertainty and estimationrisk become dangerously high. As a planner, you and the customer should recognizethat variability in software requirements means instability in cost and schedule.However, you should not become obsessive about estimation. Modern softwareengineering approaches (e.g., evolutionary process models) take an iterative viewof development. In such approaches, it is possible—although not always politicallyacceptable—to revisit the estimate (as more information is known) and revise itwhen the customer makes changes to requirements.
26.2 T HEPROJECT PLANNING PROCESS
The objective of software project planning is to provide a framework that enables themanager to make reasonable estimates of resources, cost, and schedule. In addition,estimates should attempt to define best-case and worst-case scenarios so that proj-ect outcomes can be bounded. Although there is an inherent degree of uncertainty,the software team embarks on a plan that has been established as a consequenceof these tasks. Therefore, the plan must be adapted and updated as the project pro-ceeds. In the following sections, each of the actions associated with software projectplanning is discussed.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 693
uote:
“It is the mark ofan instructed mindto rest satisfiedwith the degree ofprecision that thenature of the sub-ject admits, and notto seek exactnesswhen only anapproximationof the truth ispossible.”AristotleProject complexity,project size, and thedegree of structuraluncertainty all affectthe reliability ofestimates.
2 Size often increases due to “scope creep” that occurs when problem requirements change. In-creases in project size can have a geometric impact on project cost and schedule (Michael Mah,personal communication).The more you know,the better youestimate. Therefore,update your estimatesas the projectprogresses.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 693694 PART FOURMANAGING SOFTWARE PROJECTS
Task Set for Project Planning
1. Establish project scope.2. Determine feasibility.3. Analyze risks (Chapter 28).4. Define required resources.a. Determine required human resources.b. Define reusable software resources.c. Identify environmental resources.5. Estimate cost and effort.a. Decompose the problem.b. Develop two or more estimates using size, functionpoints, process tasks, or use cases.c. Reconcile the estimates.6. Develop a project schedule (Chapter 27).a. Establish a meaningful task set.b. Define a task network.c. Use scheduling tools to develop a time-line chart.d. Define schedule tracking mechanisms.TASKSET
26.3 S OFTWARE SCOPE AND FEASIBILITY
Software scopedescribes the functions and features that are to be delivered to endusers; the data that are input and output; the “content” that is presented to users asa consequence of using the software; and the performance, constraints, interfaces,and reliability that boundthe system. Scope is defined using one of two techniques:1.A narrative description of software scope is developed after communicationwith all stakeholders.2.A set of use cases
3is developed by end users.Functions described in the statement of scope (or within the use cases) are evaluatedand in some cases refined to provide more detail prior to the beginning of estimation.Because both cost and schedule estimates are functionally oriented, some degree ofdecomposition is often useful. Performance considerations encompass processingand response time requirements. Constraints identify limits placed on the software byexternal hardware, available memory, or other existing systems.Once scope has been identified (with the concurrence of the customer), it is rea-sonable to ask: “Can we build software to meet this scope? Is the project feasible?”All too often, software engineers rush past these questions (or are pushed pastthem by impatient managers or other stakeholders), only to become mired in aproject that is doomed from the onset. Putnam and Myers [Put97a] address thisissue when they write:
[N]ot everything imaginable is feasible, not even in software, evanescent as it may appearto outsiders. On the contrary, software feasibility has four solid dimensions: Technology—Is a project technically feasible? Is it within the state of the art? Can defects be reduced toa level matching the application’s needs? Finance—Is it financially feasible? Can devel-opment be completed at a cost the software organization, its client, or the market can
3 Use cases have been discussed in detail throughout Part 2 of this book. A use case is a scenario-based description of the user’s interaction with the software from the user’s point of view.Project feasibility isimportant, but aconsideration ofbusiness need is evenmore important. Itdoes no good to builda high-tech system orproduct that no onewants.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 694afford? Time—Will the project’s time-to-market beat the competition? Resources—Doesthe organization have the resources needed to succeed?
Putnam and Myers correctly suggest that scoping is not enough. Once scope is un-derstood, you must work to determine if it can be done within the dimensions justnoted. This is a crucial, although often overlooked, part of the estimation process.
26.4 R ESOURCES
The second planning task is estimation of the resources required to accomplish thesoftware development effort. Figure 26.1 depicts the three major categories of soft-ware engineering resources—people, reusable software components, and the devel-opment environment (hardware and software tools). Each resource is specified withfour characteristics: description of the resource, a statement of availability, timewhen the resource will be required, and duration of time that the resource will beapplied. The last two characteristics can be viewed as a time window. Availability ofthe resource for a specified window must be established at the earliest practical time.
26.4.1 Human Resources
The planner begins by evaluating software scope and selecting the skills required tocomplete development. Both organizational position (e.g., manager, senior softwareengineer) and specialty (e.g., telecommunications, database, client-server) areCHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 695
ProjectPeople Environment
ReusablesoftwareNumber
Skills
LocationNetworkresourcesHardwareSoftwaretools
COTScomponents Newcomponents
Full-experiencecomponents Part-experiencecomponentsFIGURE 26.1
Projectresourcespre75977_ch26.qxd  11/27/08  6:26 PM  Page 695specified. For relatively small projects (a few person-months), a single individual mayperform all software engineering tasks, consulting with specialists as required. Forlarger projects, the software team may be geographically dispersed across a numberof different locations. Hence, the location of each human resource is specified.The number of people required for a software project can be determined only afteran estimate of development effort (e.g., person-months) is made. Techniques forestimating effort are discussed later in this chapter.
26.4.2 Reusable Software Resources
Component-based software engineering (CBSE)4emphasizes reusability—that is, the creation and reuse of software building blocks. Such building blocks, often calledcomponents,must be cataloged for easy reference, standardized for easy application,and validated for easy integration. Bennatan [Ben00] suggests four softwareresource categories that should be considered as planning proceeds:Off-the-shelf components.Existing software that can be acquired from a thirdparty or from a past project. COTS (commercial off-the-shelf) components are pur-chased from a third party, are ready for use on the current project, and have beenfully validated.Full-experience components.Existing specifications, designs, code, or test datadeveloped for past projects that are similar to the software to be built for thecurrent project. Members of the current software team have had full experiencein the application area represented by these components. Therefore, modificationsrequired for full-experience components will be relatively low risk.Partial-experience components.Existing specifications, designs, code, or test datadeveloped for past projects that are related to the software to be built for the cur-rent project but will require substantial modification. Members of the current soft-ware team have only limited experience in the application area represented bythese components. Therefore, modifications required for partial-experience com-ponents have a fair degree of risk.New components.Software components must be built by the software teamspecifically for the needs of the current project.Ironically, reusable software components are often neglected during planning, onlyto become a paramount concern later in the software process. It is better to specifysoftware resource requirements early. In this way technical evaluation of the alter-natives can be conducted and timely acquisition can occur.
26.4.3 Environmental Resources
The environment that supports a software project, often called the software engi-neering environment(SEE), incorporates hardware and software. Hardware provides696 PART FOURMANAGING SOFTWARE PROJECTS
4 CBSE is considered in Chapter 10.Never forget that inte-grating a variety ofreusable componentscan be a significantchallenge. Worse, theintegration problemresurfaces as variouscomponents areupgraded.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 696a platform that supports the tools (software) required to produce the work productsthat are an outcome of good software engineering practice.
5Because most software organizations have multiple constituencies that require access to the SEE, you mustprescribe the time window required for hardware and software and verify that theseresources will be available.When a computer-based system (incorporating specialized hardware and soft-ware) is to be engineered, the software team may require access to hardwareelements being developed by other engineering teams. For example, software for arobotic device used within a manufacturing cell may require a specific robot (e.g., arobotic welder) as part of the validation test step; a software project for advancedpage layout may need a high-speed digital printing system at some point duringdevelopment. Each hardware element must be specified as part of planning.
26.5 S OFTWARE PROJECT ESTIMATION
Software cost and effort estimation will never be an exact science. Too manyvariables—human, technical, environmental, political—can affect the ultimate costof software and effort applied to develop it. However, software project estimationcan be transformed from a black art to a series of systematic steps that provide esti-mates with acceptable risk. To achieve reliable cost and effort estimates, a numberof options arise:1.Delay estimation until late in the project (obviously, we can achieve 100 per-cent accurate estimates after the project is complete!).2.Base estimates on similar projects that have already been completed.3.Use relatively simple decomposition techniques to generate project cost andeffort estimates.4.Use one or more empirical models for software cost and effort estimation.Unfortunately, the first option, however attractive, is not practical. Cost estimatesmust be provided up-front. However, you should recognize that the longer you wait,the more you know, and the more you know, the less likely you are to make seriouserrors in your estimates.The second option can work reasonably well, if the current project is quite similarto past efforts and other project influences (e.g., the customer, business conditions,the software engineering environment, deadlines) are roughly equivalent. Unfortu-nately, past experience has not always been a good indicator of future results.The remaining options are viable approaches to software project estimation.Ideally, the techniques noted for each option should be applied in tandem; each usedas a cross-check for the other. Decomposition techniques take a divide-and-conquerCHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 697
5 Other hardware—the target environment—is the computer on which the software will execute whenit has been released to the end user.uote:
“In an age ofoutsourcing andincreasedcompetition, theability to estimatemore accurately . . .has emerged as acritical successfactor for many ITgroups.”Rob Thomsettpre75977_ch26.qxd  11/27/08  6:26 PM  Page 697approach to software project estimation. By decomposing a project into major func-tions and related software engineering activities, cost and effort estimation can beperformed in a stepwise fashion. Empirical estimation models can be used to com-plement decomposition techniques and offer a potentially valuable estimationapproach in their own right. A model is based on experience (historical data) andtakes the formd/H11005f(v
i)where dis one of a number of estimated values (e.g., effort, cost, project duration)and v
iare selected independent parameters (e.g., estimated LOC or FP).Automated estimation tools implement one or more decomposition techniques orempirical models and provide an attractive option for estimating. In such systems,the characteristics of the development organization (e.g., experience, environment)and the software to be developed are described. Cost and effort estimates are derivedfrom these data.Each of the viable software cost estimation options is only as good as the histor-ical data used to seed the estimate. If no historical data exist, costing rests on a veryshaky foundation. In Chapter 25, we examined the characteristics of some of thesoftware metrics that provide the basis for historical estimation data.
26.6 D ECOMPOSITION TECHNIQUES
Software project estimation is a form of problem solving, and in most cases, theproblem to be solved (i.e., developing a cost and effort estimate for a softwareproject) is too complex to be considered in one piece. For this reason, you shoulddecompose the problem, recharacterizing it as a set of smaller (and hopefully, moremanageable) problems.In Chapter 24, the decomposition approach was discussed from two different pointsof view: decomposition of the problem and decomposition of the process. Estimationuses one or both forms of partitioning. But before an estimate can be made, you mustunderstand the scope of the software to be built and generate an estimate of its “size.”
26.6.1 Software Sizing
The accuracy of a software project estimate is predicated on a number of things:(1) the degree to which you have properly estimated the size of the product to be built;(2) the ability to translate the size estimate into human effort, calendar time, and dol-lars (a function of the availability of reliable software metrics from past projects);(3) the degree to which the project plan reflects the abilities of the software team; and(4) the stability of product requirements and the environment that supports the soft-ware engineering effort.In this section, I consider the software sizing problem. Because a project estimate is only as good as the estimate of the size of the work to be accomplished, sizing698 PART FOURMANAGING SOFTWARE PROJECTS
uote:
“It is very difficultto make avigorous, plausibleand job-riskingdefense of anestimate that isderived by noquantitativemethod, supportedby little data, andcertified chiefly bythe hunches of themanagers.”Fred Brooks
The “size” of softwareto be built can beestimated using a directmeasure, LOC, or anindirect measure, FP .pre75977_ch26.qxd  11/27/08  6:26 PM  Page 698represents your first major challenge as a planner. In the context of project planning,size refers to a quantifiable outcome of the software project. If a direct approach istaken, size can be measured in lines of code (LOC). If an indirect approach is chosen,size is represented as function points (FP).Putnam and Myers [Put92] suggest four different approaches to the sizing problem:
•“Fuzzy logic” sizing.This approach uses the approximate reasoning tech-niques that are the cornerstone of fuzzy logic. To apply this approach, theplanner must identify the type of application, establish its magnitude on aqualitative scale, and then refine the magnitude within the original range.
•Function point sizing.The planner develops estimates of the informationdomain characteristics discussed in Chapter 23.
•Standard component sizing.Software is composed of a number of different“standard components” that are generic to a particular application area. Forexample, the standard components for an information system are subsys-tems, modules, screens, reports, interactive programs, batch programs, files,LOC, and object-level instructions. The project planner estimates the numberof occurrences of each standard component and then uses historical projectdata to estimate the delivered size per standard component.
•Change sizing.This approach is used when a project encompasses the use ofexisting software that must be modified in some way as part of a project. Theplanner estimates the number and type (e.g., reuse, adding code, changingcode, deleting code) of modifications that must be accomplished.Putnam and Myers suggest that the results of each of these sizing approaches becombined statistically to create a three-point or expected-valueestimate. This is accomplished by developing optimistic (low), most likely, and pessimistic (high) val-ues for size and combining them using Equation (26.1), described in Section 26.6.2.
26.6.2 Problem-Based Estimation
In Chapter 25, lines of code and function points were described as measures fromwhich productivity metrics can be computed. LOC and FP data are used in two waysduring software project estimation: (1) as estimation variables to “size” each elementof the software and (2) as baseline metrics collected from past projects and used inconjunction with estimation variables to develop cost and effort projections.LOC and FP estimation are distinct estimation techniques. Yet both have a num-ber of characteristics in common. You begin with a bounded statement of softwarescope and from this statement attempt to decompose the statement of scope intoproblem functions that can each be estimated individually. LOC or FP (the estima-tion variable) is then estimated for each function. Alternatively, you may chooseanother component for sizing, such as classes or objects, changes, or businessprocesses affected.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 699
How do wesize thesoftware thatwe’re planningto build??
What doLOC- and FP-basedestimation havein common??pre75977_ch26.qxd  11/27/08  6:26 PM  Page 699Baseline productivity metrics (e.g., LOC/pm or FP/pm6) are then applied to the appropriate estimation variable, and cost or effort for the function is derived. Func-tion estimates are combined to produce an overall estimate for the entire project.It is important to note, however, that there is often substantial scatter in produc-tivity metrics for an organization, making the use of a single-baseline productivitymetric suspect. In general, LOC/pm or FP/pm averages should be computed by proj-ect domain. That is, projects should be grouped by team size, application area, com-plexity, and other relevant parameters. Local domain averages should then becomputed. When a new project is estimated, it should first be allocated to a domain,and then the appropriate domain average for past productivity should be used ingenerating the estimate.The LOC and FP estimation techniques differ in the level of detail required for de-composition and the target of the partitioning. When LOC is used as the estimationvariable, decomposition is absolutely essential and is often taken to considerablelevels of detail. The greater the degree of partitioning, the more likely reasonably ac-curate estimates of LOC can be developed.For FP estimates, decomposition works differently. Rather than focusing on func-tion, each of the information domain characteristics—inputs, outputs, data files, in-quiries, and external interfaces—as well as the 14 complexity adjustment valuesdiscussed in Chapter 23 are estimated. The resultant estimates can then be used toderive an FP value that can be tied to past data and used to generate an estimate.Regardless of the estimation variable that is used, you should begin by estimat-ing a range of values for each function or information domain value. Using histor-ical data or (when all else fails) intuition, estimate an optimistic, most likely, andpessimistic size value for each function or count for each information domainvalue. An implicit indication of the degree of uncertainty is provided when a rangeof values is specified.A three-point or expected value can then be computed. The expected value for the estimation variable (size) Scan be computed as a weighted average of the optimistic(s
opt), most likely (sm), and pessimistic (spess) estimates. For example,S/H11005 (26.1) gives heaviest credence to the “most likely” estimate and follows a beta probabilitydistribution. We assume that there is a very small probability the actual size resultwill fall outside the optimistic or pessimistic values.Once the expected value for the estimation variable has been determined, histor-ical LOC or FP productivity data are applied. Are the estimates correct? The onlyreasonable answer to this question is: “You can’t be sure.” Any estimation technique,no matter how sophisticated, must be cross-checked with another approach. Eventhen, common sense and experience must prevail. sopt/H110014sm/H11001spess
6700 PART FOURMANAGING SOFTWARE PROJECTS
6 The acronym pmmeans person-month of effort.When collectingproductivity metrics forprojects, be sure toestablish a taxonomyof project types. Thiswill enable you tocompute domain-specific averages,making estimationmore accurate.
How do wecompute the“expected value“for softwaresize??pre75977_ch26.qxd  11/27/08  6:26 PM  Page 70026.6.3 An Example of LOC-Based Estimation
As an example of LOC and FP problem-based estimation techniques, I consider asoftware package to be developed for a computer-aided design application formechanical components. The software is to execute on an engineering workstationand must interface with various computer graphics peripherals including a mouse,digitizer, high-resolution color display, and laser printer. A preliminary statement ofsoftware scope can be developed:
The mechanical CAD software will accept two- and three-dimensional geometric datafrom an engineer. The engineer will interact and control the CAD system through a userinterface that will exhibit characteristics of good human/machine interface design. Allgeometric data and other supporting information will be maintained in a CAD database.Design analysis modules will be developed to produce the required output, which willbe displayed on a variety of graphics devices. The software will be designed to controland interact with peripheral devices that include a mouse, digitizer, laser printer, andplotter.
This statement of scope is preliminary—it is not bounded. Every sentence wouldhave to be expanded to provide concrete detail and quantitative bounding. Forexample, before estimation can begin, the planner must determine what “character-istics of good human/machine interface design” means or what the size andsophistication of the “CAD database” are to be.For our purposes, assume that further refinement has occurred and that the majorsoftware functions listed in Figure 26.2 are identified. Following the decompositiontechnique for LOC, an estimation table (Figure 26.2) is developed. A range of LOCestimates is developed for each function. For example, the range of LOC estimatesfor the 3D geometric analysis function is optimistic, 4600 LOC; most likely, 6900 LOC;and pessimistic, 8600 LOC. Applying Equation 26.1, the expected value for the 3Dgeometric analysis function is 6800 LOC. Other estimates are derived in a similarCHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 701
Many modern applica-tions reside on anetwork or are part ofa client-server architec-ture. Therefore, besure that yourestimates include theeffort required todevelop “infrastruc-ture” software.
FunctionUser interface and control facilities (UICF)Two-dimensional geometric analysis (2DGA)Three-dimensional geometric analysis (3DGA)Database management (DBM)Computer graphics display facilities (CGDF)Peripheral control function (PCF)Design analysis modules (DAM)Estimated lines of codeEstimated LOC2,3005,3006,8003,3504,9502,1008,40033,200FIGURE 26.2
Estimationtable for theLOC methodspre75977_ch26.qxd  11/27/08  6:26 PM  Page 701fashion. By summing vertically in the estimated LOC column, an estimate of 33,200lines of code is established for the CAD system.A review of historical data indicates that the organizational average productivityfor systems of this type is 620 LOC/pm. Based on a burdened labor rate of $8000 permonth, the cost per line of code is approximately $13. Based on the LOC estimateand the historical productivity data, the total estimated project cost is $431,000 andthe estimated effort is 54 person-months.
7702 PART FOURMANAGING SOFTWARE PROJECTS
7 Estimates are rounded to the nearest $1000 and person-month. Further precision is unnecessaryand unrealistic, given the limitations of estimation accuracy.Estimating
The scene:Doug Miller’s office asproject planning begins.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman, JamieLazar, and other members of the product softwareengineering team.The conversation:Doug:We need to develop an effort estimate for theproject and then we’ve got to define a micro schedule forthe first increment and a macro schedule for theremaining increments.Vinod (nodding):Okay, but we haven’t defined anyincrements yet.Doug:True, but that’s why we need to estimate.Jamie (frowning):You want to know how long it’sgoing to take us?Doug:Here’s what I need. First, we need to functionallydecompose the SafeHomesoftware … at a high level …then we’ve got to estimate the number of lines of codethat each function will take . . . then . . .Jamie:Whoa! How are we supposed to do that?Vinod:I’ve done it on past projects. You begin with usecases, determine the functionality required to implementeach, guesstimate the LOC count for each piece of thefunction. The best approach is to have everyone do itindependently and then compare results.Doug:Or you can do a functional decomposition for theentire project.Jamie:But that’ll take forever and we’ve got to getstarted.Vinod:No . . . it can be done in a few hours . . . thismorning, in fact.Doug:I agree . . . we can’t expect exactitude, just aballpark idea of what the size of SafeHome will be.Jamie:I think we should just estimate effort . . . that’sall.Doug:We’ll do that too. Then use both estimates as across-check.Vinod:Let’s go do it . . .SAFEHOME
26.6.4 An Example of FP-Based Estimation
Decomposition for FP-based estimation focuses on information domain valuesrather than software functions. Referring to the table presented in Figure 26.3, youwould estimate inputs, outputs, inquiries, files, and external interfaces for the CADsoftware. An FP value is computed using the technique discussed in Chapter 23. Forthe purposes of this estimate, the complexity weighting factor is assumed to beaverage. Figure 26.3 presents the results of this estimate.Do not succumb to thetemptation to use thisresult as your projectestimate. You shouldderive another resultusing a differentapproach.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 702Each of the complexity weighting factors is estimated, and the value adjustmentfactor is computed as described in Chapter 23:
Factor Value Backup and recovery 4 Data communications 2 Distributed processing 0 Performance critical 4 Existing operating environment 3 Online data entry 4 Input transaction over multiple screens 5 Master files updated online 3 Information domain values complex 5 Internal processing complex 5 Code designed for reuse 4 Conversion/installation in design 3 Multiple installations 5 Application designed for change 5
Value adjustment factor 1.17
Finally, the estimated number of FP is derived:FP
estimated /H11005count total /H11003[0.65 /H110010.01 /H11003/H20858(Fi)] /H11005375 The organizational average productivity for systems of this type is 6.5 FP/pm. Basedon a burdened labor rate of $8000 per month, the cost per FP is approximately $1230.Based on the FP estimate and the historical productivity data, the total estimatedproject cost is $461,000 and the estimated effort is 58 person-months.
26.6.5 Process-Based Estimation
The most common technique for estimating a project is to base the estimate on theprocess that will be used. That is, the process is decomposed into a relatively smallset of tasks and the effort required to accomplish each task is estimated.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 703
Information domain value
Number of external inputsNumber of external outputsNumber of external inquiriesNumber of internal logical filesNumber of external interface filesCount totalFP count
9778884215320Opt.
20121642Likely
24152242Pess.
30222853Est.count
24162242Weight
455107FIGURE 26.3
Estimatinginformationdomain valuespre75977_ch26.qxd  11/27/08  6:26 PM  Page 703Like the problem-based techniques, process-based estimation begins with adelineation of software functions obtained from the project scope. A series of frame-work activities must be performed for each function. Functions and related frame-work activities
8may be represented as part of a table similar to the one presented inFigure 26.4.Once problem functions and process activities are melded, you estimate the effort(e.g., person-months) that will be required to accomplish each software processactivity for each software function. These data constitute the central matrix of thetable in Figure 26.4. Average labor rates (i.e., cost/unit effort) are then applied to theeffort estimated for each process activity. It is very likely the labor rate will vary foreach task. Senior staff are heavily involved in early framework activities and are gen-erally more expensive than junior staff involved in construction and release.Costs and effort for each function and framework activity are computed as the laststep. If process-based estimation is performed independently of LOC or FP estima-tion, we now have two or three estimates for cost and effort that may be comparedand reconciled. If both sets of estimates show reasonable agreement, there is goodreason to believe that the estimates are reliable. If, on the other hand, the resultsof these decomposition techniques show little agreement, further investigation andanalysis must be conducted.
26.6.6 An Example of Process-Based Estimation
To illustrate the use of process-based estimation, consider the CAD software intro-duced in Section 26.6.3. The system configuration and all software functions remainunchanged and are indicated by project scope.704 PART FOURMANAGING SOFTWARE PROJECTS
8 The framework activities chosen for this project differ somewhat from the generic activities dis-cussed in Chapter 2. They are: customer communication (CC), planning, risk analysis, engineering,and construction/release.ActivityTaskFunctionUICF2DGA3DGADBMPCFCGDFDAMTotals% effortCC PlanningRiskanalysisEngineeringConstructionreleaseTotalsCE
Analysis Design Code Test
0.25 0.25 0.25 3.50 20.50 4.50 16.50 46.001% 1% 1% 8% 45% 10% 36%CC = customer communication   CE = customer evaluation0.500.750.500.500.500.252.504.004.003.003.002.000.400.601.001.000.750.505.002.003.001.501.501.508.407.358.506.005.754.25 0.50 2.00 0.50 2.00 5.00n/an/an/an/an/an/an/aFIGURE 26.4
Process-basedestimationtable
If time permits, usefiner granularity whenspecifying tasks inFigure 26.4. Forexample, breakanalysis into its majortasks and estimateeach separately.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 704Referring to the completed process-based table shown in Figure 26.4, estimatesof effort (in person-months) for each software engineering activity are provided foreach CAD software function (abbreviated for brevity). The engineering and con-struction release activities are subdivided into the major software engineering tasksshown. Gross estimates of effort are provided for customer communication, plan-ning, and risk analysis. These are noted in the total row at the bottom of the table.Horizontal and vertical totals provide an indication of estimated effort required foranalysis, design, code, and test. It should be noted that 53 percent of all effort is ex-pended on front-end engineering tasks (requirements analysis and design), indicat-ing the relative importance of this work.Based on an average burdened labor rate of $8000 per month, the total estimatedproject cost is $368,000 and the estimated effort is 46 person-months. If desired,labor rates could be associated with each framework activity or software engineer-ing task and computed separately.
26.6.7 Estimation with Use Cases
As I have noted throughout Part 2 of this book, use cases provide a software teamwith insight into software scope and requirements. However, developing an estima-tion approach with use cases is problematic for the following reasons [Smi99]:
•Use cases are described using many different formats and styles—there is nostandard form.
•Use cases represent an external view (the user’s view) of the software andcan therefore be written at many different levels of abstraction.
•Use cases do not address the complexity of the functions and features thatare described.
•Use cases can describe complex behavior (e.g., interactions) that involvemany functions and features.Unlike an LOC or a function point, one person’s “use case” may require months ofeffort while another person’s use case may be implemented in a day or two.Although a number of investigators have considered use cases as an estimationinput, no proven estimation method has emerged to date.
9Smith [Smi99] suggests that use cases can be used for estimation, but only if they are considered within thecontext of the “structural hierarchy” that they are used to describe.Smith argues that any level of this structural hierarchy can be described by nomore than 10 use cases. Each of these use cases would encompass no more than 30distinct scenarios. Obviously, use cases that describe a large system are written at amuch higher level of abstraction (and represent considerably more developmenteffort) than use cases that are written to describe a single subsystem. Therefore,CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 705
uote:
“It’s best tounderstand thebackground of anestimate beforeyou use it.”Barry Boehmand RichardFairley
Why is itdifficult todevelop anestimationtechnique usinguse cases??
9 Recent work in the derivation of use-case points [Cle06] may ultimately lead to a workable estimation approach using use cases.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 705before use cases can be used for estimation, the level within the structural hierarchyis established, the average length (in pages) of each use case is determined, the typeof software (e.g., real-time, business, engineering/scientific, WebApp, embedded) isdefined, and a rough architecture for the system is considered. Once these charac-teristics are established, empirical data may be used to establish the estimated num-ber of LOC or FP per use case (for each level of the hierarchy). Historical data are thenused to compute the effort required to develop the system.To illustrate how this computation might be made, consider the followingrelationship:
10
LOC estimate /H11005N/H11003LOCavg/H11001[(Sa/Sh– 1) /H11001(Pa/Ph/H110021)] /H11003LOCadjust (26.2) whereN/H11005actual number of use casesLOC
avg /H11005historical average LOC per use case for this type of subsystemLOC
adjust /H11005represents an adjustment based on npercent of LOCavgwhere n is defined locally and represents the difference between thisproject and “average” projectsS
a /H11005actual scenarios per use caseS
h /H11005average scenarios per use case for this type of subsystemP
a /H11005actual pages per use caseP
h /H11005average pages per use case for this type of subsystemExpression (26.2) could be used to develop a rough estimate of the number of LOCbased on the actual number of use cases adjusted by the number of scenarios andthe page length of the use cases. The adjustment represents up to npercent of the historical average LOC per use case.
26.6.8 An Example of Use-Case–Based Estimation
The CAD software introduced in Section 26.6.3 is composed of three subsystemgroups: user interface subsystem (includes UICF), engineering subsystem group(includes the 2DGA, 3DGA, and DAM subsystems), and infrastructure subsystemgroup (includes CGDF and PCF subsystems). Six use cases describe the user interfacesubsystem. Each use case is described by no more than 10 scenarios and has anaverage length of six pages. The engineering subsystem group is described by 10 usecases (these are considered to be at a higher level of the structural hierarchy). Eachof these use cases has no more than 20 scenarios associated with it and has anaverage length of eight pages. Finally, the infrastructure subsystem group is describedby five use cases with an average of only six scenarios and an average length offive pages.706 PART FOURMANAGING SOFTWARE PROJECTS
10 It is important to note that Expression (26.2) is used for illustrative purposes only. Like all estima-tion models, it must be validated locally before it can be used with confidence.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 706Using the relationship noted in Expression (26.2) with n/H1100530 percent, the table shown in Figure 26.5 is developed. Considering the first row of the table, historicaldata indicate that UI software requires an average of 800 LOC per use case when theuse case has no more than 12 scenarios and is described in less than five pages.These data conform reasonably well for the CAD system. Hence the LOC estimate forthe user interface subsystem is computed using expression (26.2). Using the sameapproach, estimates are made for both the engineering and infrastructure subsystemgroups. Figure 26.5 summarizes the estimates and indicates that the overall size ofthe CAD is estimated at 42,500 LOC.Using 620 LOC/pm as the average productivity for systems of this type anda burdened labor rate of $8000 per month, the cost per line of code is approxi-mately $13. Based on the use-case estimate and the historical productivity data, thetotal estimated project cost is $552,000 and the estimated effort is 68 person-months.
26.6.9 Reconciling Estimates
The estimation techniques discussed in the preceding sections result in multipleestimates that must be reconciled to produce a single estimate of effort, projectduration, or cost. To illustrate this reconciliation procedure, I again consider the CADsoftware introduced in Section 26.6.3.The total estimated effort for the CAD software ranges from a low of 46 person-months (derived using a process-based estimation approach) to a high of 68 person-months (derived with use-case estimation). The average estimate (using all fourapproaches) is 56 person-months. The variation from the average estimate is approxi-mately 18 percent on the low side and 21 percent on the high side.What happens when agreement between estimates is poor? The answer to thisquestion requires a reevaluation of information used to make the estimates. Widelydivergent estimates can often be traced to one of two causes: (1) the scope of theproject is not adequately understood or has been misinterpreted by the planner, or(2) productivity data used for problem-based estimation techniques is inappropriatefor the application, obsolete (in that it no longer accurately reflects the softwareengineering organization), or has been misapplied. You should determine the causeof divergence and then reconcile the estimates.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 707
User interface subsystemEngineering subsystem groupInfrastructure subsystem groupTotal LOC estimateuse cases6105scenarios10206scenarios121610pages685pages586LOC56031001650LOC estimate3,36631,2337,97042,568FIGURE 26.5
Use-caseestimation
uote:
“Complicatedmethods might notyield a moreaccurate estimate,particularly whendevelopers canincorporate theirown intuition intothe estimate.”Philip Johnsonet al.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 70726.7 E MPIRICAL ESTIMATION MODELS
An estimation model for computer software uses empirically derived formulas topredict effort as a function of LOC or FP.
11Values for LOC or FP are estimated using the approach described in Sections 26.6.3 and 26.6.4. But instead of using the tablesdescribed in those sections, the resultant values for LOC or FP are plugged into theestimation model.The empirical data that support most estimation models are derived from a lim-ited sample of projects. For this reason, no estimation model is appropriate for allclasses of software and in all development environments. Therefore, you should usethe results obtained from such models judiciously.An estimation model should be calibrated to reflect local conditions. The modelshould be tested by applying data collected from completed projects, plugging thedata into the model, and then comparing actual to predicted results. If agreement ispoor, the model must be tuned and retested before it can be used.708 PART FOURMANAGING SOFTWARE PROJECTS
Automated Estimation Techniques for Software ProjectsINFO
Automated estimation tools allow the plannerto estimate cost and effort and to performwhat-if analyses for important project variablessuch as delivery date or staffing. Although manyautomated estimation tools exist (see sidebar later in thischapter), all exhibit the same general characteristics andall perform the following six generic functions [Jon96]:1.Sizing of project deliverables.The “size” of one ormore software work products is estimated. Workproducts include the external representation ofsoftware (e.g., screen, reports), the software itself(e.g., KLOC), functionality delivered (e.g., functionpoints), and descriptive information (e.g., documents).2.Selecting project activities.The appropriate processframework is selected, and the software engineeringtask set is specified.3.Predicting staffing levels.The number of people whowill be available to do the work is specified. Becausethe relationship between people available and work(predicted effort) is highly nonlinear, this is animportant input.4.Predicting software effort.Estimation tools use oneor more models (Section 26.7) that relate the size ofthe project deliverables to the effort required toproduce them.5.Predicting software cost.Given the results of step 4,costs can be computed by allocating labor rates tothe project activities noted in step 2.6.Predicting software schedules.When effort, staffinglevel, and project activities are known, a draftschedule can be produced by allocating labor acrosssoftware engineering activities based onrecommended models for effort distributiondiscussed later in this chapter.When different estimation tools are applied to the sameproject data, a relatively large variation in estimatedresults can be encountered. More important, predictedvalues sometimes are significantly different than actualvalues. This reinforces the notion that the output ofestimation tools should be used as one “data point” fromwhich estimates are derived—not as the only source foran estimate.
11 An empirical model using use cases as the independent variable is suggested in Section 26.6.6.However, relatively few have appeared in the literature to date.An estimation modelreflects the populationof projects from whichit has been derived.Therefore, the model isdomain sensitive.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 70826.7.1 The Structure of Estimation Models
A typical estimation model is derived using regression analysis on data collected frompast software projects. The overall structure of such models takes the form [Mat94]E /H11005A /H11001B/H11003(e
v)C(26.3) where A, B,and Care empirically derived constants, Eis effort in person-months, and e
vis the estimation variable (either LOC or FP). In addition to the relationship notedin Equation (26.3), the majority of estimation models have some form of project ad-justment component that enables Eto be adjusted by other project characteristics(e.g., problem complexity, staff experience, development environment). Among themany LOC-oriented estimation models proposed in the literature areE/H110055.2 /H11003(KLOC)
0.91Walston-Felix modelE/H110055.5 /H110010.73 /H11003(KLOC)
1.16Bailey-Basili modelE/H110053.2 /H11003(KLOC)
1.05Boehm simple modelE/H110055.288 /H11003(KLOC)
1.047Doty model for KLOC /H110229 FP-oriented models have also been proposed. These includeE/H11005/H1100291.4 /H110010.355 FPAlbrecht and Gaffney modelE/H11005/H1100237 /H110010.96 FPKemerer modelE/H11005/H1100212.88 /H110010.405 FPSmall project regression model A quick examination of these models indicates that each will yield a different resultfor the same values of LOC or FP. The implication is clear. Estimation models mustbe calibrated for local needs!
26.7.2 The COCOMO II Model
In his classic book on “software engineering economics,” Barry Boehm [Boe81]introduced a hierarchy of software estimation models bearing the name COCOMO, forCOnstructive COst MOdel.The original COCOMO model became one of the most widelyused and discussed software cost estimation models in the industry. It has evolved intoa more comprehensive estimation model, called COCOMO II [Boe00]. Like its predeces-sor, COCOMO II is actually a hierarchy of estimation models that address the followingareas:
•Application composition model.Used during the early stages of software engi-neering, when prototyping of user interfaces, consideration of software andsystem interaction, assessment of performance, and evaluation of technologymaturity are paramount.
•Early design stage model.Used once requirements have been stabilized andbasic software architecture has been established.
•Post-architecture-stage model.Used during the construction of the software.Like all estimation models for software, the COCOMO II models require sizinginformation. Three different sizing options are available as part of the modelhierarchy: object points, function points, and lines of source code.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 709
None of these modelsshould be used withoutcareful calibration toyour environment.
WebRef
Detailed information onCOCOMO II, includingdownloadable software,can be obtained at sunset.usc.edu/research/COCOMOII/cocomo_main.html.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 709The COCOMO II application composition model uses object points and is illus-trated in the following paragraphs. It should be noted that other, more sophisticatedestimation models (using FP and KLOC) are also available as part of COCOMO II.Like function points, the object pointis an indirect software measure that is com- puted using counts of the number of (1) screens (at the user interface), (2) reports,and (3) components likely to be required to build the application. Each object in-stance (e.g., a screen or report) is classified into one of three complexity levels (i.e.,simple, medium, or difficult) using criteria suggested by Boehm [Boe96]. In essence,complexity is a function of the number and source of the client and server data tablesthat are required to generate the screen or report and the number of views or sec-tions presented as part of the screen or report.Once complexity is determined, the number of screens, reports, and componentsare weighted according to the table illustrated in Figure 26.6. The object point countis then determined by multiplying the original number of object instances by theweighting factor in the figure and summing to obtain a total object point count.When component-based development or general software reuse is to be applied,the percent of reuse (%reuse) is estimated and the object point count is adjusted:NOP /H11005(object points) /H11003[(100 /H11002%reuse)/100]where NOP is defined as new object points.To derive an estimate of effort based on the computed NOP value, a “productivityrate” must be derived. Figure 26.7 presents the productivity ratePROD /H11005for different levels of developer experience and development environment maturity.Once the productivity rate has been determined, an estimate of project effort iscomputed usingEstimated effort/H11005In more advanced COCOMO II models,
12a variety of scale factors, cost drivers, and adjustment procedures are required. A complete discussion of these is beyondNOPPRODNOPperson-month710 PART FOURMANAGING SOFTWARE PROJECTS
Object type
ScreenReport3GL componentComplexity weightSimpleMediumDifficult12325810FIGURE 26.6
Complexityweighting forobject types.Source:[Boe96].
What is anobject point??
12 As noted earlier, these models use FP and KLOC counts for the size variable.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 710the scope of this book. If you have further interest, see [Boe00] or visit the COCOMO IIwebsite.
26.7.3 The Software Equation
The software equation[Put92] is a dynamic multivariable model that assumes a spe-cific distribution of effort over the life of a software development project. The modelhas been derived from productivity data collected for over 4000 contemporary soft-ware projects. Based on these data, we derive an estimation model of the formE/H11005/H11003 (26.4)whereE/H11005effort in person-months or person-yearst/H11005project duration in months or yearsB/H11005“special skills factor”
13
P/H11005“productivity parameter” that reflects: overall process maturity and man-agement practices, the extent to which good software engineering practicesare used, the level of programming languages used, the state of the soft-ware environment, the skills and experience of the software team, and thecomplexity of the applicationTypical values might be P/H110052000 for development of real-time embedded software,P/H1100510,000 for telecommunication and systems software, and P/H1100528,000 for business systems applications. The productivity parameter can be derived for local conditionsusing historical data collected from past development efforts.You should note that the software equation has two independent parameters:(1) an estimate of size (in LOC) and (2) an indication of project duration in calendarmonths or years.1t
4LOC /H11003B0.333
P3CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 711
Developer's experience/capabilityEnvironment maturity/capabilityPRODVerylowVerylow4LowLow7NominalNominal13HighHigh25VeryhighVeryhigh50FIGURE 26.7 Productivity rate for object points.Source: [Boe96].
13Bincreases slowly as “the need for integration, testing, quality assurance, documentation, andmanagement skills grows” [Put92]. For small programs (KLOC /H11005 5 to 15), B/H110050.16. For programs greater than 70 KLOC, B/H110050.39.WebRef
Information onsoftware costestimation tools thathave evolved fromthe software equationcan be found at www.qsm.com.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 711To simplify the estimation process and use a more common form for theirestimation model, Putnam and Myers [Put92] suggest a set of equations derived fromthe software equation. Minimum development time is defined ast
min/H110058.14 in months for tmin/H110226 months (26.5a)E/H11005180 Bt
3in person-months for E/H1135020 person-months(26.5b) Note that tin Equation (26.5b) is represented in years.Using Equation (26.5) with P/H1100512,000 (the recommended value for scientificsoftware) for the CAD software discussed earlier in this chapter,t
min/H110058.14 /H11003/H1100512.6 calendar monthsE/H11005180 /H110030.28 /H11003(1.05)
3/H1100558 person-monthsThe results of the software equation correspond favorably with the estimates devel-oped in Section 26.6. Like the COCOMO model noted in Section 26.7.2, the softwareequation continues to evolve. Further discussion of an extended version of thisestimation approach can be found in [Put97b].
26.8 E STIMATION FOR OBJECT -ORIENTED PROJECTS
It is worthwhile to supplement conventional software cost estimation methods with atechnique that has been designed explicitly for OO software. Lorenz and Kidd [Lor94]suggest the following approach:1.Develop estimates using effort decomposition, FP analysis, and any othermethod that is applicable for conventional applications.2.Using the requirements model (Chapter 6), develop use cases and determinea count. Recognize that the number of use cases may change as the projectprogresses.3.From the requirements model, determine the number of key classes (calledanalysis classes in Chapter 6).4.Categorize the type of interface for the application and develop a multiplierfor support classes:
Interface Type MultiplierNo GUI2.0Text-based user interface 2.25GUI2.5
Complex GUI3.0
Multiply the number of key classes (step 3) by the multiplier to obtain anestimate for the number of support classes.33,20012,000
0.43LOCp
0.43712 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch26.qxd  11/27/08  6:26 PM  Page 7125.Multiply the total number of classes (key + support) by the average number ofwork units per class. Lorenz and Kidd suggest 15 to 20 person-days per class.6.Cross-check the class-based estimate by multiplying the average number ofwork units per use case.
26.9 S PECIALIZED ESTIMATION TECHNIQUES
The estimation techniques discussed in Sections 26.6 through 26.8 can be used forany software project. However, when a software team encounters an extremely shortproject duration (weeks rather than months) that is likely to have a continuing streamof changes, project planning in general and estimation in particular should be abbre-viated.
14In the sections that follow, I examine two specialized estimation techniques.
26.9.1 Estimation for Agile Development
Because the requirements for an agile project (Chapter 3) are defined by a set of userscenarios (e.g., “stories” in Extreme Programming), it is possible to develop an esti-mation approach that is informal, reasonably disciplined, and meaningful within thecontext of project planning for each software increment. Estimation for agile proj-ects uses a decomposition approach that encompasses the following steps:1.Each user scenario (the equivalent of a mini use case created at the verystart of a project by end users or other stakeholders) is considered separatelyfor estimation purposes.2.The scenario is decomposed into the set of software engineering tasks thatwill be required to develop it.3a.The effort required for each task is estimated separately. Note: Estimation canbe based on historical data, an empirical model, or “experience.”3b.Alternatively, the “volume” of the scenario can be estimated in LOC, FP, orsome other volume-oriented measure (e.g., use-case count).4a.Estimates for each task are summed to create an estimate for the scenario.4b.Alternatively, the volume estimate for the scenario is translated into effortusing historical data.5.The effort estimates for all scenarios that are to be implemented for a givensoftware increment are summed to develop the effort estimate for theincrement.Because the project duration required for the development of a software incrementis quite short (typically three to six weeks), this estimation approach serves twopurposes:(1) to be certain that the number of scenarios to be included in the incre-ment conforms to the available resources, and (2) to establish a basis for allocatingeffort as the increment is developed.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 713
How areestimatesdeveloped whenan agile process isapplied??
14 “Abbreviated” does notmean eliminated. Even short-duration projects must be planned, and esti-mation is the foundation of solid planning.In the context ofestimation for agileprojects, “volume” isan estimate of theoverall size of a userscenario in LOC or FP .pre75977_ch26.qxd  11/27/08  6:26 PM  Page 71326.9.2 Estimation for WebApp Projects
WebApp projects often adopt the agile process model. A modified function pointmeasure, coupled with the steps outlined in Section 26.9.1, can be used to developan estimate for the WebApp. Roetzheim [Roe00] suggests the following approachwhen adapting function points for WebApp estimation:
•Inputsare each input screen or form (for example, CGI or Java), each maintenancescreen, and if you use a tab notebook metaphor anywhere, each tab.•Outputsare each static Web page, each dynamic Web page script (for example, ASP,ISAPI, or other DHTML script), and each report (whether Web based or administrativein nature).•Tablesare each logical table in the database plus, if you are using XML to store data ina file, each XML object (or collection of XML attributes).•Interfacesretain their definition as logical files (for example, unique record formats) intoour out-of-the-system boundaries.•Queriesare each externally published or use a message-oriented interface. A typicalexample is DCOM or COM external references.
Function points (interpreted in the manner noted) are a reasonable indicator ofvolume for a WebApp.Mendes and her colleagues [Men01] suggest that the volume of a WebApp is bestdetermined by collecting measures (called “predictor variables”) associated with theapplication (e.g., page count, media count, function count), its Web page characteris-tics (e.g., page complexity, linking complexity, graphic complexity), media characteris-tics (e.g., media duration), and functional characteristics (e.g., code length, reused codelength). These measures can be used to develop empirical estimation models for totalproject effort, page authoring effort, media authoring effort, and scripting effort. How-ever, further work remains to be done before such models can be used with confidence.714 PART FOURMANAGING SOFTWARE PROJECTS
Effort and Cost Estimation
Objective:The objective of effort and costestimation tools is to provide a project teamwith estimates of effort required, project duration, and costin a manner that addresses the specific characteristics ofthe project at hand and the environment in which theproject is to be built.Mechanics:In general, cost estimation tools make use ofan historical database derived from local projects anddata collected across the industry, and an empirical model(e.g., COCOMO II) that is used to derive effort, duration,and cost estimates. Characteristics of the project and thedevelopment environment are input and the tool providesa range of estimation outputs.Representative Tools:
15
Costar,developed by Softstar Systems(www.softstarsystems.com), uses the COCOMOII model to develop software estimates.SOFTWARE TOOLS
15 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 71426.10 T HEMAKE/BUYDECISION
In many software application areas, it is often more cost effective to acquire rather thandevelop computer software. Software engineering managers are faced with a make/buy decision that can be further complicated by a number of acquisition options:(1) software may be purchased (or licensed) off-the-shelf, (2) “full-experience” or“partial-experience” software components (see Section 26.4.2) may be acquired andthen modified and integrated to meet specific needs, or (3) software may be custombuilt by an outside contractor to meet the purchaser’s specifications.The steps involved in the acquisition of software are defined by the criticality of thesoftware to be purchased and the end cost. In some cases (e.g., low-cost PC software),it is less expensive to purchase and experiment than to conduct a lengthy evaluationof potential software packages. In the final analysis, the make/buy decision is madebased on the following conditions: (1) Will the delivery date of the software product besooner than that for internally developed software? (2) Will the cost of acquisition plusthe cost of customization be less than the cost of developing the software internally?(3) Will the cost of outside support (e.g., a maintenance contract) be less than the costof internal support? These conditions apply for each of the acquisition options.
26.10.1 Creating a Decision Tree
The steps just described can be augmented using statistical techniques such as de-cision tree analysis.
16For example, Figure 26.8 depicts a decision tree for a software-based system X.In this case, the software engineering organization can (1) buildsystem X from scratch, (2) reuse existing partial-experience components to constructthe system, (3) buy an available software product and modify it to meet local needs,or (4) contract the software development to an outside vendor.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 715
Cost Xpert,developed by Cost Xpert Group, Inc.(www.costxpert.com), integrates multipleestimation models and an historical project database.Estimate Professional,developed by the SoftwareProductivity Centre, Inc. (www.spc.com), is basedon COCOMO II and the SLIM Model.Knowledge Plan,developed by Software ProductivityResearch (www.spr.com), uses function point input asthe primary driver for a complete estimation package.Price S,developed by Price Systems(www.pricesystems.com), is one of the oldestand most widely used estimating tools for large-scalesoftware development projects.SEER/SEM,developed by Galorath, Inc.(www.galorath.com), provides comprehensiveestimation capability, sensitivity analysis, riskassessment, and other features.SLIM-Estimate,developed by QSM (www.qsm.com),draws on comprehensive “industry knowledge bases”to provide a “sanity check” for estimates derived usinglocal data.
Is there asystematicway to sortthrough theoptions associatedwith the make/buy decision??
16 A worthwhile introduction to decision tree analysis can be found at http://en.wikipedia.org/wiki/Decision_tree.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 715If the system is to be built from scratch, there is a 70 percent probability that thejob will be difficult. Using the estimation techniques discussed earlier in this chapter,the project planner estimates that a difficult development effort will cost $450,000.A “simple” development effort is estimated to cost $380,000. The expected value forcost, computed along any branch of the decision tree, isExpected cost /H11005/H20858(path probability)
i/H11003(estimated path cost)i
where iis the decision tree path. For the build path,Expected cost
build /H110050.30 ($380K) /H110010.70 ($450K) /H11005$429K Following other paths of the decision tree, the projected costs for reuse, purchase,and contract, under a variety of circumstances, are also shown. The expected costsfor these paths areExpected cost
reuse /H110050.40 ($275K) /H110010.60 [0.20 ($310K) /H110010.80 ($490K)] /H11005$382K Expected cost
buy/H110050.70 ($210K) /H110010.30 ($400K) /H11005$267K Expected cost
contract /H110050.60 ($350K) /H110010.40 ($500K) /H11005$410K Based on the probability and projected costs that have been noted in Figure 26.8, thelowest expected cost is the “buy” option.It is important to note, however, that many criteria—not just cost— must be consid-ered during the decision-making process. Availability, experience of the developer/vendor/contractor, conformance to requirements, local “politics,” and the likelihoodof change are but a few of the criteria that may affect the ultimate decision to build,reuse, buy, or contract.716 PART FOURMANAGING SOFTWARE PROJECTS
$380,000$450,000Simple (0.30)
$275,000$310,000$490,000
$210,000$400,000Minor changes(0.70)Major changes (0.30)
$350,000$500,000Without changes(0.60)With changes (0.40)Complex (0.80)Simple (0.20)Majorchanges(0.60)Minor changes(0.40)Difficult (0.70)BuildReuseBuy
ContractSystem XFIGURE 26.8
A decision treeto support themake/buydecisionpre75977_ch26.qxd  11/27/08  6:26 PM  Page 71626.10.2 Outsourcing
Sooner or later, every company that develops computer software asks a fundamentalquestion: “Is there a way that we can get the software and systems we need at a lowerprice?” The answer to this question is not a simple one, and the emotional discussionsthat occur in response to the question always lead to a single word: outsourcing.In concept, outsourcing is extremely simple. Software engineering activities arecontracted to a third party who does the work at lower cost and, hopefully, higherquality. Software work conducted within a company is reduced to a contract man-agement activity.
17
The decision to outsource can be either strategic or tactical. At the strategic level,business managers consider whether a significant portion of all software work can becontracted to others. At the tactical level, a project manager determines whether partor all of a project can be best accomplished by subcontracting the software work.Regardless of the breadth of focus, the outsourcing decision is often a financialone. A detailed discussion of the financial analysis for outsourcing is beyond thescope of this book and is best left to others (e.g., [Min95]). However, a brief reviewof the pros and cons of the decision is worthwhile.On the positive side, cost savings can usually be achieved by reducing the num-ber of software people and the facilities (e.g., computers, infrastructure) that supportthem. On the negative side, a company loses some control over the software that itneeds. Since software is a technology that differentiates its systems, services, andproducts, a company runs the risk of putting the fate of its competitiveness into thehands of a third party.The trend toward outsourcing will undoubtedly continue. The only way to blunt thetrend is to recognize that software work is extremely competitive at all levels. The onlyway to survive is to become as competitive as the outsourcing vendors themselves.CHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 717
uote:
“As a ruleoutsourcing requireseven more skillfulmanagementthan in-housedevelopment.”Steve McConnell
17 Outsourcing can be viewed more generally as any activity that leads to the acquisition of softwareor software components from a source outside the software engineering organization.Outsourcing
The scene:Meeting room at CPICorporation early in the project.The players:Mal Golden, senior manager, productdevelopment; Lee Warren, engineering manager; JoeCamalleri, executive VP, business development; and DougMiller, project manager, software engineering.The conversation:Joe:We’re considering outsourcing the SafeHomesoftware engineering portion of the product.Doug (shocked):When did this happen?Lee:We got a quote from an offshore developer. Itcomes in at 30 percent below what your group seems tobelieve it will cost. Here. [Hands the quote to Doug whoreads it.]Mal:As you know, Doug, we’re trying to keep costsdown and 30 percent is 30 percent. Besides, these peoplecome highly recommended.SAFEHOMEpre75977_ch26.qxd  11/27/08  6:26 PM  Page 71726.11 S UMMARY
A software project planner must estimate three things before a project begins: howlong it will take, how much effort will be required, and how many people will be in-volved. In addition, the planner must predict the resources (hardware and software)that will be required and the risk involved.The statement of scope helps the planner to develop estimates using one or moretechniques that fall into two broad categories: decomposition and empirical model-ing. Decomposition techniques require a delineation of major software functions,followed by estimates of either (1) the number of LOC, (2) selected values within theinformation domain, (3) the number of use cases, (4) the number of person-monthsrequired to implement each function, or (5) the number of person-months requiredfor each software engineering activity. Empirical techniques use empirically derivedexpressions for effort and time to predict these project quantities. Automated toolscan be used to implement a specific empirical model.Accurate project estimates generally use at least two of the three techniques justnoted. By comparing and reconciling estimates developed using different tech-niques, the planner is more likely to derive an accurate estimate. Software projectestimation can never be an exact science, but a combination of good historical dataand systematic techniques can improve estimation accuracy.718 PART FOURMANAGING SOFTWARE PROJECTS
Doug (taking a breath and trying to remaincalm):You guys caught me by surprise here, but beforeyou make a final decision a few comments?Joe (nodding):Sure, go ahead.Doug:We haven’t worked with this outsourcingcompany before, right?Mal:Right, but . . .Doug:And they note that any changes to spec will bebilled at an additional rate, right?Joe (frowning):True, but we expect that things will bereasonably stable.Doug:A bad assumption, Joe.Joe:Well, . . .Doug:It’s likely that we’ll release new versions of thisproduct over the next few years. And it’s reasonable toassume that software will provide many of the newfeatures, right?[All nod.]Doug:Have we ever coordinated an internationalproject before?Lee (looking concerned):No, but I’m told . . .Doug (trying to suppress his anger): So what you’re telling me is: (1) we’re about to work with anunknown vendor, (2) the costs to do this are not as low asthey seem, (3) we’re de facto committing to work withthem over many product releases, no matter what they doon the first one, and (4) we’re going to learn on-the-jobrelative to an international project.[All remain silent.]Doug:Guys . . . I think this is a mistake, and I’d like youto take a day to reconsider. We’ll have far more control ifwe do the work in-house. We have the expertise, and Ican guarantee that it won’t cost us much more . . . the riskwill be lower, and I know you’re all risk averse, as I am.Joe (frowning):You’ve made a few good points, butyou have a vested interest in keeping this project in-house.Doug:That’s true, but it doesn’t change the facts.Joe (with a sigh):Okay, let’s table this for a day ortwo, give it some more thought, and meet again for afinal decision. Doug, can I speak with you privately?Doug:Sure . . . I really do want to be sure we do theright thing.pre75977_ch26.qxd  11/27/08  6:26 PM  Page 718PROBLEMS AND POINTS TO PONDER
26.1.Assume that you are the project manager for a company that builds software for house-hold robots. You have been contracted to build the software for a robot that mows the lawn fora homeowner. Write a statement of scope that describes the software. Be sure your statementof scope is bounded. If you’re unfamiliar with robots, do a bit of research before you begin writ-ing. Also, state your assumptions about the hardware that will be required. Alternate: Replacethe lawn mowing robot with another problem that is of interest to you.26.2.Software project complexity is discussed briefly in Section 26.1. Develop a list of softwarecharacteristics (e.g., concurrent operation, graphical output) that affect the complexity of aproject. Prioritize the list.26.3.Performance is an important consideration during planning. Discuss how performancecan be interpreted differently depending upon the software application area.26.4.Do a functional decomposition of the robot software you described in Problem 26.1.Estimate the size of each function in LOC. Assuming that your organization produces 450 LOC/pm with a burdened labor rate of $7000 per person-month, estimate the effort and cost requiredto build the software using the LOC-based estimation technique described in this chapter.26.5.Use the COCOMO II model to estimate the effort required to build software for a sim-ple ATM that produces 12 screens, 10 reports, and will require approximately 80 softwarecomponents. Assume average complexity and average developer/environment maturity. Usethe application composition model with object points.26.6.Use the software equation to estimate the lawn mowing robot software. Assume thatEquation (26.4) is applicable and that P= 8000.26.7.Compare the effort estimates derived in Problems 26.4 and 26.6. What is the standarddeviation, and how does it affect your degree of certainty about the estimate?26.8.Using the results obtained in Problem 26.7, determine whether it’s reasonable to expectthat the software can be built within the next six months and how many people would have tobe used to get the job done.26.9.Develop a spreadsheet model that implements one or more of the estimation techniquesdescribed in this chapter. Alternatively, acquire one or more online models for estimation fromWeb-based sources.26.10.For a project team: Develop a software tool that implements each of the estimationtechniques developed in this chapter.26.11.It seems odd that cost and schedule estimates are developed during software projectplanning—before detailed software requirements analysis or design has been conducted. Whydo you think this is done? Are there circumstances when it should not be done?26.12.Recompute the expected values noted for the decision tree in Figure 26.8 assuming thatevery branch has a 50–50 probability. Would this change your final decision?
FURTHER READINGS AND INFORMATION SOURCES
Most software project management books contain discussions of project estimation. The ProjectManagement Institute (PMBOK Guide, PMI, 2001), Wysoki and his colleagues ( Effective Project Management,Wiley, 2000), Lewis (Project Planning Scheduling and Control, 3d ed., McGraw-Hill, 2000), Bennatan (On Time, Within Budget: Software Project Management Practices and Techniques,3d ed., Wiley, 2000), and Phillips [Phi98] provide useful estimation guidelines.McConnell (Software Estimation: Demystifying the Black Art, Microsoft Press, 2006) has writ-ten a pragmatic guide that provides worthwhile guidance for anyone who must estimate the costof software. Parthasarathy (Practical Software Estimation, Addison-Wesley, 2007) emphasizesCHAPTER 26ESTIMATION FOR SOFTWARE PROJECTS 719pre75977_ch26.qxd  11/27/08  6:26 PM  Page 719function points as an estimation metric. Laird and Brennan (Software Measurement and Estima-tion: A Practical Approach,Wiley-IEEE Computer Society Press, 2006) addresses measurementand its use in software estimation. Pfleeger (Software Cost Estimation and Sizing Methods, Issues,and Guidelines,RAND Corporation, 2005) has developed an abbreviated guidebook that ad-dresses many estimation fundamentals. Jones (Estimating Software Costs, 2d ed., McGraw-Hill, 2007) has written one of the most comprehensive treatments of models and data that areapplicable to software estimating in every application domain. Coombs (IT Project Estimation,Cambridge University Press, 2002 and Roetzheim and Beasley ( Software Project Cost and Schedule Estimating: Best Practices, Prentice-Hall, 1997) present many useful models and suggest step-by-step guidelines for generating the best possible estimates.A wide variety of information sources on software estimation is available on the Internet.An up-to-date list of World Wide Web references relevant to software estimating can be foundat the SEPA website:www.mhhe.com/engcs/compsci/pressman/professional/ olc/ ser.htm.720 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch26.qxd  11/27/08  6:26 PM  Page 720In the late 1960s, a bright-eyed young engineer was chosen to “write” a com-puter program for an automated manufacturing application. The reason forhis selection was simple. He was the only person in his technical group whohad attended a computer programming seminar. He knew the ins and outs ofassembly language and FORTRAN but nothing about software engineering andeven less about project scheduling and tracking.His boss gave him the appropriate manuals and a verbal description of whathad to be done. He was informed that the project must be completed in twomonths.He read the manuals, considered his approach, and began writing code. Aftertwo weeks, the boss called him into his office and asked how things were going.“Really great,” said the young engineer with youthful enthusiasm. “This wasmuch simpler than I thought. I’m probably close to 75 percent finished.”
721CHAPTER
27PROJECT
SCHEDULING
What is it? You’ve selected anappropriate process model, you’veidentified the software engineeringtasks that have to be performed, youestimated the amount of work and the numberof people, you know the deadline, you’ve evenconsidered the risks. Now it’s time to connect thedots. That is, you have to create a network ofsoftware engineering tasks that will enable youto get the job done on time. Once the networkis created, you have to assign responsibility foreach task, make sure it gets done, and adaptthe network as risks become reality. In a nut-shell, that’s software project scheduling andtracking.
Who does it? At the project level, software proj-ect managers using information solicited fromsoftware engineers. At an individual level, soft-ware engineers themselves.
Why is it important? In order to build a complexsystem, many software engineering tasks occurin parallel, and the result of work performedduring one task may have a profound effect onQUICK
LOOKwork to be conducted in another task. Theseinterdependencies are very difficult to under-stand without a schedule. It’s also virtuallyimpossible to assess progress on a moderate orlarge software project without a detailedschedule.
What are the steps? The software engineeringtasks dictated by the software process modelare refined for the functionality to be built. Effortand duration are allocated to each task and atask network (also called an “activity network”)is created in a manner that enables the softwareteam to meet the delivery deadline established.
What is the work product? The project scheduleand related information are produced.
How do I ensure that I’ve done it right? Properscheduling requires that: (1) all tasks appear inthe network, (2) effort and timing are intelli-gently allocated to each task, (3) interdepen-dencies between tasks are properly indicated,(4) resources are allocated for the work to bedone, and (5) closely spaced milestones areprovided so that progress can be tracked.KEY
CONCEPTS
critical path  . . .724earned value  . .739effortdistribution  . . .727people andeffort . . . . . . . .725scheduling principles forWebApps  . . . .736task network  . .731time-boxing  . . .735pre75977_ch27.qxd  11/27/08  6:27 PM  Page 721722 PART FOURMANAGING SOFTWARE PROJECTS
The boss smiled and encouraged the young engineer to keep up the good work.They planned to meet again in a week’s time.A week later the boss called the engineer into his office and asked, “Where are we?”“Everything’s going well,” said the youngster, “but I’ve run into a few small snags.I’ll get them ironed out and be back on track soon.”“How does the deadline look?” the boss asked.“No problem,” said the engineer. “I’m close to 90 percent complete.”If you’ve been working in the software world for more than a few years, you canfinish the story. It’ll come as no surprise that the young engineer
1stayed 90 percent complete for the entire project duration and finished (with the help of others) onlyone month late.This story has been repeated tens of thousands of times by software developersduring the past five decades. The big question is why?
27.1 B ASIC CONCEPTS
Although there are many reasons why software is delivered late, most can be tracedto one or more of the following root causes:
•An unrealistic deadline established by someone outside the software teamand forced on managers and practitioners.
•Changing customer requirements that are not reflected in schedule changes.
•An honest underestimate of the amount of effort and/or the number ofresources that will be required to do the job.
•Predictable and/or unpredictable risks that were not considered when theproject commenced.
•Technical difficulties that could not have been foreseen in advance.
•Human difficulties that could not have been foreseen in advance.
•Miscommunication among project staff that results in delays.
•A failure by project management to recognize that the project is fallingbehind schedule and a lack of action to correct the problem.Aggressive (read “unrealistic”) deadlines are a fact of life in the software business.Sometimes such deadlines are demanded for reasons that are legitimate, from thepoint of view of the person who sets the deadline. But common sense says thatlegitimacy must also be perceived by the people doing the work.Napoleon once said: “Any commander-in-chief who undertakes to carry out aplan which he considers defective is at fault; he must put forth his reasons, insist onthe plan being changed, and finally tender his resignation rather than be the instru-ment of his army’s downfall.” These are strong words that many software projectmanagers should ponder.
1 In case you were wondering, this story is autobiographical.time-linecharts  . . . . . . .732tracking  . . . . . .734workbreakdown . . . .732
uote:
“Excessive orirrational schedulesare probably thesingle mostdestructiveinfluence in allof software.”Capers Jonespre75977_ch27.qxd  11/27/08  6:27 PM  Page 722The estimation activities discussed in Chapter 26 and the scheduling techniquesdescribed in this chapter are often implemented under the constraint of a defineddeadline. If best estimates indicate that the deadline is unrealistic, a competent proj-ect manager should “protect his or her team from undue [schedule] pressure . . .[and] reflect the pressure back to its originators” [Pag85].To illustrate, assume that your software team has been asked to build a real-timecontroller for a medical diagnostic instrument that is to be introduced to the marketin nine months. After careful estimation and risk analysis (Chapter 28), you come tothe conclusion that the software, as requested, will require 14 calendar months tocreate with available staff. How should you proceed?It is unrealistic to march into the customer’s office (in this case the likely customeris marketing/sales) and demand that the delivery date be changed. External marketpressures have dictated the date, and the product must be released. It is equally fool-hardy to refuse to undertake the work (from a career standpoint). So, what to do?I recommend the following steps in this situation:1.Perform a detailed estimate using historical data from past projects. Deter-mine the estimated effort and duration for the project.2.Using an incremental process model (Chapter 2), develop a software engi-neering strategy that will deliver critical functionality by the imposed dead-line, but delay other functionality until later. Document the plan.3.Meet with the customer and (using the detailed estimate), explain why theimposed deadline is unrealistic. Be certain to note that all estimates arebased on performance on past projects. Also be certain to indicate thepercent improvement that would be required to achieve the deadline as itcurrently exists.
2The following comment is appropriate:
I think we may have a problem with the delivery date for the XYZ controller software.I’ve given each of you an abbreviated breakdown of development rates for past soft-ware projects and an estimate that we’ve done a number of different ways. You’ll notethat I’ve assumed a 20 percent improvement in past development rates, but we stillget a delivery date that’s 14 calendar months rather than 9 months away.
4.Offer the incremental development strategy as an alternative:
We have a few options, and I’d like you to make a decision based on them. First, wecan increase the budget and bring on additional resources so that we’ll have a shot atgetting this job done in nine months. But understand that this will increase the risk ofpoor quality due to the tight time line.
3Second, we can remove a number of the soft- ware functions and capabilities that you’re requesting. This will make the preliminaryCHAPTER 27PROJECT SCHEDULING 723
2 If the required improvement is 10 to 25 percent, it may actually be possible to get the job done. But,more likely, the required improvement in team performance will be greater than 50 percent. Thisis an unrealistic expectation.3 You might also add that increasing the number of people does not reduce calendar timeproportionally.uote:
“I love deadlines. Ilike the whooshingsound they makeas they fly by.”Douglas Adams
What shouldyou do whenmanagementdemands adeadline that isimpossible??pre75977_ch27.qxd  11/27/08  6:27 PM  Page 723version of the product somewhat less functional, but we can announce all function-ality and then deliver over the 14-month period. Third, we can dispense with realityand wish the project complete in nine months. We’ll wind up with nothing that can bedelivered to a customer. The third option, I hope you’ll agree, is unacceptable. Pasthistory and our best estimates say that it is unrealistic and a recipe for disaster.
There will be some grumbling, but if a solid estimate based on good historical datais presented, it’s likely that negotiated versions of option 1 or 2 will be chosen. Theunrealistic deadline evaporates.
27.2 P ROJECT SCHEDULING
Fred Brooks was once asked how software projects fall behind schedule. Hisresponse was as simple as it was profound: “One day at a time.”The reality of a technical project (whether it involves building a hydroelectric plantor developing an operating system) is that hundreds of small tasks must occur toaccomplish a larger goal. Some of these tasks lie outside the mainstream and maybe completed without worry about impact on project completion date. Other taskslie on the “critical path.” If these “critical” tasks fall behind schedule, the completiondate of the entire project is put into jeopardy.As a project manager, your objective is to define all project tasks, build a networkthat depicts their interdependencies, identify the tasks that are critical within thenetwork, and then track their progress to ensure that delay is recognized “one dayat a time.” To accomplish this, you must have a schedule that has been defined at adegree of resolution that allows progress to be monitored and the project to becontrolled.Software project schedulingis an action that distributes estimated effort across theplanned project duration by allocating the effort to specific software engineeringtasks. It is important to note, however, that the schedule evolves over time. Duringearly stages of project planning, a macroscopic schedule is developed. This type ofschedule identifies all major process framework activities and the product functionsto which they are applied. As the project gets under way, each entry on the macro-scopic schedule is refined into a detailed schedule. Here, specific software actionsand tasks (required to accomplish an activity) are identified and scheduled.Scheduling for software engineering projects can be viewed from two rather dif-ferent perspectives. In the first, an end date for release of a computer-based systemhas already (and irrevocably) been established. The software organization is con-strained to distribute effort within the prescribed time frame. The second view ofsoftware scheduling assumes that rough chronological bounds have been discussedbut that the end date is set by the software engineering organization. Effort isdistributed to make best use of resources, and an end date is defined after carefulanalysis of the software. Unfortunately, the first situation is encountered far morefrequently than the second.724 PART FOURMANAGING SOFTWARE PROJECTS
The tasks required toachieve a projectmanager’s objectiveshould not beperformed manually.There are manyexcellent schedulingtools. Use them.
uote:
“Overly optimisticscheduling doesn’tresult in shorteractual schedules, itresults in longerones.”Steve McConnellpre75977_ch27.qxd  11/27/08  6:27 PM  Page 72427.2.1 Basic Principles
Like all other areas of software engineering, a number of basic principles guidesoftware project scheduling:Compartmentalization.The project must be compartmentalized into a number ofmanageable activities and tasks. To accomplish compartmentalization, both theproduct and the process are refined.Interdependency.The interdependency of each compartmentalized activity ortask must be determined. Some tasks must occur in sequence, while others canoccur in parallel. Some activities cannot commence until the work product pro-duced by another is available. Other activities can occur independently.Time allocation.Each task to be scheduled must be allocated some number ofwork units (e.g., person-days of effort). In addition, each task must be assigned astart date and a completion date that are a function of the interdependencies andwhether work will be conducted on a full-time or part-time basis.Effort validation.Every project has a defined number of people on the softwareteam. As time allocation occurs, you must ensure that no more than the allocatednumber of people has been scheduled at any given time. For example, consider aproject that has three assigned software engineers (e.g., three person-days areavailable per day of assigned effort
4). On a given day, seven concurrent tasks mustbe accomplished. Each task requires 0.50 person-days of effort. More effort hasbeen allocated than there are people to do the work.Defined responsibilities.Every task that is scheduled should be assigned to aspecific team member.Defined outcomes.Every task that is scheduled should have a defined outcome.For software projects, the outcome is normally a work product (e.g., the design ofa component) or a part of a work product. Work products are often combined indeliverables.Defined milestones.Every task or group of tasks should be associated with aproject milestone. A milestone is accomplished when one or more work productshas been reviewed for quality (Chapter 15) and has been approved.Each of these principles is applied as the project schedule evolves.
27.2.2 The Relationship Between People and Effort
In a small software development project a single person can analyze requirements,perform design, generate code, and conduct tests. As the size of a project increases,more people must become involved. (We can rarely afford the luxury of approachinga 10 person-year effort with one person working for 10 years!)CHAPTER 27PROJECT SCHEDULING 725
4 In reality, less than three person-days of effort are available because of unrelated meetings, sick-ness, vacation, and a variety of other reasons. For our purposes, however, we assume 100 percentavailability.When you developa schedule,compartmentalize thework, note taskinterdependencies,allocate effort andtime to each task, anddefine responsibilities,outcomes, andmilestones.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 725There is a common myth that is still believed by many managers who areresponsible for software development projects: “If we fall behind schedule, we canalways add more programmers and catch up later in the project.” Unfortunately,adding people late in a project often has a disruptive effect on the project, causingschedules to slip even further. The people who are added must learn the system, andthe people who teach them are the same people who were doing the work. Whileteaching, no work is done, and the project falls further behind.In addition to the time it takes to learn the system, more people increase the num-ber of communication paths and the complexity of communication throughout aproject. Although communication is absolutely essential to successful softwaredevelopment, every new communication path requires additional effort and there-fore additional time.Over the years, empirical data and theoretical analysis have demonstrated thatproject schedules are elastic. That is, it is possible to compress a desired project com-pletion date (by adding additional resources) to some extent. It is also possible toextend a completion date (by reducing the number of resources).The Putnam-Norden-Rayleigh (PNR) Curve
5provides an indication of the relation- ship between effort applied and delivery time for a software project. A version ofthe curve, representing project effort as a function of delivery time, is shown inFigure 27.1. The curve indicates a minimum value t
othat indicates the least cost for delivery (i.e., the delivery time that will result in the least effort expended). As wemove left of t
o(i.e., as we try to accelerate delivery), the curve rises nonlinearly.As an example, we assume that a project team has estimated a level of effort E
d
will be required to achieve a nominal delivery time tdthat is optimal in terms of726 PART FOURMANAGING SOFTWARE PROJECTS
If you must add peopleto a late project, besure that you’veassigned them workthat is highly compart-mentalized.
5 Original research can be found in [Nor70] and [Put78].If delivery can bedelayed, the PNR curveindicates that projectcosts can be reducedsubstantially.Effortcost
E
dEa = m (td4/ta4)
E
o
td to Development tim e
Tmin = 0.75TdImpossibleregion Ea = effort in person-monthst
d = nominal delivery time for schedulet
o = optimal development time (in terms of cost)t
a = actual delivery time desiredFIGURE 27.1
The relation-ship betweeneffort anddelivery timepre75977_ch27.qxd  11/27/08  6:27 PM  Page 726schedule and available resources. Although it is possible to accelerate delivery, thecurve rises very sharply to the left of t
d. In fact, the PNR curve indicates that the proj-ect delivery time cannot be compressed much beyond 0.75t
d. If we attempt further compression, the project moves into “the impossible region” and risk of failure be-comes very high. The PNR curve also indicates that the lowest cost delivery option,t
o/H110052td. The implication here is that delaying project delivery can reduce costssignificantly. Of course, this must be weighed against the business cost associatedwith the delay.The software equation [Put92] introduced in Chapter 26 is derived from the PNRcurve and demonstrates the highly nonlinear relationship between chronologicaltime to complete a project and human effort applied to the project. The number ofdelivered lines of code (source statements), L,is related to effort and development time by the equation:L/H11005P/H11003E
1/3t4/3
where Eis development effort in person-months, P is a productivity parameter that reflects a variety of factors that lead to high-quality software engineering work(typical values for Prange between 2000 and 12,000), and tis the project duration in calendar months.Rearranging this software equation, we can arrive at an expression for develop-ment effort E:E/H11005 (27.1) where Eis the effort expended (in person-years) over the entire life cycle for softwaredevelopment and maintenance and tis the development time in years. The equationfor development effort can be related to development cost by the inclusion of aburdened labor rate factor ($/person-year).This leads to some interesting results. Consider a complex, real-time softwareproject estimated at 33,000 LOC, 12 person-years of effort. If eight people are assignedto the project team, the project can be completed in approximately 1.3 years. If, how-ever, we extend the end date to 1.75 years, the highly nonlinear nature of the modeldescribed in Equation (27.1) yields:E/H11005~ 3.8 person-yearsThis implies that, by extending the end date by six months, we can reduce thenumber of people from eight to four! The validity of such results is open to debate,but the implication is clear: benefit can be gained by using fewer people over a some-what longer time span to accomplish the same objective.
27.2.3 Effort Distribution
Each of the software project estimation techniques discussed in Chapter 26 leadsto estimates of work units (e.g., person-months) required to complete softwareL3
P3t4L3
P3t4CHAPTER 27PROJECT SCHEDULING 727
As the project deadlinebecomes tighter andtighter, you reach apoint at which thework cannot becompleted onschedule, regardless ofthe number of peopledoing the work. Facereality and define anew delivery date.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 727development. A recommended distribution of effort across the software process isoften referred to as the 40–20–40 rule.Forty percent of all effort is allocated to front-end analysis and design. A similar percentage is applied to back-end testing. You cancorrectly infer that coding (20 percent of effort) is deemphasized.This effort distribution should be used as a guideline only.
6The characteristics of each project dictate the distribution of effort. Work expended on project planningrarely accounts for more than 2 to 3 percent of effort, unless the plan commits anorganization to large expenditures with high risk. Customer communication andrequirements analysis may comprise 10 to 25 percent of project effort. Effort ex-pended on analysis or prototyping should increase in direct proportion with projectsize and complexity. A range of 20 to 25 percent of effort is normally applied to soft-ware design. Time expended for design review and subsequent iteration must alsobe considered.Because of the effort applied to software design, code should follow with rela-tively little difficulty. A range of 15 to 20 percent of overall effort can be achieved.Testing and subsequent debugging can account for 30 to 40 percent of softwaredevelopment effort. The criticality of the software often dictates the amount of test-ing that is required. If software is human rated (i.e., software failure can result in lossof life), even higher percentages are typical.
27.3 D EFINING A TASKSET FOR THE SOFTWARE PROJECT
Regardless of the process model that is chosen, the work that a software team per-forms is achieved through a set of tasks that enable you to define, develop, and ulti-mately support computer software. No single task set is appropriate for all projects.The set of tasks that would be appropriate for a large, complex system would likelybe perceived as overkill for a small, relatively simple software product. Therefore, aneffective software process should define a collection of task sets, each designed tomeet the needs of different types of projects.As I noted in Chapter 2, a task set is a collection of software engineering worktasks, milestones, work products, and quality assurance filters that must be accom-plished to complete a particular project. The task set must provide enough disciplineto achieve high software quality. But, at the same time, it must not burden the proj-ect team with unnecessary work.In order to develop a project schedule, a task set must be distributed on the proj-ect time line. The task set will vary depending upon the project type and the degreeof rigor with which the software team decides to do its work. Although it is difficult728 PART FOURMANAGING SOFTWARE PROJECTS
6 Today, the 40-20-40 rule is under attack. Some believe that more than 40 percent of overall effortshould be expended during analysis and design. On the other hand, some proponents of agiledevelopment (Chapter 3) argue that less time should be expended “up front” and that a team shouldmove quickly to construction.How shouldeffort bedistributed acrossthe softwareprocessworkflow??pre75977_ch27.qxd  11/27/08  6:27 PM  Page 728to develop a comprehensive taxonomy of software project types, most softwareorganizations encounter the following projects:1.Concept development projectsthat are initiated to explore some new businessconcept or application of some new technology.2.New application developmentprojects that are undertaken as a consequenceof a specific customer request.3.Application enhancementprojects that occur when existing software under-goes major modifications to function, performance, or interfaces that areobservable by the end user.4.Application maintenance projectsthat correct, adapt, or extend existing soft-ware in ways that may not be immediately obvious to the end user.5.Reengineering projectsthat are undertaken with the intent of rebuilding anexisting (legacy) system in whole or in part.Even within a single project type, many factors influence the task set to be chosen.These include [Pre05]: size of the project, number of potential users, mission criti-cality, application longevity, stability of requirements, ease of customer/developercommunication, maturity of applicable technology, performance constraints, em-bedded and nonembedded characteristics, project staff, and reengineering factors.When taken in combination, these factors provide an indication of the degree of rigor with which the software process should be applied.
27.3.1 A Task Set Example
Concept development projects are initiated when the potential for some new tech-nology must be explored. There is no certainty that the technology will be applica-ble, but a customer (e.g., marketing) believes that potential benefit exists. Conceptdevelopment projects are approached by applying the following actions:1.1Concept scopingdetermines the overall scope of the project.1.2Preliminary concept planningestablishes the organization’s ability toundertake the work implied by the project scope.1.3Technology risk assessmentevaluates the risk associated with thetechnology to be implemented as part of the project scope.1.4Proof of conceptdemonstrates the viability of a new technology in thesoftware context.1.5Concept implementationimplements the concept representation in amanner that can be reviewed by a customer and is used for “marketing”purposes when a concept must be sold to other customers or management.1.6Customer reactionto the concept solicits feedback on a new technologyconcept and targets specific customer applications.CHAPTER 27PROJECT SCHEDULING 729
WebRef
An adaptable processmodel (APM) has beendeveloped to assist indefining task sets forvarious softwareprojects. A completedescription of the APMcan be found atwww.rspa.com/apm.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 729A quick scan of these actions should yield few surprises. In fact, the softwareengineering flow for concept development projects (and for all other types of proj-ects as well) is little more than common sense.
27.3.2 Refinement of Software Engineering Actions
The software engineering actions described in the preceding section may be used todefine a macroscopic schedule for a project. However, the macroscopic schedulemust be refined to create a detailed project schedule. Refinement begins by takingeach action and decomposing it into a set of tasks (with related work products andmilestones).As an example of task decomposition, consider Action 1.1, Concept Scoping.Task refinement can be accomplished using an outline format, but in this book,a process design language approach is used to illustrate the flow of the conceptscoping action:
Task definition: Action 1.1 Concept Scoping1.1.1 Identify need, benefits and potential customers;1.1.2 Define desired output/control and input events that drive the application;Begin Task 1.1.21.1.2.1 TR: Review written description of need
7 
1.1.2.2 Derive a list of customer visible outputs/inputs1.1.2.3 TR: Review outputs/inputs with customer and revise as required; endtaskTask 1.1.21.1.3 Define the functionality/behavior for each major function;Begin Task 1.1.31.1.3.1 TR: Review output and input data objects derived in task 1.1.2;1.1.3.2 Derive a model of functions/behaviors;1.1.3.3 TR: Review functions/behaviors with customer and revise as required;endtask Task 1.1.31.1.4 Isolate those elements of the technology to be implemented in software;1.1.5 Research availability of existing software;1.1.6 Define technical feasibility;1.1.7 Make quick estimate of size;1.1.8 Create a scope definition;endtask definition: Action 1.1
The tasks and subtasks noted in the process design language refinement form thebasis for a detailed schedule for the concept scoping action.730 PART FOURMANAGING SOFTWARE PROJECTS
7 TR indicates that a technical review (Chapter 15) is to be conducted.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 73027.4 D EFINING A TASKNETWORK
Individual tasks and subtasks have interdependencies based on their sequence. Inaddition, when more than one person is involved in a software engineering project,it is likely that development activities and tasks will be performed in parallel. Whenthis occurs, concurrent tasks must be coordinated so that they will be complete whenlater tasks require their work product(s).A task network,also called an activity network,is a graphic representation of the task flow for a project. It is sometimes used as the mechanism through which tasksequence and dependencies are input to an automated project scheduling tool. In itssimplest form (used when creating a macroscopic schedule), the task networkdepicts major software engineering actions. Figure 27.2 shows a schematic tasknetwork for a concept development project.The concurrent nature of software engineering actions leads to a number ofimportant scheduling requirements. Because parallel tasks occur asynchronously,you should determine intertask dependencies to ensure continuous progress towardcompletion. In addition, you should be aware of those tasks that lie on the critical path.That is, tasks that must be completed on schedule if the project as a whole isto be completed on schedule. These issues are discussed in more detail later in thischapter.It is important to note that the task network shown in Figure 27.2 is macroscopic.In a detailed task network (a precursor to a detailed schedule), each action shown inthe figure would be expanded. For example, Task 1.1 would be expanded to show alltasks detailed in the refinement of Actions 1.1 shown in Section 27.3.2.CHAPTER 27PROJECT SCHEDULING 731
I.1Conceptscoping
I.2ConceptplanningI.3bTech. riskassessment I.4Proof ofconcept I.5bConceptimplementIntegratea, b, c
I.6CustomerreactionI.3aTech. riskassessment I.5aConceptimplement
I.3cTech. riskassessment I.5cConceptimplementThree I.5 tasks areapplied in parallel to3 different conceptfunctionsFIGURE 27.2 A task network for concept developmentThe task network is auseful mechanism fordepicting intertaskdependencies anddetermining thecritical path.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 73127.5 S CHEDULING
Scheduling of a software project does not differ greatly from scheduling of any mul-titask engineering effort. Therefore, generalized project scheduling tools and tech-niques can be applied with little modification for software projects.Program evaluation and review technique (PERT) and thecritical path method(CPM) are two project scheduling methods that can be applied to software development. Bothtechniques are driven by information already developed in earlier project planningactivities: estimates of effort, a decomposition of the product function, the selection ofthe appropriate process model and task set, and decomposition of the tasks that areselected.Interdependencies among tasks may be defined using a task network. Tasks,sometimes called the project work breakdown structure (WBS), are defined for the product as a whole or for individual functions.Both PERT and CPM provide quantitative tools that allow you to (1) determine thecritical path—the chain of tasks that determines the duration of the project, (2) establish“most likely” time estimates for individual tasks by applying statistical models, and(3) calculate “boundary times” that define a time “window” for a particular task.
27.5.1 Time-Line Charts
When creating a software project schedule, you begin with a set of tasks (the workbreakdown structure). If automated tools are used, the work breakdown is input as732 PART FOURMANAGING SOFTWARE PROJECTS
uote:
“Allwe have todecide is what todo with the timethat is given to us.”Gandalf in TheLord of theRings:Fellowship ofthe Rings
Project Scheduling
Objective:The objective of projectscheduling tools is to enable a project managerto define work tasks; establish their dependencies; assignhuman resources to tasks; and develop a variety ofgraphs, charts, and tables that aid in tracking and controlof the software project.Mechanics:In general, project scheduling tools requirethe specification of a work breakdown structure of tasksor the generation of a task network. Once the taskbreakdown (an outline) or network is defined, start andend dates, human resources, hard deadlines, and otherdata are attached to each. The tool then generates avariety of time-line charts and other tables that enable amanager to assess the task flow of a project. These datacan be updated continually as the project is under way.Representative Tools:8
AMS Realtime,developed by Advanced ManagementSystems (www.amsusa.com), provides schedulingcapabilities for projects of all sizes and types.Microsoft Project,developed by Microsoft(www.microsoft.com), is the most widely usedPC-based project scheduling tool.4C,developed by 4C Systems(www.4csys.com),supports all aspects of project planning includingscheduling.A comprehensive list of project management softwarevendors and products can be found at www.infogoal.com/pmc/pmcswr.htm.SOFTWARE TOOLS
8 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 732a task network or task outline. Effort, duration, and start date are then input for eachtask. In addition, tasks may be assigned to specific individuals.As a consequence of this input, a time-line chart, also called a Gantt chart,is generated. A time-line chart can be developed for the entire project. Alternatively,separate charts can be developed for each project function or for each individualworking on the project.Figure 27.3 illustrates the format of a time-line chart. It depicts a part of a softwareproject schedule that emphasizes the concept scoping task for a word-processing(WP) software product. All project tasks (for concept scoping) are listed in the left-hand column. The horizontal bars indicate the duration of each task. When multiplebars occur at the same time on the calendar, task concurrency is implied. The dia-monds indicate milestones.Once the information necessary for the generation of a time-line chart has beeninput, the majority of software project scheduling tools produce project tables—a tab-ular listing of all project tasks, their planned and actual start and end dates, and avariety of related information (Figure 27.4). Used in conjunction with the time-linechart, project tables enable you to track progress.CHAPTER 27PROJECT SCHEDULING 733
A time-line chartenables you todetermine what taskswill be conducted at agiven point in time.
Identify needs and benefitsMeet with customersIdentify needs and project constraintsEstablish product statementMilestone: Product statement definedDefine desired output/control/input (OCI)Scope keyboard functionsScope voice input functionsScope modes of interactionScope document diagnosisScope other WP functionsDocument OCIFTR: Review OCI with customerRevise OCI as required Milestone: OCI definedDefine the function/behaviorDefine keyboard functionsDefine voice input functionsDescribe modes of interactionDescribe spell/grammar checkDescribe other WP functionsFTR: Review OCI definition with customerRevise as requiredMilestone: OCI definition completeIsolation software elementsMilestone: Software elements definedResearch availability of existing softwareResearch text editing componentsResearch voice input componentsResearch file management componentsResearch spell/grammar check componentsMilestone: Reusable components identifiedDefine technical feasibilityEvaluate voice inputEvaluate grammar checkingMilestone: Technical feasibility assessedMake quick estimate of sizeCreate a scope definitionReview scope document with customerRevise document as requiredMilestone: Scope document completeI.1.1
I.1.2
I.1.3
I.1.4I.1.5
I.1.6
I.1.7I.1.8Work tasks Week 1 Week 2 Week 3 Week 4 Week 5FIGURE 27.3 An example time-line chartpre75977_ch27.qxd  11/27/08  6:27 PM  Page 73327.5.2 Tracking the Schedule
If it has been properly developed, the project schedule becomes a road map thatdefines the tasks and milestones to be tracked and controlled as the projectproceeds. Tracking can be accomplished in a number of different ways:
•Conducting periodic project status meetings in which each team memberreports progress and problems
•Evaluating the results of all reviews conducted throughout the softwareengineering process
•Determining whether formal project milestones (the diamonds shown inFigure 27.3) have been accomplished by the scheduled date
•Comparing the actual start date to the planned start date for each projecttask listed in the resource table (Figure 27.4)
•Meeting informally with practitioners to obtain their subjective assessment ofprogress to date and problems on the horizon
•Using earned value analysis (Section 27.6) to assess progress quantitativelyIn reality, all of these tracking techniques are used by experienced projectmanagers.Control is employed by a software project manager to administer projectresources, cope with problems, and direct project staff. If things are going well (i.e.,the project is on schedule and within budget, reviews indicate that real progress isbeing made and milestones are being reached), control is light. But when problems734 PART FOURMANAGING SOFTWARE PROJECTS
PlannedstartActualstartPlannedcompleteActualcompleteAssignedpersonEffortallocatedNotes
wk1, d1wk1, d2wk1, d3wk1, d3wk1, d4wk1, d3wk2, d1wk2, d1wk1, d4wk2, d1wk2, d3wk2, d4wk2, d5wk1, d1wk1, d2wk1, d3wk1, d3wk1, d4wk1, d3wk1, d4wk1, d2wk1, d2wk1, d3wk1, d3wk2, d2wk2, d2wk2, d3wk2, d2wk2, d3wk2, d3wk2, d3wk2, d4wk2, d5wk1, d2wk1, d2wk1, d3wk1, d3BLSJPPBLS/JPPBLSJPPMLLBLSJPPMLLallall2 p-d1 p-d1 p-d1.5 p-d2 p-d1 p-d1.5 p-d2 p-d3 p-d3 p-d3 p-dScoping willrequire moreeffort/timeWork tasks
Identify needs and benefitsMeet with customersIdentify needs and project constraintsEstablish product statementMilestone: Product statement definedDefine desired output/control/input (OCI)Scope keyboard functionsScope voice input functionsScope modes of interactionScope document diagnosticsScope other WP functionsDocument OCIFTR: Review OCI with customerRevise OCI as requiredMilestone: OCI definedDefine the function/behaviorI.1.1
I.1.2
I.1.3FIGURE 27.4 An example project table
uote:
“The basic rule ofsoftware statusreporting can besummarized ina single phrase:‘No surprises’.”Capers Jones
The best indicationof progress is thecompletion andsuccessful review ofa defined softwarework product.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 734occur, you must exercise control to reconcile them as quickly as possible. After aproblem has been diagnosed, additional resources may be focused on the problemarea: staff may be redeployed or the project schedule can be redefined.When faced with severe deadline pressure, experienced project managers some-times use a project scheduling and control technique called time-boxing [Jal04]. The time-boxing strategy recognizes that the complete product may not be deliverable bythe predefined deadline. Therefore, an incremental software paradigm (Chapter 2) ischosen, and a schedule is derived for each incremental delivery.The tasks associated with each increment are then time-boxed. This means thatthe schedule for each task is adjusted by working backward from the delivery datefor the increment. A “box” is put around each task. When a task hits the boundary ofits time box (plus or minus 10 percent), work stops and the next task begins.The initial reaction to the time-boxing approach is often negative: “If the workisn’t finished, how can we proceed?” The answer lies in the way work is accom-plished. By the time the time-box boundary is encountered, it is likely that 90 percentof the task has been completed.
9The remaining 10 percent, although important, can(1) be delayed until the next increment or (2) be completed later if required. Ratherthan becoming “stuck” on a task, the project proceeds toward the delivery date.
27.5.3 Tracking Progress for an OO Project
Although an iterative model is the best framework for an OO project, task parallelismmakes project tracking difficult. You may have difficulty establishing meaningfulmilestones for an OO project because a number of different things are happeningat once. In general, the following major milestones can be considered “completed”when the criteria noted have been met.Technical milestone: OO analysis completed
•All classes and the class hierarchy have been defined and reviewed.
•Class attributes and operations associated with a class have been definedand reviewed.
•Class relationships (Chapter 6) have been established and reviewed.
•A behavioral model (Chapter 7) has been created and reviewed.
•Reusable classes have been noted.Technical milestone: OO design completed
•The set of subsystems has been defined and reviewed.
•Classes are allocated to subsystems and reviewed.
•Task allocation has been established and reviewed.CHAPTER 27PROJECT SCHEDULING 735
9 A cynic might recall the saying: “The first 90 percent of the system takes 90 percent of the time; theremaining 10 percent of the system takes 90 percent of the time.”When the definedcompletion date of atime-boxed task isreached, work ceasesfor that task and thenext task begins.pre75977_ch27.qxd  11/27/08  6:27 PM  Page 735•Responsibilities and collaborations have been identified.
•Attributes and operations have been designed and reviewed.
•The communication model has been created and reviewed.Technical milestone: OO programming completed
•Each new class has been implemented in code from the design model.
•Extracted classes (from a reuse library) have been implemented.
•Prototype or increment has been built.Technical milestone: OO testing
•The correctness and completeness of OO analysis and design models hasbeen reviewed.
•A class-responsibility-collaboration network (Chapter 6) has been developedand reviewed.
•Test cases are designed, and class-level tests (Chapter 19) have beenconducted for each class.
•Test cases are designed, and cluster testing (Chapter 19) is completed and theclasses are integrated.
•System-level tests have been completed.Recalling that the OO process model is iterative, each of these milestones may berevisited as different increments are delivered to the customer.
27.5.4 Scheduling for WebApp Projects
WebApp project schedulingdistributes estimated effort across the planned time line(duration) for building each WebApp increment. This is accomplished by allocatingthe effort to specific tasks. It is important to note, however, that the overall WebAppschedule evolves over time. During the first iteration, a macroscopic schedule isdeveloped. This type of schedule identifies all WebApp increments and projects thedates on which each will be deployed. As the development of an increment getsunder way, the entry for the increment on the macroscopic schedule is refined intoa detailed schedule. Here, specific development tasks (required to accomplish anactivity) are identified and scheduled.As an example of macroscopic scheduling, consider the SafeHomeAssured.comWebApp. Recalling earlier discussions of SafeHomeAssured.com, seven incrementscan be identified for the Web-based component of the project:Increment 1: Basic company and product informationIncrement 2: Detailed product information and downloadsIncrement 3: Product quotes and processing product ordersIncrement 4: Space layout and security system design736 PART FOURMANAGING SOFTWARE PROJECTS
Debugging and testingoccur in concert withone another. Thestatus of debugging isoften assessed byconsidering the typeand number of “open”errors (bugs).pre75977_ch27.qxd  11/27/08  6:28 PM  Page 736Increment 5: Information and ordering of monitoring servicesIncrement 6: Online control of monitoring equipmentIncrement 7: Accessing account informationThe team consults and negotiates with stakeholders and develops a preliminarydeployment schedule for all seven increments. A time-line chart for this schedule isillustrated in Figure 27.5.It is important to note that the deployment dates (represented by diamonds on thetime-line chart) are preliminary and may change as more detailed scheduling of theincrements occurs. However, this macroscopic schedule provides management withan indication of when content and functionality will be available and when the entireproject will be completed. As a preliminary estimate, the team will work to deploy allincrements with a 12-week time line. It’s also worth noting that some of the incre-ments will be developed in parallel (e.g., increments 3, 4, 6 and 7). This assumes thatthe team will have sufficient people to do this parallel work.Once the macroscopic schedule has been developed, the team is ready to sched-ule work tasks for a specific increment. To accomplish this, you can use a genericprocess framework that is applicable for all WebApp increments. A task list is created by using the generic tasks derived as part of the framework as a starting point andthen adapting these by considering the content and functions to be derived for aspecific WebApp increment.Each framework action (and its related tasks) can be adapted in one of four ways:(1) a task is applied as is, (2) a task is eliminated because it is not necessary for theCHAPTER 27PROJECT SCHEDULING 737
#1.Basic company and product informationWeeksIncrements1 2 3 4 5 6 7 8 9 10 11 12 13
#2.Detailed product information and downloads#3.Product quotes and processing product orders#4.Space layout and security system design#5.Information and ordering of monitoring services#6.On line control of monitoring equipment#7.Accessing account informationFIGURE 27.5 Time line for macroscopic project schedulepre75977_ch27.qxd  11/27/08  6:28 PM  Page 737increment, (3) a new (custom) task is added, and (4) a task is refined (elaborated) intoa number of named subtasks that each becomes part of the schedule.To illustrate, consider a generic design modeling action for WebApps that can be accomplished by applying some or all of the following tasks:
•Design the aesthetic for the WebApp.
•Design the interface.
•Design the navigation scheme.
•Design the WebApp architecture.
•Design the content and the structure that supports it.
•Design functional components.
•Design appropriate security and privacy mechanisms.
•Review the design.As an example, consider the generic task Design the Interface as it is applied to the fourth increment of SafeHomeAssured.com . Recall that the fourth increment implements the content and function for describing the living or business space tobe secured by the SafeHomesecurity system. Referring to Figure 27.5, the fourthincrement commences at the beginning of the fifth week and terminates at the endof the ninth week.There is little question that the Design the Interface task must be conducted. The team recognizes that the interface design is pivotal to the success of the incrementand decides to refine (elaborate) the task. The following subtasks are derived for theDesign the Interfacetask for the fourth increment:
•Develop a sketch of the page layout for the space design page.
•Review layout with stakeholders.
•Design space layout navigation mechanisms.
•Design “drawing board” layout.10
•Develop procedural details for the graphical wall layout function.
•Develop procedural details for the wall length computation and displayfunction.
•Develop procedural details for the graphical window layout function.
•Develop procedural details for the graphical door layout function.
•Design mechanisms for selecting security system components (sensors,cameras, microphones, etc.).738 PART FOURMANAGING SOFTWARE PROJECTS
10 At this stage, the team envisions creating the space by literally drawing the walls, windows, anddoors using graphical functions. Wall lines will “snap” onto grip points. Dimensions of the wall willbe displayed automatically. Windows and doors will be positioned graphically. The end user canalso select specific sensors, cameras, etc., and position them once the space has been defined.pre75977_ch27.qxd  11/27/08  6:28 PM  Page 738•Develop procedural details for the graphical layout of security systemcomponents.
•Conduct pair walkthroughs as required.These tasks become part of the increment schedule for the fourth WebApp incre-ment and are allocated over the increment development schedule. They can be inputto scheduling software and used for tracking and control.CHAPTER 27PROJECT SCHEDULING 739
Tracking the Schedule
The scene:Doug Miller’s office priorto the initiation of the SafeHomesoftware project.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman, JamieLazar, and other members of the product softwareengineering team.The conversation:Doug (glancing at a PowerPoint slide): The schedule for the first SafeHomeincrement seemsreasonable, but we’re going to have trouble trackingprogress.Vinod (a concerned look on his face): Why? We have tasks scheduled on a daily basis, plenty of workproducts, and we’ve been sure that we’re notoverallocating resources.Doug:All good, but how do we know when therequirements model for the first increment is complete?Jamie:Things are iterative, so that’s difficult.Doug:I understand that, but . . . well, for instance, take“analysis classes defined.” You indicated that as amilestone.Vinod:We have.Doug:Who makes that determination?Jamie (aggravated):They’re done when they’redone.Doug:That’s not good enough, Jamie. We have toschedule TRs [technical reviews, Chapter 15], and youhaven’t done that. The successful completion of a reviewon the analysis model, for instance, is a reasonablemilestone. Understand?Jamie (frowning):Okay, back to the drawing board.Doug:It shouldn’t take more than an hour to make thecorrections . . . everyone else can get started now.SAFEHOME
27.6 E ARNED VALUE ANALYSIS
In Section 27.5, I discussed a number of qualitative approaches to project tracking.Each provides the project manager with an indication of progress, but an assessmentof the information provided is somewhat subjective. It is reasonable to ask whetherthere is a quantitative technique for assessing progress as the software team pro-gresses through the work tasks allocated to the project schedule. In fact, a techniquefor performing quantitative analysis of progress does exist. It is called earned valueanalysis(EVA). Humphrey [Hum95] discusses earned value in the following manner:
The earned value system provides a common value scale for every [software project]task, regardless of the type of work being performed. The total hours to do the wholeproject are estimated, and every task is given an earned value based on its estimatedpercentage of the total.Earned value providesa quantitativeindication of progress.pre75977_ch27.qxd  11/27/08  6:28 PM  Page 739Stated even more simply, earned value is a measure of progress. It enables you toassess the “percent of completeness” of a project using quantitative analysis ratherthan rely on a gut feeling. In fact, Fleming and Koppleman [Fle98] argue that earnedvalue analysis “provides accurate and reliable readings of performance from as earlyas 15 percent into the project.” To determine the earned value, the following stepsare performed:1.The budgeted cost of work scheduled(BCWS) is determined for each work taskrepresented in the schedule. During estimation, the work (in person-hours orperson-days) of each software engineering task is planned. Hence, BCWS
iis the effort planned for work task i.To determine progress at a given pointalong the project schedule, the value of BCWS is the sum of the BCWS
ivalues for all work tasks that should have been completed by that point in time onthe project schedule.2.The BCWS values for all work tasks are summed to derive the budget atcompletion(BAC). Hence,BAC /H11005/H20858(BCWS
k) for all tasks k3.Next, the value for budgeted cost of work performed (BCWP) is computed. The value for BCWP is the sum of the BCWS values for all work tasks that haveactually been completed by a point in time on the project schedule.Wilkens [Wil99] notes that “the distinction between the BCWS and the BCWP isthat the former represents the budget of the activities that were planned to be com-pleted and the latter represents the budget of the activities that actually werecompleted.” Given values for BCWS, BAC, and BCWP, important progress indicatorscan be computed:Schedule performance index, SPI /H11005Schedule variance, SV /H11005BCWP /H11002BCWSSPI is an indication of the efficiency with which the project is utilizing scheduledresources. An SPI value close to 1.0 indicates efficient execution of the projectschedule. SV is simply an absolute indication of variance from the planned schedule.Percent scheduled for completion /H11005provides an indication of the percentage of work that should have been completedby time t.Percent complete /H11005provides a quantitative indication of the percent of completeness of the project at agiven point in time t.It is also possible to compute the actual cost of work performed (ACWP). The value for ACWP is the sum of the effort actually expended on work tasks that have
BCWPBACBCWSBACBCWPBCWS740 PART FOURMANAGING SOFTWARE PROJECTS
How do Icomputeearned value anduse it to assessprogress??
WebRef
A wide array of earnedvalue analysisresources can be foundat www.acq.osd.mil/pm/.pre75977_ch27.qxd  11/27/08  6:28 PM  Page 740been completed by a point in time on the project schedule. It is then possible tocomputeCost performance index, CPI /H11005Cost variance, CV /H11005BCWP /H11002ACWPA CPI value close to 1.0 provides a strong indication that the project is within itsdefined budget. CV is an absolute indication of cost savings (against planned costs)or shortfall at a particular stage of a project.Like over-the-horizon radar, earned value analysis illuminates scheduling diffi-culties before they might otherwise be apparent. This enables you to take correctiveaction before a project crisis develops.
27.7 S UMMARY
Scheduling is the culmination of a planning activity that is a primary component ofsoftware project management. When combined with estimation methods and riskanalysis, scheduling establishes a road map for the project manager.Scheduling begins with process decomposition. The characteristics of the projectare used to adapt an appropriate task set for the work to be done. A task networkdepicts each engineering task, its dependency on other tasks, and its projectedduration. The task network is used to compute the critical path, a time-line chart, anda variety of project information. Using the schedule as a guide, you can track andcontrol each step in the software process.
PROBLEMS AND POINTS TO PONDER
27.1.“Unreasonable” deadlines are a fact of life in the software business. How should youproceed if you’re faced with one?27.2.What is the difference between a macroscopic schedule and a detailed schedule? Is itpossible to manage a project if only a macroscopic schedule is developed? Why?27.3.Is there ever a case where a software project milestone is not tied to a review? If so,provide one or more examples.27.4.“Communication overhead” can occur when multiple people work on a software project.The time spent communicating with others reduces individual productively (LOC/month), andthe result can be less productivity for the team. Illustrate (quantitatively) how engineers who arewell versed in good software engineering practices and use technical reviews can increase theproduction rate of a team (when compared to the sum of individual production rates). Hint: Youcan assume that reviews reduce rework and that rework can account for 20 to 40 percent of aperson’s time.27.5.Although adding people to a late software project can make it later, there are circum-stances in which this is not true. Describe them.27.6.The relationship between people and time is highly nonlinear. Using Putnam’s softwareequation (described in Section 27.2.2), develop a table that relates number of people to projectBCWPACWPCHAPTER 27PROJECT SCHEDULING 741pre75977_ch27.qxd  11/27/08  6:28 PM  Page 741duration for a software project requiring 50,000 LOC and 15 person-years of effort (the produc-tivity parameter is 5000 and B /H110050.37). Assume that the software must be delivered in 24 monthsplus or minus 12 months.27.7.Assume that you have been contracted by a university to develop an online course reg-istration system (OLCRS). First, act as the customer (if you’re a student, that should be easy!)and specify the characteristics of a good system. (Alternatively, your instructor will provideyou with a set of preliminary requirements for the system.) Using the estimation methods dis-cussed in Chapter 26, develop an effort and duration estimate for OLCRS. Suggest how youwould:a. Define parallel work activities during the OLCRS project.b. Distribute effort throughout the project.c. Establish milestones for the project.27.8.Select an appropriate task set for the OLCRS project.27.9.Define a task network for OLCRS described in Problem 27.7, or alternatively, for anothersoftware project that interests you. Be sure to show tasks and milestones and to attach effortand duration estimates to each task. If possible, use an automated scheduling tool to performthis work.27.10.If an automated scheduling tool is available, determine the critical path for the networkdefined in Problem 27.9.27.11.Using a scheduling tool (if available) or paper and pencil (if necessary), develop a time-line chart for the OLCRS project.27.12.Assume you are a software project manager and that you’ve been asked to computeearned value statistics for a small software project. The project has 56 planned work tasks thatare estimated to require 582 person-days to complete. At the time that you’ve been asked to dothe earned value analysis, 12 tasks have been completed. However the project schedule indi-cates that 15 tasks should have been completed. The following scheduling data (in person-days)are available:
Task Planned Effort Actual Effort
112.012.5215.011.0313.017.048.09.559.59.0618.019.0710.010.084.04.5912.010.0106.06.5115.04.01214.014.51316.0— 146.0— 158.0—Compute the SPI, schedule variance, percent scheduled for completion, percent complete, CPI,and cost variance for the project.742 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch27.qxd  11/27/08  6:28 PM  Page 742FURTHER READINGS AND INFORMATION SOURCES
Virtually every book written on software project management contains a discussion of sched-uling. Wysoki (Effective Project Management, Wiley, 2006), Lewis (Project Planning Scheduling and Control,4th ed., McGraw-Hill, 2006), Luckey and Phillips ( Software Project Management for Dummies,For Dummies, 2006), Kerzner (Project Management: A Systems Approach to Planning,Scheduling, and Controlling,9th ed., Wiley, 2005), Hughes (Software Project Management, McGraw-Hill, 2005), The Project Management Institute ( PMBOK Guide,3d ed., PMI, 2004), Lewin (Better Software Project Management, Wiley, 2001), and Bennatan (On Time, Within Budget: Soft- ware Project Management Practices and Techniques, 3d ed., Wiley, 2000) contain worthwhile dis- cussions of the subject. Although application specific, Harris (Planning and Scheduling UsingMicrosoft Office Project 2007,Eastwood Harris Pty Ltd., 2007) provides a useful discussion of howscheduling tools can be used to successfully track and control a software project.Fleming and Koppelman (Earned Value Project Management, 3d ed., Project Management Institute Publications, 2006), Budd (A Practical Guide to Earned Value Project Management,Management Concepts, 2005), and Webb and Wake (Using Earned Value: A Project Manager’sGuide,Ashgate Publishing, 2003) discuss the use of earned value techniques for projectplanning, tracking, and control in considerable detail.A wide variety of information sources on software project scheduling is available on theInternet. An up-to-date list of World Wide Web references relevant to software project schedul-ing can be found at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 27PROJECT SCHEDULING 743pre75977_ch27.qxd  11/27/08  6:28 PM  Page 743In his book on risk analysis and management, Robert Charette [Cha89]presents a conceptual definition of risk:
First, risk concerns future happenings. Today and yesterday are beyond activeconcern, as we are already reaping what was previously sowed by our past actions.The question is, can we, therefore, by changing our actions today, create an oppor-tunity for a different and hopefully better situation for ourselves tomorrow. Thismeans, second, that risk involves change, such as in changes of mind, opinion,actions, or places. . . . [Third,] risk involves choice, and the uncertainty that choiceitself entails. Thus paradoxically, risk, like death and taxes, is one of the fewcertainties of life.
When you consider risk in the context of software engineering, Charette’sthree conceptual underpinnings are always in evidence. The future is your 
744RISK
MANAGEMENT
KEY
CONCEPTS
assessment  . . .748identification  . .747projection . . . . .749refinement  . . . .754risk categories  .746risk exposure  . .753risk itemchecklist . . . . . .748risk table  . . . . .750RMMM  . . . . . .757safety andhazards  . . . . . .757strategies  . . . .745proactive  . . . .745reactive  . . . . .745
What is it? Risk analysis andmanagement are actions that helpa software team to understand andmanage uncertainty. Many problemscan plague a software project. A risk is a poten-tial problem—it might happen, it might not. But,regardless of the outcome, it’s a really good ideato identify it, assess its probability of occurrence,estimate its impact, and establish a contingencyplan should the problem actually occur.
Who does it? Everyone involved in the softwareprocess—managers, software engineers, andother stakeholders—participate in risk analysisand management.
Why is it important? Think about the Boy Scoutmotto: “Be prepared.” Software is a difficult un-dertaking. Lots of things can go wrong, andfrankly, many often do. It’s for this reason thatbeing prepared—understanding the risks andtaking proactive measures to avoid or managethem—is a key element of good software projectmanagement.QUICK
LOOKWhat are the steps? Recognizing what can gowrong is the first step, called “risk identifica-tion.” Next, each risk is analyzed to determinethe likelihood that it will occur and the damagethat it will do if it does occur. Once this informa-tion is established, risks are ranked, by proba-bility and impact. Finally, a plan is developed tomanage those risks that have high probabilityand high impact.
What is the work product? A risk mitigation,monitoring, and management (RMMM) plan ora set of risk information sheets is produced.
How do I ensure that I’ve done it right? Therisks that are analyzed and managed shouldbe derived from thorough study of the people,the product, the process, and the project. TheRMMM should be revisited as the project pro-ceeds to ensure that risks are kept up to date.Contingency plans for risk management shouldbe realistic.CHAPTER
28pre75977_ch28.qxd  11/27/08  6:29 PM  Page 744concern—what risks might cause the software project to go awry? Change is yourconcern—how will changes in customer requirements, development technologies,target environments, and all other entities connected to the project affect timelinessand overall success? Last, you must grapple with choices—what methods and toolsshould you use, how many people should be involved, how much emphasis on qual-ity is “enough”?Peter Drucker [Dru75] once said, “While it is futile to try to eliminate risk, andquestionable to try to minimize it, it is essential that the risks taken be the right risks.”Before you can identify the “right risks” to be taken during a software project, it is im-portant to identify all risks that are obvious to both managers and practitioners.
28.1 R EACTIVE VERSUS PROACTIVE RISKSTRATEGIES
Reactiverisk strategies have been laughingly called the “Indiana Jones school of riskmanagement” [Tho92]. In the movies that carried his name, Indiana Jones, whenfaced with overwhelming difficulty, would invariably say, “Don’t worry, I’ll think ofsomething!” Never worrying about problems until they happened, Indy would reactin some heroic way.Sadly, the average software project manager is not Indiana Jones and the mem-bers of the software project team are not his trusty sidekicks. Yet, the majority ofsoftware teams rely solely on reactive risk strategies. At best, a reactive strategymonitors the project for likely risks. Resources are set aside to deal with them,should they become actual problems. More commonly, the software team doesnothing about risks until something goes wrong. Then, the team flies into action inan attempt to correct the problem rapidly. This is often called a fire-fighting mode. When this fails, “crisis management” [Cha92] takes over and the project is in realjeopardy.A considerably more intelligent strategy for risk management is to be proactive.A proactivestrategy begins long before technical work is initiated. Potential risks areidentified, their probability and impact are assessed, and they are ranked by impor-tance. Then, the software team establishes a plan for managing risk. The primaryobjective is to avoid risk, but because not all risks can be avoided, the team worksto develop a contingency plan that will enable it to respond in a controlled andeffective manner. Throughout the remainder of this chapter, I discuss a proactivestrategy for risk management.
28.2 S OFTWARE RISKS
Although there has been considerable debate about the proper definition for soft-ware risk, there is general agreement that risk always involves two character-istics:uncertainty—the risk may or may not happen; that is, there are no 100 percentCHAPTER 28RISK MANAGEMENT 745
uote:
“If you don'tactively attack therisks, they willactively attackyou.”Tom Gilbpre75977_ch28.qxd  11/27/08  6:29 PM  Page 745probable risks1—and loss—if the risk becomes a reality, unwanted consequences orlosses will occur [Hig95]. When risks are analyzed, it is important to quantify thelevel of uncertainty and the degree of loss associated with each risk. To accomplishthis, different categories of risks are considered.Project risksthreaten the project plan. That is, if project risks become real, it islikely that the project schedule will slip and that costs will increase. Project risksidentify potential budgetary, schedule, personnel (staffing and organization), re-source, stakeholder, and requirements problems and their impact on a software proj-ect. In Chapter 26, project complexity, size, and the degree of structural uncertaintywere also defined as project (and estimation) risk factors.Technical risksthreaten the quality and timeliness of the software to be produced.If a technical risk becomes a reality, implementation may become difficult or impos-sible. Technical risks identify potential design, implementation, interface, verifica-tion, and maintenance problems. In addition, specification ambiguity, technicaluncertainty, technical obsolescence, and “leading-edge” technology are also riskfactors. Technical risks occur because the problem is harder to solve than youthought it would be.Business risksthreaten the viability of the software to be built and often jeopard-ize the project or the product. Candidates for the top five business risks are (1) build-ing an excellent product or system that no one really wants (market risk), (2) buildinga product that no longer fits into the overall business strategy for the company(strategic risk), (3) building a product that the sales force doesn’t understand how tosell (sales risk), (4) losing the support of senior management due to a change in focusor a change in people (management risk), and (5) losing budgetary or personnelcommitment (budget risks).It is extremely important to note that simple risk categorization won’t alwayswork. Some risks are simply unpredictable in advance.Another general categorization of risks has been proposed by Charette[Cha89].Known risksare those that can be uncovered after careful evaluation ofthe project plan, the business and technical environment in which the project isbeing developed, and other reliable information sources (e.g., unrealistic deliverydate, lack of documented requirements or software scope, poor developmentenvironment).Predictable risksare extrapolated from past project experience(e.g., staff turnover, poor communication with the customer, dilution of staff effortas ongoing maintenance requests are serviced). Unpredictable risksare the joker in the deck. They can and do occur, but they are extremely difficult to identify inadvance.746 PART FOURMANAGING SOFTWARE PROJECTS
What typesof risks areyou likely toencounter assoftware isbuilt??
1 A risk that is 100 percent probable is a constraint on the software project.uote:
“Projects with noreal risks arelosers. They arealmost alwaysdevoid of benefit;that's why theyweren't doneyears ago.”Tom DeMarcoand Tim Listerpre75977_ch28.qxd  11/27/08  6:29 PM  Page 74628.3 R ISKIDENTIFICATION
Risk identification is a systematic attempt to specify threats to the project plan (esti-mates, schedule, resource loading, etc.). By identifying known and predictable risks,the project manager takes a first step toward avoiding them when possible and con-trolling them when necessary.There are two distinct types of risks for each of the categories that have been pre-sented in Section 28.2: generic risks and product-specific risks. Generic risks are a potential threat to every software project. Product-specific risks can be identified only by those with a clear understanding of the technology, the people, and the environ-ment that is specific to the software that is to be built. To identify product-specificrisks, the project plan and the software statement of scope are examined, and ananswer to the following question is developed: “What special characteristics of thisproduct may threaten our project plan?”One method for identifying risks is to create a risk item checklist. The checklistcan be used for risk identification and focuses on some subset of known and pre-dictable risks in the following generic subcategories:
•Product size—risks associated with the overall size of the software to be builtor modified.
•Business impact—risks associated with constraints imposed by managementor the marketplace.CHAPTER 28RISK MANAGEMENT 747
Seven Principles of Risk Management
The Software Engineering Institute (SEI)(www.sei.cmu.edu) identifies sevenprinciples that “provide a framework to accomplisheffective risk management.” They are:Maintain a global perspective—view software riskswithin the context of a system in which it is acomponent and the business problem that it isintended to solveTake a forward-looking view—think about the risksthat may arise in the future (e.g., due to changes in thesoftware); establish contingency plans so that futureevents are manageable.Encourage open communication—if someone statesa potential risk, don’t discount it. If a risk is proposedin an informal manner, consider it. Encourageall stakeholders and users to suggest risks at any time.Integrate—a consideration of risk must be integratedinto the software process.Emphasize a continuous process—the teammust be vigilant throughout the software process,modifying identified risks as more information isknown and adding new ones as better insight isachieved.Develop a shared product vision—if allstakeholders share the same vision of the software, it islikely that better risk identification and assessment willoccur.Encourage teamwork—the talents, skills, andknowledge of all stakeholders should be pooledwhen risk management activities are conducted.INFO
Although generic risksare important toconsider, it's theproduct-specific risksthat cause the mostheadaches. Be certainto spend the time toidentify as manyproduct-specific risksas possible.pre75977_ch28.qxd  11/27/08  6:29 PM  Page 747•Stakeholder characteristics—risks associated with the sophistication of thestakeholders and the developer’s ability to communicate with stakeholders ina timely manner.
•Process definition—risks associated with the degree to which the softwareprocess has been defined and is followed by the development organization.
•Development environment—risks associated with the availability and qualityof the tools to be used to build the product.
•Technology to be built—risks associated with the complexity of the system tobe built and the “newness” of the technology that is packaged by the system.
•Staff size and experience—risks associated with the overall technical andproject experience of the software engineers who will do the work.The risk item checklist can be organized in different ways. Questions relevant toeach of the topics can be answered for each software project. The answers to thesequestions allow you to estimate the impact of risk. A different risk item checklist for-mat simply lists characteristics that are relevant to each generic subcategory. Finally,a set of “risk components and drivers” [AFC88] are listed along with their probabilityof occurrence. Drivers for performance, support, cost, and schedule are discussed inanswer to later questions.A number of comprehensive checklists for software project risk are availableon the Web (e.g., [Baa07], [NAS07], [Wor04]). You can use these checklists to gaininsight into generic risks for software projects.
28.3.1 Assessing Overall Project Risk
The following questions have been derived from risk data obtained by surveyingexperienced software project managers in different parts of the world [Kei98]. Thequestions are ordered by their relative importance to the success of a project.1.Have top software and customer managers formally committed to supportthe project?2.Are end users enthusiastically committed to the project and the system/product to be built?3.Are requirements fully understood by the software engineering team and itscustomers?4.Have customers been involved fully in the definition of requirements?5.Do end users have realistic expectations?6.Is the project scope stable?7.Does the software engineering team have the right mix of skills?8.Are project requirements stable?9.Does the project team have experience with the technology to be implemented?748 PART FOURMANAGING SOFTWARE PROJECTS
Is thesoftwareproject we'reworking on atserious risk??pre75977_ch28.qxd  11/27/08  6:29 PM  Page 74810.Is the number of people on the project team adequate to do the job?11.Do all customer/user constituencies agree on the importance of the projectand on the requirements for the system/product to be built?If any one of these questions is answered negatively, mitigation, monitoring, and man-agement steps should be instituted without fail. The degree to which the project is atrisk is directly proportional to the number of negative responses to these questions.
28.3.2 Risk Components and Drivers
The U.S. Air Force [AFC88] has published a pamphlet that contains excellent guide-lines for software risk identification and abatement. The Air Force approach requiresthat the project manager identify the risk drivers that affect software risk components—performance, cost, support, and schedule. In the context of this discussion, the riskcomponents are defined in the following manner:
•Performance risk—the degree of uncertainty that the product will meet itsrequirements and be fit for its intended use.
•Cost risk—the degree of uncertainty that the project budget will bemaintained.
•Support risk—the degree of uncertainty that the resultant software will beeasy to correct, adapt, and enhance.
•Schedule risk—the degree of uncertainty that the project schedule will bemaintained and that the product will be delivered on time.The impact of each risk driver on the risk component is divided into one of fourimpact categories—negligible, marginal, critical, or catastrophic. Referring to Fig-ure 28.1 [Boe89], a characterization of the potential consequences of errors (rowslabeled 1) or a failure to achieve a desired outcome (rows labeled 2) are described.The impact category is chosen based on the characterization that best fits thedescription in the table.
28.4 R ISKPROJECTION
Risk projection, also called risk estimation, attempts to rate each risk in two ways— (1) the likelihood or probability that the risk is real and (2) the consequences of theproblems associated with the risk, should it occur. You work along with other man-agers and technical staff to perform four risk projection steps:1.Establish a scale that reflects the perceived likelihood of a risk.2.Delineate the consequences of the risk.3.Estimate the impact of the risk on the project and the product.4.Assess the overall accuracy of the risk projection so that there will be nomisunderstandings.CHAPTER 28RISK MANAGEMENT 749
uote:
“Risk managementis projectmanagement foradults.”Tim ListerWebRef
Risk radaris adatabase and tools thathelp managers identify,rank, and communicateproject risks. It can befound at www.spmn.compre75977_ch28.qxd  11/27/08  6:29 PM  Page 749The intent of these steps is to consider risks in a manner that leads to prioritization.No software team has the resources to address every possible risk with the samedegree of rigor. By prioritizing risks, you can allocate resources where they will havethe most impact.
28.4.1 Developing a Risk Table
A risk table provides you with a simple technique for risk projection.2A sample risk table is illustrated in Figure 28.2.You begin by listing all risks (no matter how remote) in the first column of thetable. This can be accomplished with the help of the risk item checklists referencedin Section 28.3. Each risk is categorized in the second column (e.g., PS implies a750 PART FOURMANAGING SOFTWARE PROJECTS
ComponentsCategoryCatastrophic
Critical
Marginal
NegligiblePerformance SupportCost Schedule
Failure to meet the requirementwould result in mission failureSignificantdegradation tononachievementof technicalperformanceNonresponsive orunsupportablesoftwareSignificant financialshortages, budgetoverrun likelyUnachievable IOCFailure results in increased costsand schedule delays with expected values in excess of $500K
1
2Failure to meet the requirement woulddegrade system performance to a pointwhere mission success is questionableSome reductionin technical performanceMinor delays insoftwaremodificationsSome shortage offinancial resources,possible overrunsPossible slippagein IOCFailure results in operational delays and/or increased costs with expected value of $100K to $500K 12Failure to meet the requirement wouldresult in degradation of secondary missionMinimal to smallreduction intechnicalperformanceResponsive softwaresupportSufficient financialresourcesRealistic, achievablescheduleCosts, impacts, and/or recoverable schedule slips with expected value of $1K to $100K 12Failure to meet the requirement wouldcreate inconvenience or nonoperationalimpactNo reduction intechnicalperformanceEasily supportablesoftwarePossible budgetunderrunEarly achievable IOCError results in minor cost and/or schedule impact with expected value of less than $1K 12Note: (1) The potential consequence of undetected software errors or faults. (2) The potential consequence if the desired outcome is not achieved.FIGURE 28.1
Impactassessment.Source: [Boe89].
2 The risk table can be implemented as a spreadsheet model. This enables easy manipulation andsorting of the entries.Think hard about thesoftware you're aboutto build and askyourself, “what can gowrong?” Create yourown list and ask othermembers of the teamto do the same.pre75977_ch28.qxd  11/27/08  6:29 PM  Page 750project size risk, BU implies a business risk). The probability of occurrence of eachrisk is entered in the next column of the table. The probability value for each risk canbe estimated by team members individually. One way to accomplish this is to pollindividual team members in round-robin fashion until their collective assessment ofrisk probability begins to converge.Next, the impact of each risk is assessed. Each risk component is assessed usingthe characterization presented in Figure 28.1, and an impact category is determined.The categories for each of the four risk components—performance, support, cost,and schedule—are averaged
3to determine an overall impact value.Once the first four columns of the risk table have been completed, the table issorted by probability and by impact. High-probability, high-impact risks percolate tothe top of the table, and low-probability risks drop to the bottom. This accomplishesfirst-order risk prioritization.You can study the resultant sorted table and define a cutoff line. The cutoff line(drawn horizontally at some point in the table) implies that only risks that lie abovethe line will be given further attention. Risks that fall below the line are reevaluatedto accomplish second-order prioritization. Referring to Figure 28.3, risk impact andCHAPTER 28RISK MANAGEMENT 751
RisksSize estimate may be significantly lowLarger number of users than plannedLess reuse than plannedEnd-users resist systemDelivery deadline will be tightenedFunding will be lostCustomer will change requirementsTechnology will not meet expectationsLack of training on toolsStaff inexperiencedStaff turnover will be highPSPSPSBUBUCUPSTEDESTST60%30%70%40%50%40%80%30%80%30%60%23232121322Probability
Impact values:1—catastrophic2—critical3—marginal4—negligibleImpact RMMM Category
∑∑∑FIGURE 28.2
Sample risktable prior tosorting
3 A weighted average can be used if one risk component has more significance for a project.A risk table is sorted byprobability and impactto rank risks.pre75977_ch28.qxd  11/27/08  6:29 PM  Page 751probability have a distinct influence on management concern. A risk factor that hasa high impact but a very low probability of occurrence should not absorb a signifi-cant amount of management time. However, high-impact risks with moderate tohigh probability and low-impact risks with high probability should be carried forwardinto the risk analysis steps that follow.All risks that lie above the cutoff line should be managed. The column labeledRMMM contains a pointer into a risk mitigation, monitoring, and management plan or, alternatively, a collection of risk information sheets developed for all risks that lieabove the cutoff. The RMMM plan and risk information sheets are discussed inSections 28.5 and 28.6.Risk probability can be determined by making individual estimates and thendeveloping a single consensus value. Although that approach is workable, moresophisticated techniques for determining risk probability have been developed[AFC88]. Risk drivers can be assessed on a qualitative probability scale that has thefollowing values: impossible, improbable, probable, and frequent. Mathematicalprobability can then be associated with each qualitative value (e.g., a probability of0.7 to 0.99 implies a highly probable risk).
28.4.2 Assessing Risk Impact
Three factors affect the consequences that are likely if a risk does occur: its nature,its scope, and its timing. The nature of the risk indicates the problems that are likelyif it occurs. For example, a poorly defined external interface to customer hardware752 PART FOURMANAGING SOFTWARE PROJECTS
1.00Very lowVery high
ImpactManagement
concernHighDisregardrisk factor
Probabilityof occurrenceFIGURE 28.3
Risk andmanagementconcern
uote:
“[Today,] no onehas the luxury ofgetting to know atask so well that itholds no surprises,and surprises meanrisk.”Stephen Greypre75977_ch28.qxd  11/27/08  6:29 PM  Page 752(a technical risk) will preclude early design and testing and will likely lead to sys-tem integration problems late in a project. The scope of a risk combines the sever-ity (just how serious is it?) with its overall distribution (how much of the project willbe affected or how many stakeholders are harmed?). Finally, the timing of a risk con-siders when and for how long the impact will be felt. In most cases, you want the“bad news” to occur as soon as possible, but in some cases, the longer the delay,the better.Returning once more to the risk analysis approach proposed by the U.S. Air Force[AFC88], you can apply the following steps to determine the overall consequences ofa risk: (1) determine the average probability of occurrence value for each risk com-ponent; (2) using Figure 28.1, determine the impact for each component based onthe criteria shown, and (3) complete the risk table and analyze the results as de-scribed in the preceding sections.The overall risk exposureRE is determined using the following relationship[Hal98]:RE /H11005P/H11003Cwhere Pis the probability of occurrence for a risk, and C is the cost to the project should the risk occur.For example, assume that the software team defines a project risk in the follow-ing manner:Risk identification.Only 70 percent of the software components scheduledfor reuse will, in fact, be integrated into the application. The remainingfunctionality will have to be custom developed.Risk probability.80 percent (likely).Risk impact.Sixty reusable software components were planned. If only70 percent can be used, 18 components would have to be developedfrom scratch (in addition to other custom software that has beenscheduled for development). Since the average component is 100 LOCand local data indicate that the software engineering cost for each LOCis $14.00, the overall cost (impact) to develop the components would be18 /H11003100 /H1100314 /H11005$25,200.Risk exposure.RE /H110050.80 /H1100325,200 /H11011$20,200. Risk exposure can be computed for each risk in the risk table, once an estimate ofthe cost of the risk is made. The total risk exposure for all risks (above the cutoff inthe risk table) can provide a means for adjusting the final cost estimate for a project.It can also be used to predict the probable increase in staff resources required atvarious points during the project schedule.The risk projection and analysis techniques described in Sections 28.4.1 and28.4.2 are applied iteratively as the software project proceeds. The project teamCHAPTER 28RISK MANAGEMENT 753
How do weassess theconsequences of a risk??
Compare RE for allrisks to the costestimate for theproject. If RE is greaterthan 50 percent of theproject cost, theviability of the projectmust be evaluated.pre75977_ch28.qxd  11/27/08  6:30 PM  Page 75328.5 R ISKREFINEMENT
During early stages of project planning, a risk may be stated quite generally. As timepasses and more is learned about the project and the risk, it may be possible to refinethe risk into a set of more detailed risks, each somewhat easier to mitigate, monitor,and manage.One way to do this is to represent the risk in condition-transition-consequence(CTC) format [Glu94]. That is, the risk is stated in the following form:
Given that <condition> then there is concern that (possibly) <consequence>.754 PART FOURMANAGING SOFTWARE PROJECTS
Risk Analysis
The scene:Doug Miller’s office priorto the initiation of the SafeHomesoftware project.The players:Doug Miller (manager of the SafeHome software engineering team) and Vinod Raman, JamieLazar, and other members of the product softwareengineering team.The conversation:Doug:I’d like to spend some time brainstorming risks forthe SafeHomeproject.Jamie:As in what can go wrong?Doug:Yep. Here are a few categories where things cango wrong. [He shows everyone the categories noted inthe introduction to Section 28.3.]Vinod:Umm . . . do you want us to just call them out,or . . .Doug:No here’s what I thought we’d do. Everyonemake a list of risks . . . right now . . .”[Ten minutes pass, everyone is writing.]Doug:Okay, stop.Jamie:But I’m not done!Doug:That’s okay. We’ll revisit the list again. Now, foreach item on your list, assign a percent likelihood that therisk will occur. Then, assign an impact to the project on ascale of 1 (minor) to 5 (catastrophic).Vinod:So if I think that the risk is a coin flip, I specify a50 percent likelihood, and if I think it’ll have a moderateproject impact, I specify a 3, right?Doug:Exactly.[Five minutes pass, everyone is writing.]Doug:Okay, stop. Now we’ll make a group list on thewhite board. I’ll do the writing; we’ll call out one entryfrom your list in round-robin format.[Fifteen minutes pass; the list is created.]Jamie (pointing at the board and laughing):Vinod, that risk (pointing toward an entry on the board)is ridiculous. There’s a higher likelihood that we’ll all gethit by lightning. We should remove it.Doug:No, let’s leave it for now. We consider all risks,no matter how weird. Later we’ll winnow the list.Jamie:But we already have over 40 risks . . . how onearth can we manage them all?Doug:We can’t. That’s why we’ll define a cut-off afterwe sort these guys. I’ll do that off-line and we’ll meetagain tomorrow. For now, get back to work . . . andin your spare time, think about any risks that we’vemissed.SAFEHOME
What's agood way todescribe a risk??should revisit the risk table at regular intervals, reevaluating each risk to determinewhen new circumstances cause its probability and impact to change. As a conse-quence of this activity, it may be necessary to add new risks to the table, removesome risks that are no longer relevant, and change the relative positions of stillothers.pre75977_ch28.qxd  11/27/08  6:30 PM  Page 754Using the CTC format for the reuse risk noted in Section 28.4.2, you could write:
Given that all reusable software components must conform to specific design standardsand that some do not conform, then there is concern that (possibly) only 70 percent of theplanned reusable modules may actually be integrated into the as-built system, resultingin the need to custom engineer the remaining 30 percent of components.
This general condition can be refined in the following manner:
Subcondition 1.Certain reusable components were developed by a third party with noknowledge of internal design standards.Subcondition 2.The design standard for component interfaces has not been solidifiedand may not conform to certain existing reusable components.Subcondition 3.Certain reusable components have been implemented in a languagethat is not supported on the target environment.
The consequences associated with these refined subconditions remain the same(i.e., 30 percent of software components must be custom engineered), but therefinement helps to isolate the underlying risks and might lead to easier analysis andresponse.
28.6 R ISKMITIGATION , M ONITORING , AND MANAGEMENT
All of the risk analysis activities presented to this point have a single goal—to assistthe project team in developing a strategy for dealing with risk. An effective strategymust consider three issues: risk avoidance, risk monitoring, and risk managementand contingency planning.If a software team adopts a proactive approach to risk, avoidance is always thebest strategy. This is achieved by developing a plan for risk mitigation. For example, assume that high staff turnover is noted as a project risk r
1. Based on past history and management intuition, the likelihood l
1of high turnover is estimated to be 0.70 (70 percent, rather high) and the impact x
1is projected as critical. That is, high turnover will have a critical impact on project cost and schedule.To mitigate this risk, you would develop a strategy for reducing turnover. Amongthe possible steps to be taken are:
•Meet with current staff to determine causes for turnover (e.g., poor workingconditions, low pay, competitive job market).
•Mitigate those causes that are under your control before the project starts.
•Once the project commences, assume turnover will occur and develop tech-niques to ensure continuity when people leave.
•Organize project teams so that information about each development activityis widely dispersed.CHAPTER 28RISK MANAGEMENT 755
What canwe do tomitigate a risk??uote:
“If I take so manyprecautions, it isbecause I leavenothing to chance.”Napoleanpre75977_ch28.qxd  11/27/08  6:30 PM  Page 755•Define work product standards and establish mechanisms to be sure that allmodels and documents are developed in a timely manner.
•Conduct peer reviews of all work (so that more than one person is “up tospeed”).
•Assign a backup staff member for every critical technologist.As the project proceeds, risk-monitoring activities commence. The project man- ager monitors factors that may provide an indication of whether the risk is becom-ing more or less likely. In the case of high staff turnover, the general attitude of teammembers based on project pressures, the degree to which the team has jelled, inter-personal relationships among team members, potential problems with compensa-tion and benefits, and the availability of jobs within the company and outside it areall monitored.In addition to monitoring these factors, a project manager should monitor theeffectiveness of risk mitigation steps. For example, a risk mitigation step noted herecalled for the definition of work product standards and mechanisms to be sure thatwork products are developed in a timely manner. This is one mechanism for ensur-ing continuity, should a critical individual leave the project. The project managershould monitor work products carefully to ensure that each can stand on its own andthat each imparts information that would be necessary if a newcomer were forcedto join the software team somewhere in the middle of the project.Risk management and contingency planning assumes that mitigation efforts have failed and that the risk has become a reality. Continuing the example, the project iswell under way and a number of people announce that they will be leaving. If themitigation strategy has been followed, backup is available, information is docu-mented, and knowledge has been dispersed across the team. In addition, you cantemporarily refocus resources (and readjust the project schedule) to those functionsthat are fully staffed, enabling newcomers who must be added to the team to “getup to speed.” Those individuals who are leaving are asked to stop all work and spendtheir last weeks in “knowledge transfer mode.” This might include video-basedknowledge capture, the development of “commentary documents or Wikis,” and/ormeeting with other team members who will remain on the project.It is important to note that risk mitigation, monitoring, and management (RMMM)steps incur additional project cost. For example, spending the time to back up everycritical technologist costs money. Part of risk management, therefore, is to evaluatewhen the benefits accrued by the RMMM steps are outweighed by the costs associ-ated with implementing them. In essence, you perform a classic cost-benefit analy-sis. If risk aversion steps for high turnover will increase both project cost andduration by an estimated 15 percent, but the predominant cost factor is “backup,”management may decide not to implement this step. On the other hand, if the riskaversion steps are projected to increase costs by 5 percent and duration by only3 percent, management will likely put all into place.756 PART FOURMANAGING SOFTWARE PROJECTS
If RE for a specific riskis less than the cost ofrisk mitigation, don'ttry to mitigate the riskbut continue tomonitor it.pre75977_ch28.qxd  11/27/08  6:30 PM  Page 756For a large project, 30 or 40 risks may be identified. If between three and sevenrisk management steps are identified for each, risk management may become a proj-ect in itself! For this reason, you should adapt the Pareto 80–20 rule to software risk.Experience indicates that 80 percent of the overall project risk (i.e., 80 percent of thepotential for project failure) can be accounted for by only 20 percent of the identifiedrisks. The work performed during earlier risk analysis steps will help you to deter-mine which of the risks reside in that 20 percent (e.g., risks that lead to the highestrisk exposure). For this reason, some of the risks identified, assessed, and projectedmay not make it into the RMMM plan—they don’t fall into the critical 20 percent (therisks with highest project priority).Risk is not limited to the software project itself. Risks can occur after the softwarehas been successfully developed and delivered to the customer. These risks are typ-ically associated with the consequences of software failure in the field.Software safety and hazard analysis(e.g., [Dun02], [Her00], [Lev95]) are softwarequality assurance activities (Chapter 16) that focus on the identification and assess-ment of potential hazards that may affect software negatively and cause an entiresystem to fail. If hazards can be identified early in the software engineering process,software design features can be specified that will either eliminate or control poten-tial hazards.
28.7 T HERMMM P LAN
A risk management strategy can be included in the software project plan, or the riskmanagement steps can be organized into a separate risk mitigation, monitoring, and management plan(RMMM).The RMMM plan documents all work performed as partof risk analysis and is used by the project manager as part of the overall projectplan.Some software teams do not develop a formal RMMM document. Rather, eachrisk is documented individually using a risk information sheet (RIS) [Wil97]. In most cases, the RIS is maintained using a database system so that creation and informa-tion entry, priority ordering, searches, and other analysis may be accomplished eas-ily. The format of the RIS is illustrated in Figure 28.4.Once RMMM has been documented and the project has begun, risk mitigation andmonitoring steps commence. As I have already discussed, risk mitigation is a prob-lem avoidance activity. Risk monitoring is a project tracking activity with three pri-mary objectives: (1) to assess whether predicted risks do, in fact, occur; (2) to ensurethat risk aversion steps defined for the risk are being properly applied; and (3) to col-lect information that can be used for future risk analysis. In many cases, the prob-lems that occur during a project can be traced to more than one risk. Another job ofrisk monitoring is to attempt to allocate origin [what risk(s) caused which problemsthroughout the project].CHAPTER 28RISK MANAGEMENT 757pre75977_ch28.qxd  11/27/08  6:30 PM  Page 757758 PART FOURMANAGING SOFTWARE PROJECTS
Risk Management
Objective:The objective of risk managementtools is to assist a project team in defining risks,assessing their impact and probability, and tracking risksthroughout a software project.Mechanics:In general, risk management tools assist ingeneric risk identification by providing a list of typicalproject and business risks, provide checklists or other“interview” techniques that assist in identifying projectspecific risks, assign probability and impact to each risk,support risk mitigation strategies, and generate manydifferent risk-related reports.Representative Tools:4
@risk,developed by Palisade Corporation (www.palisade.com), is a generic risk analysis tool thatuses Monte Carlo simulation to drive its analytical engine. Riskman,distributed by ABS Consulting(www.absconsulting.com/riskmansoftware/index.html), is a risk evaluation expert system thatidentifies project-related risks.Risk Radar,developed by SPMN (www.spmn.com),assists project managers in identifying and managingproject risks.SOFTWARE TOOLS
4 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.Risk information sheet
Date:  5/9/09 Prob:  80% Impact: highRisk ID:  P02-4-32
Description:
Only 70 percent of the software components scheduled for reuse will, in fact, beintegrated into the application.  The remaining functionality will have to be custom developed.
Refinement/context:
Subcondition 1: Certain reusable components were developed by a third party with no knowledge of internal design standards. Subcondition 2: The design standard for component interfaces has not been solidified and may not conform to certain existing reusable components.Subcondition 3:  Certain reusable components have been implemented in a language that is not supported on the target environment.
Mitigation/monitoring:
1.  Contact third party to determine conformance with design standards.2.  Press for interface standards completion; consider component structure when deciding on interface protocol.3.  Check to determine number of components in subcondition 3 category; check to determine if language support can be acquired.
Management/contingency plan/trigger:
RE computed to be $20,200. Allocate this amount within project contingency cost. Develop revised schedule assuming that 18 additional components will have to be custom built; allocate staff accordingly.Trigger:  Mitigation steps unproductive as of 7/1/09.
Current status:
5/12/09: Mitigation steps initiated.Originator: D. Gagne  Assigned: B. LasterFIGURE 28.4
Risk informa-tion sheet.Source: [Wil97].pre75977_ch28.qxd  11/27/08  6:30 PM  Page 75828.8 S UMMARY
Whenever a lot is riding on a software project, common sense dictates risk analysis.And yet, most software project managers do it informally and superficially, if they do itat all. The time spent identifying, analyzing, and managing risk pays itself back inmany ways—less upheaval during the project, a greater ability to track and control aproject, and the confidence that comes with planning for problems before they occur.Risk analysis can absorb a significant amount of project planning effort. Identifi-cation, projection, assessment, management, and monitoring all take time. But theeffort is worth it. To quote Sun Tzu, a Chinese general who lived 2500 years ago, “Ifyou know the enemy and know yourself, you need not fear the result of a hundredbattles.” For the software project manager, the enemy is risk.
PROBLEMS AND POINTS TO PONDER
28.1.Provide five examples from other fields that illustrate the problems associated with areactive risk strategy.28.2.Describe the difference between “known risks” and “predictable risks.”28.3.Add three additional questions or topics to each of the risk item checklists presented atthe SEPA website.28.4.You’ve been asked to build software to support a low-cost video editing system. The sys-tem accepts digital video as input, stores the video on disk, and then allows the user to do a widerange of edits to the digitized video. The result can then be output to DVD or other media. Do asmall amount of research on systems of this type and then make a list of technology risks thatyou would face as you begin a project of this type.28.5.You’re the project manager for a major software company. You’ve been asked to lead ateam that’s developing “next generation” word-processing software. Create a risk table for theproject.28.6.Describe the difference between risk components and risk drivers.28.7.Develop a risk mitigation strategy and specific risk mitigation activities for three of therisks noted in Figure 28.2.28.8.Develop a risk monitoring strategy and specific risk monitoring activities for three of therisks noted in Figure 28.2. Be sure to identify the factors that you’ll be monitoring to determinewhether the risk is becoming more or less likely.28.9.Develop a risk management strategy and specific risk management activities for three ofthe risks noted in Figure 28.2.CHAPTER 28RISK MANAGEMENT 759
Risk+,developed by Deltek (www.deltek.com),integrates with Microsoft Project to quantify cost andschedule uncertainty.X:PRIMER,developed by GrafP Technologies(www.grafp.com) is a generic Web-based tool thatpredicts what can go wrong on a project and identifiesroot causes for potential failures and effectivecountermeasures.pre75977_ch28.qxd  11/27/08  6:30 PM  Page 75928.10.Attempt to refine three of the risks noted in Figure 28.2, and then create risk informa-tion sheets for each.28.11.Represent three of the risks noted in Figure 28.2 using a CTC format.28.12.Recompute the risk exposure discussed in Section 28.4.2 when cost/LOC is $16 and theprobability is 60 percent.28.13.Can you think of a situation in which a high-probability, high-impact risk would not beconsidered as part of your RMMM plan?28.14.Describe five software application areas in which software safety and hazard analysiswould be a major concern.
FURTHER READINGS AND INFORMATION SOURCES
The software risk management literature has expanded significantly over the past few decades.Vun (Modeling Risk,Wiley, 2006) presents a detailed mathematical treatment of risk analysis thatcan be applied to software projects. Crohy and his colleagues (The Essentials of Risk Manage-ment,McGraw-Hill, 2006), Mulcahy (Risk Management, Tricks of the Trade for Project Managers, RMC Publications, Inc., 2003), Kendrick ( Identifying and Managing Project Risk, American Management Association, 2003), and Marrison (The Fundamentals of Risk Measurement,McGraw-Hill, 2002) present useful methods and tools that every project manager can use.DeMarco and Lister (Dancing with Bears, Dorset House, 2003) have written an entertaining and insightful book that guides software managers and practitioners through risk management.Moynihan (Coping with IT/IS Risk Management, Springer-Verlag, 2002) presents pragmatic ad- vice from project managers who deal with risk on a continuing basis. Royer (Project Risk Man-agement,Management Concepts, 2002) and Smith and Merritt ( Proactive Risk Management, Productivity Press, 2002) suggest a proactive process for risk management. Karolak ( Software Engineering Risk Management,Wiley, 2002) has written a guidebook that introduces an easy-to-use risk analysis model with worthwhile checklists and questionnaires supported by a softwarepackage.Capers Jones (Assessment and Control of Software Risks, Prentice Hall, 1994) presents a de- tailed discussion of software risks that includes data collected from hundreds of software proj-ects. Jones defines 60 risk factors that can affect the outcome of software projects. Boehm[Boe89] suggests excellent questionnaire and checklist formats that can prove invaluable inidentifying risk. Charette [Cha89] presents a detailed treatment of the mechanics of risk analy-sis, calling on probability theory and statistical techniques to analyze risks. In a companion vol-ume, Charette (Application Strategies for Risk Analysis, McGraw-Hill, 1990) discusses risk in the context of both system and software engineering and suggests pragmatic strategies for riskmanagement. Gilb (Principles of Software Engineering Management, Addison-Wesley, 1988) pres- ents a set of “principles” (which are often amusing and sometimes profound) that can serve asa worthwhile guide for risk management.Ewusi-Mensah (Software Development Failures: Anatomy of Abandoned Projects, MIT Press, 2003) and Yourdon (Death March,Prentice Hall, 1997) discuss what happens when risks over- whelm a software project team. Bernstein (Against the Gods, Wiley, 1998) presents an enter- taining history of risk that goes back to ancient times.The Software Engineering Institute has published many detailed reports and guidebooks onrisk analysis and management. The Air Force Systems Command pamphlet AFSCP 800-45[AFC88] describes risk identification and reduction techniques. Every issue of the ACM Software Engineering Noteshas a section entitled “Risks to the Public” (editor, P. G. Neumann). If you wantthe latest and best software horror stories, this is the place to go.A wide variety of information sources on software risk management is available on theInternet. An up-to-date list of World Wide Web references relevant to risk management can befound at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.760 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch28.qxd  11/27/08  6:30 PM  Page 760Regardless of its application domain, its size, or its complexity, computersoftware will evolve over time. Change drives this process. For computersoftware, change occurs when errors are corrected, when the software isadapted to a new environment, when the customer requests new features orfunctions, and when the application is reengineered to provide benefit in a mod-ern context. Over the past 30 years, Manny Lehman [e.g., Leh97a] and hiscolleagues have performed detailed analyses of industry-grade software and
761CHAPTER
29MAINTENANCE AND
REENGINEERING
What is it? Consider any technol-ogy product that has served you well.You use it regularly, but it’s gettingold. It breaks too often, takes longerto repair than you’d like, and no longer repre-sents the newest technology. What to do? For atime, you try to fix it, patch it, even extend itsfunctionality. That’s called maintenance. Butmaintenance becomes increasingly difficult asthe years pass. There comes a time when you’llneed to rebuild it. You’ll create a product withadded functionality, better performance andreliability, and improved maintainability. That’swhat we call reengineering.
Who does it? At an organizational level, mainte-nance is performed by support staff that arepart of the software engineering organization.Reengineering is performed by business special-ists (often consulting companies), and at the soft-ware level, reengineering is performed bysoftware engineers.
Why is it important? We live in a rapidly chang-ing world. The demands on business functionsand the information technology that supportsthem are changing at a pace that puts enormouscompetitive pressure on every commercialorganization. That’s why software must be main-tained continually, and at the appropriate time,reengineered to keep pace.QUICK
LOOKWhat are the steps? Maintenance correctsdefects, adapts the software to meet a changingenvironment, and enhances functionality to meetthe evolving needs of customers. At a strategiclevel, business process reengineering (BPR)defines business goals, identifies and evaluatesexisting business processes, and creates revisedbusiness processes that better meet currentgoals. Software reengineering encompassesinventory analysis, document restructuring,reverse engineering, program and data restruc-turing, and forward engineering. The intent ofthese activities is to create versions of existingprograms that exhibit higher quality and bettermaintainability.
What is the work product? A variety of mainte-nance and reengineering work products (e.g.,use cases, analysis and design models, test pro-cedures) are produced. The final output isupgraded software.
How do I ensure that I’ve done it right? Use thesame SQA practices that are applied in everysoftware engineering process—technical re-views assess the analysis and design models;specialized reviews consider business applica-bility and compatibility; and testing is applied touncover errors in content, functionality, andinteroperability.KEY
CONCEPTS
business processreengineering (BPR) . . . . . . . .765documentrestructuring  . .770pre75977_ch29.qxd  11/27/08  6:32 PM  Page 761systems in an effort to develop a unified theory for software evolution. The details of this work are beyond the scope of this book, but the underlying laws that have beenderived are worthy of note [Leh97b]:
The Law of Continuing Change (1974): Software that has been implemented in a real- world computing context and will therefore evolve over time (called E-type systems) mustbe continually adapted else they become progressively less satisfactory.The Law of Increasing Complexity (1974): As an E-type system evolves its complexity increases unless work is done to maintain or reduce it.The Law of Self Regulation (1974): The E-type system evolution process is self- regulating with distribution of product and process measures close to normal.The Law of Conservation of Organizational Stability (1980): The average effective global activity rate in an evolving E-type system is invariant over product lifetime.The Law of Conservation of Familiarity (1980): As an E-type system evolves all associated with it, developers, sales personnel, users, for example, must maintainmastery of its content and behavior to achieve satisfactory evolution. Excessive growthdiminishes that mastery. Hence the average incremental growth remains invariant as thesystem evolves.The Law of Continuing Growth (1980): The functional content of E-type systems must be continually increased to maintain user satisfaction over their lifetime.The Law of Declining Quality (1996): The quality of E-type systems will appear to be declining unless they are rigorously maintained and adapted to operational environ-ment changes.The Feedback System Law (1996): E-type evolution processes constitute multi- level, multi-loop, multi-agent feedback systems and must be treated as such to achievesignificant improvement over any reasonable base.
The laws that Lehman and his colleagues have defined are an inherent part of a soft-ware engineer’s reality. In this chapter, I’ll discuss the challenge of software mainte-nance and the reengineering activities that are required to extend the effective life oflegacy systems.
29.1 S OFTWARE MAINTENANCE
It begins almost immediately. Software is released to end users, and within days, bugreports filter back to the software engineering organization. Within weeks, one classof users indicates that the software must be changed so that it can accommodate thespecial needs of their environment. And within months, another corporate groupwho wanted nothing to do with the software when it was released now recognizesthat it may provide them with unexpected benefit. They’ll need a few enhancementsto make it work in their world.The challenge of software maintenance has begun. You’re faced with a growingqueue of bug fixes, adaptation requests, and outright enhancements that must be762 PART FOURMANAGING SOFTWARE PROJECTS
forward engineering  . . .778inventory analysis  . . . . . .770maintainability . .763restructuring  . .776code . . . . . . . .776data . . . . . . . .777reverseengineering  . . .772data . . . . . . . .773processing  . . .774user interface . .775softwaremaintenance  . . .762softwarereengineering  . .768supportability . .764
How dolegacysystems evolve astime passes??pre75977_ch29.qxd  11/27/08  6:32 PM  Page 762planned, scheduled, and ultimately accomplished. Before long, the queue has grownlong and the work it implies threatens to overwhelm the available resources. As timepasses, your organization finds that it’s spending more money and time maintainingexisting programs than it is engineering new applications. In fact, it’s not unusual fora software organization to expend as much as 60 to 70 percent of all resources onsoftware maintenance.You may ask why so much maintenance is required and why so much effort isexpended. Osborne and Chikofsky [Osb90] provide a partial answer:
Much of the software we depend on today is on average 10 to 15 years old. Even whenthese programs were created using the best design and coding techniques known at thetime [and most were not], they were created when program size and storage space wereprinciple concerns. They were then migrated to new platforms, adjusted for changes inmachine and operating system technology and enhanced to meet new user needs—allwithout enough regard to overall architecture. The result is the poorly designed struc-tures, poor coding, poor logic, and poor documentation of the software systems we arenow called on to keep running . . .
Another reason for the software maintenance problem is the mobility of softwarepeople. It is likely that the software team (or person) that did the original work is nolonger around. Worse, other generations of software people have modified thesystem and moved on. And today, there may be no one left who has any directknowledge of the legacy system.As I noted in Chapter 22, the ubiquitous nature of change underlies all softwarework. Change is inevitable when computer-based systems are built; therefore, youmust develop mechanisms for evaluating, controlling, and making modifications.Throughout this book, I’ve emphasized the importance of understanding theproblem (analysis) and developing a well-structured solution (design). In fact, Part 2of the book is dedicated to the mechanics of these software engineering actions, andPart 3 focuses on the techniques required to be sure you’ve done them correctly. Bothanalysis and design lead to an important software characteristic that we call main-tainability. In essence, maintainabilityis a qualitative indication
1of the ease with which existing software can be corrected, adapted, or enhanced. Much of what soft-ware engineering is about is building systems that exhibit high maintainability.But what is maintainability? Maintainable software exhibits effective modularity(Chapter 8). It makes use of design patterns (Chapter 12) that allow ease of under-standing. It has been constructed using well-defined coding standards and conven-tions, leading to source code that is self-documenting and understandable. It hasundergone a variety of quality assurance techniques (Part 3 of this book) that haveuncovered potential maintenance problems before the software is released. It hasbeen created by software engineers who recognize that they may not be aroundCHAPTER 29MAINTENANCE AND REENGINEERING 763
uote:
“Programmaintainabilityand programunderstandabilityare parallelconcepts: the moredifficult a programis to understand,the more difficult itis to maintain.Gerald Berns
1 There are some quantitative measures that provide an indirect indication of maintainability (e.g.,[Sch99], [SEI02]).pre75977_ch29.qxd  11/27/08  6:32 PM  Page 763when changes must be made. Therefore, the design and implementation of the soft-ware must “assist” the person who is making the change.
29.2 S OFTWARE SUPPORTABILITY
In order to effectively support industry-grade software, your organization (or itsdesignee) must be capable of making the corrections, adaptations, and enhance-ments that are part of the maintenance activity. But in addition, the organizationmust provide other important support activities that include ongoing operationalsupport, end-user support, and reengineering activities over the complete life cycleof the software. A reasonable definition of software supportability is
. . . the capability of supporting a software system over its whole product life. This impliessatisfying any necessary needs or requirements, but also the provision of equipment,support infrastructure, additional software, facilities, manpower, or any other resourcerequired to maintain the software operational and capable of satisfying its function [SSO08].
In essence, supportability is one of many quality factors that should be consideredduring the analysis and design actions that are part of the software process. It shouldbe addressed as part of the requirements model (or specification) and considered asthe design evolves and construction commences.For example, the need to “antibug” software at the component and code level hasbeen discussed earlier in the book. The software should contain facilities to assistsupport personnel when a defect is encountered in the operational environment (andmake no mistake, defects willbe encountered). In addition, support personnel shouldhave access to a database that contains records of all defects that have already beenencountered—their characteristics, cause, and cure. This will enable support per-sonnel to examine “similar” defects and may provide a means for more rapid diag-nosis and correction.Although defects encountered in an application are a critical support issue, sup-portability also demands that resources be provided to support day-to-day end-userissues. The job of end-user support personnel is to answer user queries about theinstallation, operation, and use of the application.
29.3 R EENGINEERING
In a seminal article written for the Harvard Business Review, Michael Hammer [Ham90] laid the foundation for a revolution in management thinking about businessprocesses and computing:
It is time to stop paving the cow paths. Instead of embedding outdated processes insilicon and software, we should obliterate them and start over. We should “reengineer”our businesses: use the power of modern information technology to radically redesignour business processes in order to achieve dramatic improvements in their performance.764 PART FOURMANAGING SOFTWARE PROJECTS
WebRef
A wide array ofdownloadabledocuments on softwaresupportability can befound atwww.software-supportability.org/Downloads.html.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 764Every company operates according to a great many unarticulated rules. . . . Reengi- neering strives to break away from the old rules about how we organize and conduct ourbusiness.
Like all revolutions, Hammer’s call to arms resulted in both positive and negativechanges. During the 1990s, some companies made a legitimate effort to reengineer,and the results led to improved competitiveness. Others relied solely on downsizingand outsourcing (instead of reengineering) to improve their bottom line. “Mean”organizations with little potential for future growth often resulted [DeM95a].By the end of the first decade of the twenty-first century, the hype associatedwith reengineering waned, but the process itself continues in companies large andsmall. The nexus between business reengineering and software engineering lies ina “system view.”Software is often the realization of the business rules that Hammer discusses.Today, major companies have tens of thousands of computer programs that supportthe “old business rules.” As managers work to modify the rules to achieve greatereffectiveness and competitiveness, software must keep pace. In some cases, thismeans the creation of major new computer-based systems.
2But in many others, it means the modification or rebuilding of existing applications.In the sections that follow, I examine reengineering in a top-down manner, begin-ning with a brief overview of business process reengineering and proceeding to a moredetailed discussion of the technical activities that occur when software is reengineered.
29.4 B USINESS PROCESS REENGINEERING
Business process reengineering(BPR) extends far beyond the scope of informationtechnologies and software engineering. Among the many definitions (most some-what abstract) that have been suggested for BPR is one published in Fortune Magazine[Ste93]: “the search for, and the implementation of, radical change in busi-ness process to achieve breakthrough results.” But how is the search conducted, andhow is the implementation achieved? More important, how can we ensure that the“radical change” suggested will in fact lead to “breakthrough results” instead oforganizational chaos?
29.4.1 Business Processes
A business process is “a set of logically related tasks performed to achieve a definedbusiness outcome” [Dav90]. Within the business process, people, equipment, mate-rial resources, and business procedures are combined to produce a specified result.Examples of business processes include designing a new product, purchasing serv-ices and supplies, hiring a new employee, and paying suppliers. Each demands a setof tasks, and each draws on diverse resources within the business.CHAPTER 29MAINTENANCE AND REENGINEERING 765
uote:
“To face tomorrowwith the thought ofusing the methodsof yesterday is toenvision life at astandstill.”James Bell
2 The explosion of Web-based applications and systems is indicative of this trend.BPR often results innew software function-ality, whereas softwarereengineering works toreplace existing soft-ware functionality withbetter, more maintain-able software.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 765Every business process has a defined customer—a person or group that receivesthe outcome (e.g., an idea, a report, a design, a service, a product). In addition, busi-ness processes cross organizational boundaries. They require that different organi-zational groups participate in the “logically related tasks” that define the process.Every system is actually a hierarchy of subsystems. A business is no exception.The overall business is segmented in the following manner:The businessãbusiness systemsãbusiness processesãbusiness subprocessesEach business system (also called business function) is composed of one or morebusiness processes, and each business process is defined by a set of subprocesses.BPR can be applied at any level of the hierarchy, but as the scope of BPR broadens(i.e., as we move upward in the hierarchy), the risks associated with BPR growdramatically. For this reason, most BPR efforts focus on individual processes orsubprocesses.
29.4.2 A BPR Model
Like most engineering activities, business process reengineering is iterative. Busi-ness goals and the processes that achieve them must be adapted to a changing busi-ness environment. For this reason, there is no start and end to BPR—it is anevolutionary process. A model for business process reengineering is depicted inFigure 29.1. The model defines six activities:Business definition.Business goals are identified within the context of fourkey drivers: cost reduction, time reduction, quality improvement, and personnel766 PART FOURMANAGING SOFTWARE PROJECTS
As a softwareengineer, your workoccurs at the bottomof this hierarchy. Besure, however, thatsomeone has givenserious thought to thelevels above. If thishasn’t been done, yourwork is at risk.
Businessdefinition
Refinement &instantiation
Prototyping
Processspecificationand designProcessidentification
ProcessevaluationFIGURE 29.1
A BPR modelpre75977_ch29.qxd  11/27/08  6:32 PM  Page 766development and empowerment. Goals may be defined at the business levelor for a specific component of the business.Process identification.Processes that are critical to achieving the goalsdefined in the business definition are identified. They may then be ranked byimportance, by need for change, or in any other way that is appropriate forthe reengineering activity.Process evaluation.The existing process is thoroughly analyzed andmeasured. Process tasks are identified; the costs and time consumed byprocess tasks are noted; and quality/performance problems are isolated.Process specification and design.Based on information obtained duringthe first three BPR activities, use cases (Chapters 5 and 6) are prepared for eachprocess that is to be redesigned. Within the context of BPR, use cases identify ascenario that delivers some outcome to a customer. With the use case as thespecification of the process, a new set of tasks are designed for the process.Prototyping.A redesigned business process must be prototyped before itis fully integrated into the business. This activity “tests” the process so thatrefinements can be made.Refinement and instantiation.Based on feedback from the prototype, thebusiness process is refined and then instantiated within a business system.These BPR activities are sometimes used in conjunction with workflow analysistools. The intent of these tools is to build a model of existing workflow in an effort tobetter analyze existing processes.CHAPTER 29MAINTENANCE AND REENGINEERING 767
uote:
“As soon as we areshown somethingold in a new thing,we are pacified.”F. W. Nietzsche
Business Process Reengineering (BPR)
Objective:The objective of BPR tools is tosupport the analysis and assessment of existingbusiness processes and the specification and design ofnew ones.Mechanics:Tools mechanics vary. In general, BPR toolsallow a business analyst to model existing businessprocesses in an effort to assess workflow inefficienciesor functional problems. Once existing problems areidentified, tools allow the analysis to prototype and/orsimulate revised business processes.Representative Tools:3
Extend,developed by ImagineThat, Inc.(www.imaginethatinc.com), is a simulation toolfor modeling existing processes and exploring newones. Extend provides comprehensive what-ifcapability that enables a business analysis to exploredifferent process scenarios.e-Work,developed by Metastorm(www.metastorm.com), provides businessprocess management support for both manual andautomated processes.SOFTWARE TOOLS
3 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 76729.5 S OFTWARE REENGINEERING
The scenario is all too common: An application has served the business needs of acompany for 10 or 15 years. During that time it has been corrected, adapted, and en-hanced many times. People approached this work with the best intentions, but goodsoftware engineering practices were always shunted to the side (due to the press ofother matters). Now the application is unstable. It still works, but every time a changeis attempted, unexpected and serious side effects occur. Yet the application mustcontinue to evolve. What to do?Unmaintainable software is not a new problem. In fact, the broadening emphasison software reengineering has been spawned by software maintenance problemsthat have been building for more than four decades.
29.5.1 A Software Reengineering Process Model
Reengineering takes time, it costs significant amounts of money, and it absorbs re-sources that might be otherwise occupied on immediate concerns. For all of thesereasons, reengineering is not accomplished in a few months or even a few years.Reengineering of information systems is an activity that will absorb informationtechnology resources for many years. That’s why every organization needs a prag-matic strategy for software reengineering.A workable strategy is encompassed in a reengineering process model. I’ll discussthe model later in this section, but first, some basic principles.Reengineering is a rebuilding activity. To better understand it, consider an analo-gous activity: the rebuilding of a house. Consider the following situation. You’ve pur-chased a house in another state. You’ve never actually seen the property, but youacquired it at an amazingly low price, with the warning that it might have to be com-pletely rebuilt. How would you proceed?
•Before you can start rebuilding, it would seem reasonable to inspect thehouse. To determine whether it is in need of rebuilding, you (or a profes-sional inspector) would create a list of criteria so that your inspection wouldbe systematic.768 PART FOURMANAGING SOFTWARE PROJECTS
IceTools,developed by Blue Ice (www.blueice.com), isa collection of BPR templates for Microsoft Office andMicrosoft Project.SpeeDev,developed by SpeeDev Inc.(www.speedev.com), is one of many tools thatenable an organization to model process workflow(in this case, IT workflow).Workflow tool suite,developed by MetaSoftware(www.metasoftware.com), incorporates a suite oftools for workflow modeling, simulation, and scheduling.A useful list of BPR tool links can be found atwww.opfro.org/index.html?Components/Producers/Tools/BusinessProcessReengineeringTools.html~Contents.
WebRef
An excellent sourceof information onsoftware reengineeringcan be found atreengineer.org.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 768•Before you tear down and rebuild the entire house, be sure that the structureis weak. If the house is structurally sound, it may be possible to “remodel”without rebuilding (at much lower cost and in much less time).
•Before you start rebuilding be sure you understand how the original wasbuilt. Take a peek behind the walls. Understand the wiring, the plumbing,and the structural internals. Even if you trash them all, the insight you’ll gainwill serve you well when you start construction.
•If you begin to rebuild, use only the most modern, long-lasting materials.This may cost a bit more now, but it will help you to avoid expensive andtime-consuming maintenance later.
•If you decide to rebuild, be disciplined about it. Use practices that will resultin high quality—today and in the future.Although these principles focus on the rebuilding of a house, they apply equally wellto the reengineering of computer-based systems and applications.To implement these principles, you can use a software reengineering processmodel that defines six activities, shown in Figure 29.2. In some cases, these activi-ties occur in a linear sequence, but this is not always the case. For example, it maybe that reverse engineering (understanding the internal workings of a program) mayhave to occur before document restructuring can commence.CHAPTER 29MAINTENANCE AND REENGINEERING 769
Forwardengineering
Documentrestructuring
ReverseengineeringInventoryanalysis
Datarestructuring
CoderestructuringFIGURE 29.2
A softwarereengineeringprocess modelpre75977_ch29.qxd  11/27/08  6:32 PM  Page 76929.5.2 Software Reengineering Activities
The reengineering paradigm shown in Figure 29.2 is a cyclical model. This meansthat each of the activities presented as a part of the paradigm may be revisited.For any particular cycle, the process can terminate after any one of theseactivities.Inventory analysis.Every software organization should have an inventory of allapplications. The inventory can be nothing more than a spreadsheet model contain-ing information that provides a detailed description (e.g., size, age, business critical-ity) of every active application. By sorting this information according to businesscriticality, longevity, current maintainability and supportability, and other locallyimportant criteria, candidates for reengineering appear. Resources can then beallocated to candidate applications for reengineering work.It is important to note that the inventory should be revisited on a regular cycle.The status of applications (e.g., business criticality) can change as a function of time,and as a result, priorities for reengineering will shift.Document restructuring.Weak documentation is the trademark of many legacysystems. But what can you do about it? What are your options?1.Creating documentation is far too time consuming. If the system works, you may choose to live with what you have. In some cases, this is the correctapproach. It is not possible to re-create documentation for hundreds of com-puter programs. If a program is relatively static, is coming to the end of itsuseful life, and is unlikely to undergo significant change, let it be!2.Documentation must be updated, but your organization has limited resources.You’ll use a “document when touched” approach. It may not be necessary tofully redocument an application. Rather, those portions of the system that arecurrently undergoing change are fully documented. Over time, a collection ofuseful and relevant documentation will evolve.3.The system is business critical and must be fully redocumented. Even in this case, an intelligent approach is to pare documentation to an essentialminimum.Each of these options is viable. Your software organization must choose the one thatis most appropriate for each case.Reverse engineering.The term reverse engineeringhas its origins in the hardware world. A company disassembles a competitive hardware product in an effort tounderstand its competitor’s design and manufacturing “secrets.” These secrets couldbe easily understood if the competitor’s design and manufacturing specificationswere obtained. But these documents are proprietary and unavailable to the companydoing the reverse engineering. In essence, successful reverse engineering derives770 PART FOURMANAGING SOFTWARE PROJECTS
If time and resourcesare in short supply,you might considerapplying the Paretoprinciple to thesoftware that is to bereengineered. Applythe reengineeringprocess to the20 percent of thesoftware that accountsfor 80 percent of theproblems.
Create only as muchdocumentation as youneed to understand thesoftware, not one pagemore.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 770one or more design and manufacturing specifications for a product by examiningactual specimens of the product.Reverse engineering for software is quite similar. In most cases, however, the pro-gram to be reverse engineered is not a competitor’s. Rather, it is the company’s ownwork (often done many years earlier). The “secrets” to be understood are obscurebecause no specification was ever developed. Therefore, reverse engineering forsoftware is the process of analyzing a program in an effort to create a representationof the program at a higher level of abstraction than source code. Reverse engineer-ing is a process of design recovery. Reverse engineering tools extract data, architec-tural, and procedural design information from an existing program.Code restructuring.The most common type of reengineering (actually, the use ofthe term reengineering is questionable in this case) is code restructuring.
4Some legacy systems have a relatively solid program architecture, but individual moduleswere coded in a way that makes them difficult to understand, test, and maintain. Insuch cases, the code within the suspect modules can be restructured.To accomplish this activity, the source code is analyzed using a restructuringtool. Violations of structured programming constructs are noted and code is thenrestructured (this can be done automatically) or even rewritten in a more modernprogramming language. The resultant restructured code is reviewed and tested toensure that no anomalies have been introduced. Internal code documentation isupdated.Data restructuring.A program with weak data architecture will be difficult toadapt and enhance. In fact, for many applications, information architecture has moreto do with the long-term viability of a program than the source code itself.Unlike code restructuring, which occurs at a relatively low level of abstraction,data restructuring is a full-scale reengineering activity. In most cases, data restruc-turing begins with a reverse engineering activity. Current data architecture is dis-sected, and necessary data models are defined (Chapters 6 and 9). Data objects andattributes are identified, and existing data structures are reviewed for quality.When data structure is weak (e.g., flat files are currently implemented, when arelational approach would greatly simplify processing), the data are reengineered.Because data architecture has a strong influence on program architecture and thealgorithms that populate it, changes to the data will invariably result in either archi-tectural or code-level changes.Forward engineering.In an ideal world, applications would be rebuilt using anautomated “reengineering engine.” The old program would be fed into the engine,analyzed, restructured, and then regenerated in a form that exhibited the bestCHAPTER 29MAINTENANCE AND REENGINEERING 771
WebRef
An array of resourcesfor the reengineeringcommunity can beobtained atwww.comp.lancs.ac.uk/projects/RenaissanceWeb/.
4 Code restructuring has some of the elements of “refactoring,” a redesign concept introduced inChapter 8 and discussed elsewhere in this book.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 771aspects of software quality. In the short term, it is unlikely that such an “engine” willappear, but vendors have introduced tools that provide a limited subset of thesecapabilities that addresses specific application domains (e.g., applications that areimplemented using a specific database system). More important, these reengineer-ing tools are becoming increasingly more sophisticated.Forward engineering not only recovers design information from existing softwarebut uses this information to alter or reconstitute the existing system in an effort toimprove its overall quality. In most cases, reengineered software reimplements thefunction of the existing system and also adds new functions and/or improves over-all performance.
29.6 R EVERSE ENGINEERING
Reverse engineering conjures an image of the “magic slot.” You feed a haphazardlydesigned, undocumented source file into the slot and out the other end comesa complete design description (and full documentation) for the computer program.Unfortunately, the magic slot doesn’t exist. Reverse engineering can extract designinformation from source code, but the abstraction level, the completeness of the doc-umentation, the degree to which tools and a human analyst work together, and thedirectionality of the process are highly variable.The abstraction levelof a reverse engineering process and the tools used to effectit refers to the sophistication of the design information that can be extracted fromsource code. Ideally, the abstraction level should be as high as possible. That is, thereverse engineering process should be capable of deriving procedural design repre-sentations (a low-level abstraction), program and data structure information(a somewhat higher level of abstraction), object models, data and/or control flowmodels (a relatively high level of abstraction), and entity relationship models (a highlevel of abstraction). As the abstraction level increases, you are provided with infor-mation that will allow easier understanding of the program.The completenessof a reverse engineering process refers to the level of detail thatis provided at an abstraction level. In most cases, the completeness decreases as theabstraction level increases. For example, given a source code listing, it is relativelyeasy to develop a complete procedural design representation. Simple architecturaldesign representations may also be derived, but it is far more difficult to develop acomplete set of UML diagrams or models.Completeness improves in direct proportion to the amount of analysis performedby the person doing reverse engineering. Interactivity refers to the degree to which the human is “integrated” with automated tools to create an effective reverse engi-neering process. In most cases, as the abstraction level increases, interactivity mustincrease or completeness will suffer.If the directionalityof the reverse engineering process is one-way, all informa-tion extracted from the source code is provided to the software engineer who can772 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch29.qxd  11/27/08  6:32 PM  Page 772then use it during any maintenance activity. If directionality is two-way, the infor-mation is fed to a reengineering tool that attempts to restructure or regenerate theold program.The reverse engineering process is represented in Figure 29.3. Before reverseengineering activities can commence, unstructured (“dirty”) source code is restruc-tured (Section 29.5.1) so that it contains only the structured programming con-structs.
5This makes the source code easier to read and provides the basis for all thesubsequent reverse engineering activities.The core of reverse engineering is an activity called extract abstractions. You mustevaluate the old program and from the (often undocumented) source code, developa meaningful specification of the processing that is performed, the user interface thatis applied, and the program data structures or database that is used.
29.6.1 Reverse Engineering to Understand Data
Reverse engineering of data occurs at different levels of abstraction and is often thefirst reengineering task. At the program level, internal program data structuresmust often be reverse engineered as part of an overall reengineering effort. At thesystem level, global data structures (e.g., files, databases) are often reengineeredto accommodate new database management paradigms (e.g., the move from flatfile to relational or object-oriented database systems). Reverse engineering of theCHAPTER 29MAINTENANCE AND REENGINEERING 773
WebRef
Useful resources for“design recovery andprogram understanding”can be found atwwwsel.iit.nrc.ca/projects/dr/dr.html.Refine &simplifyFinal specificationExtractabstractionsInitial specificationRestructurecodeClean source codeDirty source code
DatabaseInterfaceProcessingFIGURE 29.3
The reverseengineeringprocess
5 Code can be restructured using a restructuring engine—a tool that restructures source code.In some cases, the firstreengineering activityattempts to construct aUML class diagram.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 773current global data structures sets the stage for the introduction of a new sys-temwide database.Internal data structures.Reverse engineering techniques for internal programdata focus on the definition of classes of objects. This is accomplished by examiningthe program code with the intent of grouping related program variables. In manycases, the data organization within the code identifies abstract data types. Forexample, record structures, files, lists, and other data structures often provide aninitial indicator of classes.Database structure.Regardless of its logical organization and physical structure,a database allows the definition of data objects and supports some method forestablishing relationships among the objects. Therefore, reengineering one databaseschema into another requires an understanding of existing objects and theirrelationships.The following steps [Pre94] may be used to define the existing data model as aprecursor to reengineering a new database model: (1) build an initial object model,(2) determine candidate keys (the attributes are examined to determine whetherthey are used to point to another record or table; those that serve as pointersbecome candidate keys), (3) refine the tentative classes, (4) define generalizations,and (5) discover associations using techniques that are analogous to the CRCapproach. Once information defined in the preceding steps is known, a series oftransformations [Pre94] can be applied to map the old database structure into anew database structure.
29.6.2 Reverse Engineering to Understand Processing
Reverse engineering to understand processing begins with an attempt to understandand then extract procedural abstractions represented by the source code. To under-stand procedural abstractions, the code is analyzed at varying levels of abstraction:system, program, component, pattern, and statement.The overall functionality of the entire application system must be understood be-fore more detailed reverse engineering work occurs. This establishes a context forfurther analysis and provides insight into interoperability issues among applicationswithin the system. Each of the programs that make up the application system repre-sents a functional abstraction at a high level of detail. A block diagram, representingthe interaction between these functional abstractions, is created. Each componentperforms some subfunction and represents a defined procedural abstraction. A pro-cessing narrative for each component is developed. In some situations, system,program, and component specifications already exist. When this is the case, thespecifications are reviewed for conformance to existing code.
6774 PART FOURMANAGING SOFTWARE PROJECTS
The approach toreverse engineering fordata for conventionalsoftware follows ananalogous path:(1) build a datamodel, (2) identifyattributes of dataobjects, and (3) definerelationships.
uote:
“There exists apassion forcomprehension,just as there existsa passion formusic. That passionis rather commonin children, butgets lost in mostpeople later on.”Albert Einstein
6 Often, specifications written early in the life history of a program are never updated. As changesare made, the code no longer conforms to the specification.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 774Things become more complex when the code inside a component is considered.You should look for sections of code that represent generic procedural patterns. Inalmost every component, a section of code prepares data for processing (within themodule), a different section of code does the processing, and another section ofcode prepares the results of processing for export from the component. Withineach of these sections, you can encounter smaller patterns; for example, data val-idation and bounds checking often occur within the section of code that preparesdata for processing.For large systems, reverse engineering is generally accomplished using asemiautomated approach. Automated tools can be used to help you understandthe semantics of existing code. The output of this process is then passed torestructuring and forward engineering tools to complete the reengineeringprocess.
29.6.3 Reverse Engineering User Interfaces
Sophisticated GUIs have become de rigueur for computer-based products and sys-tems of every type. Therefore, the redevelopment of user interfaces has become oneof the most common types of reengineering activity. But before a user interface canbe rebuilt, reverse engineering should occur.To fully understand an existing user interface, the structure and behavior of theinterface must be specified. Merlo and his colleagues [Mer93] suggest three basicquestions that must be answered as reverse engineering of the UI commences:
•What are the basic actions (e.g., keystrokes and mouse clicks) that theinterface must process?
•What is a compact description of the behavioral response of the system tothese actions?
•What is meant by a “replacement,” or more precisely, what concept of equiv-alence of interfaces is relevant here?Behavioral modeling notation (Chapter 7) can provide a means for developinganswers to the first two questions. Much of the information necessary to create abehavioral model can be obtained by observing the external manifestation of theexisting interface. But additional information necessary to create the behavioralmodel must be extracted from the code.It is important to note that a replacement GUI may not mirror the old interfaceexactly (in fact, it may be radically different). It is often worthwhile to develop anew interaction metaphor. For example, an old UI requests that a user providea scale factor (ranging from 1 to 10) to shrink or magnify a graphical image. Areengineered GUI might use a slide-bar and mouse to accomplish the samefunction.CHAPTER 29MAINTENANCE AND REENGINEERING 775
How do Iunderstandthe workings ofan existing userinterface??pre75977_ch29.qxd  11/27/08  6:32 PM  Page 77529.7 R ESTRUCTURING
Software restructuring modifies source code and/or data in an effort to make itamenable to future changes. In general, restructuring does not modify the overallprogram architecture. It tends to focus on the design details of individual modulesand on local data structures defined within modules. If the restructuring effortextends beyond module boundaries and encompasses the software architecture,restructuring becomes forward engineering (Section 29.7).Restructuring occurs when the basic architecture of an application is solid,even though technical internals need work. It is initiated when major parts of thesoftware are serviceable and only a subset of all modules and data need extensivemodification.
8
29.7.1 Code Restructuring
Code restructuringis performed to yield a design that produces the same functionbut with higher quality than the original program. In general, code restructuring tech-niques (e.g., Warnier’s logical simplification techniques [War74]) model programlogic using Boolean algebra and then apply a series of transformation rules that yieldrestructured logic. The objective is to take “spaghetti-bowl” code and derive a proce-dural design that conforms to the structured programming philosophy (Chapter 10).Other restructuring techniques have also been proposed for use with reengineer-ing tools. A resource exchange diagram maps each program module and theresources (data types, procedures and variables) that are exchanged between it and776 PART FOURMANAGING SOFTWARE PROJECTS
7 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.8 It is sometimes difficult to make a distinction between extensive restructuring and redevelopment.Both are reengineering.Reverse Engineering
Objective:To help software engineersunderstand the internal design structure ofcomplex programs.Mechanics:In most cases, reverse engineering toolsaccept source code as input and produce a variety ofstructural, procedural, data, and behavioral designrepresentations.Representative Tools:
7
Imagix 4D,developed by Imagix (www.imagix.com),“helps software developers understand complex or legacy C and C++ software” by reverse engineeringand documenting source code.Understand,developed by Scientific Toolworks, Inc.(www.scitools.com), parses Ada, Fortran, C, C++,and Java “to reverse engineer, automaticallydocument, calculate code metrics, and help youunderstand, navigate and maintain source code.”A comprehensive listing of reverse engineering tools canbe found at http://scgwiki.iam.unibe.ch:8080/SCG/370.SOFTWARE TOOLS
Although code restruc-turing can alleviateimmediate problemsassociated withdebugging or smallchanges, it is notreengineering. Realbenefit is achievedonly when data andarchitecture arerestructured.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 776other modules. By creating representations of resource flow, the program architec-ture can be restructured to achieve minimum coupling among modules.
29.7.2 Data Restructuring
Before data restructuring can begin, a reverse engineering activity called analysis ofsource codeshould be conducted. All programming language statements that con-tain data definitions, file descriptions, I/O, and interface descriptions are evaluated.The intent is to extract data items and objects, to get information on data flow, andto understand the existing data structures that have been implemented. This activityis sometimes called data analysis.Once data analysis has been completed, data redesign commences. In its simplest form, a data record standardizationstep clarifies data definitions to achieve consis-tency among data item names or physical record formats within an existing datastructure or file format. Another form of redesign, called data name rationalization,ensures that all data naming conventions conform to local standards and that aliasesare eliminated as data flow through the system.When restructuring moves beyond standardization and rationalization, physicalmodifications to existing data structures are made to make the data design moreeffective. This may mean a translation from one file format to another, or in somecases, translation from one type of database to another.CHAPTER 29MAINTENANCE AND REENGINEERING 777
Software Restructuring
Objective:The objective of restructuring toolsis to transform older unstructured computersoftware into modern programming languages and designstructures.Mechanics:In general, source code is input andtransformed into a better structured program. In somecases, the transformation occurs within the sameprogramming language. In other cases, an olderprogramming language is transformed into a moremodern language.Representative Tools:
9
DMS Software Reengineering Toolkit,developed bySemantic Design (www.semdesigns.com),provides a variety of restructuring capabilities forCOBOL, C/C++, Java, Fortran 90, and VHDL.Clone Doctor,developed by Semantic Designs, Inc.(www.semdesigns.com), analyzes and transformsprograms written in C, C++, Java, or COBOL or anyother text-based computer language.plusFORT,developed by Polyhedron(www.polyhedron.com) is a suite of FORTRANtools that contains capabilities for restructuring poorlydesigned FORTRAN programs into the modernFORTRAN or C standard.Pointers to a variety of reengineering and reverseengineering tools can be found at www.csse.monash.edu/~ipeake/reeng/free-swre-tools.htmlandwww.cs.ualberta.ca/~kenw/toolsdir/all.html.SOFTWARE TOOLS
9 Tools noted here do not represent an endorsement, but rather a sampling of tools in this category.In most cases, tool names are trademarked by their respective developers.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 77729.8 F ORWARD ENGINEERING
A program with control flow that is the graphic equivalent of a bowl of spaghetti,with “modules” that are 2000 statements long, with few meaningful comment linesin 290,000 source statements and no other documentation must be modified toaccommodate changing user requirements. You have the following options:1.You can struggle through modification after modification, fighting the ad hocdesign and tangled source code to implement the necessary changes.2.You can attempt to understand the broader inner workings of the program inan effort to make modifications more effectively.3.You can redesign, recode, and test those portions of the software that requiremodification, applying a software engineering approach to all revisedsegments.4.You can completely redesign, recode, and test the program, using reengi-neering tools to assist you in understanding the current design.There is no single “correct” option. Circumstances may dictate the first option evenif the others are more desirable.Rather than waiting until a maintenance request is received, the development orsupport organization uses the results of inventory analysis to select a program that(1) will remain in use for a preselected number of years, (2) is currently being usedsuccessfully, and (3) is likely to undergo major modification or enhancement in thenear future. Then, option 2, 3, or 4 is applied.At first glance, the suggestion that you redevelop a large program when a work-ing version already exists may seem quite extravagant. Before passing judgment,consider the following points:1.The cost to maintain one line of source code may be 20 to 40 times the costof initial development of that line.2.Redesign of the software architecture (program and/or data structure), usingmodern design concepts, can greatly facilitate future maintenance.3.Because a prototype of the software already exists, development productivityshould be much higher than average.4.The user now has experience with the software. Therefore, new require-ments and the direction of change can be ascertained with greater ease.5.Automated tools for reengineering will facilitate some parts of the job.6.A complete software configuration (documents, programs, and data) willexist upon completion of preventive maintenance.A large in-house software developer (e.g., a business systems software develop-ment group for a large consumer products company) may have 500 to 2000 production778 PART FOURMANAGING SOFTWARE PROJECTS
Whatoptions existwhen we’re facedwith a poorlydesigned andimplementedprogram??
Reengineering is a lotlike getting your teethcleaned. You can thinkof a thousand reasonsto delay it, and you’llget away with procras-tinating for quite awhile. But eventually,your delaying tacticswill come back tocause pain.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 778programs within its domain of responsibility. These programs can be ranked byimportance and then reviewed as candidates for forward engineering.The forward engineering process applies software engineering principles, con-cepts, and methods to re-create an existing application. In most cases, forwardengineering does not simply create a modern equivalent of an older program.Rather, new user and technology requirements are integrated into the reengi-neering effort. The redeveloped program extends the capabilities of the olderapplication.
29.8.1 Forward Engineering for Client-Server Architectures
Over the past few decades, many mainframe applications have been reengineeredto accommodate client-server architectures (including WebApps). In essence, cen-tralized computing resources (including software) are distributed among many clientplatforms. Although a variety of different distributed environments can be designed,the typical mainframe application that is reengineered into a client-server architec-ture has the following features:
•Application functionality migrates to each client computer.
•New GUI interfaces are implemented at the client sites.
•Database functions are allocated to the server.
•Specialized functionality (e.g., compute-intensive analysis) may remain at theserver site.
•New communications, security, archiving, and control requirements must beestablished at both the client and server sites.It is important to note that the migration from mainframe to client-server computingrequires both business and software reengineering. In addition, an “enterprise networkinfrastructure” [Jay94] should be established.Reengineering for client-server applications begins with a thorough analysis ofthe business environment that encompasses the existing mainframe. Three layers ofabstraction can be identified. The database sits at the foundation of a client-server architecture and manages transactions and queries from server applications. Yetthese transactions and queries must be controlled within the context of a set of busi-ness rules (defined by an existing or reengineered business process). Client applica-tions provide targeted functionality to the user community.The functions of the existing database management system and the data archi-tecture of the existing database must be reverse engineered as a precursor to the re-design of the database foundation layer. In some cases a new data model (Chapter 6)is created. In every case, the client-server database is reengineered to ensure thattransactions are executed in a consistent manner, that all updates are performedonly by authorized users, that core business rules are enforced (e.g., before a vendorrecord is deleted, the server ensures that no related accounts payable, contracts, orCHAPTER 29MAINTENANCE AND REENGINEERING 779
In some cases,migration to a client-server architectureshould be approachednot as reengineering,but as a new develop-ment effort. Reengi-neering enters thepicture only whenspecific functionalityfrom the old system isto be integrated intothe new architecture.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 779communications exist for that vendor), that queries can be accommodatedefficiently, and that full archiving capability has been established.The business rules layer represents software resident at both the client and theserver. This software performs control and coordination tasks to ensure that trans-actions and queries between the client application and the database conform to theestablished business process.The client applications layer implements business functions that are required byspecific groups of end users. In many instances, a mainframe application is segmentedinto a number of smaller, reengineered desktop applications. Communication amongthe desktop applications (when necessary) is controlled by the business rules layer.A comprehensive discussion of client-server software design and reengineeringis best left to books dedicated to the subject. If you have further interest, see [Van02],[Cou00], or [Orf99].
29.8.2 Forward Engineering for Object-Oriented Architectures
Object-oriented software engineering has become the development paradigm ofchoice for many software organizations. But what about existing applications thatwere developed using conventional methods? In some cases, the answer is to leavesuch applications “as is.” In others, older applications must be reengineered so thatthey can be easily integrated into large, object-oriented systems.Reengineering conventional software into an object-oriented implementationuses many of the same techniques discussed in Part 2 of this book. First, the existingsoftware is reverse engineered so that appropriate data, functional, and behavioralmodels can be created. If the reengineered system extends the functionality orbehavior of the original application, use cases (Chapters 5 and 6) are created. Thedata models created during reverse engineering are then used in conjunction withCRC modeling (Chapter 6) to establish the basis for the definition of classes. Classhierarchies, object-relationship models, object-behavior models, and subsystemsare defined, and object-oriented design commences.As object-oriented forward engineering progresses from analysis to design, a CBSEprocess model (Chapter 10) can be invoked. If the existing application resides within adomain that is already populated by many object-oriented applications, it is likely thata robust component library exists and can be used during forward engineering.For those classes that must be engineered from scratch, it may be possible toreuse algorithms and data structures from the existing conventional application.However, these must be redesigned to conform to the object-oriented architecture.
29.9 T HEECONOMICS OF REENGINEERING
In a perfect world, every unmaintainable program would be retired immediately, tobe replaced by high-quality, reengineered applications developed using modern soft-ware engineering practices. But we live in a world of limited resources. Reengineer-ing drains resources that can be used for other business purposes. Therefore, before780 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch29.qxd  11/27/08  6:32 PM  Page 780an organization attempts to reengineer an existing application, it should perform acost-benefit analysis.A cost-benefit analysis model for reengineering has been proposed by Sneed[Sne95]. Nine parameters are defined:P
1/H11005current annual maintenance cost for an applicationP
2/H11005current annual operations cost for an applicationP
3/H11005current annual business value of an applicationP
4/H11005predicted annual maintenance cost after reengineeringP
5/H11005predicted annual operations cost after reengineeringP
6/H11005predicted annual business value after reengineeringP
7/H11005estimated reengineering costsP
8/H11005estimated reengineering calendar timeP
9/H11005reengineering risk factor (P9/H110051.0 is nominal)L/H11005expected life of the systemThe cost associated with continuing maintenance of a candidate application (i.e.,reengineering is not performed) can be defined asC
maint /H11005[P3/H11002(P1/H11001P2)] /H11003L (29.1)The costs associated with reengineering are defined using the following relationship:C
reeng /H11005P6/H11002(P4/H11001P5) /H11003(L/H11002P8) /H11002(P7/H11003P9)(29.2) Using the costs presented in Equations (29.1) and (29.2), the overall benefit of reengi-neering can be computed asCost benefit /H11005C
reeng /H11002Cmaint (29.3) The cost-benefit analysis presented in these equations can be performed for all high-priority applications identified during inventory analysis (Section 29.4.2). Thoseapplications that show the highest cost-benefit can be targeted for reengineering,while work on others can be postponed until resources are available.
29.10 S UMMARY
Software maintenance and support are ongoing activities that occur throughout thelife cycle of an application. During these activities, defects are corrected, applicationsare adapted to a changing operational or business environment, enhancements areimplemented at the request of stakeholders, and users are supported as they inte-grate an application into their personal or business workflow.Reengineering occurs at two different levels of abstraction. At the business level,reengineering focuses on the business process with the intent of making changes toimprove competitiveness in some area of the business. At the software level, reengi-neering examines information systems and applications with the intent of restruc-turing or reconstructing them so that they exhibit higher quality.CHAPTER 29MAINTENANCE AND REENGINEERING 781
uote:
“You can pay alittle now, or youcan pay a lot morelater.”Sign in an autodealershipsuggesting atune-up.pre75977_ch29.qxd  11/27/08  6:32 PM  Page 781Business process reengineering defines business goals; identifies and evalu-ates existing business processes (in the context of defined goals); specifies anddesigns revised processes; and prototypes, refines, and instantiates them within abusiness. BPR has a focus that extends beyond software. The result of BPR is oftenthe definition of ways in which information technologies can better support thebusiness.Software reengineering encompasses a series of activities that include inventoryanalysis, document restructuring, reverse engineering, program and data restruc-turing, and forward engineering. The intent of these activities is to create versions ofexisting programs that exhibit higher quality and better maintainability—programsthat will be viable well into the twenty-first century.The cost-benefit of reengineering can be determined quantitatively. The cost of thestatus quo, that is, the cost associated with ongoing support and maintenance of anexisting application, is compared to the projected costs of reengineering and the re-sultant reduction in maintenance and support costs. In almost every case in which aprogram has a long life and currently exhibits poor maintainability or supportability,reengineering represents a cost-effective business strategy.
PROBLEMS AND POINTS TO PONDER
29.1.Consider any job that you’ve held in the last five years. Describe the business process inwhich you played a part. Use the BPR model described in Section 29.4.2 to recommend changesto the process in an effort to make it more efficient.29.2.Do some research on the efficacy of business process reengineering. Present pro and conarguments for this approach.29.3.Your instructor will select one of the programs that everyone in the class has developedduring this course. Exchange your program randomly with someone else in the class. Do notexplain or walk through the program. Now, implement an enhancement (specified by yourinstructor) in the program you have received.a. Perform all software engineering tasks including a brief walkthrough (but not with theauthor of the program).b. Keep careful track of all errors encountered during testing.c. Discuss your experiences in class.29.4.Explore the inventory analysis checklist presented at the SEPA website and attempt todevelop a quantitative software rating system that could be applied to existing programs in aneffort to pick candidate programs for reengineering. Your system should extend beyond theeconomic analysis presented in Section 29.9.29.5.Suggest alternatives to paper and ink or conventional electronic documentation thatcould serve as the basis for document restructuring. (Hint: Think of new descriptive technolo-gies that could be used to communicate the intent of the software.)29.6.Some people believe that artificial intelligence technology will increase the abstractionlevel of the reverse engineering process. Do some research on this subject (i.e., the use of AI forreverse engineering), and write a brief paper that takes a stand on this point.29.7.Why is completeness difficult to achieve as abstraction level increases?29.8.Why must interactivity increase if completeness is to increase?782 PART FOURMANAGING SOFTWARE PROJECTSpre75977_ch29.qxd  11/27/08  6:32 PM  Page 78229.9.Using information obtained via the Web, present characteristics of three reverse engi-neering tools to your class.29.10.There is a subtle difference between restructuring and forward engineering. What is it?29.11.Research the literature and/or Internet sources to find one or more papers that discusscase studies of mainframe to client-server reengineering. Present a summary.29.12.How would you determine P
4through P7in the cost-benefit model presented in Section 29.9?
FURTHER READINGS AND INFORMATION SOURCES
It is ironic that software maintenance and support represent the most costly activities in the lifeof an application, and yet, fewer books have been written about maintenance and support thanany other major software engineering topics. Among recent additions to the literature are booksby Jarzabek (Effective Software Maintenance and Evolution, Auerbach, 2007), Grubb and Takang (Software Maintenance: Concepts and Practice, World Scientific Publishing Co., 2d ed., 2003), and Pigoski (Practical Software Maintenance, Wiley, 1996). These books cover basic maintenance and support practices and present useful management guidance. Maintenance techniques that focuson client-server environments are discussed by Schneberger ( Client/Server Software Mainte- nance,McGraw-Hill, 1997). Current research in “software evolution” is presented in an anthol-ogy edited by Mens and Demeyer (Software Evolution, Springer, 2008). Like many hot topics in the business community, the hype surrounding business processreengineering has given way to a more pragmatic view of the subject. Hammer and Champy(Reengineering the Corporation, HarperBusiness, revised edition, 2003) precipitated early inter-est with their best-selling book. Other books by Smith and Fingar [Business Process Management(BPM): The Third Wave,Meghan-Kiffer Press, 2003], Jacka and Keller (Business Process Mapping:Improving Customer Satisfaction,Wiley, 2001), Sharp and McDermott (Workflow Modeling, Artech House, 2001), Andersen (Business Process Improvement Toolbox, American Society for Quality, 1999), and Harrington et al. (Business Process Improvement Workbook, McGraw-Hill, 1997) pres- ent case studies and detailed guidelines for BPR.Fong (Information Systems Reengineering and Integration, Springer, 2006) describes database conversion techniques, reverse engineering, and forward engineering as they are applied formajor information systems. Demeyer and his colleagues (Object Oriented Reengineering Patterns,Morgan Kaufmann, 2002) provides a patterns-based view of how to refactor and/or reengineerOO systems. Secord and his colleagues (Modernizing Legacy Systems, Addison-Wesley, 2003), Ulrich (Legacy Systems: Transformation Strategies, Prentice Hall, 2002), Valenti (Successful Soft- ware Reengineering,IRM Press, 2002), and Rada (Reengineering Software: How to Reuse Pro-gramming to Build New, State-of-the-Art Software, Fitzroy Dearborn Publishers, 1999) focus on strategies and practices for reengineering at a technical level. Miller (Reengineering Legacy Soft-ware Systems,Digital Press, 1998) “provides a framework for keeping application systems syn-chronized with business strategies and technology changes.”Cameron (Reengineering Business for Success in the Internet Age, Computer Technology Research, 2000) and Umar [Application (Re)Engineering: Building Web-Based Applications andDealing with Legacies,Prentice Hall, 1997] provide worthwhile guidance for organizations thatwant to transform legacy systems into a Web-based environment. Cook (Building EnterpriseInformation Architectures: Reengineering Information Systems, Prentice Hall, 1996) discusses the bridge between BPR and information technology. Aiken ( Data Reverse Engineering,McGraw-Hill, 1996) discusses how to reclaim, reorganize, and reuse organizational data. Arnold (SoftwareReengineering,IEEE Computer Society Press, 1993) has put together an excellent anthology ofearly papers that focus on software reengineering technologies.A wide variety of information sources on software reengineering is available on the Internet.An up-to-date list of World Wide Web references  relevant to software maintenance and reengi-neering can be found atthe SEPA website:www.mhhe.com/engcs/compsci/pressman/ professional/olc/ser.htm.CHAPTER 29MAINTENANCE AND REENGINEERING 783pre75977_ch29.qxd  11/27/08  6:32 PM  Page 783pre75977_ch29.qxd  11/27/08  6:32 PM  Page 784ADVANCED
TOPICS
785PART
Five
In this part of Software Engineering: A Practitioner’s Approach, we consider a number of advanced topics that will extend yourunderstanding of software engineering. The following ques-tions are addressed in the chapters that follow:•What is software process improvement and how can it beused to improve the state of software engineering practice?•What emerging trends can be expected to have a significantinfluence on software engineering practice in the nextdecade?•What is the road ahead for software engineers?Once these questions are answered, you'll understand topicsthat may have a profound impact on software engineering in theyears to come.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 785Long before the phrase “software process improvement” was widely used,I worked with major corporations in an attempt to improve the state oftheir software engineering practices. As a consequence of my experiences,I wrote a book entitledMaking Software Engineering Happen[Pre88]. In the pref- ace of that book I made the following comment:
For the past ten years I have had the opportunity to help a number of large companiesimplement software engineering practices. The job is difficult and rarely goes assmoothly as one might like—but when it succeeds, the results are profound. Softwareprojects are more likely to be completed on time. Communication between all con-stituencies involved in software development is improved. The level of confusion andchaos that is often prevalent for large software projects is reduced substantially. Thenumber of errors encountered by the customer drops substantially. The credibility of thesoftware organization increases. And management has one less problem to worry about.But all is not sweetness and light. Many companies attempt to implement softwareengineering practice and give up in frustration. Others do it half-way and never seethe benefits noted above. Still others do it in a heavy-handed fashion that results inopen rebellion among technical staff and managers and subsequent loss of morale.
786CHAPTER
30SOFTWARE PROCESS
IMPROVEMENT
KEY
CONCEPTS
assessment  . . .791CMMI  . . . . . . .797critical successfactors . . . . . . .796education andtraining  . . . . . .793evaluation  . . . .795installation/migration  . . . . .794justification  . . .793maturity models . . . . . . .789people CMM . . .801return oninvestment . . . .804risk management  . .795
What is it? Software process im-provement encompasses a set ofactivities that will lead to a better soft-ware process and, as a conse-quence, higher-quality software delivered in amore timely manner.
Who does it? The people who champion SPI comefrom three groups: technical managers, softwareengineers, and individuals who have qualityassurance responsibility.
Why is it important? Some software organiza-tions have little more than an ad hoc softwareprocess. As they work to improve their softwareengineering practices, they must address weak-nesses in their existing process and try toimprove their approach to software work.
What are the steps? The approach to SPI is itera-tive and continuous, but it can be viewed in fiveQUICK
LOOKsteps: (1) assessment of the current softwareprocess, (2) education and training of practition-ers and managers, (3) selection and justificationof process elements, software engineering meth-ods, and tools, (4) implementation of the SPIplan, and (5) evaluation and tuning based on theresults of the plan.
What is the work product? Although there aremany intermediate SPI work products, the endresult is an improved software process that leadsto higher-quality software.
How do I ensure that I’ve done it right? Thesoftware your organization produces will bedelivered with fewer defects, rework at eachstage of the software process will be reduced, andon-time delivery will become much more likely.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 786CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 787
Although those words were written more than 20 years ago, they remain equallytrue today.As we move into the second decade of the twenty-first century, most major soft-ware engineering organizations have attempted to “make software engineeringhappen.” Some have implemented individual practices that have helped to improvethe quality of the product they build and the timeliness of their delivery. Others haveestablished a “mature” software process that guides their technical and project man-agement activities. But others continue to struggle. Their practices are hit-and-miss,and their process is ad hoc. Occasionally, their work is spectacular, but in the main,each project is an adventure, and no one knows whether it will end badly or well.So, which of these two cohorts needs software process improvement? Theanswer (which may surprise you) is both. Those that have succeeded in making soft- ware engineering happen cannot become complacent. They must work continuallyto improve their approach to software engineering. And those that struggle mustbegin their journey down the road toward improvement.
30.1 W HATISSPI?
The term software process improvement (SPI) implies many things. First, it implies that elements of an effective software process can be defined in an effective manner;second, that an existing organizational approach to software development can beassessed against those elements; and third, that a meaningful strategy for improve-ment can be defined. The SPI strategy transforms the existing approach to softwaredevelopment into something that is more focused, more repeatable, and more reli-able (in terms of the quality of the product produced and the timeliness of delivery).Because SPI is not free, it must deliver a return on investment. The effort and timethat is required to implement an SPI strategy must pay for itself in some measura-ble way. To do this, the results of improved process and practice must lead to areduction in software “problems” that cost time and money. It must reduce the num-ber of defects that are delivered to end users, reduce the amount of rework due toquality problems, reduce the costs associated with software maintenance andsupport (Chapter 29), and reduce the indirect costs that occur when software isdelivered late.
30.1.1 Approaches to SPI
Although an organization can choose a relatively informal approach to SPI, the vastmajority choose one of a number of SPI frameworks. An SPI framework defines (1) a set of characteristics that must be present if an effective software process is to beachieved, (2) a method for assessing whether those characteristics are present, (3) amechanism for summarizing the results of any assessment, and (4) a strategy forassisting a software organization in implementing those process characteristics thathave been found to be weak or missing.selection  . . . . .793software processimprovement (SPI)  . . . . . . . .787applicability  . .790frameworks  . .787process  . . . . .791
SPI implies a definedsoftware process, anorganizationalapproach, and astrategy forimprovement.
uote:
“Much of thesoftware crisis isself-inflicted, aswhen a CIO says,‘I’d rather have itwrong than haveit late. We canalways fix itlater.’”Mark Paulkpre75977_ch30.qxd  11/27/08  6:33 PM  Page 787An SPI framework assesses the “maturity” of an organization’s software processand provides a qualitative indication of a maturity level. In fact, the term “maturitymodel” (Section 30.1.2) is often applied. In essence, the SPI framework encompassesa maturity model that in turn incorporates a set of process quality indicators that pro-vide an overall measure of the process quality that will lead to product quality.Figure 30.1 provides an overview of a typical SPI framework. The key elements ofthe framework and their relationship to one another are shown.You should note that there is no universal SPI framework. In fact, the SPI frame-work that is chosen by an organization reflects the constituency that is championingthe SPI effort. Conradi [Con96] defines six different SPI support constituencies:Quality certifiers.Process improvement efforts championed by this groupfocus on the following relationship:Quality(Process) ⇒Quality(Product)Their approach is to emphasize assessment methods and to examine a well-defined set of characteristics that allow them to determine whether theprocess exhibits quality. They are most likely to adopt a process frameworksuch as the CMM, SPICE, TickIT, or Bootstrap.
1
Formalists.This group wants to understand (and when possible, optimize)process workflow. To accomplish this, they use process modeling languages788 PART FIVEADVANCED TOPICS
Softwareprocess
Assessment
Is a foundation forLeads toLeads toIsexaminedbyIdentifies capabilities,strengths, and weaknesses ofIdentifies maturity ofIdentifies changes toSuggests improvementapproach for
Capabilitydetermination ImprovementstrategyFIGURE 30.1
Elements of anSPI framework.Source:Adapted from[Rou02].
What groupschampion anSPI effort??
1 Each of these SPI frameworks is discussed later in this chapter.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 788(PMLs) to create a model of the existing process and then design extensionsor modifications that will make the process more effective.Tool advocates.This group insists on a tool-assisted approach to SPI thatmodels workflow and other process characteristics in a manner that can beanalyzed for improvement.Practitioners.This constituency uses a pragmatic approach, “emphasizingmainstream project-, quality- and product management, applying project-level planning and metrics, but with little formal process modeling or enact-ment support” [Con96].Reformers.The goal of this group is organizational change that mightlead to a better software process. They tend to focus more on human issues(Section 30.5) and emphasize measures of human capability and structure.Ideologists.This group focuses on the suitability of a particular process modelfor a specific application domain or organizational structure. Rather than typi-cal software process models (e.g., iterative models), ideologists would have agreater interest in a process that would, say, support reuse or reengineering.As an SPI framework is applied, the sponsoring constituency (regardless of its over-all focus) must establish mechanisms to: (1) support technology transition, (2) deter-mine the degree to which an organization is ready to absorb process changes thatare proposed, and (3) measure the degree to which changes have been adopted.
30.1.2 Maturity Models
A maturity modelis applied within the context of an SPI framework. The intent of thematurity model is to provide an overall indication of the “process maturity” exhibitedby a software organization. That is, an indication of the quality of the softwareprocess, the degree to which practitioner’s understand and apply the process, andthe general state of software engineering practice. This is accomplished using sometype of ordinal scale.For example, the Software Engineering Institute’s Capability Maturity Model(Section 30.4) suggests five levels of maturity [Sch96]:
Level 5, Optimized—The organization has quantitative feedback systems in place toidentify process weaknesses and strengthen them pro-actively. Project teams analyzedefects to determine their causes; software processes are evaluated and updated to pre-vent known types of defects from recurring.Level 4, Managed—Detailed software process and product quality metrics establishthe quantitative evaluation foundation. Meaningful variations in process performancecan be distinguished from random noise, and trends in process and product qualities canbe predicted.Level 3, Defined—Processes for management and engineering are documented,standardized, and integrated into a standard software process for the organization.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 789
A maturity modeldefines levels ofsoftware processcompetence andimplementation.“What arethe differentconstituencies thatsupport SPI?”?pre75977_ch30.qxd  11/27/08  6:33 PM  Page 789All projects use an approved, tailored version of the organization’s standard softwareprocess for developing software.Level 2, Repeatable—Basic project management processes are established to trackcost, schedule, and functionality. Planning and managing new products is based onexperience with similar projects.Level 1, Initial—Few processes are defined, and success depends more on individ-ual heroic efforts than on following a process and using a synergistic team effort.
The CMM maturity scale goes no further, but experience indicates that many organ-izations exhibit levels of “process immaturity” [Sch96] that undermine any rationalattempt at improving software engineering practices. Schorsch [Sch06] suggestsfour levels of immaturity that are often encountered in the real world of softwaredevelopment organizations:
Level 0, Negligent—Failure to allow successful development process to succeed. All prob-lems are perceived to be technical problems. Managerial and quality assurance activitiesare deemed to be overhead and superfluous to the task of software development process.Reliance on silver pellets.Level –1, Obstructive—Counterproductive processes are imposed. Processes are rigidlydefined and adherence to the form is stressed. Ritualistic ceremonies abound. Collectivemanagement precludes assigning responsibility. Status quo über alles.Level –2, Contemptuous—Disregard for good software engineering institutionalized.Complete schism between software development activities and software processimprovement activities. Complete lack of a training program.Level –3, Undermining—Total neglect of own charter, conscious discrediting of peerorganization’s software process improvement efforts. Rewarding failure and poorperformance.
Schorsch’s immaturity levels are toxic for any software organization. If youencounter any one of them, attempts at SPI are doomed to failure.The overriding question is whether maturity scales, such as the one proposed as partof the CMM, provide any real benefit. I think that they do. A maturity scale provides aneasily understood snapshot of process quality that can be used by practitioners andmanagers as a benchmark from which improvement strategies can be planned.
30.1.3 Is SPI for Everyone?
For many years, SPI was viewed as a “corporate” activity—a euphemism for some-thing that only large companies perform. But today, a significant percentage ofall software development is being performed by companies that employ fewer than100 people. Can a small company initiate SPI activities and do it successfully?There are substantial cultural differences between large software developmentorganizations and small ones. It should come as no surprise that small organizationsare more informal, apply fewer standard practices, and tend to be self-organizing.They also tend to pride themselves on the “creativity” of individual members of the790 PART FIVEADVANCED TOPICS
If a specific processmodel or SPI approachfeels like overkill foryour organization, itprobably is.“How do yourecognize anorganization thatwill resist SPIefforts?”?pre75977_ch30.qxd  11/27/08  6:33 PM  Page 790software organization, and initially view an SPI framework as overly bureaucraticand ponderous. Yet, process improvement is as important for a small organizationas it is for a large one.Within small organizations the implementation of an SPI framework requiresresources that may be in short supply. Managers must allocate people and money tomake software engineering happen. Therefore, regardless of the size of the softwareorganization, it’s reasonable to consider the business motivation for SPI.SPI will be approved and implemented only after its proponents demonstratefinancial leverage [Bir98]. Financial leverage is demonstrated by examining tech-nical benefits (e.g., fewer defects delivered to the field, reduced rework, lowermaintenance costs, or more rapid time-to-market) and translating them intodollars. In essence, you must show a realistic return on investment (Section 30.7)for SPI costs.
30.2 T HESPI P ROCESS
The hard part of SPI isn’t the definition of characteristics that define a high-qualitysoftware process or the creation of a process maturity model. Those things are rela-tively easy. Rather, the hard part is establishing a consensus for initiating SPI anddefining an ongoing strategy for implementing it across a software organization.The Software Engineering Institute has developed IDEAL—“an organizationalimprovement model that serves as a roadmap for initiating, planning, and imple-menting improvement actions” [SEI08]. IDEAL is representative of many processmodels for SPI, defining five distinct activities—initiating, diagnosing, establishing,acting, and learning—that guide an organization through SPI activities.In this book, I present a somewhat different road map for SPI, based on theprocess model for SPI originally proposed in [Pre88]. It applies a commonsense phi-losophy that requires an organization to (1) look in the mirror, (2) then get smarterso it can make intelligent choices, (3) select the process model (and related technol-ogy elements) that best meets its needs, (4) instantiate the model into its operatingenvironment and its culture, and (5) evaluate what has been done. These five activ-ities (discussed in the subsections
2that follow) are applied in an iterative (cyclical)manner in an effort to foster continuous process improvement.
30.2.1 Assessment and Gap Analysis
Any attempt to improve your current software process without first assessing theefficacy of current framework activities and associated software engineering prac-tices would be like starting on a long journey to a new location with no idea whereyou are starting from. You’d depart with great flourish, wander around trying to getyour bearings, expend lots of energy and endure large doses of frustration, and likely,CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 791
2 Some of the content in these sections has been adapted from [Pre88] with permission.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 791decide you really didn’t want to travel anyway. Stated simply, before you begin anyjourney, it’s a good idea to know precisely where you are.The first road-map activity, called assessment, allows you to get your bearings. The intent of assessment is to uncover both strengths and weaknesses in the wayyour organization applies the existing software process and the software engineer-ing practices that populate the process.Assessment examines a wide range of actions and tasks that will lead to a high-quality process. For example, regardless of the process model that is chosen, the soft-ware organization must establish generic mechanisms such as: defined approachesfor customer communication; established methods for representing user require-ments; defining a project management framework that includes scoping, estimation,scheduling, and project tracking; risk analysis methods; change management proce-dures; quality assurance and control activities including reviews; and many others.Each is considered within the context of the framework and umbrella activities(Chapter 2) that have been established and is assessed to determine whether each ofthe following questions has been addressed:
•Is the objective of the action clearly defined?
•Are work products required as input and produced as output identified anddescribed?
•Are the work tasks to be performed clearly described?
•Are the people who must perform the action identified by role?
•Have entry and exit criteria been established?
•Have metrics for the action been established?
•Are tools available to support the action?
•Is there an explicit training program that addresses the action?
•Is the action performed uniformly for all projects?Although the questions noted imply a yes or noanswer, the role of assessment is to look behind the answer to determine whether the action in question is beingperformed in a manner that would conform to best practice.As the process assessment is conducted, you (or those who have been hired toperform the assessment) should also focus on the following attributes:Consistency.Are important activities, actions, and tasks applied consistentlyacross all software projects and by all software teams?Sophistication.Are management and technical actions performed with a levelof sophistication that implies a thorough understanding of best practice?Acceptance.Is the software process and software engineering practice widelyaccepted by management and technical staff?Commitment.Has management committed the resources required to achieveconsistency, sophistication, and acceptance?792 PART FIVEADVANCED TOPICS
Be sure to understandyour strengths as wellas your weaknesses. Ifyou’re smart, you’llbuild on the strengths.
“Whatgenericattributes do youlook for duringassessment?”?pre75977_ch30.qxd  11/27/08  6:33 PM  Page 792The difference between local application and best practice represents a “gap” thatoffers opportunities for improvement. The degree to which consistency, sophistica-tion, acceptance, and commitment are achieved indicates the amount of culturalchange that will be required to achieve meaningful improvement.
30.2.2 Education and Training
Although few software people question the benefit of an agile, organized softwareprocess or solid software engineering practices, many practitioners and managersdo not know enough about either subject.
3As a consequence, inaccurate percep- tions of process and practice lead to inappropriate decisions when an SPI frameworkis introduced. It follows that a key element of any SPI strategy is education and train-ing for practitioners, technical managers and more senior managers who have directcontact with the software organization. Three types of education and training shouldbe conducted:Generic concepts and methods.Directed toward both managers andpractitioners, this category stresses both process and practice. The intent isto provide professionals with the intellectual tools they need to apply thesoftware process effectively and to make rational decisions about improve-ments to the process.Specific technology and tools.Directed primarily toward practitioners,this category stresses technologies and tools that have been adopted for localuse. For example, if UML has been chosen for analysis and design modeling, atraining curriculum for software engineering using UML would be established.Business communication and quality-related topics. Directed toward all stakeholders, this category focuses on “soft” topics that help enable bettercommunication among stakeholders and foster a greater quality focus.In a modern context, education and training can be delivered in a variety of dif-ferent ways. Everything from podcasts, to Internet-based training (e.g., [QAI08]), toDVDs, to classroom courses can be offered as part of an SPI strategy.
30.2.3 Selection and Justification
Once the initial assessment activity4has been completed and education has begun, asoftware organization should begin to make choices. These choices occur during aselection and justification activityin which process characteristics and specific softwareengineering methods and tools are chosen to populate the software process.First, you should choose the process model (Chapters 2 and 3) that best fits yourorganization, its stakeholders, and the software that you build. You should decideCHAPTER 30SOFTWARE PROCESS IMPROVEMENT 793
Try to provide “just-in-time” training targetedto the real needs of asoftware team.
3 If you’ve spent time reading this book, you won’t be one of them!4 In actuality, assessment is an ongoing activity. It is conducted periodically in an effort to determinewhether the SPI strategy has achieved its immediate goals and to set the stage for future improvement.As you make yourchoices, be sure toconsider the culture ofyour organization andthe level of acceptancethat each choice willlikely elicit.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 793which of the set of framework activities will be applied, the major work products thatwill be produced, and the quality assurance checkpoints that will enable your teamto assess progress. If the SPI assessment activity indicates specific weaknesses(e.g., no formal SQA functions), you should focus attention on process characteris-tics that will address these weaknesses directly.Next, develop a work breakdown for each framework activity (e.g., modeling),defining the task set that would be applied for a typical project. You should also con-sider the software engineering methods that can be applied to achieve these tasks.As choices are made, education and training should be coordinated to ensure thatunderstanding is reinforced.Ideally, everyone works together to select various process and technologyelements and moves smoothly toward the installation or migration activity (Sec-tion 30.2.4). In reality, selection can be a rocky road. It is often difficult to achieveconsensus among different constituencies. If the criteria for selection are establishedby committee, people may argue endlessly about whether the criteria are appropri-ate and whether a choice truly meets the criteria that have been established.It is true that a bad choice can do more harm than good, but “paralysis by analysis”means that little if any progress occurs and process problems remain. As long as theprocess characteristic or technology element has a good chance at meeting anorganization’s needs, it’s sometimes better to pull the trigger and make a choice,rather than waiting for the optimal solution.Once a choice is made, time and money must be expended to instantiate itwithin an organization, and these resource expenditures should be justified. Adiscussion of cost justification and return on investment for SPI is presented inSection 30.7.
30.2.4 Installation/Migration
Installationis the first point at which a software organization feels the effects ofchanges implemented as a consequence of the SPI road map. In some cases, anentirely new process is recommended for an organization. Framework activities,software engineering actions, and individual work tasks must be defined andinstalled as part of a new software engineering culture. Such changes represent asubstantial organizational and technological transition and must be managedvery carefully.In other cases, changes associated with SPI are relatively minor, representingsmall, but meaningful modifications to an existing process model. Such changes areoften referred to as process migration. Today, many software organizations have a “process” in place. The problem is that it doesn’t work in an effective manner. There-fore, an incremental migrationfrom one process (that doesn’t work as well asdesired) to another process is a more effective strategy.Installation and migration are actually software process redesign (SPR) activities. Scacchi [Sca00] states that “SPR is concerned with identification, application, and794 PART FIVEADVANCED TOPICSpre75977_ch30.qxd  11/27/08  6:33 PM  Page 794refinement of new ways to dramatically improve and transform software processes.”When a formal approach to SPR is initiated, three different process models areconsidered: (1) the existing (“as is”) process, (2) a transitional (“here to there”)process, and (3) the target (“to be”) process. If the target process is significantly dif-ferent from the existing process, the only rational approach to installation is an in-cremental strategy in which the transitional process is implemented in steps. Thetransitional process provides a series of way-points that enable the software organi-zation’s culture to adapt to small changes over a period of time.
30.2.5 Evaluation
Although it is listed as the last activity in the SPI road map, evaluation occurs throughout SPI. The evaluation activity assesses the degree to which changes havebeen instantiated and adopted, the degree to which such changes result in bettersoftware quality or other tangible process benefits, and the overall status of theprocess and the organizational culture as SPI activities proceed.Both qualitative factors and quantitative metrics are considered during the eval-uation activity. From a qualitative point of view, past management and practitionerattitudes about the software process can be compared to attitudes polled after in-stallation of process changes. Quantitative metrics (Chapter 25) are collected fromprojects that have used the transitional or “to be” process and compared with sim-ilar metrics that were collected for projects that were conducted under the “as is”process.
30.2.6 Risk Management for SPI
SPI is a risky undertaking. In fact, more than half of all SPI efforts end in failure. Thereasons for failure vary greatly and are organizationally specific. Among the mostcommon risks are: a lack of management support, cultural resistance by technicalstaff, a poorly planned SPI strategy, an overly formal approach to SPI, selection of aninappropriate process, a lack of buy-in by key stakeholders, an inadequate budget, alack of staff training, organizational instability, and a myriad of other factors. Therole of those chartered with the responsibility for SPI is to analyze likely risks anddevelop an internal strategy for mitigating them.A software organization should manage risk at three key points in the SPI process[Sta97b]: prior to the initiation of the SPI road map, during the execution of SPIactivities (assessment, education, selection, installation), and during the evaluationactivity that follows the instantiation of some process characteristic. In general, thefollowing categories [Sta97b] can be identified for SPI risk factors: budget and cost,content and deliverables, culture, maintenance of SPI deliverables, mission andgoals, organizational management, organizational stability, process stakeholders,schedule for SPI development, SPI development environment, SPI developmentprocess, SPI project management, and SPI staff.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 795
SPI often fails becauserisks were not properlyconsidered and nocontingency planningoccurred.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 795Within each category, a number of generic risk factors can be identified. Forexample, the organizational culture has a strong bearing on risk. The followinggeneric risk factors
5can be defined for the culture category [Sta97b]:
•Attitude toward change, based on prior efforts to change
•Experience with quality programs, level of success
•Action orientation for solving problems versus political struggles
•Use of facts to manage the organization and business
•Patience with change; ability to spend time socializing
•Tools orientation—expectation that tools can solve the problems
•Level of “planfulness”—ability of organization to plan
•Ability of organization members to participate with various levels oforganization openly at meetings
•Ability of organization members to manage meetings effectively
•Level of experience in organization with defined processesUsing the risk factors and generic attributes as a guide, risk exposure is computed inthe following manner:Exposure/H11005(risk probability)/H11003(estimated loss)A risk table (Chapter 28) can be developed to isolate those risks that warrant furthermanagement attention.
30.2.7 Critical Success Factors
In Section 30.2.6, I noted that SPI is a risky endeavor and that the failure rate for com-panies that try to improve their process is distressingly high. Organizational risks,people risks, and project management risks present challenges for those who leadany SPI effort. Although risk management is important, it’s equally important torecognize those critical factors that lead to success.After examining 56 software organizations and their SPI efforts, Stelzer and Mellis[Ste99] identify a set of critical success factors (CSFs) that must be present if SPI is tosucceed. The top five CSFs are presented in this section.Management commitment and support. Like most activities that precipi- tate organizational and cultural change, SPI will succeed only if managementis actively involved. Senior business managers should recognize the impor-tance of software to their company and be active sponsors of the SPI effort.Technical managers should be heavily involved in the development of the localSPI strategy. As the authors of the study note: “Software process improvementis not feasible without investing time, money, and effort” [Ste99]. Managementcommitment and support are essential to sustain that investment.796 PART FIVEADVANCED TOPICS
5 Risk factors for each of the risk categories noted in this section can be found in [Sta97b].What criticalsuccessfactors are crucialfor successfulSPI??pre75977_ch30.qxd  11/27/08  6:33 PM  Page 796Staff involvement.SPI cannot be imposed top down, nor can it be imposedfrom the outside. If SPI efforts are to succeed, improvement must beorganic—sponsored by technical managers and senior technologists, andadopted by local practitioners.Process integration and understanding. The software process does not exist in an organizational vacuum. It must be characterized in a manner thatis integrated with other business processes and requirements. To accomplishthis, those responsible for the SPI effort must have an intimate knowledgeand understanding of other business processes. In addition, they must under-stand the “as is” software process and appreciate how much transitionalchange is tolerable within the local culture.A customized SPI strategy.There is no cookie-cutter SPI strategy. As Inoted earlier in this chapter, the SPI road map must be adapted to the localenvironment—team culture, product mix, and local strengths and weak-nesses must all be considered.Solid management of the SPI project. SPI is a project like any other. It involves coordination, scheduling, parallel tasks, deliverables, adaptation(when risks become realities), politics, budget control, and much more.Without active and effective management, an SPI project is doomed tofailure.
30.3 T HECMMI
The original CMM was developed and upgraded by the Software Engineering Insti-tute throughout the 1990s as a complete SPI framework. Today, it has evolved intothe Capability Maturity Model Integration(CMMI) [CMM07], a comprehensive process meta-model that is predicated on a set of system and software engineering capabil-ities that should be present as organizations reach different levels of process capa-bility and maturity.The CMMI represents a process meta-model in two different ways: (1) as a“continuous” model and (2) as a “staged” model. The continuous CMMI meta-model describes a process in two dimensions as illustrated in Figure 30.2. Eachprocess area (e.g., project planning or requirements management) is formallyassessed against specific goals and practices and is rated according to the follow-ing capability levels:Level 0:Incomplete—the process area (e.g., requirements management) iseither not performed or does not achieve all goals and objectives defined bythe CMMI for level 1 capability for the process area.Level 1:Performed—all of the specific goals of the process area (as definedby the CMMI) have been satisfied. Work tasks required to produce definedwork products are being conducted.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 797
WebRef
Complete informationon the CMMI can beobtained atwww.sei.cmu.edu/cmmi/.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 797Level 2:Managed—all capability level 1 criteria have been satisfied. In addi-tion, all work associated with the process area conforms to an organizationallydefined policy; all people doing the work have access to adequate resourcesto get the job done; stakeholders are actively involved in the process area asrequired; all work tasks and work products are “monitored, controlled, andreviewed; and are evaluated for adherence to the process description” [CMM07].Level 3:Defined—all capability level 2 criteria have been achieved. In addi-tion, the process is “tailored from the organization’s set of standardprocesses according to the organization’s tailoring guidelines, and con-tributes work products, measures, and other process-improvement informa-tion to the organizational process assets” [CMM07].Level 4:Quantitatively managed—all capability level 3 criteria have beenachieved. In addition, the process area is controlled and improved usingmeasurement and quantitative assessment. “Quantitative objectives for qual-ity and process performance are established and used as criteria in managingthe process” [CMM07].Level 5:Optimized—all capability level 4 criteria have been achieved. Inaddition, the process area is adapted and optimized using quantitative(statistical) means to meet changing customer needs and to continuallyimprove the efficacy of the process area under consideration.The CMMI defines each process area in terms of “specific goals” and the “specificpractices” required to achieve these goals. Specific goals establish the characteristics that must exist if the activities implied by a process area are to be effective. Specificpracticesrefine a goal into a set of process-related activities.798 PART FIVEADVANCED TOPICS
012345Capability level
Process areaREQMPP CMMAPPQA othersPP Project planningREQM Requirements managementMA Measurement and analysisCM Configuration managementPPQA Process and product QAFIGURE 30.2
CMMI processarea capa-bility profile.Source:[Phi02].
Every organizationshould strive toachieve the intent ofthe CMMI. However,implementing everyaspect of the modelmay be overkill in yoursituation.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 798For example, project planningis one of eight process areas defined by the CMMIfor “project management” category.
6The specific goals (SG) and the associated spe-cific practices (SP) defined for project planningare [CMM07]:
SG 1 Establish EstimatesSP 1.1-1 Estimate the Scope of the ProjectSP 1.2-1 Establish Estimates of Work Product and Task AttributesSP 1.3-1 Define Project Life CycleSP 1.4-1 Determine Estimates of Effort and CostSG 2 Develop a Project PlanSP 2.1-1 Establish the Budget and ScheduleSP 2.2-1 Identify Project RisksSP 2.3-1 Plan for Data ManagementSP 2.4-1 Plan for Project ResourcesSP 2.5-1 Plan for Needed Knowledge and SkillsSP 2.6-1 Plan Stakeholder InvolvementSP 2.7-1 Establish the Project PlanSG 3 Obtain Commitment to the PlanSP 3.1-1 Review Plans That Affect the ProjectSP 3.2-1 Reconcile Work and Resource LevelsSP 3.3-1 Obtain Plan Commitment
In addition to specific goals and practices, the CMMI also defines a set of fivegeneric goals and related practices for each process area. Each of the five genericgoals corresponds to one of the five capability levels. Hence, to achieve a particularcapability level, the generic goal for that level and the generic practices that corre-spond to that goal must be achieved. To illustrate, the generic goals (GG) and prac-tices (GP) for the project planningprocess area are [CMM07]:
GG 1 Achieve Specific GoalsGP 1.1 Perform Base PracticesGG 2 Institutionalize a Managed ProcessGP 2.1 Establish an Organizational PolicyGP 2.2 Plan the ProcessGP 2.3 Provide ResourcesGP 2.4 Assign ResponsibilityGP 2.5 Train PeopleCHAPTER 30SOFTWARE PROCESS IMPROVEMENT 799
WebRef
Complete informationas well as adownloadable versionof the CMMI can beobtained atwww.sei.cmu.edu/cmmi/.
6 Other process areas defined for “project management” include: project monitoring and control,supplier agreement management, integrated project management for IPPD, risk management,integrated teaming, integrated supplier management, and quantitative project management.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 799GP 2.6 Manage ConfigurationsGP 2.7 Identify and Involve Relevant StakeholdersGP 2.8 Monitor and Control the ProcessGP 2.9 Objectively Evaluate AdherenceGP 2.10 Review Status with Higher-Level ManagementGG 3 Institutionalize a Defined ProcessGP 3.1 Establish a Defined ProcessGP 3.2 Collect Improvement InformationGG 4 Institutionalize a Quantitatively Managed ProcessGP 4.1 Establish Quantitative Objectives for the ProcessGP 4.2 Stabilize Subprocess PerformanceGG 5 Institutionalize an Optimizing ProcessGP 5.1 Ensure Continuous Process ImprovementGP 5.2 Correct Root Causes of Problems
The staged CMMI model defines the same process areas, goals, and practices asthe continuous model. The primary difference is that the staged model defines fivematurity levels, rather than five capability levels. To achieve a maturity level, the spe-cific goals and practices associated with a set of process areas must be achieved. Therelationship between maturity levels and process areas is shown in Figure 30.3.800 PART FIVEADVANCED TOPICS
The CMMI—Should We or Shouldn’t We?
The CMMI is a process meta-model. It defines(in 700+ pages) the process characteristicsthat should exist if an organization wants to establish asoftware process that is complete. The question that hasbeen debated for well over a decade is: “Is the CMMIoverkill?” Like most things in life (and in software), theanswer is not a simple “yes” or “no.”The spirit of the CMMI should always be adopted.At the risk of oversimplification, it argues that softwaredevelopment must be taken seriously—it must be plannedthoroughly, it must be controlled uniformly, it must betracked accurately, and it must be conducted professionally.It must focus on the needs of project stakeholders, the skillsof the software engineers, and the quality of the endproduct. No one would argue with these ideas.The detailed requirements of the CMMI should beseriously considered if an organization builds largecomplex systems that involve dozens or hundreds ofpeople over many months or years. It may be thatthe CMMI is “just right” in such situations, if theorganizational culture is amenable to standard processmodels and management is committed to making it asuccess. However, in other situations, the CMMI maysimply be too much for an organization to successfullyassimilate. Does this mean that the CMMI is “bad” or“overly bureaucratic” or “old fashioned?” No ...i t does not. It simply means that what is right for oneorganizational culture may not be right for another.The CMMI is a significant achievement in softwareengineering. It provides a comprehensive discussion of theactivities and actions that should be present when anorganization builds computer software. Even if a softwareorganization chooses not to adopt its details, everysoftware team should embrace its spirit and gain insightfrom its discussion of software engineering process andpractice.INFOpre75977_ch30.qxd  11/27/08  6:33 PM  Page 80030.4 T HEPEOPLE CMM
A software process, no matter how well conceived, will not succeed without tal-ented, motivated software people. The People Capability Maturity Model “is a roadmap for implementing workforce practices that continuously improve the capability of anorganization’s workforce” [Cur02]. Developed in the mid-1990s and refined over theintervening years, the goal of the People CMM is to encourage continuous improve-ment of generic workforce knowledge (called “core competencies”), specific soft-ware engineering and project management skills (called “workforce competencies”),and process-related abilities.Like the CMM, CMMI, and related SPI frameworks, the People CMM defines aset of five organizational maturity levels that provide an indication of the relativesophistication of workforce practices and processes. These maturity levels[CMM08] are tied to the existence (within an organization) of a set of key processareas (KPAs). An overview of organizational levels and related KPAs is shown inFigure 30.4.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 801
Organizational innovation and deploymentCausal analysis and resolutionContinuousprocessimprovementQuantitativemanagement
Processstandardization
BasicprojectmanagementOrganizational process performanceQuantitative project managementRequirements developmentTechnical solution Product integration VerificationValidationOrganizational process focusOrganizational process definitionOrganizational training Integrated project managementIntegrated supplier managementRisk managementDecision analysis and resolutionOrganizational environment for integrationIntegrated teamingRequirements managementProject planningProject monitoring and controlSupplier agreement managementMeasurement and analysisProcess and product quality assuranceConfiguration managementOptimizingQuantitativelymanaged
Defined
Managed
PerformedProcess Areas LevelFocusFIGURE 30.3
Process areasrequired toachieve amaturity level.Source:[Phi02].
The People CMMsuggests practices thatimprove the workforcecompetence andculture.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 801The People CMM complements any SPI framework by encouraging an organiza-tion to nurture and improve its most important asset—its people. As important, itestablishes a workforce atmosphere that enables a software organization to “attract,develop, and retain outstanding talent” [CMM08].
30.5 O THER SPI F RAMEWORKS
Although the SEI’s CMM and CMMI are the most widely applied SPI frameworks, anumber of alternatives
7have been proposed and are in use. Among the most widelyused of these alternatives are:
•SPICE—an international initiative to support ISO’s process assessment andlife cycle process standards [SPI99]
•ISO/IEC 15504for (Software) Process Assessment [ISO08]802 PART FIVEADVANCED TOPICS
Continuous workforce innovationOrganizational performance alignmentContinuous capability improvementContinuousimprovement
Identifies anddevelopsknowledge, skills,and abilities
Repeatable, basicpeoplemanagementpracticesMentoringOrganizational capability managementQuantitative performance managementCompetency-based assetsEmpowered workgroupsCompetency integrationParticipatory cultureWorkgroup developmentCompetency-based practicesCareer developmentCompetency developmentWorkforce planningCompetency analysisCompensationTraining and developmentPerformance managementWork environmentCommunication and co-ordinationStaffingOptimizedQuantifies andmanagesknowledge, skills, and abilitiesPredictable
Defined
Managed
InitialInconsistentpracticesProcess Areas LevelFocusFIGURE 30.4
Process areasfor the PeopleCMM
7 It’s reasonable to argue that some of these frameworks are not so much “alternatives” as they arecomplementary approaches to SPI. A comprehensive table of many more SPI frameworks can befound at www.geocities.com/lbu_measure/spi/spi.htm#p2 .pre75977_ch30.qxd  11/27/08  6:33 PM  Page 802•Bootstrap—an SPI framework for small and medium-sized organizationsthat conforms to SPICE [Boo06]
•PSP and TSP—individual and team-specific SPI frameworks ([Hum97],[Hum00]) that focus on process in-the-small, a more rigorous approach tosoftware development coupled with measurement
•TickIT—an auditing method [Tic05] that assesses an organization’s compli-ance to ISO Standard 9001:2000A brief overview of each of these SPI frameworks is presented in the paragraphs thatfollow. If you have further interest, a wide array of print and Web-based resources isavailable for each.SPICE.The SPICE (Software Process Improvement and Capability dEtermination ) model provides an SPI assessment framework that is compliant with ISO 15504:2003and ISO 12207. The SPICE document suite [SDS08] presents a complete SPI frame-work including a model for process management, guidelines for conducting anassessment and rating the process under consideration, construction, selection, anduse of assessment instruments and tools, and training for assessors.Bootstrap.The BootstrapSPI framework “has been developed to ensure confor-mance with the emerging ISO standard for software process assessment and im-provement (SPICE) and to align the methodology with ISO 12207” [Boo06]. Theobjective of Bootstrap is to evaluate a software process using a set of software engi-neering best practices as a basis for assessment. Like the CMMI, Bootstrap providesa process maturity level using the results of questionnaires that gather informationabout the “as is” software process and software projects. SPI guidelines are based onmaturity level and organizational goals.PSP and TSP.Although SPI is generally characterized as an organizationalactivity, there is no reason why process improvement cannot be conducted at anindividual or team level. Both PSP and TSP (Chapter 2) emphasize the need to con-tinuously collect data about the work that is being performed and to use that datato develop strategies for improvement. Watts Humphrey [Hum97], the developer ofboth methods, comments:
The PSP [and TSP] will show you how to plan and track your work and how to consis-tently produce high quality software. Using PSP [and TSP] will give you the data that showthe effectiveness of your work and identify your strengths and weaknesses. ...T o  have a successful and rewarding career, you need to know your skills and abilities, strive toimprove them, and capitalize on your unique talents in the work you do.
TickIT.The Ticket auditing method ensures compliance with ISO 9001:2000 forSoftware—a generic standard that applies to any organization that wants to improvethe overall quality of the products, systems, or services that it provides. Therefore,the standard is directly applicable to software organizations and companies.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 803
In additionto the CMM,are there otherSPI frameworksthat we mightconsider??
uote:
“Softwareorganizations haveexhibitedsignificantshortcomings intheir ability tocapitalize on theexperiences gainedfrom completedprojects.”NASApre75977_ch30.qxd  11/27/08  6:33 PM  Page 803The underlying strategy suggested by ISO 9001:2000 is described in the followingmanner [ISO01]:
ISO 9001:2000 stresses the importance for an organization to identify, implement, man-age and continually improve the effectiveness of the processes that are necessary forthe quality management system, and to manage the interactions of these processes inorder to achieve the organization’s objectives....Process effectiveness and efficiencycan be assessed through internal or external review processes and be evaluated on amaturity scale.
ISO 9001:2000 has adopted a “plan-do-check-act” cycle that is applied to the qualitymanagement elements of a software project. Within a software context, “plan”establishes the process objectives, activities, and tasks necessary to achieve high-quality software and resultant customer satisfaction. “Do” implements the softwareprocess (including both framework and umbrella activities). “Check” monitors andmeasures the process to ensure that all requirements established for quality man-agement have been achieved. “Act” initiates software process improvement activi-ties that continually work to improve the process. TickIt can be used throughout the“plan-do-check-act” cycle to ensure that SPI progress is being made. TickIT auditorsassess the application of the cycle as a precursor to ISO 9001:2000 certification. Fora detailed discussion of ISO 9001:2000 and TickIT you should examine [Ant06],[Tri05], or [Sch03].
30.6 SPI R ETURN ON INVESTMENT
SPI is hard work and requires substantial investment of dollars and people.Managers who approve the budget and resources for SPI will invariably ask thequestion: “How do I know that we’ll achieve a reasonable return for the moneywe’re spending?”At a qualitative level, proponents of SPI argue that an improved software processwill lead to improved software quality. They contend that improved process willresult in the implementation of better quality filters (resulting in fewer propagateddefects), better control of change (resulting in less project chaos), and less technicalrework (resulting in lower cost and better time-to-market). But can these qualitativebenefits be translated into quantitative results? The classic return on investment(ROI) equation is:ROI /H11005
/H20900/H20901 /H11003100%wherebenefitsinclude the cost savings associated with higher product quality (fewerdefects), less rework, reduced effort associated with changes, and the income thataccrues from shorter time-to-market./H20858(benefits)/H11002/H20858(costs)/H20858(costs)804 PART FIVEADVANCED TOPICS
WebRef
An excellent summaryof ISO 9001: 2000can be found athttp://praxiom.com/iso-9001.htm.pre75977_ch30.qxd  11/27/08  6:33 PM  Page 804costsinclude both direct SPI costs (e.g., training, measurement) and indirectcosts associated with greater emphasis on quality control and change managementactivities and more rigorous application of software engineering methods (e.g., thecreation of a design model).In the real world, these quantitative benefits and costs are sometimes difficult tomeasure with accuracy, and all are open to interpretation. But that doesn’t mean thata software organization should conduct an SPI program without careful analysis ofthe costs and benefits that accrue. A comprehensive treatment of ROI for SPI can befound in a unique book by David Rico [Ric04].
30.7 SPI T RENDS
Over the past two decades, many companies have attempted to improve their soft-ware engineering practices by applying an SPI framework to effect organizationalchange and technology transition. As I noted earlier in this chapter, over half fail inthis endeavor. Regardless of success or failure, all spend significant amounts ofmoney. David Rico [Ric04] reports that a typical application of an SPI framework suchas the SEI CMM can cost between $25,000 and $70,000 per person and take years tocomplete! It should come as no surprise that the future of SPI should emphasize aless costly and time-consuming approach.To be effective in the twenty-first century world of software development, futureSPI frameworks must become significantly more agile. Rather than an organizationalfocus (which can take years to complete successfully), contemporary SPI effortsshould focus on the project level, working to improve a team process in weeks, notmonths or years. To achieve meaningful results (even at the project level) in a shorttime frame, complex framework models may give way to simpler models. Ratherthan dozens of key practices and hundreds of supplementary practices, an agile SPIframework should emphasize only a few pivotal practices (e.g., analogous to theframework activities discussed throughout this book).Any attempt at SPI demands a knowledgeable workforce, but education and train-ing expenses can be expensive and should be minimized (and streamlined). Ratherthan classroom courses (expensive and time consuming), future SPI efforts shouldrely on Web-based training that is targeted at pivotal practices. Rather than far-reaching attempts to change organizational culture (with all of the political perilsthat ensue), cultural change should occur as it does in the real world, one smallgroup at a time until a tipping point is reached.The SPI work of the past two decades has significant merit. The frameworks andmodels that have been developed represent substantial intellectual assets for thesoftware engineering community. But like all things, these assets guide futureattempts at SPI not by becoming a recurring dogma, but by serving as the basis forbetter, simpler, and more agile SPI models.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 805pre75977_ch30.qxd  11/27/08  6:33 PM  Page 80530.8 S UMMARY
A software process improvement framework defines the characteristics that must bepresent if an effective software process is to be achieved, an assessment method thathelps determine whether those characteristics are present, and a strategy for assist-ing a software organization in implementing those process characteristics that havebeen found to be weak or missing. Regardless of the constituency that sponsors SPI,the goal is to improve process quality and, as a consequence, improve software qual-ity and timeliness.A process maturity model provides an overall indication of the “process maturity”exhibited by a software organization. It provides a qualitative feel for the relativeeffectiveness of the software process that is currently being used.The SPI road map begins with assessment—a series of evaluation activities that un-cover both strengths and weaknesses in the way your organization applies the existingsoftware process and the software engineering practices that populate the process. Asa consequence of assessment, a software organization can develop an overall SPI plan.One of the key elements of any SPI plan is education and training, an activity thatfocuses on improving the knowledge level of managers and practitioners. Once staffbecomes well versed in current software technologies, selection and justification com-mence. These tasks lead to choices about the architecture of the software process, themethods that populate it, and the tools that support it. Installation and evaluation areSPI activities that instantiate process changes and assess their efficacy and impact.To successfully improve its software process, an organization must exhibit the fol-lowing characteristics: management commitment and support for SPI, staff involve-ment throughout the SPI process, process integration into the overall organizationalculture, an SPI strategy that has been customized for local needs, and solid man-agement of the SPI project.A number of SPI frameworks are in use today. The SEI’s CMM and CMMI arewidely used. The People CMM has been customized to assess the quality of theorganizational culture and the people who populate it. SPICE, Bootstrap, PSP, TSP,and TickIT are additional frameworks that can lead to effective SPI.SPI is hard work that requires substantial investment of dollars and people. To en-sure that a reasonable return on investment is achieved, an organization must meas-ure the costs associated with SPI and the benefits that can be directly attributed to it.
PROBLEMS AND POINTS TO PONDER
30.1.Why is it that software organizations often struggle when they embark on an effort toimprove local software process?30.2.Describe the concept of “process maturity” in your own words.30.3.Do some research (check the SEI website) and determine the process maturity distribu-tion for software organizations in the United States and worldwide.806 PART FIVEADVANCED TOPICSpre75977_ch30.qxd  11/27/08  6:33 PM  Page 80630.4.You work for a very small software organization—only 11 people are involved in devel-oping software. Is SPI for you? Explain your answer.30.5.Assessment is analogous to an annual physical exam. Using a physical exam as ametaphor, describe the SPI assessment activity.30.6.What is the difference between an “as is” process, a “here to there” process, and a “to be”process?30.7.How is risk management applied within the context of SPI?30.8.Select one of the critical success factors noted in Section 30.2.7. Do some research andwrite a brief paper on how it can be achieved.30.9.Do some research and explain how the CMMI differs from its predecessor, the CMM.30.10.Select one of the SPI frameworks discussed in Section 30.5, and write a brief paperdescribing it in more detail.
FURTHER READINGS AND INFORMATION SOURCES
One of the most readily accessible and comprehensive resources for information on SPI hasbeen developed by the Software Engineering Institute and is available at www.sei.cmu.edu . The SEI website contains hundreds of papers, studies, and detailed SPI framework descriptions.Over the past few years, a number of worthwhile books have been added to a broad litera-ture developed during the past two decades. Land (Jumpstart CMM/CMMI Software ProcessImprovements,Wiley-IEEE Computer Society, 2007) melds the requirements defined as part ofthe SEI CMM and CMMI with IEEE software engineering standards with an emphasis on the in-tersection of process and practice. Mutafelija and Stromberg ( Systematic Process Improvement Using ISO 9001:2000 and CMMI,Artech House Publishers, 2007) discuss both the ISO 9001:2000and CMMI SPI frameworks and the “synergy” between them. Conradi and his colleagues(Software Process Improvement: Results and Experience from the Field, Springer, 2006) presents the results of a series of case studies and experiments related to SPI. Van Loon (Process Assess-ment and Improvement: A Practical Guide for Managers, Quality Professionals and Assessors,Springer, 2006) discusses SPI within the context of ISO/IEC 15504. Watts Humphrey ( PSP, Addison-Wesley, 2005, and TSP,Addison-Wesley, 2005) addresses his Personal Team ProcessSPI framework and his Team Software Process SPI framework in two separate books. Fantina(Practical Software Process Improvement, Artech House Publishers, 2004) provides pragmatic how-to guidance with an emphasis on CMMI/CMM.A wide variety of information sources on software process improvement is available on theInternet. An up-to-date list of World Wide Web references relevant to SPI can be found at theSEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.CHAPTER 30SOFTWARE PROCESS IMPROVEMENT 807pre75977_ch30.qxd  11/27/08  6:33 PM  Page 807Throughout the relatively brief history of software engineering, practitionersand researchers have developed an array of process models, technicalmethods, and automated tools in an effort to foster fundamental change inthe way we build computer software. Even though past experience indicatesotherwise, there is a tacit desire to find the “silver bullet”—the magic process ortranscendent technology that will allow us to build large, complex, software-based systems easily, without confusion, without mistakes, without delay—without the many problems that continue to plague software work.But history indicates that our quest for the silver bullet appears doomedto failure. New technologies are introduced regularly, hyped as a “solution” tomany of the problems software engineers face, and incorporated into projectslarge and small. Industry pundits stress the importance of these “new” softwaretechnologies, the cognoscenti of the software community adopt them withenthusiasm, and ultimately, they do play a role in the software engineeringworld. But they tend not to meet their promise, and as a consequence, the questcontinues.
808CHAPTER
31EMERGING TRENDSIN
SOFTWARE ENGINEERING
KEY
CONCEPTS
building blocks . .817collaborativedevelopment  . .822complexity  . . . .814emergentrequirements  . .816hype cycle  . . . .811innovation life cycle . . . . . .810model-drivendevelopment  . .825open-worldsoftware  . . . . .815open source  . . .818postmodern design  . . . . . . .825
What is it? No one can predict thefuture with absolute certainty. But it ispossible to assess trends in the soft-ware engineering area and fromthose trends to suggest possible directions for thetechnology. That’s what I attempt to do in thischapter.
Who does it? Anyone who is willing to spend thetime to stay abreast of software engineeringissues can try to predict the future direction of thetechnology.
Why is it important? Why did ancient kings hiresoothsayers? Why do major multinational cor-porations hire consulting firms and think tanks toprepare forecasts? Why does a substantial per-centage of the public read horoscopes? Wewant to know what’s coming so we can readyourselves.QUICK
LOOKWhat are the steps? There is no formula for pre-dicting the road ahead. We attempt to do this bycollecting data, organizing it to provide usefulinformation, examining subtle associations toextract knowledge, and from this knowledgesuggest probable trends that predict how thingswill be at some future time.
What is the work product? A view of the near-term future that may or may not be correct.
How do I ensure that I’ve done it right?
Predicting the road ahead is an art, not ascience. In fact, it’s quite rare when a seriousprediction about the future is absolutely right orunequivocally wrong (with the exception, thank-fully, of predictions of the end of the world). Welook for trends and try to extrapolate them. Wecan assess the correctness of the extrapolationonly as time passes.pre75977_ch31.qxd  11/27/08  6:34 PM  Page 808Mili and Cowan [Mil00b] comment on the challenges we face when trying toisolate meaningful technology trends:
What Factors Determine the Success of a Trend? What characterizes successful technological trends: Their technical merit? Their ability to open new markets? Their abil-ity to alter the economics of existing markets?What Lifecycle Does a Trend Follow? Whereas the traditional view is that trends evolve along a well defined, predictable lifecycle that proceeds from a research idea to afinished product through a transfer process, we find that many current trends have eithershort circuited this cycle or followed another one.How Early Can a Successful Trend Be Identified? If we know how to identify suc- cess factors, and/or we understand the lifecycle of a trend, then we seek to identify earlysigns of success of a trend. Rhetorically, we seek the ability to recognize the next trendahead of everybody else.What Aspects of Evolution Are Controllable? Can corporations use their market clout to impose trends? Can the government use its resources to impose trends? Whatrole do standards play in defining trends? The careful analysis of Ada vs. Java, for exam-ple, should be enlightening in this regard.
There are no easy answers to these questions, and there can be no debate that pastattempts at identifying meaningful technologies are mediocre at best.In past editions of this book (over the past 30 years), I have discussed emerg-ing technologies and their projected impact on software engineering. Some havebeen widely adopted, but others never reached their potential. My conclusion:technologies come and go; the real trends you and I should explore are softer. Bythis I mean that progress in software engineering will be guided by business,organizational, market, and cultural trends. Those trends lead to technologyinnovation.In this chapter, we’ll look at a few software engineering technology trends, but myprimary emphasis will be on some of the business, organizational, market, andcultural trends that may have an important influence on software engineering tech-nology over the next 10 or 20 years.
31.1 T ECHNOLOGY EVOLUTION
In a fascinating book that provides a compelling look at how computing (and otherrelated) technologies will evolve, Ray Kurzweil [Kur05] argues that technologicalevolution is similar to biological evolution, but occurs at a rate that is orders of mag-nitude faster. Evolution (whether biological or technological) occurs as a result ofpositive feedback—“the more capable methods resulting from one stage of evolu-tionary progress are used to create the next stage” [Kur06].The big questions for the twenty-first century are: (1) How rapidly does a tech-nology evolve? (2) How significant are the effects of positive feedback. (3) How pro-found will the resultant changes be?CHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 809requirementsengineering  . . .824soft trends  . . . .812technologydirections  . . . . .819technology evolution  . . . . .809test-drivendevelopment  . .826tools  . . . . . . . .827
What arethe “bigquestions” whenwe considertechnologyevolution??pre75977_ch31.qxd  11/27/08  6:34 PM  Page 809When a successful new technology is introduced, the initial concept movesthrough a reasonably predictable “innovation life cycle” [Gai95] illustrated inFigure 31.1. In the breakthroughphase, a problem is recognized and repeatedattempts at a viable solution are attempted. At some point, a solution showspromise. The initial breakthrough work is reproduced in the replicator phase and gains wider usage. Empiricismleads to the creation of empirical rules that govern theuse of the technology, and repeated success leads to a broader theory of usage that is followed by the creation of automated tools during the automation phase. Finally, the technology matures and is used widely.You should note that many research and technology trends never reach maturity.In fact, the vast majority of “promising” technologies in the software engineeringdomain receive widespread interest for a few years and then fall into niche usage bya dedicated band of adherents. This is not to say that these technologies lack merit,but rather to emphasize that the journey through the innovation life cycle is longand hard.Kurzweil [Kur05] agrees that computing technologies evolve through an “S-curve”that exhibits relatively slow growth during the technology’s formative years, rapidacceleration during its growth period, and then a leveling-off period as the technol-ogy reaches its limits. But computing and other related technologies have exhibitedexplosive (exponential) growth during the central stages shown in Figure 31.1 andwill continue to do so. In addition, as one S-curve ends, another replaces it with evenmore explosive growth during its growth period.
1Today, we are at the knee of the S-curve for modern computing technologies—at the transition between early growthand the explosive growth that is to follow. The implication is that over the next 20 to40 years, we will see dramatic (even mind-boggling) changes in computing capability.The coming decades will result in order-of-magnitude changes in computing speed,size, capacity, and energy consumption (to name only a few characteristics).810 PART FIVEADVANCED TOPICS
100
Percent adoption
Breakthrough Replicator Empiricism Theory Automation MaturityFIGURE 31.1
A technologyinnovation lifecycle
Computing technologyis evolving at anexponential rate, andits growth may soonbecome explosive.
1 For example, the limits of integrated circuits may be reached within the next decade, but that tech-nology may be replaced by molecular computing technologies and another accelerated S-curve.uote:
“Predictions arevery difficult tomake, especiallywhen they dealwith the future.”Mark Twainpre75977_ch31.qxd  11/27/08  6:35 PM  Page 810Kurzweil [Kur05] suggests that within 20 years, technology evolution will accel-erate at an increasingly rapid pace, ultimately leading to an era of nonbiologicalintelligence that will merge with and extend human intelligence in ways that are fas-cinating to contemplate.And all of this, no matter how it evolves, will require software and systems thatmake our current efforts look infantile by comparison. By the year 2040, a combina-tion of extreme computation, nanotechnology, massively high bandwidth ubiquitousnetworks, and robotics will lead us into a different world.
2Software, possibly in forms we cannot yet comprehend, will continue to reside at the core of this newworld. Software engineering will not go away.
31.2 O BSERVING SOFTWARE ENGINEERING TRENDS
Section 31.1 briefly considered the fascinating possibilities that may accrue fromlong-term trends in computing and related technologies. But what of the near term?Barry Boehm [Boe08] suggests that “software engineers [will] face the often for-midable challenges of dealing with rapid change, uncertainty and emergence, de-pendability, diversity, and interdependence, but they also have opportunities to makesignificant contributions that will make a difference for the better.” But what are thetrends that will enable you to face these challenges in the years ahead?In the introduction to this chapter, I noted that “soft trends” have a significantimpact on the overall direction of software engineering. But other (“harder”) research-and technology-oriented trends remain important. Research trends “are driven bygeneral perceptions of the state of the art and the state of the practice, by researcherperceptions of practitioner needs, by national funding programs that rally aroundspecific strategic goals, and by sheer technical interest” [Mil00a]. Technology trendsoccur when research trends are extrapolated to meet industry needs and are shapedby market-driven demand.In Section 31.1, I discussed the S-curve model for technology evolution. TheS-curve is appropriate for considering the long-term effects of core technologies asthey evolve. But what of more modest, short-term innovations, tools, and methods?The Gartner Group [Gar08]—a consultancy that studies technology trends acrossmany industries—has developed a hype cycle for emerging technologies, represented in Figure 31.2. The Gartner Group cycle exhibits five phases:
•Technology trigger—a research breakthrough or launch of an innovative newproduct that leads to media coverage and public enthusiasm.
•Peak of inflated expectations—overenthusiasm and overly optimistic projectionsof impact based on limited, but well-publicized successes.CHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 811
2 Kurzweil [Kur05] presents a reasoned technical argument that predicts a strong artificial intelli-gence (that will pass the Turing Test) by 2029 and suggests that the evolution of humans andmachines will begin to merge by 2045. The vast majority of readers of this book will live to seewhether this, in fact, comes to pass.uote:
“I think there is aworld market formaybe fivecomputers.”Thomas Watson,chairman ofIBM, 1943
The “hype cycle”presents a realisticview of short-termtechnology integration.The long-term trend,however, isexponential.pre75977_ch31.qxd  11/27/08  6:35 PM  Page 811•Disillusionment—overly optimistic projections of impact are not met andcritics begin the drumbeat; the technology becomes unfashionable amongthe cognoscenti.
•Slope of enlightenment—growing usage by a wide variety of companies leadsto a better understanding of the technology’s true potential; off-the-shelfmethods and tools emerge to support the technology.
•Plateau of productivity—real-world benefits are now obvious, and usage pene-trates a significant percentage of the potential market.Not every software engineering technology makes it all the way through the hype cycle.In some cases, disillusionment is justified and the technology is relegated to obscurity.
31.3 I DENTIFYING “SOFTTRENDS ”
Each nation with a substantial IT industry has a set of unique characteristics that de-fine the manner in which business is conducted, the organizational dynamics thatarise within a company, the distinct marketing issues that apply to local customers,and the overriding culture that dictates all human interaction. However, some trendsin each of these areas are universal and have as much to do with sociology, anthro-pology, and group psychology (often referred to as the “soft sciences”) as they dowith academic or industrial research.Connectivity and collaboration(enabled by high-bandwidth communication) hasalready led to software teams that do not occupy the same physical space (tele-commuting and part-time employment in a local context). One team collaborateswith other teams that are separated by time zones, primary language, and culture.812 PART FIVEADVANCED TOPICS
Visibility
TechnologytriggerPeak ofinflatedexpectationsTroughofdisillusionmentSlopeofenlightenmentPlateauofproductivityFIGURE 31.2
The GartnerGroup’s hypecycle foremergingtechnologies.Source:[Gar08].
uote:
“640K ought to beenough foranybody.”Bill Gates,chairman ofMicrosoft, 1981pre75977_ch31.qxd  11/27/08  6:35 PM  Page 812Software engineering must respond with an overarching process model for “distrib-uted teams” that is agile enough to meet the demands of immediacy but disciplinedenough to coordinate disparate groups.Globalizationleads to a diverse workforce (in terms of language, culture, problemresolution, management philosophy, communication priorities, and person-to-person interaction). This, in turn, demands a flexible organizational structure.Different teams (in different countries) must respond to engineering problems in away that best accommodates their unique needs, while at the same time fosteringa level of uniformity that allows a global project to proceed. This type of organizationsuggests fewer levels of management and a greater emphasis on team-level decisionmaking. It can lead to greater agility, but only if communication mechanisms havebeen established so that every team can understand project and technical status (vianetworked groupware) at any time. Software engineering methods and tools canhelp achieve some level of uniformity (teams speak the same “language” imple-mented through specific methods and tools). Software process can provide theframework for the instantiation of these methods and tools.In some world regions (the United States and Europe are examples), the popula-tion is aging. This undeniable demographic (and cultural trend) implies that manyexperienced software engineers and managers will be leaving the field over the com-ing decade. The software engineering community must respond with viable mecha-nisms that capture the knowledge of these aging managers and technologists [e.g.,the use of patterns(Chapter 12) is a step in the right direction], so that it will be avail-able to future generations of software workers. In other regions of the world, thenumber of young people available to the software industry is exploding. This pro-vides an opportunity to mold a software engineering culture without the burden of50 years of “old-school” prejudices.It is estimated that over one billion new consumers will enter the worldwidemarketplace over the next decade. Consumer spending in “emerging economies willdouble to well over $9 trillion” [Pet06]. There is little doubt that a nontrivial percent-age of this spending will be applied to products and services that have a digitalcomponent—that are software based or software driven. The implication—anincreasing demand for new software. The question then is, “Can new software engi-neering technologies be developed to meet this worldwide demand?” Modernmarket trends are often driven by the supply side.
3In other cases, demand-side requirements drive the market. In either case, a cycle of innovation and demand pro-gresses in a way that sometimes makes it difficult to determine which came first!Finally, human culture itself will impact the direction of software engineering.Every generation establishes its own imprint on local culture, and yours will be nodifferent. Faith Popcorn [Pop08], a well-known consultant who specializes inCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 813
What softtrends willimpacttechnologiesrelated tosoftwareengineering??
3 Supply side adopts a “build it and they will come” approach to markets. Unique technologies arecreated, and consumers flock to adopt them—sometimes!pre75977_ch31.qxd  11/27/08  6:35 PM  Page 813cultural trends, characterizes them in the following manner: “Our Trends are notfads. Our Trends endure. Our Trends evolve. They represent underlying forces, firstcauses, basic human needs, attitudes, aspirations. They help us navigate the world,understand what’s happening and why, and prepare for what is yet to come.” A de-tailed discussion of how modern cultural trends will have an impact on softwareengineering is best left to those who specialize in the “soft sciences.”
31.3.1 Managing Complexity
When the first edition of this book was written (1982), digital consumer products aswe now know them today didn’t exist, and mainframe-based systems containing amillion lines of source code (LOC) were considered to be quite large. Today, it is notuncommon for small digital devices to encompass between 60,000 to 200,000 linesof custom software, coupled with a few million LOC for operating system features.Modern computer-based systems containing 10 to 50 million lines of code are notuncommon.
4In the relatively near future, systems5requiring over 1 billion LOC will begin to emerge.
6
Think about that for a moment!Consider the interfaces for a billion LOC system, both to the outside world, toother interoperable systems, to the Internet (or its successor), and to the millions ofinternal components that must all work together to make this computing monsteroperate successfully. Is there a reliable way to ensure that all of these connectionswill allow information to flow properly?Consider the project itself. How do we manage the workflow and track progress?Will conventional approaches scale upward by orders of magnitude?Consider the number of people (and their locations) who will be doing the work,the coordination of people and technology, the unrelenting flow of changes, the like-lihood of a multiplatform, multioperating system environment. Is there a way tomanage and coordinate people who are working on a monster project?Consider the engineering challenge. How can we analyze tens of thousands ofrequirements, constraints, and restrictions in a way that ensures that inconsistencyand ambiguity, omissions, and outright errors are uncovered and corrected? Howcan we create a design architecture that is robust enough to handle a system of thissize? How can software engineers establish a change management system that willhave to handle hundreds of thousands of changes?Consider the challenge of quality assurance. How can we perform verification andvalidation in a meaningful way? How do you test a 1 billion LOC system?814 PART FIVEADVANCED TOPICS
4 For example, modern PC operating systems (e.g., Linux, MacOS, and Windows) have between 30and 60 million LOC. Operating system software for mobile devices can exceed 2 million LOC.5 In reality, this “system” will actually be a system of systems—hundreds of interoperable applica-tions working together to achieve some overall objective.6 Not all complex systems are large. A relatively small application (say, less than 100,000 LOC canstill be exceedingly complex.uote:
“There is no reasonanyone would wanta computer in theirhome.”Ken Olson,President,Chairman, andFounder ofDigitalEquipmentCorp., 1977pre75977_ch31.qxd  11/27/08  6:35 PM  Page 814In the early days, software engineers attempted to manage complexity in what canonly be described as an ad hoc fashion. Today, we use process, methods, and tools tokeep complexity under control. But tomorrow? Is our current approach up to the task?
31.3.2 Open-World Software
Concepts such as ambient intelligence,7context-aware applications, and pervasive/ ubiquitous computing—all focus on integrating software-based systems into an envi-ronment far broader that a PC, a mobile computing device, or any other digital device.These separate visions of the near-term future of computing collectively suggest“open-world software”—software that is designed to adapt to a continually changingenvironment “by self-organizing its structure and self-adapting its behavior” [Bar06].To help illustrate the challenges that software engineers will face in the foresee-able future, consider the notion of ambient intelligence (amI). Ducatel [Duc01] defines amI in the following way: “People are surrounded by intelligent, intuitive interfacesthat are embedded in all kinds of objects. The ambient intelligence environment iscapable of recognizing and responding to the presence of different individuals [whileworking] in a seamless, unobstrusive way.”Let’s examine a vision of the near future in which amI has become ubiquitous.You’ve just purchased a personal communicator (called a P-com, a pocket-sized mo-bile device) and have spent the last few weeks creating
8your “image”—everything from your daily schedule, to-do list, address book, medical records, business-relatedinformation, travel documents, wish list (things you’re looking for, e.g., a specificbook, a bottle of hard-to-find wine, a local course in glass blowing), and “Digital-Me”(D-Me) that describes you at a level of detail that allows a digital introduction to oth-ers (sort of a MySpaceor FaceBookthat moves with you). The P-com contains a per-sonal identifier called a “key of keys”—a multifunctional personal identifier that wouldprovide access to and enable queries from a wide range of amI devices and systems.It should be obvious that significant privacy and security issues come into play. A“trust management system” [Duc01] will be an integral part of amI and will manageprivileges that enable communication with networks, health, entertainment, finan-cial, employment, and personal systems.New amI-capable systems will be added to the network constantly, each provid-ing useful capabilities and demanding access to your P-com. Therefore, the P-comsoftware must be designed so that it can adapt to the requirements that emergeas some new amI systems go online. There are many ways to accomplish this, butthe bottom line is this: the P-com software must be flexible and robust in ways thatconventional software can’t match.CHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 815
7 A worthwhile and quite detailed introduction to ambient intelligence can be found atwww.emergingcommunication.com/volume6.html . More information can be obtained at www.ambientintelligence.org/ . 8 All interaction with the P-com occurs via continuous voice recognition commands and statements,which has evolved to become 99 percent accurate.Open-world softwareencompasses ambientintelligence, context-aware apps, and per-vasive computing.pre75977_ch31.qxd  11/27/08  6:35 PM  Page 81531.3.3 Emergent Requirements
At the beginning of a software project, there’s a truism that applies equally to everystakeholder involved: “You don’t know what you don’t know.” That means that cus-tomers rarely define “stable” requirements. It also means that software engineerscannot always foresee where ambiguities and inconsistencies lie. Requirementschange—but that’s nothing new.As systems become more complex, it follows that even a rudimentary attempt tostate comprehensive requirements is doomed to failure. A statement of overall goalsmay be possible, delineation of intermediate objectives can be accomplished, butstable requirements—not a chance! Requirements will emerge as everyone involvedin the engineering and construction of a complex system learns more about it, theenvironment in which it is to reside, and the users who will interact with it.This reality implies a number of software engineering trends. First, process mod-els must be designed to embrace change and adopt the basic tenets of the agile phi-losophy (Chapter 3). Next, methods that yield engineering models (e.g., requirementsand design models) must be used judiciously because those models will changerepeatedly as more knowledge about the system is acquired. Finally, tools thatsupport both process and methods must make adaptation and change easy.But there is another aspect to emergent requirements. The vast majority of soft-ware developed to date assumes that the boundary between the software-basedsystem and its external environment is stable. The boundary may change, but it willdo so in a controlled manner, allowing the software to be adapted as part of a regularsoftware maintenance cycle. This assumption is beginning to change. Open-worldsoftware (Section 31.2.2) demands that computer-based systems “adapt and react tochanges dynamically, even if they’re unanticipated” [Bar06].By their nature, emergent requirements lead to change. How do we control theevolution of a widely used application or system over its lifetime, and what effectdoes this have on the way we design software?As the number of changes grows, the likelihood of unintended side effects alsogrows. This should be a cause for concern as complex systems with emergentrequirements become the norm. The software engineering community must developmethods that help software teams predict the impact of change across an entire sys-tem, thereby mitigating unintended side effects. Today, our ability to accomplish thisis severely limited.
31.3.4 The Talent Mix
As software-based systems become more complex, as communication and collabo-ration among global teams becomes commonplace, as emergent requirements (withthe resultant flow of changes) become the norm, the very nature of a software engi-neering team may change. Each software team must bring a variety of creative tal-ent and technical skills to its part of a complex system, and the overall process mustallow the output of these islands of talent to merge effectively.816 PART FIVEADVANCED TOPICS
Because emergentrequirements arealready a reality, yourorganization shouldconsider adopting anincremental processmodel.pre75977_ch31.qxd  11/27/08  6:35 PM  Page 816Alexandra Weber Morales [Mor05] suggests the talent mix of a “software dreamteam.” The Brainis a chief architect who is able to navigate the demands of stake-holders and map them into a technology framework that is both extensible andimplementable. The Data Grrlis a database and data structures guru who “blaststhrough rows and columns with profound understanding of predicate logic andset theory as it pertains to the relational model.” The Blocker is a technical leader (manager) who allows the team to work free of interference from other teams whileat the same time ensuring that collaboration is occurring. The Hacker is a consum- mate programmer who is at home with patterns and languages and can use botheffectively. The Gatherer“deftly discovers system requirements with . . . anthropo-logical insight” and accurately expresses them with clarity.
31.3.5 Software Building Blocks
All of us who have fostered a software engineering philosophy have emphasized theneed for reuse—of source code, object-oriented classes, components, patterns, andCOTS software. Although the software engineering community has made progressas it attempts to capture past knowledge and reuse proven solutions, a significantpercentage of the software that is built today continues to be built “from scratch.”Part of the reason for this is a continuing desire (by stakeholders and software engi-neering practitioners) for “unique solutions.”In the hardware world, original equipment manufacturers (OEMs) of digitaldevices use application-specific standard products (ASSPs) produced by siliconvendors almost exclusively. This “merchant hardware” provides the building blocksnecessary to implement everything from a mobile phone to an HD-DVD player.Increasingly, the same OEMs are using “merchant software”—software buildingblocks designed specifically for a unique application domain [e.g., VoIP devices].Michael Ward [War07] comments:
One advantage of the use of software components is that the OEM can leverage the func-tionality provided by the software without having to develop in-house expertise in thespecific functions or invest developer time on the effort to implement and validate thecomponents. Other advantages include the ability to acquire and deploy only the specificset of functionalities that are needed for the system, as well as the ability to integratethese components into an already-existing architecture.However, the software component approach does have a disadvantage in that thereis a given level of effort required to integrate the individual components into the overallproduct. This integration challenge may be further complicated if the components aresourced from a variety of vendors, each with its own interface methodologies. As addi-tional sources of components are used, the effort required to manage various vendors in-creases, and there is a greater risk of encountering problems related to the interactionacross components from different sources.
In addition to components packaged as merchant software, there is an increasingtendency to adopt software platform solutions that “incorporate collections of relatedCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 817
uote:
“The proper artisticresponse to digitaltechnology is toembrace it as anew window oneverything that’seternally human,and to use it withpassion, wisdom,fearlessnessand joy.”RalphLombregliapre75977_ch31.qxd  11/27/08  6:35 PM  Page 817functionalities, typically provided within an integrated software framework”[War07]. A software platform frees an OEM from the work associated with develop-ing base functionality and instead allows the OEM to dedicate software effort onthose features that differentiate its product.
31.3.6 Changing Perceptions of “Value”
During the last quarter of the twentieth century, the operative question that busi-nesspeople asked when discussing software was: “Why does it cost so much?” Thatquestion is rarely asked today and has been replaced by “Why can’t we get it (soft-ware and/or the software-based product) sooner?” When computer software is considered, the modern perception of value is chang-ing from business value (cost and profitability) to customer values that include:speed of delivery, richness of functionality, and overall product quality.
31.3.7 Open Source
Who owns the software you or your organization uses? Increasingly, the answer is“everyone.” The “open source” movement has been described in the following man-ner [OSO08]: “Open source is a development method for software that harnesses thepower of distributed peer review and transparency of process. The promise of opensource is better quality, higher reliability, more flexibility, lower cost, and an end topredatory vendor lock-in.” The term open source when applied to computer software, implies that software engineering work products (models, source code, test suites)are open to the public and can be reviewed and extended (with controls) by anyonewith interest and permission.An open-source “team” may have a number of full-time “dream team” members(Section 31.3.4), but the number of people working on the software expands andcontracts as interest in the application strengthens or weakens. The power of theopen-source team is derived from constant peer review and design/code refactor-ing that results in a slow progression toward an optimal solution.If you have further interest, Weber [Web05] provides a worthwhile introduction,and Feller and his colleagues [Fel07] have edited a comprehensive and objectiveanthology that considers the benefits and problems associated with open source.818 PART FIVEADVANCED TOPICS
Technologies to Watch
Many emerging technologies are likely to havea significant impact on the types of computer-based systems that evolve. These technologies add to thechallenges confronting software engineers. The followingtechnologies are worthy of note:Grid computing—this technology (available today)creates a network that taps the billions of unused CPUcycles from every machine on the network and allowsexceedingly complex computing jobs to be completedwithout a dedicated supercomputer. For a real-lifeINFOpre75977_ch31.qxd  11/27/08  6:35 PM  Page 81831.4 T ECHNOLOGY DIRECTIONS
We always seem to think that software engineering will change more rapidly than itdoes. A new “hype” technology (it could be a new process, a unique method, or anexciting tool) is introduced, and pundits suggest that “everything” will change. Butsoftware engineering is about far more than technology—it’s about people and theirability to communicate their needs and innovate to make those needs a reality.Whenever people are involved, change occurs slowly in fits and starts. It’s only whena “tipping point” [Gla02] is reached, that a technology cascades across the softwareengineering community and broad-based change truly does occur.In this section I’ll examine a few trends in process, methods, and tools that arelikely to have some influence on software engineering over the next decade. Willthey lead to a tipping point? We’ll just have to wait and see.
31.4.1 Process Trends
It can be argued that all of the business, organizational, and cultural trends discussedin Section 31.3 reinforce the need for process. But do the frameworks discussed inChapter 30 provide a road map into the future? Will process frameworks evolve tofind a better balance between discipline and creativity? Will the software processadapt to the differing needs of stakeholders who procure software, those who buildit, and those who use it? Can it provide a means for reducing risk for all three con-stituencies at the same time?These and many other questions remain open. However, some trends are begin-ning to emerge. Conradi and Fuggetta [Con02] suggest six “theses on how toCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 819
example encompassing over 4.5 million computers,visit http://setiathome.berkeley.edu/.Open-world computing—“It’s ambient, implicit,invisible, and adaptive. It’s when network devicesembedded in the environment provide unobtrusiveconnectivity and services all the time” [McC05].Microcommerce—a new branch of e-commerce thatcharges very small amounts for access to or purchaseof various forms of intellectual property. Apple iTunes isa widely used example.Cognitive machines—the “holy grail” in the roboticsfield is to develop machines that are aware of theirenvironment, that can “pick up on cues, respond to ever-changing situations, and interact with people naturally”[PCM03]. Cognitive machines are still in the early stagesof development, but the potential is enormous.OLED displays—an OLED “uses a carbon-baseddesigner molecule that emits light when an electriccurrent passes through it. Piece lots of moleculestogether and you’ve got a superthin display of stunningquality—no power-draining backlight required”[PCM03]. The result—ultrathin displays that can berolled up or folded, sprayed onto a curved surface, orotherwise adapted to a specific environment.RFIDs—radio frequency identification brings open-worldcomputing to an industrial base and the consumerproducts industry. Everything from tubes of toothpasteto automobile engines will be identifiable as it movesthrough the supply chain to its ultimate destination.Web 2.0—one of a broad array of Web services thatwill lead to even greater integration of the Web intoboth commerce and personal computing.For further discussion of technologies to watch,presented in a unique combination of video and print,visit the Consumer Electronics Association website atwww.ce.org/Press/CEA_Pubs/135.asp .
uote:
“But what is itgood for?”Engineer at theAdvancedComputingSystemsDivision ofIBM, 1968,commenting onthe microchippre75977_ch31.qxd  11/27/08  6:35 PM  Page 819enhance and better apply SPI frameworks.” They begin their discussion with thefollowing statement:
A software procurer’s goal is to select the best contractor objectively and rationally. Asoftware company’s goal is to survive and grow in a competitive market. An end user’sgoal is to acquire the software product that can solve the right problem, at the right time,at an acceptable price. We cannot expect the same SPI approach and consequent effortto accommodate all these viewpoints.
In the paragraphs that follow, I have adapted the theses proposed by Conradi andFuggetta [Con02] to suggest possible process trends over the next decade.1.As SPI frameworks evolve, they will emphasize “strategies that focus on goalorientation and product innovation”[Con02]. In the fast-paced world of soft-ware development, long-term SPI strategies rarely survive in a dynamicbusiness environment. Too much changes too quickly. This means that astable, step-by-step road map for SPI may have to be replaced with aframework that emphasizes short-term goals that have a product orienta-tion. If the requirements for a new software-based product line will emergeover a series of incremental product releases (to be delivered to end usersvia the Web) the software organization may recognize the need to improveits ability to manage change. Process improvements associated withchange management must be coordinated with the release cycle of theproduct in a way that will improve change management while at the sametime not being disruptive.2.Because software engineers have a good sense of where the process is weak,process changes should generally be driven by their needs and should start formthe bottom up.Conradi and Fuggetta [Con02] suggest that future SPI activitiesshould “use a simple and focused scorecard to start with, not a large assess-ment.” By focusing SPI efforts narrowly and working from the bottom up,practitioners will begin to see substantive changes early—changes that makea real difference in the way that software engineering work is conducted.3.Automated software process technology (SPT) will move away from globalprocess management (broad-based support of the entire software process)to focus on those aspects of the software process that can best benefit fromautomation.No one is against tools and automation, but in many instances,SPT has not met its promise (see Section 31.2). To be most effective, itshould focus on umbrella activities (Chapter 2)—the most stable elementsof the software process.4.Greater emphasis will be placed on the return on investment of SPI activities. In Chapter 30, you learned that return on investment (ROI) can be defined as:ROI /H11005/H11003100%
/H20858(benefits)/H11002/H20858(costs)/H20858(costs)820 PART FIVEADVANCED TOPICS
Whatprocesstrends are likelyover the nextdecade??pre75977_ch31.qxd  11/27/08  6:35 PM  Page 820To date, software organizations have struggled to clearly delineate “benefits”in a quantitative manner. It can be argued [Con02] that “we therefore need astandardized market-value model, such as the one employed in Cocomo II(see Chapter 26) to account for software improvement initiatives.”5.As time passes, the software community may come to understand that expertisein sociology and anthropology may have as much or more to do with successfulSPI as other, more technical disciplines.Above all else, SPI changes organiza-tional culture, and cultural change involves individuals and groups of people.Conradi and Fuggetta [Con02] correctly note that “software developers areknowledge workers. They tend to respond negatively to top-level dictates onhow to do work or change processes.” Much can be learned by examining thesociology of groups to better understand effective ways to introduce change.6.New modes of learning may facilitate the transition to a more effective softwareprocess.In this context, “learning” implies learning from successes and mis-takes. A software organization that collects metrics (Chapters 23 and 25)allows itself to understand how elements of a process affect the quality of theend product.
31.4.2 The Grand Challenge
There is one trend that is undeniable—software-based systems will undoubtedlybecome bigger and more complex as time passes. It is the engineering of these large,complex systems, regardless of delivery platform or application domain, that posesthe “grand challenge” [Bro06] for software engineers. Manfred Broy [Bro06] suggeststhat software engineers can meet “the daunting challenge of complex softwaresystems development” by creating new approaches to understanding system mod-els and using those models as a basis for the construction of high-quality next-generation software.As the software engineering community develops new model-driven approaches(discussed later in this section) to the representation of system requirements anddesign, the following characteristics [Bro06] must be addressed:
•Multifunctionality—as digital devices evolve into their second and third gener-ation, they have begun to deliver a rich set of sometimes unrelated functions.The mobile phone, once considered a communication device, is now usedfor taking photos, keeping a calendar, navigating a journey, and as a musicplayer. If open-world interfaces come to pass, these mobile devices will beused for much more over the coming years. As Broy [Bro06] notes,“engineers must describe the detailed context in which the functions will bedelivered and, most important, must identify the potentially harmful interac-tions between the system’s different features.”
•Reactivity and timeliness—digital devices increasingly interact with the realworld and must react to external stimuli in a timely manner. They mustCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 821
What systemcharacter-istics mustanalysts anddesigners considerfor future apps??pre75977_ch31.qxd  11/27/08  6:35 PM  Page 821interface with a broad array of sensors and must respond in a time framethat is appropriate to the task at hand. New methods must be developed that(1) help software engineers predict the timing of various reactive featuresand (2) implement those features in a way that makes the feature lessmachine dependent and more portable.
•New modes of user interaction—the keyboard and mouse work well in aPC environment, but open-world trends for software mean that new modesof interaction must be modeled and implemented. Whether these newapproaches use multitouch interfaces, voice recognition, or direct mind inter-faces,
9new generations of software for digital devices must model these newhuman-computer interfaces.
•Complex architectures—a luxury automobile has over 2000 functionscontrolled by software that resides within a complex hardware architecturethat includes multiple CPUs, a sophisticated bus structure, actuators, sensors,an increasingly sophisticated human interface, and many safety-ratedcomponents. Even more complex systems are on the immediate horizon,presenting significant challenges for software designers.
•Heterogeneous, distributed systems—the real-time components of any modernembedded system can be connected via an internal bus, a wireless network,or across the Internet (or all three).
•Criticality—software has become the pivotal component in virtually allbusiness-critical systems and in most safety-critical systems. Yet, thesoftware engineering community has only begun to apply even the mostbasic principles of software safety.
•Maintenance variability—the life of software within a digital device rarely lastsbeyond 3 to 5 years, but the complex avionics systems within an aircraft hasa useful life of at least 20 years. Automobile software falls somewhere inbetween. Should this have an impact on design?Broy [Bro06] argues that these and other software characteristics can be managedonly if the software engineering community develops a more effective distributedand collaborative software engineering philosophy, better requirements engineeringapproaches, a more robust approach to model-driven development, and better soft-ware tools. In the sections that follow I’ll explore each of these areas briefly.
31.4.3 Collaborative Development
It seems almost too obvious to state, but I’ll do so anyway: software engineering is an information technology.From the onset of any software project, every stakeholder822 PART FIVEADVANCED TOPICS
9 A brief discussion of direct mind interfaces can be found at http://en.wikipedia.org/wiki/Brain-computer_interface, and a commercial example is described at http://au.gamespot.com/news/6166959.html.pre75977_ch31.qxd  11/27/08  6:35 PM  Page 822must share information—about basic business goals and objectives, about specificsystem requirements, about architectural design issues, about almost every aspectof the software to be built.Today, software engineers collaborate across time zones and internationalboundaries, and every one of them must share information. The same holds foropen-source projects in which hundreds or thousands of software developers workto build an open-source app. Again, information must be disseminated so that opencollaboration can occur.The challenge over the next decade is to develop methods and tools that facilitatethat collaboration. Today, we continue to struggle to make collaboration easy.Eugene Kim [Kim04] comments:
Consider a basic collaborative task: document-sharing. A number of applications (bothcommercial and open source) claim to solve the document-sharing problem, and yet, thepredominant method for sharing files is to email them back and forth. This is the com-putational equivalent of sneakernet. If the tools that purport to solve this problem aregood, why aren’t we using them?We see similar problems in other basic areas. I can walk into any meeting anywherein the world with a piece of paper in hand, and I can be sure that people will be able toread it, mark it up, pass it around, and file it away. I can’t say the same for electronic doc-uments. I can’t annotate a Web page or use the same filing system for both my email andmy Word documents, at least not in a way that is guaranteed to be interoperable withapplications on my own machine and on others. Why not?. . . In order to make a real impact in the collaborative space, tools must not only begood, they must be interoperable.
But a lack of comprehensive collaborative tools is only one part of the challengefaced by those who must develop software collaboratively.Today, a significant percentage
10of IT projects are outsourced internationally, andthe number will grow substantially over the next decade. Not surprisingly, Bhat andhis colleagues [Bha06] contend that requirements engineering is the crucial activityin an outsourcing project. They identify a number of success factors that lead tosuccessful collaborative efforts:•Shared goals—project goals must be clearly enunciated, and all stakeholdersmust understand them and agree with their intent.•Shared culture—cultural differences should be clearly defined, and aneducational approach (that will help to mitigate those differences) and acommunication approach (that will facilitate knowledge transfer) should bedeveloped.CHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 823
Collaboration involvesthe timelydissemination ofinformation and aneffective process forcommunication anddecision making.
10 Approximately 20 percent of a typical IT budget for large companies is currently dedicated tooutsourcing, and the percentage is growing every year. (Source: www.logicacmg.com/page/400002849.)pre75977_ch31.qxd  11/27/08  6:35 PM  Page 823•Shared process—in some ways, process serves as the skeleton of a collabora-tive project, providing a uniform means for assessing progress and directionand introducing a common technical “language” for all team members.•Shared responsibility—every team member must recognize the importance ofrequirements engineering and work to provide the best possible definitionof the system.When combined, these success factors lead to “trust”—a global team that can relyon disparate groups to accomplish the job they are assigned.
31.4.4 Requirements Engineering
Basic requirements engineering actions—elicitation, elaboration, negotiation, spec-ification, and validation—were presented in Chapters 5 through 7. The success orfailure of these actions has a very strong influence on the success or failure of theentire software engineering process. And yet, requirements engineering (RE) hasbeen compared to “trying to put a hose clamp around jello” [Gon04]. As I’ve noted inmany places throughout this book, software requirements have a tendency to keepchanging, and with the advent of open-world systems, emergent requirements (andnear-continuous change) may become the norm.Today, most “informal” requirements engineering approaches begin with the cre-ation of user scenarios (e.g., use cases). More formal approaches create one or morerequirements models and use these as a basis for design. Formal methods enable asoftware engineer to represent requirements using a verifiable mathematical nota-tion. All can work reasonably well when requirements are stable, but do not readilysolve the problem of dynamic or emergent requirements.There are a number of distinct requirements engineering research directionsincluding natural language processing from translated textual descriptions into morestructured representations (e.g., analysis classes), greater reliance on databases forstructuring and understanding software requirements, the use of RE patterns todescribe typical problems and solutions when requirements engineering tasks areconducted, and goal-oriented requirements engineering. However, at the industrylevel, RE actions remain relatively informal and surprisingly basic. To improve themanner in which requirements are defined, the software engineering community willlikely implement three distinct subprocesses as RE is conducted [Gli07]: (1) improvedknowledge acquisition and knowledge sharing that allows more complete under-standing of application domain constraints and stakeholder needs, (2) greater empha-sis on iteration as requirements are defined, and (3) more effective communicationand coordination tools that enable all stakeholders to collaborate effectively.The RE subprocesses noted in the preceding paragraph will only succeed if theyare properly integrated into an evolving approach to software engineering. Aspattern-based problem solving and component-based solutions begin to dominatemany application domains, RE must accommodate the desire for agility (rapid824 PART FIVEADVANCED TOPICS
“New RE subprocessesinclude: (1) improvedknowledge acquisition,(2) even moreiteration, and(3) more effectivecommunication andcoordination tools.”pre75977_ch31.qxd  12/3/08  1:56 PM  Page 824incremental delivery) and the inherent emergent requirements that result. The con-current nature of many software engineering process models means that RE will beintegrated with design and construction activities. As a consequence, the notion ofa static “software specification” is beginning to disappear, to be replaced by “value-driven requirements” [Som05] derived as stakeholders respond to features and func-tions delivered in early software increments.
31.4.5 Model-Driven Software Development
Software engineers grapple with abstraction at virtually every step in the softwareengineering process. As design commences, architectural and component-levelabstractions are represented and assessed. They must then be translated into a pro-gramming language representation that transforms the design (a relatively high levelof abstraction) into an operable system with a specific computing environment(a low level of abstraction). Model-driven software development
11couples domain- specific modeling languages with transformation engines and generators in a waythat facilitates the representation of abstraction at high levels and then transforms itinto lower levels [Sch06].Domain-specific modeling languages(DSMLs) represent “application structure, behavior and requirements within particular application domains” and are describedwith meta-models that “define the relationships among concepts in the domain andprecisely specify the key semantics and constraints associated with these domainconcepts” [Sch06]. The key difference between a DSML and a general-purpose mod-eling language such as UML (Appendix 1) is that the DSML is tuned to design con-cepts inherent in the application domain and can therefore represent relationshipsand constraints among design elements in an efficient manner.
31.4.6 Postmodern Design
In an interesting article on software design in the “postmodern era,” PhilippeKruchten [Kru05] makes the following observation:
Computer science hasn’t achieved the grand narrative that explains it all, the big picture — we haven’t found the fundamental laws of software that would play the role that the fun-damental laws of physics play in other engineering disciplines. We still live with the bitteraftertaste of the Internet bubble burst and the Y2K doomsday. So, in this postmodern era,where it seems that everything matters a bit yet not much really matters, what are thenext directions for software design?
Part of any attempt to understand trends in software design is to establish bound-aries for design. Where does requirements engineering stop and design begin?Where does design stop and code generation begin? The answers to these questionsare not as easy as they might first appear. Even though the requirements modelshould focus on “what,” not “how,” every analyst does a bit of design and almost allCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 825
11 The term model-driven engineering (MDE) is also used.Model-drivenapproaches address acontinuing challengefor all softwaredevelopers—how torepresent software at ahigher level ofabstraction than code.pre75977_ch31.qxd  12/3/08  1:56 PM  Page 825designers do a bit of analysis. Similarly, as the design of software components movescloser to algorithmic detail, a designer begins to represent the component at a levelof abstraction that is close to code.Postmodern design will continue to emphasize the importance of software archi-tecture (Chapter 9). A designer must state an architectural issue, make a decisionthat addresses the issue, and then clearly define the assumptions, constraints, andimplications that the decision places on the software as a whole. But is there a frame-work in which the issues can be described and the architecture can be defined?Aspect-oriented software development (Chapter 2) or model-driven software devel-opment (Section 31.4.4) may become important design approaches in the yearsahead, but it’s still too soon to tell. It may be that breakthroughs in component-baseddevelopment (Chapter 10) may lead to a design philosophy that emphasizes the as-sembly of existing components. If the past is prologue, it’s highly likely that many“new” design methods will emerge, but few will ride the hype curve (Figure 31.2)much beyond the “trough of disillusionment.”
31.4.7 Test-Driven Development
Requirements drive design, and design establishes a foundation for construction.This simple software engineering reality works reasonably well and is essential as asoftware architecture is created. However, a subtle change can provide significantbenefit when component-level design and construction are considered.In test-driven development(TDD),requirements for a software component serve asthe basis for the creation of a series of test cases that exercise the interface andattempt to find errors in the data structures and functionality delivered by the com-ponent. TDD is not really a new technology but rather a trend that emphasizes thedesign of test cases beforethe creation of source code.
12
The TDD process follows the simple procedural flow illustrated in Figure 31.3.Before the first small segment of code is created, a software engineer creates a testto exercise the code (to try to make the code fail). The code is then written to satisfythe test. If it passes, a new test is created for the next segment of code to be devel-oped. The process continues until the component is fully coded and all tests executewithout error. However, if any test succeeds in finding an error, the existing code isrefactored (corrected) and all tests created to that point are reexecuted. This itera-tive flow continues until there are no tests left to be created, implying that the com-ponent meets all requirements defined for it.During TDD, code is developed in very small increments (one subfunction at atime), and no code is written until a test exists to exercise it. You should note thateach iteration results in one or more new tests that are added to a regression testsuite that is run with every change. This is done to ensure that the new code has notgenerated side effects that cause errors in the older code.826 PART FIVEADVANCED TOPICS
12 Recall that Extreme Programming (Chapter 3) emphasizes this approach as part of its agile processmodel.“TDD is a trend thatemphasizes the designof test cases beforethe creation ofsource code.”pre75977_ch31.qxd  12/3/08  1:56 PM  Page 826In TDD, tests drive the detailed component design and the resultant source code. Theresults of these tests cause immediate modifications to the component design (via thecode), and more important, the resultant component (when completed) has been ver-ified in stand-alone fashion. If you have further interest in TDD, see [Bec04b] or [Ast04].
31.5 T OOLS -RELATED TRENDS
Hundreds of industry-grade software engineering tools are introduced each year.The majority are provided by tools vendors who claim that their tool will improveproject management, or requirements analysis, or design modeling, or code gener-ation, or testing, or change management, or any of the many software engineeringactivities, actions, and tasks discussed throughout this book. Other tools have beendeveloped as open-source offerings. The majority of open-source tools focus on“programming” activities with a specific emphasis on the construction activity (par-ticularly code generation). Still other tools grow out of research efforts at universi-ties and government labs. Although they have appeal in very limited applications, themajority are not ready for broad industry application.At the industry level, the most comprehensive tools packages form software engi-neering environments(SEE)
13that integrate a collection of individual tools arounda central database (repository). When considered as a whole, an SEE integratesCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 827
Tests remain tobe createdCreate atest case
Write a newcode segment
Run thetest(s)Refactor (correct)thecode segment No tests remain tobe created
Finds errorDoes not find errorFIGURE 31.3
Test-drivendevelopmentprocess flow
13 The term integrated development environment (IDE) is also used.pre75977_ch31.qxd  11/27/08  6:35 PM  Page 827information across the software process and assists in the collaboration that isrequired for many large, complex software-based systems. But current environmentsare not easily extensible (it’s difficult to integrate a COTS tool that is not part of thepackage) and tend to be general purpose (i.e., they are not application domainspecific). There is also a substantial time lag between the introduction of new tech-nology solutions (e.g., model-driven software development) and the availability ofviable SEEs that support the new technology.Future trends in software tools will follow two distinct paths—a human-focusedpaththat responds to some of the “soft trends” discussed in Section 31.3, and atechnology-centered path that addresses new technologies (Section 31.4) as they areintroduced and adopted. In the sections that follow, I’ll examine each path briefly.
31.5.1 Tools That Respond to Soft Trends
The soft trends discussed in Section 31.3—the need to manage complexity, accom-modate emergent requirements, establish process models that embrace change,coordinate global teams with a changing talent mix, among others—suggest a newera in which tools support for stakeholder collaboration will become as important astools support for technology. But what kind of tool set supports these soft trends?One example of research in this area is GENESIS—a generalized, open-sourceenvironment designed to support collaborative software engineering work [Ave04].The GENESIS environment may or may not gain widespread usage, but its basicelements are representative of the direction of collaborative SEEs that will evolve tosupport the soft trends noted in this chapter.A collaborative SEE “supports co-operation and communication among softwareengineers belonging to distributed development teams involved in modeling, control-ling, and measuring software development and maintenance processes. Moreover, itincludes an artifact management function that stores and manages software artifacts(work products) produced by different teams in the course of their work” [Bol02].Figure 31.4 illustrates an architecture for a collaborative SEE. The architecture,based on the GENESIS environment [Ave04], is constructed of subsystems that areintegrated within a common Web client and is complemented by server-basedcomponents that provide support for all clients. Each development organizationhas its own client-side subsystems that communicate to other clients. Referring toFigure 31.4, a resource management subsystem manages the allocation of human resources to different projects or subprojects; a work product management system is “responsible for the creation, modification, deletion,” indexing, searching, and stor-age of all software engineering work products [Ave04]; a workflow managementsubsystemcoordinates the definition, instantiation, and implementation of softwareprocess activities, actions, and tasks; an event engine“collects events” that occur dur- ing the software process (e.g., a successful review of a work product, the completionof unit testing of a component) and notifies others; a communication system supports both synchronous and asynchronous communication among the distributed teams.828 PART FIVEADVANCED TOPICSpre75977_ch31.qxd  11/27/08  6:35 PM  Page 828On the server side, four components share a workflow support database. Thecomponents implement the following functions:
•Process definition—a tool set that enables a team to define new processactivities, actions, or tasks and defines the rules that govern how theseprocess elements interact with one another and the work products theyproduce.
•Project management—a tool set that allows the team to build a project planand coordinate the plan with other teams or projects.
•Workflow engine—“interacts with the event engine to propagate events thatare relevant for the execution of cooperating processes executed on othersites” [Ave04].
•Worklist handler—interacts with the server-side database to provide asoftware engineer with information about the task currently under way orany future task that is derived from work that is currently being performed.Although the architecture of a collaborative SEE may vary considerably from theone discussed in this section, the basic functional elements (management systemsCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 829
WorkflowmanagementsystemClient-side coordination layerCommunicationsystemResourcemanagementsystemWork productmanagementsystemWorklisthandlerServer-sideWorkflowengineProcessdefinitiontoolWorkflowsupportdatabaseProjectmanagementtoolOther sites and teams
EventengineFIGURE 31.4 Collaborative SEE architecture.Source:Adapted from [Ave04].pre75977_ch31.qxd  11/27/08  6:35 PM  Page 829and components) will appear to achieve the level of coordination that is required fora distributed software engineering project.
31.5.2 Tools That Address Technology Trends
Agility in software engineering (Chapter 3) is achieved when stakeholders work as ateam. Therefore, the trend toward collaborative SEEs (Section 31.5.1) will providebenefits even when software is developed locally. But what of the technology toolsthat complement the system and components that empower better collaboration?One of the dominant trends in technology tools is the creation of a tool setthat supports model-driven development (Section 31.4.4) with an emphasis onarchitecture-driven design. Oren Novotny [Nov04] suggests that the model ratherthan the source code becomes the central software engineering focus:
Platform independent models are created in UML and then undergo various levels oftransformation to eventually wind up as source code for a specific platform. It stands toreason then, that the model, not the file, should become the new unit of output. A modelhas many different views at different levels of abstraction. At the highest level, platformindependent components can be specified in analysis; at the lowest level there is a plat-form specific implementation that reduces to a set of classes in code.
Novotny argues that a new generation of tools will work in conjunction with a repos-itory to create models at all necessary levels of abstraction, establish relationshipsbetween the various models, translate models at one level of abstraction to anotherlevel (e.g., translate a design model into source code), manage changes and versions,and coordinate quality control and assurance actions against the software models.In addition to complete software engineering environments, point-solution toolsthat address everything from requirements gathering to design/code refactoring totesting will continue to evolve and become more functionally capable. In some in-stances, modeling and testing tools targeted at a specific application domain willprovide enhanced benefit when compared to their generic equivalents.
31.6 S UMMARY
The trends that have an effect on software engineering technology often come fromthe business, organizational, market, and cultural arenas. These “soft trends” canguide the direction of research and the technology that is derived as a consequenceof research.As a new technology is introduced, it moves through a life cycle that does notalways lead to widespread adoption, even though original expectations are high. Thedegree to which any software engineering technology gains widespread adoption istied to its ability to address the problems posed by both soft and hard trends.Soft trends—the growing need for connectivity and collaboration, global projects,knowledge transfer, the impact of emerging economies, and the influence of humanculture itself, lead to a set of challenges that span managing complexity and emergent830 PART FIVEADVANCED TOPICSpre75977_ch31.qxd  11/27/08  6:35 PM  Page 830requirements to juggling an ever-changing talent mix among geographically dispersedsoftware teams.Hard trends—the ever-accelerating pace of technology change—flow out of softtrends and affect the structure of the software and scope of the process and the man-ner in which a process framework is characterized. Collaborative development, newforms of requirements engineering, model-based and test-driven development, andpostmodern design will change the methods landscape. Tools environments willrespond to a growing need for communication and collaboration and at the sametime integrate domain-specific point solutions that may change the nature of currentsoftware engineering tasks.
PROBLEMS AND POINTS TO PONDER
31.1.Get a copy of the best-selling book The Tipping Point by Malcolm Gladwell (available via Google Book Search), and discuss how his theories apply to the adoption of new softwareengineering technologies.31.2.Why does open-world software present a challenge to conventional software engineer-ing approaches?31.3.Review the Gartner Group’s hype cycle for emerging technologies. Select a well-known technology product and present a brief history that illustrates how it traveled along the curve.Select another well-known technology product that did not follow the path suggested by thehype curve.31.4.What is a “soft trend”?31.5.You’re faced with an extremely complex problem that will require a lengthy solution.How would you go about addressed the complexity and crafting a solution?31.6.What are “emergent requirements” and why do they present a challenge to softwareengineers?31.7.Select an open-source development effort (other than Linux), and present a brief historyof its evolution and relative success.31.8.Describe how you think the software process will change over the next decade.31.9.You’re based in Los Angeles and are working on a global software engineering team. Youand colleagues in London, Mumbai, Hong Kong, and Sydney must edit a 245-page requirementsspecification for a large system. The first editing pass must be completed in three days. Describethe ideal online tool set that would enable you to collaborate effectively.31.10.Describe model-driven software development in your own words. Do the same for test-driven development.
FURTHER READINGS AND INFORMATION SOURCES
Books that discuss the road ahead for software and computing span a vast array of technical,scientific, economic, political, and social issues. Kurweil (The Singularity Is Near, Penguin Books, 2005) presents a compelling look at a world that will change in truly profound ways by the mid-dle of this century. Sterling (Tomorrow Now, Random House, 2002) reminds us that real progress is rarely orderly and efficient. Teich (Technology and the Future, Wadworth, 2002) presents thoughtful essays on the societal impact of technology and how changing culture shapesCHAPTER 31EMERGING TRENDS IN SOFTWARE ENGINEERING 831pre75977_ch31.qxd  11/27/08  6:35 PM  Page 831technology. Naisbitt, Philips, and Naisbitt ( High Tech/High Touch,Nicholas Brealey, 2001) note that many of us have become “intoxicated” with high technology and that the “great irony of thehigh-tech age is that we’ve become enslaved to devices that were supposed to give us freedom.”Zey (The Future Factor,McGraw-Hill, 2000) discusses five forces that will shape human destinyduring this century. Negroponte’s (Being Digital, Alfred A. Knopf, 1995) was a best seller in the mid-1990s and continues to provide an insightful view of computing and its overall impact.As software becomes part of the fabric of virtually every facet of our lives, “cyberethics” hasevolved as an important topic of discussion. Books by Spinello (Cyberethics: Morality and Law inCyberspace, Jones & Bartlett Publishers, 2002), Halbert and Ingulli (Cyberethics, South-Western College Publishers, 2001), and Baird and his colleagues (Cyberethics: Social and Moral Issues inthe Computer Age, Prometheus Books, 2000) consider the topic in detail. The U.S Governmenthas published a voluminous report on CD-ROM (21st Century Guide to Cybercrime, Progressive Management, 2003) that considers all aspects of computer crime, intellectual property issues,and the National Infrastructure Protection Center (NIPC).A wide variety of information sources on future directions in software-related technologiesand software engineering is available on the Internet. An up-to-date list of World Wide Webreferences relevant to future trends in software engineering can be found at the SEPA website:www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm .832 PART FIVEADVANCED TOPICSpre75977_ch31.qxd  11/27/08  6:35 PM  Page 832833CHAPTER
32CONCLUDING
COMMENTS
In the 31 chapters that have preceded this one, I’ve explored a process for soft-ware engineering that encompasses management procedures and technicalmethods, basic concepts and principles, specialized techniques, people-oriented activities and tasks that are amenable to automation, paper-and-pencilnotation, and software tools. I have argued that measurement, discipline, and anoverriding focus on agility and quality will result in software that meets the cus-tomer’s needs, software that is reliable, software that is maintainable, softwarethat is better. Yet, I have never promised that software engineering is a panacea.As we move into the second decade of this new century, software and systemstechnologies remain a challenge for every software professional and every com-pany that builds computer-based systems. Although he wrote these words with atwentieth century outlook, Max Hopper [Hop90] accurately describes the currentstate of affairs:
Because changes in information technology are becoming so rapid and unforgiving,and the consequences of falling behind are so irreversible, companies will either mas-ter the technology or die. . . . Think of it as a technology treadmill. Companies will haveto run harder and harder just to stay in place.
Changes in software engineering technology are indeed ”rapid and unforgiving,”but at the same time progress is often quite slow. By the time a decision is madeto adopt a new process, method, or tool; conduct the training necessary tounderstand its application; and introduce the technology into the software devel-opment culture, something newer (and even better) has come along, and theprocess begins anew.
What is it? As we come to the endof a relatively long journey throughsoftware engineering, it’s time to putthings into perspective and make afew concluding comments.
Who does it? Authors like me. When you cometo the end of a long and challenging book, it’s nice to wrap things up in a meaningful way.
Why is it important? It’s always worthwhile to re-member where we’ve been and to considerwhere we’re going.QUICK
LOOKWhat are the steps? I’ll consider where we’vebeen and address some of the core issues andsome directions for the future.
What is the work product? A discussion that willhelp you understand the big picture.
How do I ensure that I’ve done it right? That’sdifficult to accomplish in real time. It’s only aftera number of years that either you or I can tellwhether the software engineering concepts,principles, methods, and techniques discussed inthis book have helped you to become a bettersoftware engineer.KEY
CONCEPTS
ethics . . . . . . . .838future  . . . . . . .837informationspectrum  . . . . .836knowledge  . . . .836people  . . . . . . .834softwarerevisited  . . . . .834pre75977_ch32.qxd  11/27/08  6:35 PM  Page 833One thing I’ve learned over my years in this field is that software engineeringpractitioners are “fashion conscious.” The road ahead will be littered with the car-casses of exciting new technologies (the latest fashion) that never really made it(despite the hype). It will be shaped by more modest technologies that somehowmodify the direction and width of the thoroughfare. I discussed a few of those inChapter 31.In this concluding chapter I’ll take a broader view and consider where we’ve beenand where we’re going from a more philosophical perspective.
32.1 T HEIMPORTANCE OF SOFTWARE —R EVISITED
The importance of computer software can be stated in many ways. In Chapter 1, soft-ware was characterized as a differentiator. The function delivered by software dif-ferentiates products, systems, and services and provides competitive advantage inthe marketplace. But software is more than a differentiator. When taken as a whole,software engineering work products generate the most important commodity thatany individual, business, or government can acquire—information.In Chapter 31, I briefly discussed open-world computing—ambient intelligence,context-aware applications, and pervasive/ubiquitous computing—a direction thatwill fundamentally change our perception of computers, the things that we do withthem (and they do for us), and our perception of information as a guide, a com-modity, and a necessity. I also noted that software required to support open-worldcomputing will present dramatic new challenges for software engineers. But farmore important, the coming pervasiveness of computer software will present evenmore dramatic challenges for society as a whole. Whenever a technology has abroad impact—an impact that can save lives or endanger them, build businesses ordestroy them, inform government leaders or mislead them—it must be “handledwith care.”
32.2 P EOPLE AND THE WAYTHEYBUILD SYSTEMS
The software required for high-technology systems becomes more and more com-plex with each passing year, and the size of resultant programs increases propor-tionally. The rapid growth in the size of the “average” program would present us withfew problems if it wasn’t for one simple fact: As program size increases, the numberof people who must work on the program must also increase.Experience indicates that as the number of people on a software project teamincreases, the overall productivity of the group may suffer. One way around thisproblem is to create a number of software engineering teams, thereby compart-mentalizing people into individual working groups. However, as the number ofsoftware engineering teams grows, communication between them becomes asdifficult and time consuming as communication between individuals. Worse,834 PART FIVEADVANCED TOPICSpre75977_ch32.qxd  11/27/08  6:35 PM  Page 834communication (between individuals or teams) tends to be inefficient—that is, toomuch time is spent transferring too little information content, and all too often,important information “falls into the cracks.”If the software engineering community is to deal effectively with the communica-tion dilemma, the road ahead for software engineers must include radical changesin the way individuals and teams communicate with one another. In Chapter 31, Idiscussed collaborative environments that may provide dramatic improvements inthe ways teams communicate.In the final analysis, communication is the transfer of knowledge, and the acqui-sition (and transfer) of knowledge is changing in profound ways. As search enginesbecome increasingly sophisticated and Web 2.0 applications provide better synergy,the world’s largest library of research papers and reports, tutorials, commentary, andreferences becomes readily accessible and usable.If past history is any indication, it is fair to say that people themselves will notchange. However, the ways in which they communicate, the environment in whichthey work, the manner in which they acquire knowledge, the methods and tools thatthey use, the discipline that they apply, and therefore, the overall culture for softwaredevelopment will change in significant and even profound ways.
32.3 N EWMODES FOR REPRESENTING INFORMATION
Over the history of computing, a subtle transition has occurred in the terminologythat is used to describe software development work performed for the business com-munity. Forty years ago, the term data processing was the operative phrase for de- scribing the use of computers in a business context. Today, data processing has givenway to another phrase—information technology—that implies the same thing butpresents a subtle shift in focus. The emphasis is not merely to process large quanti-ties of data but rather to extract meaningful information from this data. Obviously,this was always the intent, but the shift in terminology reflects a far more importantshift in management philosophy.When software applications are discussed today, the words data, information, andcontentoccur repeatedly. We encounter the word knowledge in some artificial intel- ligence applications, but its use is relatively rare. Virtually no one discusses wisdom in the context of software applications.Data is raw information—collections of facts that must be processed to be mean-ingful. Information is derived by associating facts within a given context. Knowledgeassociates information obtained in one context with other information obtained ina different context. Finally, wisdom occurs when generalized principles are derivedfrom disparate knowledge. Each of these four views of “information” is representedschematically in Figure 32.1.To date, the vast majority of all software has been built to process data or infor-mation. Software engineers are now equally concerned with systems that processCHAPTER 32CONCLUDING COMMENTS 835
uote:
“Future shock [is]the shatteringstress anddisorientation thatwe induce inindividuals bysubjecting them totoo much change intoo short a periodof time.”Alvin Toffler
uote:
“The bestpreparation forgood worktomorrow is to dogood work today.”Elbert Hubbardpre75977_ch32.qxd  11/27/08  6:35 PM  Page 835knowledge.1Knowledge is two dimensional. Information collected on a variety of re-lated and unrelated topics is connected to form a body of fact that we call knowledge. The key is our ability to associate information from a variety of different sources thatmay not have any obvious connection and combine it in a way that provides us withsome distinct benefit.
2
To illustrate the progression from data to knowledge, consider census data indi-cating that the birthrate in 1996 in the United States was 4.9 million. This numberrepresents a data value. Relating this piece of data with birthrates for the preceding40 years, we can derive a useful piece of information—aging baby boomers of the1950s and early 1960s made a last-gasp effort to have children prior to the end oftheir child-bearing years. In addition, gen-Xers began their childbearing years. Thecensus data can then be connected to other seemingly unrelated pieces of informa-tion. For example, the current number of elementary school teachers who will retireduring the next decade, the number of college students graduating with degrees inprimary and secondary education, the pressure on politicians to hold down taxes andtherefore limit pay increases for teachers. All of these pieces of information can becombined to formulate a representation of knowledge—there will be significantpressure on the education system in the United States in the early twenty-first cen-tury, and this pressure will continue for a number of decades. Using this knowledge,a business opportunity may emerge. There may be significant opportunity to developnew modes of learning that are more effective and less costly than currentapproaches.836 PART FIVEADVANCED TOPICS
Data:no associativityInformation:associativity withinone context
Knowledge:associativity withinmultiple contextsWisdom:creation of generalizedprinciples based onexisting knowledgefrom different sourcesFIGURE 32.1
An “informa-tion” spectrum
uote:
“Wisdom is thepower that enablesus to useknowledge for thebenefit ofourselves andothers.”Thomas J.Watson
1 The rapid growth of data mining and data warehousing technologies reflect this growing trend.2 The semantic Web (Web 2.0) allows the creation of “mashups” that may provide a facile mecha-nism for achieving this.pre75977_ch32.qxd  11/27/08  6:35 PM  Page 836The road ahead for software leads to systems that process knowledge. We havebeen processing data using computers for over 50 years and extracting informationfor more than three decades. One of the most significant challenges facing the soft-ware engineering community is to build systems that take the next step along thespectrum—systems that extract knowledge from data and information in a way thatis practical and beneficial.
32.4 T HELONG VIEW
In Section 32.3, I suggested that the road ahead leads to systems that “processknowledge.” But the future of computing in general and software-based systems inparticular may lead to events that are considerably more profound.In a fascinating book that is must reading for every person involved in computingtechnologies, Ray Kurzweil [Kur05] suggests that we have reached a time when “thepace of technological change will be so rapid, its impact so deep, that human life willbe irreversibly transformed.” Kurzweil
3makes a compelling argument that we are currently at the “knee” of an exponential growth curve that will lead to enormous in-creases in computing capacity over the next two decades. When coupled with equiv-alent advances in nanotechnology, genetics, and robotics, we may approach a timein the middle part of this century when the distinction between humans (as we knowthem today) and machines begins to blur—a time when human evolution acceleratesin ways that are both frightening (to some) and spectacular (to others).By sometime in the 2030s, Kurzweil argues that computing capacity and the req-uisite software will be sufficient to model every aspect of the human brain—all of thephysical connections, analog processes, and chemical overlays. When this occurs,human beings will have achieved “strong AI (artificial intelligence),” and as a conse-quence, machines that truly do think (using today’s conventional use of the word).But there will be a fundamental difference. Human brain processes are exceedinglycomplex and only loosely connected to external informal sources. They are alsocomputationally slow, even in comparison to today’s computing technology. Whenfull human brain emulation occurs, “thought” will occur at speeds thousands oftimes more rapid than its human counterpart with intimate connections to a sea ofinformation (think of the present-day Web as a primitive example). The result is . . .well . . . so fantastical that it’s best left to Kurzweil to describe.It’s important to note that not everyone believes that the future Kurzweil describesis a good thing. In a now famous essay entitled “The Future Doesn’t Need Us,” BillJoy [Joy00], one of the founders of Sun Microsystems, argues that “robotics, geneticCHAPTER 32CONCLUDING COMMENTS 837
3 It’s important to note that Kurzweil is not a run-of-the mill science fiction writer or a futurist with-out portfolio. He is a serious technologist who (from Wikipedia) “has been a pioneer in the fields ofoptical character recognition (OCR), text-to-speech synthesis, speech recognition technology, andelectronic keyboard instruments.”pre75977_ch32.qxd  11/27/08  6:35 PM  Page 837engineering, and nanotech are threatening to make humans an endangeredspecies.” His arguments predicting a technology dystopia represent a counterpointto Kurzweil’s predicted utopian future. Both should be seriously considered assoftware engineers take one of the lead roles in defining the long view for the humanrace.
32.5 T HESOFTWARE ENGINEER ’SRESPONSIBILITY
Software engineering has evolved into a respected, worldwide profession. As pro-fessionals, software engineers should abide by a code of ethics that guides the workthat they do and the products that they produce. An ACM/IEEE-CS Joint Task Forcehas produced a Software Engineering Code of Ethics and Professional Practices(Version 5.1). The code [ACM98] states:
Software engineers shall commit themselves to making the analysis, specification,design, development, testing and maintenance of software a beneficial and respectedprofession. In accordance with their commitment to the health, safety and welfare of thepublic, software engineers shall adhere to the following Eight Principles:1. PUBLIC—Software engineers shall act consistently with the public interest.2. CLIENT AND EMPLOYER—Software engineers shall act in a manner that is in the bestinterests of their client and employer consistent with the public interest.3. PRODUCT—Software engineers shall ensure that their products and related modifica-tions meet the highest professional standards possible.4. JUDGMENT—Software engineers shall maintain integrity and independence in theirprofessional judgment.5. MANAGEMENT—Software engineering managers and leaders shall subscribe to andpromote an ethical approach to the management of software development and main-tenance.6. PROFESSION—Software engineers shall advance the integrity and reputation of theprofession consistent with the public interest.7. COLLEAGUES—Software engineers shall be fair to and supportive of their colleagues.8. SELF—Software engineers shall participate in lifelong learning regarding the practiceof their profession and shall promote an ethical approach to the practice of theprofession.
Although each of these eight principles is equally important, an overriding themeappears: a software engineer should work in the public interest. On a personal level,a software engineer should abide by the following rules:
•Never steal data for personal gain.
•Never distribute or sell proprietary information obtained as part of your workon a software project.838 PART FIVEADVANCED TOPICS
WebRef
A complete discussionof the ACM/IEEEcode of ethicscan be found atseeri.etsu.edu/Codes/default.shtm.pre75977_ch32.qxd  11/27/08  6:35 PM  Page 838•Never maliciously destroy or modify another person’s programs, files, ordata.
•Never violate the privacy of an individual, a group, or an organization.
•Never hack into a system for sport or profit.
•Never create or promulgate a computer virus or worm.
•Never use computing technology to facilitate discrimination or harassment.Over the past decade, certain members of the software industry have lobbied forprotective legislation that [SEE03]: (1) allows companies to release software withoutdisclosing known defects, (2) exempts developers from liability for any damagesresulting from these known defects, (3) constrains others from disclosing defectswithout permission from the original developer, (4) allows the incorporation of “self-help” software within a product that can disable (via remote command) the opera-tion of the product, and (5) exempts developers of software with “self-help” fromdamages should the software be disabled by a third party.Like all legislation, debate often centers on issues that are political, not techno-logical. However, many people (including me) feel that protective legislation, if im-properly drafted, conflicts with the software engineering code of ethics by indirectlyexempting software engineers from their responsibility to produce high-qualitysoftware.
32.6 A F INAL COMMENT
It has been 30 years since I began work on the first edition of this book. I can stillrecall sitting at my desk as a young professor, writing the manuscript for a book ona subject that few people cared about and even fewer really understood. I rememberthe rejection letters from publishers, who argued (politely, but firmly) that therewould never be a market for a book on “software engineering.” Luckily, McGraw-Hilldecided to give it a try,
4and the rest, as they say, is history.Over the past 30 years, this book has changed dramatically—in scope, in size, instyle, and in content. Like software engineering, it has grown and (I hope) maturedover the years.An engineering approach to the development of computer software is now con-ventional wisdom. Although debate continues on the “right paradigm,” the impor-tance of agility, the degree of automation, and the most effective methods, theunderlying principles of software engineering are now accepted throughout theindustry. Why, then, have we seen their broad adoption only recently?The answer, I think, lies in the difficulty of technology transition and the culturalchange that accompanies it. Even though most of us appreciate the need for anCHAPTER 32CONCLUDING COMMENTS 839
4 Actually, credit should go to Peter Freeman and Eric Munson, who convinced McGraw-Hill that itwas worth a shot. Over a million copies later, it’s fair to say they made a good decision.pre75977_ch32.qxd  11/27/08  6:35 PM  Page 839engineering discipline for software, we struggle against the inertia of past practiceand face new application domains (and the developers who work in them) that ap-pear ready to repeat the mistakes of the past. To ease the transition we need manythings—an agile, adaptable, and sensible software process; more effective methods;more powerful tools; better acceptance by practitioners and support from managers;and no small dose of education.You may not agree with every approach described in this book. Some of the tech-niques and opinions are controversial; others must be tuned to work well in differ-ent software development environments. It is my sincere hope, however, thatSoftware Engineering: A Practitioner’s Approach has delineated the problems we face, demonstrated the strength of software engineering concepts, and provided a frame-work of methods and tools.As we move further into the twenty-first century, software continues to be themost important product and the most important industry on the world stage. Itsimpact and importance have come a long, long way. And yet, a new generation ofsoftware developers must meet many of the same challenges that faced earlier gen-erations. Let us hope that the people who meet the challenge—software engineers—will have the wisdom to develop systems that improve the human condition.840 PART FIVEADVANCED TOPICSpre75977_ch32.qxd  11/27/08  6:35 PM  Page 840The Unified Modeling Language(UML) is “a standard language for writingsoftware blueprints. UML may be used to visualize, specify, construct, anddocument the artifacts of a software-intensive system” [Boo05]. In otherwords, just as building architects create blueprints to be used by a constructioncompany, software architects create UML diagrams to help software developersbuild the software. If you understand the vocabulary of UML (the diagrams’pictorial elements and their meanings), you can much more easily understandand specify a system and explain the design of that system to others.Grady Booch, Jim Rumbaugh, and Ivar Jacobson developed UML in the mid-1990s with much feedback from the software development community. UMLmerged a number of competing modeling notations that were in use by the soft-ware industry at the time. In 1997, UML 1.0 was submitted to the Object Manage-ment Group, a nonprofit consortium involved in maintaining specifications foruse by the computer industry. UML 1.0 was revised to UML 1.1 and adopted laterthat year. The current standard is UML 2.0 and is now an ISO standard. Becausethis standard is so new, many older references, such as [Gam95] do not use UMLnotation.UML 2.0 provides 13 different diagrams for use in software modeling. In thisappendix, I will discuss only class, deployment, use case, sequence, communication,activity,and statediagrams. These diagrams are used in this edition of SoftwareEngineering: A Practitioner’s Approach.You should note that there are many optional features in UML diagrams. TheUML language provides these (sometimes arcane) options so that you canexpress all the important aspects of a system. At the same time, you havethe flexibility to suppress those parts of the diagram that are not relevant to theaspect being modeled in order to avoid cluttering the diagram with irrelevantdetails. Therefore, the omission of a particular feature does not mean that thefeature is absent; it may mean that the feature was suppressed. In this appendix,exhaustive coverage of all the features of the UML diagrams is not presented. Instead, I will focus on the standard options, especially those options that havebeen used in this book.
841APPENDIX
1ANINTRODUCTIONTO
UML1
KEY
CONCEPTS
activity diagram  . . . . . .853class diagram  . .842communicationdiagram  . . . . . .851dependency  . . .844deployment diagram  . . . . . .846generalization . .843interaction frames  . . . . . . .850multiplicity  . . . .844Object ConstraintLanguage  . . . . .859sequence diagram  . . . . . .848state diagram . .856stereotype  . . . .843swimlanes  . . . .855use-case diagram  . . . . . .847
1 This appendix has been contributed by Dale Skrien and has been adapted from his book, An Intro- duction to Object-Oriented Design and Design Patterns in Java (McGraw-Hill, 2008). All content is used with permission.pre75977_Apx1.qxd  11/27/08  6:41 PM  Page 841CLASS DIAGRAMS
To model classes, including their attributes, operations, and their relationships andassociations with other classes,
2UML provides a class diagram.A class diagram pro- vides a static or structural view of a system. It does not show the dynamic nature ofthe communications between the objects of the classes in the diagram.The main elements of a class diagram are boxes, which are the icons used to rep-resent classes and interfaces. Each box is divided into horizontal parts. The top partcontains the name of the class. The middle section lists the attributes of the class. Anattributerefers to something that an object of that class knows or can provide all thetime. Attributes are usually implemented as fields of the class, but they need not be.They could be values that the class can compute from its instance variables or val-ues that the class can get from other objects of which it is composed. For example,an object might always know the current time and be able to return it to you when-ever you ask. Therefore, it would be appropriate to list the current time as anattribute of that class of objects. However, the object would most likely not have thattime stored in one of its instance variables, because it would need to continuallyupdate that field. Instead, the object would likely compute the current time (e.g.,through consultation with objects of other classes) at the moment when the time isrequested. The third section of the class diagram contains the operations or behav-iors of the class. An operationrefers to what objects of the class can do. It is usuallyimplemented as a method of the class.Figure A1.1 presents a simple example of a Thoroughbred class that models thoroughbred horses. It has three attributes displayed—mother, father, and birthyear. The diagram also shows three operations: getCurrentAge(), getFather(), and getMother(). There may be other suppressed attributes and operations not shown inthe diagram.Each attribute can have a name, a type, and a level of visibility. The type and visi-bility are optional. The type follows the name and is separated from the name by a842 APPENDIX 1AN INTRODUCTION TO UML
2 If you are unfamiliar with object-oriented concepts, a brief introduction is presented in Appendix 2.Thoroughbred
-father: Thoroughbred-mother: Thoroughbred-birthyear: int
+getFather(): Thoroughbred+getMother(): Thoroughbred+getCurrentAge(currentYear:Date): intFIGURE A1.1
A classdiagram for aThoroughbredclasspre75977_Apx1.qxd  11/27/08  6:41 PM  Page 842colon. The visibility is indicated by a preceding –, #, ~, or +, indicating, respectively,private, protected, package,or publicvisibility. In Figure A1.1, all attributes have privatevisibility, as indicated by the leading minus sign (–). You can also specify that anattribute is a static or class attribute by underlining it. Each operation can also be dis-played with a level of visibility, parameters with names and types, and a return type.An abstract class or abstract method is indicated by the use of italics for the namein the class diagram. See the Horseclass in Figure A1.2 for an example. An inter-face is indicated by adding the phrase “«interface»” (called a stereotype) above thename. See the OwnedObjectinterface in Figure A1.2. An interface can also berepresented graphically by a hollow circle.It is worth mentioning that the icon representing a class can have other optionalparts. For example, a fourth section at the bottom of the class box can be used to listthe responsibilities of the class. This section is particularly useful when transitioningfrom CRC cards (Chapter 6) to class diagrams in that the responsibilities listed on theCRC cards can be added to this fourth section in the class box in the UML diagrambefore creating the attributes and operations that carry out these responsibilities.This fourth section is not shown in any of the figures in this appendix.Class diagrams can also show relationships between classes. A class that is asubclass of another class is connected to it by an arrow with a solid line for its shaftand with a triangular hollow arrowhead. The arrow points from the subclass to thesuperclass. In UML, such a relationship is called a generalization. For example, inFigure A1.2, the Thoroughbredand QuarterHorseclasses are shown to be sub- classes of the Horseabstract class. An arrow with a dashed line for the arrow shaftindicates implementation of an interface. In UML, such a relationship is called arealization. For example, in Figure A1.2, the Horse class implements or realizes the OwnedObjectinterface.APPENDIX 1AN INTRODUCTION TO UML 843
Horse-name:String+getName():String+getOwner().Person<< interface >>OwnedObject
ThoroughbredQuarterHorsePerson*   owner
DateusesFIGURE A1.2
A classdiagramregardinghorsespre75977_Apx1.qxd  11/27/08  6:41 PM  Page 843An associationbetween two classes means that there is a structural relationshipbetween them. Associations are represented by solid lines. An association has manyoptional parts. It can be labeled, as can each of its ends, to indicate the role of eachclass in the association. For example, in Figure A1.2, there is an association betweenOwnedObjectand Personin which the Personplays the role of owner. Arrows on either or both ends of an association line indicate navigability. Also, each end of theassociation line can have a multiplicity value displayed. Navigability and multiplicityare explained in more detail later in this section. An association might also connecta class with itself, using a loop. Such an association indicates the connection of anobject of the class with other objects of the same class.An association with an arrow at one end indicates one-way navigability. Thearrow means that from one class you can easily access the second associated classto which the association points, but from the second class, you cannot necessarilyeasily access the first class. Another way to think about this is that the first class isaware of the second class, but the second class object is not necessarily directlyaware of the first class. An association with no arrows usually indicates a two-wayassociation, which is what was intended in Figure A1.2, but it could also just meanthat the navigability is not important and so was left off.It should be noted that an attribute of a class is very much the same thing as anassociation of the class with the class type of the attribute. That is, to indicate that aclass has a property called “name” of type String, one could display that propertyas an attribute, as in the Horseclass in Figure A1.2. Alternatively, one could createa one-way association from the Horse class to the Stringclass with the role of the Stringclass being “name.” The attribute approach is better for primitive data types,whereas the association approach is often better if the property’s class plays a majorrole in the design, in which case it is valuable to have a class box for that type.A dependencyrelationship represents another connection between classes andis indicated by a dashed line (with optional arrows at the ends and with optionallabels). One class depends on another if changes to the second class might requirechanges to the first class. An association from one class to another automaticallyindicates a dependency. No dashed line is needed between classes if there is alreadyan association between them. However, for a transient relationship (i.e., a class thatdoes not maintain any long-term connection to another class but does use that classoccasionally) we should draw a dashed line from the first class to the second. Forexample, in Figure A1.2, the Thoroughbred class uses the Dateclass whenever its getCurrentAge()method is invoked, and so the dependency is labeled “uses.”Themultiplicityof one end of an association means the number of objects of thatclass associated with the other class. A multiplicity is specified by a nonnegativeinteger or by a range of integers. A multiplicity specified by “0..1” means that there are0 or 1 objects on that end of the association. For example, each person in the worldhas either a Social Security number or no such number (especially if they are not U.S.844 APPENDIX 1AN INTRODUCTION TO UMLpre75977_Apx1.qxd  11/27/08  6:41 PM  Page 844citizens), and so a multiplicity of 0..1 could be used in an association between aPersonclass and aSocialSecurityNumberclass in a class diagram. A multiplicity specified by “1..*” means one or more, and a multiplicity specified by “0..*” or just “*“means zero or more. An * was used as the multiplicity on the OwnedObjectend of the association with classPersonin Figure A1.2 because aPersoncan own zero or more objects.If one end of an association has multiplicity greater than 1, then the objects of theclass referred to at that end of the association are probably stored in a collection,such as a set or ordered list. One could also include that collection class itself in theUML diagram, but such a class is usually left out and is implicitly assumed to be theredue to the multiplicity of the association.An aggregationis a special kind of association indicated by a hollow diamond onone end of the icon. It indicates a “whole/part” relationship, in that the class to whichthe arrow points is considered a “part” of the class at the diamond end of the asso-ciation. A compositionis an aggregation indicating strong ownership of the parts. Ina composition, the parts live and die with the owner because they have no role in thesoftware system independent of the owner. See Figure A1.3 for examples of aggre-gation and composition.A Collegehas an aggregation of Buildingobjects, which represent the buildings making up the campus. The college also has a collection of courses. If the collegewere to fold, the buildings would still exist (assuming the college wasn’t physicallydestroyed) and could be used for other things, but a Course object has no use out- side of the college at which it is being offered. If the college were to cease to exist asa business entity, the Courseobject would no longer be useful and so it would alsocease to exist.Another common element of a class diagram is a note, which is represented by a box with a dog-eared corner and is connected to other icons by a dashed line. Itcan have arbitrary content (text and graphics) and is similar to comments in pro-gramming languages. It might contain comments about the role of a class or con-straints that all objects of that class must satisfy. If the contents are a constraint,braces surround the contents. Note the constraint attached to the Course class in Figure A1.3.APPENDIX 1AN INTRODUCTION TO UML 845
 {must take place in a Building}Course College
Building**FIGURE A1.3
The relation-ship betweenColleges,Courses, andBuildingspre75977_Apx1.qxd  11/27/08  6:41 PM  Page 845DEPLOYMENT DIAGRAMS
A UML deployment diagramfocuses on the structure of a software system and isuseful for showing the physical distribution of a software system among hardwareplatforms and execution environments. Suppose, for example, you are developing aWeb-based graphics-rendering package. Users of your package will use their Webbrowser to go to your website and enter rendering information. Your website wouldrender a graphical image according to the user’s specification and send it back to theuser. Because graphics rendering can be computationally expensive, you decide tomove the rendering itself off the Web server and onto a separate platform. Therefore,there will be three hardware devices involved in your system: the Web client (theusers’ computer running a browser), the computer hosting the Web server, and thecomputer hosting the rendering engine.Figure A1.4 shows the deployment diagram for such a package. In such a diagram,hardware components are drawn in boxes labeled with “«device»”. Communicationpaths between hardware components are drawn with lines with optional labels. InFigure A1.4, the paths are labeled with the communication protocol and the type ofnetwork used to connect the devices.Each node in a deployment diagram can also be annotated with details aboutthe device. For example, in Figure A1.4, the browser client is depicted to show thatit contains an artifact consisting of the Web browser software. An artifact is typicallya file containing software running on a device. You can also specify tagged values,as is shown in Figure A1.4 in the Web server node. These values define the vendorof the Web server and the operating system used by the server.Deployment diagrams can also display execution environment nodes, which aredrawn as boxes containing the label “«execution environment»”. These nodes rep-resent systems, such as operating systems, that can host other software.846 APPENDIX 1AN INTRODUCTION TO UML
{web server = apache}{OS = linux}<<device>>Web Server
http/LANhttp/Internet
<<device>>Render engine<<artifact>>web brower<<device>>Browser ClientFIGURE A1.4
A deploymentdiagrampre75977_Apx1.qxd  11/27/08  6:41 PM  Page 846USE-CASEDIAGRAMS
Use cases (Chapters 5 and 6) and the UML use-case diagramhelp you determine the functionality and features of the software from the user’s perspective. To give you afeeling for how use cases and use-case diagrams work, I’ll create some for a soft-ware application for managing digital music files, similar to Apple’s iTunes software.Some of the things the software might do include:
•Download an MP3 music file and store it in the application’s library.
•Capture streaming music and store it in the application’s library.
•Manage the application’s library (e.g., delete songs or organize them inplaylists).
•Burn a list of the songs in the library onto a CD.
•Load a list of the songs in the library onto an iPod or MP3 player.
•Convert a song from MP3 format to AAC format and vice versa.This is not an exhaustive list, but it is sufficient to understand the role of use casesand use-case diagrams.A use casedescribes how a user interacts with the system by defining the stepsrequired to accomplish a specific goal (e.g., burning a list of songs onto a CD). Vari-ations in the sequence of steps describe various scenarios (e.g., what if all the songsin the list don’t fit on one CD?).A UML use-case diagram is an overview of all the use cases and how they arerelated. It provides a big picture of the functionality of the system. A use-casediagram for the digital music application is shown in Figure A1.5.In this diagram, the stick figure represents an actor(Chapter 5) that is associ- ated with one category of user (or other interaction element). Complex systems typically have more than one actor. For example, a vending machine applicationmight have three actors representing customers, repair personnel, and vendorswho refill the machine.In the use-case diagram, the use cases are displayed as ovals. The actors are con-nected by lines to the use cases that they carry out. Note that none of the details ofthe use cases are included in the diagram and instead need to be stored separately.Note also that the use cases are placed in a rectangle but the actors are not. This rec-tangle is a visual reminder of the system boundaries and that the actors are outsidethe system.Some use cases in a system might be related to each other. For example, there aresimilar steps in burning a list of songs to a CD and in loading a list of songs to aniPod. In both cases, the user first creates an empty list and then adds songs from thelibrary to the list. To avoid duplication in use cases, it is usually better to create anew use case representing the duplicated activity, and then let the other uses casesinclude this new use case as one of their steps. Such inclusion is indicated inAPPENDIX 1AN INTRODUCTION TO UML 847pre75977_Apx1.qxd  11/27/08  6:42 PM  Page 847848 APPENDIX 1AN INTRODUCTION TO UML
Userdownload music file & save to library
capture streaming music & save to library
burn a list of songs to CD
load a list of songs to iPodconvert music file to new format
organize the libraryFIGURE A1.5
A use-casediagram forthe musicsystem
use-case diagrams, as in Figure A1.6, by means of a dashed arrow labeled «include»connecting a use case with an included use case.A use-case diagram, because it displays all use cases, is a helpful aid for ensuringthat you have covered all the functionality of the system. In the digital music organ-izer, you would surely want more use cases, such as a use case for playing a song inthe library. But keep in mind that the most valuable contribution of use cases to thesoftware development process is the textual description of each use case, not theoverall use-case diagram. [Fow04b]. It is through the descriptions that you are ableto form a clear understanding of the goals of the system you are developing.
SEQUENCE DIAGRAMS
In contrast to class diagrams and deployment diagrams, which show the static struc-ture of a software component, a sequence diagram is used to show the dynamic com- munications between objects during execution of a task. It shows the temporal orderin which messages are sent between the objects to accomplish that task. One mightuse a sequence diagram to show the interactions in one use case or in one scenarioof a software system.pre75977_Apx1.qxd  11/27/08  6:42 PM  Page 848In Figure A1.7, you see a sequence diagram for a drawing program. The diagramshows the steps involved in highlighting a figure in a drawing when it has beenclicked. Each box in the row at the top of the diagram usually corresponds to anobject, although it is possible to have the boxes model other things, such as classes.If the box represents an object (as is the case in all our examples), then inside thebox you can optionally state the type of the object preceded by the colon. You canalso precede the colon and type by a name for the object, as shown in the third boxin Figure A1.7. Below each box there is a dashed line called the lifeline of the object. The vertical axis in the sequence diagram corresponds to time, with time increasingas you move downward.A sequence diagram shows method calls using horizontal arrows from the callerto the callee, labeled with the method name and optionally including its parameters,their types, and the return type. For example, in Figure A1.7, the MouseListenercalls the Drawing’s getFigureAt()method. When an object is executing a method(that is, when it has an activation frame on the stack), you can optionally display awhite bar, called an activation bar, down the object’s lifeline. In Figure A1.7, activa-tion bars are drawn for all method calls. The diagram can also optionally show thereturn from a method call with a dashed arrow and an optional label. In Figure A1.7,APPENDIX 1AN INTRODUCTION TO UML 849
Userconvert music file to new format
download music file & save to library
capture streaming music & save to library
organize the library
<< include >>
<< include >><< include >>
edit song listburn a list of songs to CD
load a list of songs to iPodFIGURE A1.6
A use-casediagram withincluded usecasespre75977_Apx1.qxd  11/27/08  6:42 PM  Page 849the getFigureAt()method call’s return is shown labeled with the name of the objectthat was returned. A common practice, as we have done in Figure A1.7, is to leaveoff the return arrow when a void method has been called, since it clutters up the di-agram while providing little information of importance. A black circle with an arrowcoming from it indicates a found message whose source is unknown or irrelevant. You should now be able to understand the task that Figure A1.7 is displaying. Anunknown source calls the mouseClicked() method of a MouseListener, passing in the point where the click occurred as the argument. The MouseListener in turn calls the getFigureAt()method of a Drawing, which returns a Figure. The MouseListenerthen calls the highlight method of Figure, passing in a Graphicsobject as an argument. In response, Figure calls three methods of the Graphics object to draw the figure in red.The diagram in Figure A1.7 is very straightforward and contains no conditionalsor loops. If logical control structures are required, it is probably best to draw a sepa-rate sequence diagram for each case. That is, if the message flow can take two dif-ferent paths depending on a condition, then draw two separate sequence diagrams,one for each possibility.If you insist on including loops, conditionals, and other control structures in a se-quence diagram, you can use interaction frames, which are rectangles that surroundparts of the diagram and that are labeled with the type of control structures they rep-resent. Figure A1.8 illustrates this, showing the process involved in highlighting allfigures inside a given rectangle. The MouseListener is sent the rectDraggedmessage. The MouseListenerthen tells the drawing to highlight all figures in the rectangleby called the method highlightFigures(), passing the rectangle as the argument.The method loops through all Figureobjects in the Drawingobject and, if the850 APPENDIX 1AN INTRODUCTION TO UML
:MouseListener :Drawing :Graphics aFigure:Figure
.setColor(red).highlight(graphics).getFigureAt(point).mouseClicked(point) aFigure
.drawRect (x,y,w,h)
.drawString(s)FIGURE A1.7
A samplesequencediagrampre75977_Apx1.qxd  11/27/08  6:42 PM  Page 850Figureintersects the rectangle, the Figureis asked to highlight itself. The phrases in square brackets are called guards, which are Boolean conditions that must be trueif the action inside the interaction frame is to continue.There are many other special features that can be included in a sequencediagram. For example:1.You can distinguish between synchronous and asynchronous messages.Synchronous messages are shown with solid arrowheads while asynchro-nous messages are shown with stick arrowheads.2.You can show an object sending itself a message with an arrow going out fromthe object, turning downward, and then pointing back to the same object.3.You can show object creation by drawing an arrow appropriately labeled (forexample, with a «create» label) to an object’s box. In this case, the box willappear lower in the diagram than the boxes corresponding to objects alreadyin existence when the action begins.4.You can show object destruction by a big X at the end of the object’s lifeline.Other objects can destroy an object, in which case an arrow points from theother object to the X. An X is also useful for indicating that an object is nolonger usable and so is ready for garbage collection.The last three features are all shown in the sequence diagram in Figure A1.9.
COMMUNICATION DIAGRAMS
The UML communication diagram(called a “collaboration diagram” in UML 1.X) pro-vides another indication of the temporal order of the communications but empha-sizes the relationships among the objects and classes instead of the temporal order.APPENDIX 1AN INTRODUCTION TO UML 851
:MouseListener :Figure :Drawing
.highlightFiguresIn(rect) .rectDragged(rect)
.highlight(g)[ figure intersectsrect ][ for all Figures in the Drawing ]optloop (  )FIGURE A1.8
A sequencediagram withtwo interactionframespre75977_Apx1.qxd  11/27/08  6:42 PM  Page 851A communication diagram, illustrated in Figure A1.10, displays the same actionsshown in the sequence diagram in Figure A1.7.In a communication diagram the interacting objects are represented by rectan-gles. Associations between objects are represented by lines connecting the rectan-gles. There is typically an incoming arrow to one object in the diagram that startsthe sequence of message passing. That arrow is labeled with a number and a mes-sage name. If the incoming message is labeled with the number 1 and if it causesthe receiving object to invoke other messages on other objects, then those messagesare represented by arrows from the sender to the receiver along an association lineand are given numbers 1.1, 1.2, and so forth, in the order they are called. If those852 APPENDIX 1AN INTRODUCTION TO UML
1.1: getFigureAt(point)1: mouseClicked(point)1.2: highlight(graphics)
1.2.2: drawRect(x,y,w,h)1.2.1: setColor(red)1.2.3: drawString(s)MouseListener
GraphicsFigure DrawingFIGURE A1.10
A UMLcommunica-tion diagram:Thing1
:Thing2.Thing2().destroy().foo()x<< create >>FIGURE A1.9
Creation,destruction,and loops insequencediagramspre75977_Apx1.qxd  12/3/08  2:02 PM  Page 852messages in turn invoke other messages, another decimal point and number areadded to the number labeling these messages, to indicate further nesting of themessage passing.In Figure A1.10, you see that the mouseClickedmessage invokes the methods getFigureAt()and then highlight().The highlight()message invokes three other mes- sages: setColor(), drawRect(),and drawstring().The numbering in each label shows the nesting as well as the sequential nature of each message.There are many optional features that can be added to the arrow labels. Forexample, you can precede the number with a letter. An incoming arrow could belabeled A1: mouseClicked(point). indicating an execution thread, A. If other messagesare executed in other threads, their label would be preceded by a different letter. Forexample, if the mouseClicked()method is executed in thread A but it creates a newthread B and invokes highlight()in that thread, then the arrow from MouseListenerto Figurewould be labeled 1.B2: highlight(graphics).If you are interested in showing the relationships among the objects in additionto the messages being sent between them, the communication diagram is probablya better option than the sequence diagram. If you are more interested in the tempo-ral order of the message passing, then a sequence diagram is probably better.
ACTIVITY DIAGRAMS
A UML activity diagramdepicts the dynamic behavior of a system or part of a systemthrough the flow of control between actions that the system performs. It is similar toa flowchart except that an activity diagram can show concurrent flows.The main component of an activity diagram is an actionnode, represented by a rounded rectangle, which corresponds to a task performed by the software system.Arrows from one action node to another indicate the flow of control. That is, anarrow between two action nodes means that after the first action is complete thesecond action begins. A solid black dot forms the initial node that indicates the start- ing point of the activity. A black dot surrounded by a black circle is the final nodeindicating the end of the activity.A forkrepresents the separation of activities into two or more concurrent activi-ties. It is drawn as a horizontal black bar with one arrow pointing to it and two ormore arrows pointing out from it. Each outgoing arrow represents a flow of controlthat can be executed concurrently with the flows corresponding to the other outgo-ing arrows. These concurrent activities can be performed on a computer using dif-ferent threads or even using different computers.Figure A1.11 shows a sample activity diagram involving baking a cake. The firststep is finding the recipe. Once the recipe has been found, the dry ingredients andwet ingredients can be measured and mixed and the oven can be preheated. Themixing of the dry ingredients can be done in parallel with the mixing of the wetingredients and the preheating of the oven.APPENDIX 1AN INTRODUCTION TO UML 853pre75977_Apx1.qxd  11/27/08  6:42 PM  Page 853A joinis a way of synchronizing concurrent flows of control. It is represented bya horizontal black bar with two or more incoming arrows and one outgoing arrow.The flow of control represented by the outgoing arrow cannot begin execution untilall flows represented by incoming arrows have been completed. In Figure A1.11, wehave a join before the action of mixing together the wet and dry ingredients. This joinindicates that all dry ingredients must be mixed and all wet ingredients must bemixed before the two mixtures can be combined. The second join in the figure indi-cates that, before the baking of the cake can begin, all ingredients must be mixedtogether and the oven must be at the right temperature.A decisionnode corresponds to a branch in the flow of control based on a condi-tion. Such a node is displayed as a white triangle with an incoming arrow and two854 APPENDIX 1AN INTRODUCTION TO UML
Find recipe
Mix dryingredients Mix wetingredients
Heat oven
Bake
Remove from ovenMix together
(not done)(done)FIGURE A1.11
A UML activitydiagramshowing howto bake a cakepre75977_Apx1.qxd  11/27/08  6:42 PM  Page 854or more outgoing arrows. Each outgoing arrow is labeled with a guard (a conditioninside square brackets). The flow of control follows the outgoing arrow whose guardis true. It is advisable to make sure that the conditions cover all possibilities so thatexactly one of them is true every time a decision node is reached. Figure A1.11 showsa decision node following the baking of the cake. If the cake is done, then it isremoved from the oven. Otherwise, it is baked for a while longer.One of the things the activity diagram in Figure A1.11 does not tell you is who orwhat does each of the actions. Often, the exact division of labor does not matter. Butif you do want to indicate how the actions are divided among the participants, you candecorate the activity diagram with swimlanes, as shown in Figure A1.12. Swimlanes,as the name implies, are formed by dividing the diagram into strips or “lanes,” each ofwhich corresponds to one of the participants. All actions in one lane are done by thecorresponding participant. In Figure A1.12, Evan is responsible for mixing the dryAPPENDIX 1AN INTRODUCTION TO UML 855
Find recipe
Mix dryingredients Mix wetingredients
Heat oven
BakeMix together
(not done)EvanMaryHelen
(done)
Remove from ovenFIGURE A1.12
The cake-bakingactivitydiagram withswimlanesaddedpre75977_Apx1.qxd  11/27/08  6:42 PM  Page 855ingredients and then mixing the dry and wet ingredients together, Helen is responsi-ble for heating the oven and taking the cake out, and Mary is responsible for every-thing else.
STATE DIAGRAMS
The behavior of an object at a particular point in time often depends on the state ofthe object, that is, the values of its variables at that time. As a trivial example, con-sider an object with a Boolean instance variable. When asked to perform an opera-tion, the object might do one thing if that variable is trueand do something else if it is false.A UML state diagrammodels an object’s states, the actions that are performeddepending on those states, and the transitions between the states of the object.As an example, consider the state diagram for a part of a Java compiler. The inputto the compiler is a text file, which can be thought of as a long string of characters.The compiler reads characters one at a time and from them determines the structureof the program. One small part of this process of reading the characters involvesignoring “white-space” characters (e.g., the space, tab, newline, and returncharac- ters) and characters inside a comment.Suppose that the compiler delegates to a WhiteSpaceAndCommentEliminator the job of advancing over white-space characters and characters in comments. Thatis, this object’s job is to read input characters until all white-space and comment char-acters have been read, at which point it returns control to the compiler to read andprocess non-white-space and noncomment characters. Think about how theWhiteSpaceAndCommentEliminator object reads in characters and determines whether the next character is white space or part of a comment. The object can checkfor white space by testing the next character against “ ”, “\t”, “\n”, and “\r”. But howdoes it determine whether the next character is part of a comment? For example,when it sees a“/”for the first time, it doesn’t yet know whether that character repre-sents a division operator, part of the /= operator, or the beginning of a line or blockcomment. To make this determination, WhiteSpaceAndCommentEliminator needs to make a note of the fact that it saw a “/” and then move on to the nextcharacter. If the character following the “/” is another “/” or an “*”, thenWhiteSpaceAndCommentEliminator knows that it is now reading a comment and can advance to the end of the comment without processing or saving any characters.If the character following the first “/” is anything other than a “/” or an “*”, thenWhiteSpaceAndCommentEliminator knows that the “/” represents the division operator or part of the /= operator and so it stops advancing over characters.In summary, as WhiteSpaceAndCommentEliminator reads in characters, it needs to keep track of several things, including whether the current character is whitespace, whether the previous character it read was a “/”, whether it is currently read-ing characters in a comment, whether it has reached the end of comment, and so forth.856 APPENDIX 1AN INTRODUCTION TO UMLpre75977_Apx1.qxd  11/27/08  6:42 PM  Page 856These all correspond to different states of the WhiteSpaceAndCommentEliminatorobject. In each of these states, WhiteSpaceAndCommentEliminator behaves dif- ferently with regard to the next character read in.To help you visualize all the states of this object and how it changes state, you canuse a UML state diagram as shown in Figure A1.13. A state diagram displays states us-ing rounded rectangles, each of which has a name in its upper half. There is also a blackcircle called the “initial pseudostate,” which isn’t really a state and instead just pointsto the initial state. In Figure A1.13, the start state is the initial state. Arrows from one state to another state indicate transitions or changes in the state of the object. Eachtransition is labeled with a trigger event, a slash (/), and an activity. All parts of thetransition labels are optional in state diagrams. If the object is in one state and the trig-ger event for one of its transitions occurs, then that transition’s activity is performedand the object takes on the new state indicated by the transition. For example, in Fig-ure A1.13, if the WhiteSpaceAndCommentEliminator object is in the startstate and the next character is “/”, then WhiteSpaceAndCommentEliminator advances past that character and changes to the saw ‘/’state. If the character after the “/” is another “/”, then the object advances to the line comment state and stays there until it readsAPPENDIX 1AN INTRODUCTION TO UML 857
next char = eoln/advance next char != eoln/advance
next char != ‘*’/advancenext char = ‘/’/advancenext char = ‘/’/advance
next char = ‘*’/advancenext char = ‘*’/advancenext char = ‘*’/advancenext char = ‘/’/advancenext char = anything elsenext char = ‘ ’,’\t‘,’\r’,’\n’/advance
end of whitespacenext char != ‘/’ or ‘*’/pushback’/’
saw’*’
block comment
startline comment
saw ‘/’FIGURE A1.13 A state diagram for advancing past white space and comments in Javapre75977_Apx1.qxd  11/27/08  6:42 PM  Page 857an end-of-line character. If instead the next character after the “/” is a “*”, then theobject advances to the block comment state and stays there until it sees another “*” followed by a “/”, which indicates the end of the block comment. Study the diagramto make sure you understand it. Note that, after advancing past white space or acomment, WhiteSpaceAndCommentEliminator goes back to the startstate and starts over. That behavior is necessary since there might be several successive com-ments or white-space characters before any other characters in the Java source code.An object may transition to a final state, indicated by a black circle with a whitecircle around it, which indicates there are no more transitions. In Figure A1.13, theWhiteSpaceAndCommentEliminator object is finished when the next character is not white space or part of a comment. Note that all transitions except the two tran-sitions leading to the final state have activities consisting of advancing to the nextcharacter. The two transitions to the final state do not advance over the next char-acter because the next character is part of a word or symbol of interest to the com-piler. Note that if the object is in the saw ‘/’ state but the next character is not “/” or “*”, then the “/” is a division operator or part of the /= operator and so we don’t wantto advance. In fact, we want to back up one character to make the “/” into the nextcharacter, so that the “/” can be used by the compiler. In Figure A1.13, this activityof backing up is labeled as pushback ‘/’.A state diagram will help you to uncover missed or unexpected situations. Thatis, with a state diagram, it is relatively easy to ensure that all possible trigger eventsfor all possible states have been accounted for. For example, in Figure A1.13, you caneasily verify that every state has included transitions for all possible characters.UML state diagrams can contain many other features not included in Figure A1.13.For example, when an object is in a state, it usually does nothing but sit and wait fora trigger event to occur. However, there is a special kind of state, called an activitystate, in which the object performs some activity, called a do-activity, while it is in thatstate. To indicate that a state is an activity state in the state diagram, you include inthe bottom half of the state’s rounded rectangle the phrase “do/” followed by theactivity that is to be done while in that state. The do-activity may finish before anystate transitions occur, after which the activity state behaves like a normal waitingstate. If a transition out of the activity state occurs before the do-activity is finished,then the do-activity is interrupted.Because a trigger event is optional when a transition occurs, it is possible that notrigger event may be listed as part of a transition’s label. In such cases for normalwaiting states, the object will immediately transition from that state to the new state.For activity states, such a transition is taken as soon as the do-activity finishes.Figure A1.14 illustrates this situation using the states for a business telephone.When a caller is placed on hold, the call goes into the on hold with musicstate (soothing music is played for 10 seconds). After 10 seconds, the do-activity ofthe state is completed and the state behaves like a normal nonactivity state. If thecaller pushes the # key when the call is in the on hold with music state, the call858 APPENDIX 1AN INTRODUCTION TO UMLpre75977_Apx1.qxd  11/27/08  6:42 PM  Page 858transitions to the canceledstate and then transitions immediately to the dial tonestate. If the # key is pushed before the 10 seconds of soothing music has completed,the do-activity is interrupted and the music stops immediately.
OBJECT CONSTRAINT LANGUAGE —A NOVERVIEW
The wide variety of diagrams available as part of UML provide you with a rich set ofrepresentational forms for the design model. However, graphical representationsare often not enough. You may need a mechanism for explicitly and formally repre-senting information that constrains some element of the design model. It is possible,of course, to describe constraints in a natural language such as English, but thisapproach invariably leads to inconsistency and ambiguity. For this reason, a moreformal language—one that draws on set theory and formal specification languages(see Chapter 21) but has the somewhat less mathematical syntax of a programminglanguage—seems appropriate.The Object Constraint Language(OCL) complements UML by allowing you to usea formal grammar and syntax to construct unambiguous statements about variousdesign model elements (e.g., classes and objects, events, messages, interfaces). Thesimplest OCL statements are constructed in four parts: (1) a context that defines the limited situation in which the statement is valid, (2) a property that represents some characteristics of the context (e.g., if the context is a class, a property might be anattribute), (3) an operation(e.g., arithmetic, set-oriented) that manipulates or quali-fies a property, and (4) keywords (e.g., if, then, else, and, or, not, implies ) that are used to specify conditional expressions.As a simple example of an OCL expression, consider the printing system dis-cussed in Chapter 10. The guard condition placed on the jobCostAcceptedevent thatAPPENDIX 1AN INTRODUCTION TO UML 859
on hold with musicdo/play soothing music for 10 secondsput on hold
canceled conversing# key pushed taken off hold
hang up
dial toneFIGURE A1.14
A statediagram withan activitystate and atriggerlesstransitionpre75977_Apx1.qxd  11/27/08  6:42 PM  Page 859causes a transition between the states computingJobCost and formingJobwithin the statechart diagram for the PrintJobobject (Figure 10.9). In the diagram (Figure 10.9),the guard condition is expressed in natural language and implies that authorizationcan only occur if the customer is authorized to approve the cost of the job. In OCL,the expression may take the form:
customerself.authorizationAuthority /H11549‘yes’
where a Boolean attribute, authorizationAuthority, of the class (actually a specific instance of the class) named Customer must be set to “yes” for the guard condition to be satisfied.As the design model is created, there are often instances in which pre- or post-conditions must be satisfied prior to completion of some action specified by thedesign. OCL provides a powerful tool for specifying pre- and postconditions in aformal manner. As an example, consider an extension to the print shop system(discussed as an example in Chapter 10) in which the customer provides an uppercost bound for the print job and a “drop-dead” delivery date at the same time as otherprint job characteristics are specified. If cost and delivery estimates exceed thesebounds, the job is not submitted and the customer must be notified. In OCL, a set ofpre- and postconditions may be specified in the following manner:
context PrintJob::validate(upperCostBound : Integer, custDeliveryReq :Integer)pre: upperCostBound > 0and custDeliveryReq > 0and self.jobAuthorization /H11549‘no’post: if self.totalJobCost </H11549upperCostBoundand self.deliveryDate </H11549custDeliveryReqthenself.jobAuthorization = ‘yes’endif
This OCL statement defines an invariant (inv)—conditions that must exist prior to(pre) and after (post) some behavior. Initially, a precondition establishes that bound-ing cost and delivery date must be specified by the customer, and authorization mustbe set to “no.” After costs and delivery are determined, the postcondition specified isapplied. It should also be noted that the expression: self.jobAuthorization = ‘yes’is not assigning the value “yes” but is declaring that the jobAuthorization must have been set to “yes” by the time the operation finishes. A complete description of OCLis beyond the scope of this appendix. The complete OCL specification can beobtained at www.omg.org/technology/documents/formal/ocl.htm .860 APPENDIX 1AN INTRODUCTION TO UMLpre75977_Apx1.qxd  12/1/08  3:28 PM  Page 860FURTHER READINGS AND INFORMATION SOURCES
Dozens of books discuss UML. Those that address the latest version include: Miles and Hamilton(Learning UML 2.0,O’Reilly Media, Inc., 2006); Booch, Rumbaugh, and Jacobson ( Unified Model- ing Language User Guide,2d ed., Addison-Wesley, 2005), Ambler (The Elements of UML 2.0 Style,Cambridge University Press, 2005), and Pilone and Pitman ( UML 2.0 in a Nutshell,O’Reilly Media, Inc., 2005).A wide variety of information sources on the use of UML in the software engineeringmodeling is available on the Internet. An up-to-date list of World Wide Web references can befound under “analysis” and “design” at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.APPENDIX 1AN INTRODUCTION TO UML 861pre75977_Apx1.qxd  11/27/08  6:42 PM  Page 861pre75977_Apx1.qxd  11/27/08  6:42 PM  Page 862What is an object-oriented (OO) viewpoint? Why is a method consideredto be object oriented? What is an object? As OO concepts gained wide-spread adherents during the 1980s and 1990s, there were many differ-ent opinions about the correct answers to these questions, but today a coherentview of OO concepts has emerged. This appendix is designed to provide you witha brief overview of this important topic and to introduce basic concepts andterminology.To understand the object-oriented point of view, consider an example of a real-world object—the thing you are sitting in right now—a chair. Chair is a subclass of a much larger class that we can call PieceOfFurniture.Individual chairs are members (usually called instances) of the class Chair. A set of generic attributescan be associated with every object in the class PieceOfFurniture. For example,all furniture has a cost, dimensions, weight, location, and color, among many pos-sible attributes. These apply whether we are talking about a table or a chair, a sofaor an armoire. Because Chairis a member of PieceOfFurniture, Chairinherits all attributes defined for the class.We have attempted an anecdotal definition of a class by describing its attrib-utes, but something is missing. Every object in the class PieceOfFurniture can be manipulated in a variety of ways. It can be bought and sold, physically modi-fied (e.g., you can saw off a leg or paint the object purple), or moved from oneplace to another. Each of these operations (other terms are servicesor methods) will modify one or more attributes of the object. For example, if the attributelocation is a composite data item defined as
location /H11549building /H11545floor /H11545room
then an operation named move()would modify one or more of the data items(building, floor, or room) that form the attribute location. To do this, move() must have “knowledge” of these data items. The operation move() could be used for a chair or a table, as long as both are instances of the class PieceOfFurniture. Validoperations for the class PieceOfFurniture—buy(), sell(), weigh()—are specified aspart of the class definition and are inherited by all instances of the class.The class Chair(and all objects in general) encapsulates data (the attributevalues that define the chair), operations (the actions that are applied to changethe attributes of chair), other objects, constants (set values), and other relatedinformation. Encapsulationmeans that all of this information is packaged underone name and can be reused as one specification or program component.
863APPENDIX
2OBJECT-ORIENTED
CONCEPTS
KEY
CONCEPTS
attributes . . . . .865classes . . . . . . .864boundary  . . . .866characteristics . .869controller  . . . .866definition  . . . .863design  . . . . . .868entity  . . . . . .866encapsulation  . .863inheritance  . . . .866messages . . . . .867methods . . . . . .865operations  . . . .865polymorphism . .868services  . . . . . .865subclass  . . . . . .865superclass  . . . .865pre75977_Apx2.qxd  11/27/08  6:45 PM  Page 863Now that I have introduced a few basic concepts, a more formal definition ofobject orientedwill prove more meaningful. Coad and Yourdon [Coa91] define theterm this way:
Object oriented /H11549objects /H11545classification /H11545inheritance /H11545communication
Three of these concepts have already been introduced. Communication is discussedlater in this appendix.
CLASSES AND OBJECTS
A class is an OO concept that encapsulates the data and procedural abstractionsrequired to describe the content and behavior of some real-world entity. Dataabstractions that describe the class are enclosed by a “wall” of procedural abstrac-tions [Tay90] (represented in Figure A2.1) that are capable of manipulating the datain some way. In a well-designed class, the only way to reach the attributes (andoperate on them) is to go through one of the methods that form the “wall” illustratedin the figure. Therefore, the class encapsulates data (inside the wall) and the pro-cessing that manipulates the data (the methods that make up the wall). This achievesinformation hiding (Chapter 8) and reduces the impact of side effects associated withchange. Since the methods tend to manipulate a limited number of attributes, theircohesion is improved, and because communication occurs only through the meth-ods that make up the “wall,” the class tends to be less strongly coupled from otherelements of a system.
1864 APPENDIX 2OBJECT-ORIENTED CONCEPTS
AttributesMethod1()
Method
3()Method4()Methodn() Method2()FIGURE A2.1
A schematicrepresentationof a class
1 It should be noted, however, that coupling can become a serious problem in OO systems. It ariseswhen classes from various parts of the system are used as the data types of attributes, and argu-ments to methods. Even though access to the objects may only be through procedure calls, thisdoes not mean that coupling is necessarily low, just lower than if direct access to the internals ofobjects were allowed.pre75977_Apx2.qxd  11/27/08  6:45 PM  Page 864Stated another way, a class is a generalized description (e.g., a template or blue-print) that describes a collection of similar objects. By definition, objects are in-stances of a specific class and inherit its attributes and the operations that areavailable to manipulate the attributes. A superclass (often called a base class) is a gen- eralization of a set of classes that are related to it. A subclassis a specialization of the superclass. For example, the superclass MotorVehicleis a generalization of the classes Truck, SUV, Automobile,and Van.The subclass Automobileinherits all attributes of MotorVehicle,but in addition, incorporates additional attributes thatare specific only to automobiles.These definitions imply the existence of a class hierarchy in which the attributesand operations of the superclass are inherited by subclasses that may each addadditional “private” attributes and methods. For example, the operations sitOn() and turn()might be private to the Chairsubclass.
ATTRIBUTES
You have learned that attributes are attached to classes and that they describe theclass in some way. An attribute can take on a value defined by an enumerateddomain.In most cases, a domain is simply a set of specific values. For example,assume that a class Automobilehas an attribute color. The domain of values for coloris {white, black, silver, gray, blue, red, yellow, green }. In more complex situa- tions, the domain can be a class. Continuing the example, the class Automobile also has an attribute powerTrainthat is itself a class. The class PowerTrain would contain attributes that describe the specific engine and transmission for the car.The features(values of the domain) can be augmented by assigning a default value(feature) to an attribute. For example, the color attribute defaults to white. It may also be useful to associate a probability with a particular feature by assigning {value,probability} pairs. Consider the colorattribute for automobile. In some applications(e.g., manufacturing planning) it might be necessary to assign a probability to eachof the colors (e.g., white and black are highly probable as automobile colors).
OPERATIONS , M ETHODS , AND SERVICES
An object encapsulates data (represented as a collection of attributes) and the algo-rithms that process the data. These algorithms are called operations, methods, or services
2and can be viewed as processing components.Each of the operations that is encapsulated by an object provides a representationof one of the behaviors of the object. For example, the operation GetColor()for the object Automobilewill extract the color stored in the color attribute. The implication of the existence of this operation is that the class Automobilehas been designed toAPPENDIX 2OBJECT-ORIENTED CONCEPTS 865
2 In the context of this discussion, the term operations is used, but the terms methodsand servicesare equally popular.pre75977_Apx2.qxd  11/27/08  6:45 PM  Page 865receive a stimulus (we call the stimulus a message) that requests the color of the par-ticular instance of a class. Whenever an object receives a stimulus, it initiates somebehavior. This can be as simple as retrieving the color of automobile or as complexas the initiation of a chain of stimuli that are passed among a variety of differentobjects. In the latter case, consider an example in which the initial stimulus receivedby Object 1results in the generation of two other stimuli that are sent to Object 2and Object 3. Operations encapsulated by the second and third objects act on thestimuli, returning necessary information to the first object. Object 1 then uses the returned information to satisfy the behavior demanded by the initial stimulus.
OBJECT -ORIENTED ANALYSIS AND DESIGN CONCEPTS
Requirements modeling (also called analysis modeling) focuses primarily on classesthat are extracted directly from the statement of the problem. These entity classes typ- ically represent things that are to be stored in a database and persist throughout theduration of the application (unless they are specifically deleted).Design refines and extends the set of entity classes. Boundary and controllerclasses are developed and/or refined during design. Boundary classescreate the interface (e.g., interactive screen and printed reports) that the user sees and inter-acts with as the software is used. Boundary classes are designed with the responsi-bility of managing the way entity objects are represented to users.Controller classesare designed to manage (1) the creation or update of entityobjects, (2) the instantiation of boundary objects as they obtain information fromentity objects, (3) complex communication between sets of objects, and (4) valida-tion of data communicated between objects or between the user and the application.The concepts discussed in the paragraphs that follow can be useful in analysis anddesign work.Inheritance.Inheritance is one of the key differentiators between conventional andobject-oriented systems. A subclass Y inherits all of the attributes and operations associated with its superclass X. This means that all data structures and algorithmsoriginally designed and implemented for X are immediately available for Y—no further work need be done. Reuse has been accomplished directly.Any change to the attributes or operations contained within a superclass isimmediately inherited by all subclasses. Therefore, the class hierarchy becomes amechanism through which changes (at high levels) can be immediately propagatedthrough a system.It is important to note that at each level of the class hierarchy new attributes andoperations may be added to those that have been inherited from higher levels in thehierarchy. In fact, whenever a new class is to be created, you have a number of options:
•The class can be designed and built from scratch. That is, inheritance is notused.866 APPENDIX 2OBJECT-ORIENTED CONCEPTSpre75977_Apx2.qxd  11/27/08  6:45 PM  Page 866•The class hierarchy can be searched to determine if a class higher in thehierarchy contains most of the required attributes and operations. The newclass inherits from the higher class and additions may then be added, asrequired.
•The class hierarchy can be restructured so that the required attributes andoperations can be inherited by the new class.
•Characteristics of an existing class can be overridden, and different versionsof attributes or operations are implemented for the new class.Like all fundamental design concepts, inheritance can provide significant benefit forthe design, but if it is used inappropriately,
3it can complicate a design unnecessar- ily and lead to error-prone software that is difficult to maintain.Messages.Classes must interact with one another to achieve design goals. A mes-sage stimulates some behavior to occur in the receiving object. The behavior isaccomplished when an operation is executed.The interaction between objects is illustrated schematically in Figure A2.2. Anoperation withinSenderObjectgenerates a message of the form message (<parameters>) where the parameters identify ReceiverObjectas the object to be stimulated by the message, the operation within ReceiverObjectthat is to receive the message, and the data items that provide information that is required for the operationto be successful. The collaboration defined between classes as part of the require-ments model provides useful guidance in the design of messages.Cox [Cox86] describes the interchange between classes in the following manner:
An object [class] is requested to perform one of its operations by sending it a messagetelling the object what to do. The receiver [object] responds to the message by first choos-ing the operation that implements the message name, executing this operation, and thenreturning control to the caller. Messaging ties an object-oriented system together. Mes-sages provide insight into the behavior of individual objects and the OO system as a whole.APPENDIX 2OBJECT-ORIENTED CONCEPTS 867
3 For example, designing a subclass that inherits attributes and operations from more than onesuperclass (sometimes called “multiple inheritance”) is frowned upon by most designers.:SenderObject
Message (<parameters>)
:ReceiverObjectFIGURE A2.2
Messagepassingbetweenobjectspre75977_Apx2.qxd  11/27/08  6:45 PM  Page 867Polymorphism.Polymorphismis a characteristic that greatly reduces the effortrequired to extend the design of an existing object-oriented system. To understandpolymorphism, consider a conventional application that must draw four differenttypes of graphs: line graphs, pie charts, histograms, and Kiviat diagrams. Ideally,once data are collected for a particular type of graph, the graph should draw itself.To accomplish this in a conventional application (and maintain module cohesion), itwould be necessary to develop drawing modules for each type of graph. Then, withinthe design, control logic similar to the following would have to be embedded:
case of graphtype:if graphtype /H11549linegraph then DrawLineGraph (data);if graphtype /H11549piechart then DrawPieChart (data);if graphtype /H11549histogram then DrawHisto (data);if graphtype /H11549kiviat then DrawKiviat (data);end case;
Although this design is reasonably straightforward, adding new graph types could betricky. A new drawing module would have to be created for each graph type and thenthe control logic would have to be updated to reflect the new graph type.To solve this problem in an object-oriented system, all of the graphs become sub-classes of a general class called Graph. Using a concept called overloading [Tay90], each subclass defines an operation called draw. An object can send a draw message to any one of the objects instantiated from any one of the subclasses. The objectreceiving the message will invoke its own drawoperation to create the appropriate graph. Therefore, the design is reduced to
draw <graphtype>
When a new graph type is to be added to the system, a subclass is created with its owndrawoperation. But no changes are required within any object that wants a graphdrawn because the message draw <graphtype> remains unchanged. To summarize, polymorphism enables a number of different operations to have the same name. Thisin turn decouples objects from one another, making each more independent.Design classes.The requirements model defines a complete set of analysisclasses. Each describes some element of the problem domain, focusing on aspectsof the problem that are user or customer visible. The level of abstraction of an analy-sis class is relatively high.As the design model evolves, the software team must define a set of design classesthat (1) refine the analysis classes by providing design detail that will enable theclasses to be implemented and (2) create a new set of design classes that implementa software infrastructure that supports the business solution. Five different types of868 APPENDIX 2OBJECT-ORIENTED CONCEPTSpre75977_Apx2.qxd  11/27/08  6:45 PM  Page 868design classes, each representing a different layer of the design architecture aresuggested [Amb01]:
•User interface classesdefine all abstractions that are necessary for human-computer interaction (HCI).
•Business domain classesare often refinements of the analysis classes definedearlier. The classes identify the attributes and operations (methods) that arerequired to implement some element of the business domain.
•Process classesimplement lower-level business abstractions required to fullymanage the business domain classes.
•Persistent classesrepresent data stores (e.g., a database) that will persistbeyond the execution of the software.
•System classesimplement software management and control functions thatenable the system to operate and communicate within its computing envi-ronment and with the outside world.As the architectural design evolves, the software team should develop a completeset of attributes and operations for each design class. The level of abstraction isreduced as each analysis class is transformed into a design representation. That is,analysis classes represent objects (and associated methods that are applied to them)using the jargon of the business domain. Design classes present significantly moretechnical detail as a guide for implementation.Arlow and Neustadt [Arl02] suggest that each design class be reviewed to ensurethat it is “well formed.” They define four characteristics of a well-formed design class:Complete and sufficient.A design class should be the complete encapsu-lation of all attributes and methods that can reasonably be expected (basedon a knowledgeable interpretation of the class name) to exist for the class.For example, the class Scenedefined for video-editing software is completeonly if it contains all attributes and methods that can reasonably be associ-ated with the creation of a video scene. Sufficiency ensures that the designclass contains only those methods that are sufficient to achieve the intent ofthe class, no more and no less.Primitiveness.Methods associated with a design class should be focusedon accomplishing one specific function for the class. Once the function hasbeen implemented with a method, the class should not provide another wayto accomplish the same thing. For example, the class VideoClip of the video editing software might have attributes start-pointand end-pointto indicate the start and end points of the clip (note that the raw video loaded into the sys-tem may be longer than the clip that is used). The methods, setStartPoint()and setEndPoint()provide the only means for establishing start and endpoints for the clip.APPENDIX 2OBJECT-ORIENTED CONCEPTS 869pre75977_Apx2.qxd  11/27/08  6:45 PM  Page 869High cohesion.A cohesive design class is single minded. That is, it has asmall, focused set of responsibilities and single-mindedly applies attributesand methods to implement those responsibilities. For example, the classVideoClipof the video-editing software might contain a set of methods forediting the video clip. As long as each method focuses solely on attributesassociated with the video clip, cohesion is maintained.Low coupling.Within the design model, it is necessary for design classesto collaborate with one another. However, collaboration should be kept to anacceptable minimum. If a design model is highly coupled (all design classescollaborate with all other design classes), the system is difficult to implement,test, and maintain over time. In general, design classes within a subsystemshould have only limited knowledge of other classes. This restriction, calledthe Law of Demeter[Lie03],suggests that a method should only send mes-sages to methods in neighboring classes.
4
FURTHER READINGS AND INFORMATION SOURCES
Over the past three decades hundreds of books have been written on object-oriented pro-gramming, analysis, and design. Weisfeld (The Object-Oriented Thought Process, 2d ed., Sams Publishing, 2003) presents a worthwhile treatment of general OO concepts and principles.McLaughlin and his colleagues (Head First Object-Oriented Analysis and Design: A Brain FriendlyGuide to OOA&D,O’Reilly Media, Inc., 2006) provide an accessible and enjoyable treatment ofOO analysis and design approaches. A more in-depth treatment of OO analysis and design ispresented by Booch and his colleagues (Object-Oriented Analysis and Design with Applications,3d ed., Addison-Wesley, 2007). Wu ( An Introduction to Object-Oriented Programming with Java, McGraw-Hill, 2005) has written a comprehensive book on OO programming that is typical ofdozens written for many different programming languages.A wide variety of information sources on object-oriented technologies is available on theInternet. An up-to-date list of World Wide Web references can be found under “analysis” and“design” at the SEPA website: www.mhhe.com/engcs/compsci/pressman/professional/olc/ser.htm.870 APPENDIX 2OBJECT-ORIENTED CONCEPTS
4 A less formal way of stating the Law of Demeter is, “Each unit should only talk to its friends; don’ttalk to strangers.”pre75977_Apx2.qxd  11/27/08  6:45 PM  Page 870871REFERENCES
[Abb83] Abbott, R., “Program Design by Informal English Descriptions,“ CACM, vol. 26, no. 11, November 1983, pp. 892–894.[ACM98] ACM/IEEE-CS Joint Task Force, Software Engineering Code of Ethics and ProfessionalPractice, 1998, available at www.acm.org/serving/se/code.htm.[Ada93] Adams, D., Mostly Harmless, Macmillan, 1993.[AFC88] Software Risk Abatement, AFCS/AFLC Pamphlet 800-45, U.S. Air Force, September 30,1988.[Agi03] The Agile Alliance Home Page, www.agilealliance.org/home.[Air99] Airlie Council, “Performance Based Management: The Program Manager’s Guide Basedon the 16-Point Plan and Related Metrics,” Draft Report, March 8, 1999.[Aka04] Akao, Y., Quality Function Deployment, Productivity Press, 2004.[Ale77] Alexander, C., A Pattern Language, Oxford University Press, 1977.[Ale79] Alexander, C., The Timeless Way of Building , Oxford University Press, 1979. [Amb95] Ambler, S., “Using Use-Cases,” Software Development, July 1995, pp. 53–61. [Amb98] Ambler, S., Process Patterns: Building Large-Scale Systems Using Object Technology,Cambridge University Press/SIGS Books, 1998.[Amb01] Ambler, S., The Object Primer, 2d ed., Cambridge University Press, 2001.[Amb02a] Ambler, S., “What Is Agile Modeling (AM)?” 2002, www.agilemodeling.com/index.htm.[Amb02b] Ambler, S., and R. Jeffries, Agile Modeling, Wiley, 2002. [Amb02c] Ambler, S., “UML Component Diagramming Guidelines,” available at www.modelingstyle.info/, 2002.[Amb04] Ambler, S., “Examining the Cost of Change Curve,” in The Object Primer, 3d ed.,Cambridge University Press, 2004.[Amb06] Ambler, S., “The Agile Unified Process (AUP), 2006, available at www.ambysoft.com/unifiedprocess/agileUP.html.[And06] Andrews, M., and J. Whittaker, How to Break Web Software: Functional and SecurityTesting of Web Applications and Web Services, Addison-Wesley, 2006.[ANS87] ANSI/ASQC A3-1987, Quality Systems Terminology, 1987.[Ant06] Anton, D., and C. Anton, ISO 9001 Survival Guide, 3d ed., AEM Consulting Group, 2006. [AOS07] AOSD.net (Aspect-Oriented Software Development), glossary, available at http://aosd.net/wiki/index.php?title=Glossary.[App00] Appleton, B., “Patterns and Software: Essential Concepts and Terminology,” February2000, available at www.cmcrossroads.com/bradapp/docs/patterns-intro.html.[App08] Apple Computer, Accessibility, 2008, available at www.apple.com/disability/.[Arl02] Arlow, J., and I. Neustadt, UML and the Unified Process , Addison-Wesley, 2002. [Arn89] Arnold, R. S., “Software Restructuring,” Proc. IEEE, vol. 77, no. 4, April 1989, pp. 607–617.[Art97] Arthur, L. J., “Quantum Improvements in Software System Quality,” CACM, vol. 40, no. 6,June 1997, pp. 47–52.[Ast04] Astels, D., Test Driven Development: A Practical Guide , Prentice Hall, 2004. [Ave04] Aversan, L., et al., “Managing Coordination and Cooperation in Distributed SoftwareProcesses: The GENESIS Environment,” Software Process Improvement and Practice, vol. 9,Wiley Interscience, 2004, pp. 239–263.[Baa07] de Baar, B., “Project Risk Checklist,” 2007, available at www.softwareprojects.org/project_riskmanagement_starting62.htm.[Bab86] Babich, W. A., Software Configuration Management, Addison-Wesley, 1986.[Bac97] Bach, J., “‘Good Enough Quality: Beyond the Buzzword,” IEEE Computer, vol. 30, no. 8,August 1997, pp. 96–98.pre75977_Ref.qxd  11/27/08  6:40 PM  Page 871[Bac98] Bach, J., “The Highs and Lows of Change Control,” Computer, vol. 31, no. 8, August 1998, pp. 113–115.[Bae98] Baetjer, Jr., H., Software as Capital, IEEE Computer Society Press, 1998, p. 85.[Bak72] Baker, F. T., “Chief Programmer Team Management of Production Programming,” IBMSystems Journal., vol. 11, no. 1, 1972, pp. 56–73.[Ban06] Baniassad, E., et al., “Discovering Early Aspects,” IEEE Software, vol. 23, no. 1, January–February, 2006, pp. 61–69.[Bar06] Baresi, L., E. DiNitto, and C. Ghezzi, “Toward Open-World Software: Issues andChallenges,” IEEE Computer, vol. 39, no. 10, October 2006, pp. 36–43.[Bas84] Basili, V. R., and D. M. Weiss, “A Methodology for Collecting Valid Software EngineeringData,” IEEE Trans. Software Engineering, vol. SE-10, 1984, pp. 728–738.[Bas03] Bass, L., P. Clements, and R. Kazman, Software Architecture in Practice, 2d ed., Addison- Wesley, 2003.[Bec00] Beck, K., Extreme Programming Explained: Embrace Change, Addison-Wesley, 1999.[Bec01a] Beck, K., et al., “Manifesto for Agile Software Development,” www.agilemanifesto.org/.[Bec04a] Beck, K., Extreme Programming Explained: Embrace Change, 2d ed., Addison-Wesley,2004.[Bec04b] Beck, K., Test-Driven Development: By Example, 2d ed., Addison-Wesley, 2002.[Bee99] Beedle, M., et al., “SCRUM: An Extension Pattern Language for Hyperproductive Soft-ware Development,” included in: Pattern Languages of Program Design 4, Addison-WesleyLongman, Reading MA, 1999, downloadable from http:/ /jeffsutherland.com/scrum/scrum_plop.pdf.[Bei84] Beizer, B., Software System Testing and Quality Assurance, Van Nostrand-Reinhold, 1984.[Bei90] Beizer, B., Software Testing Techniques , 2d ed., Van Nostrand-Reinhold, 1990. [Bei95] Beizer, B., Black-Box Testing, Wiley, 1995.[Bel81] Belady, L., Foreword to Software Design: Methods and Techniques (L. J. Peters, author), Yourdon Press, 1981.[Bel95] Bellinzona R., M. G. Gugini, and B. Pernici, “Reusing Specifications in OO Applications,”IEEE Software, March 1995, pp. 65–75.[Ben99] Bentley, J., Programming Pearls, 2d ed., Addison-Wesley, 1999.[Ben00] Bennatan, E. M., Software Project Management: A Practitioner’s Approach , 3d ed., McGraw-Hill, 2000.[Ben02] Bennett, S., S. McRobb, and R. Farmer, Object-Oriented Analysis and Design, 2d ed.,McGraw-Hill, 2002.[Ber80] Bersoff, E. H., V. D. Henderson, and S. G. Siegel, Software Configuration Management, Prentice Hall, 1980.[Ber93] Berard, E., Essays on Object-Oriented Software Engineering , vol. 1, Addison-Wesley, 1993. [Bes04] Bessin, J., “The Business Value of Quality,” IBM developerWorks, June 15, 2004, avail-able at www-128.ibm.com/developerworks/rational/library/4995.html.[Bha06] Bhat, J., M. Gupta, and S. Murthy, “Lessons from Offshore Outsourcing,” IEEE Software,vol. 23, no. 5, September–October 2006.[Bie94] Bieman, J. M., and L. M. Ott, “Measuring Functional Cohesion,” IEEE Trans. SoftwareEngineering, vol. SE-20, no. 8, August 1994, pp. 308–320.[Bin93] Binder, R., “Design for Reuse Is for Real,” American Programmer, vol. 6, no. 8, August1993, pp. 30–37.[Bin94a] Binder, R., “Testing Object-Oriented Systems: A Status Report,” American Programmer, vol. 7, no. 4, April 1994, pp. 23–28.[Bin94b] Binder, R. V., “Object-Oriented Software Testing,” Communications of the ACM, vol. 37,no. 9, September 1994, p. 29.[Bin99] Binder, R., Testing Object-Oriented Systems: Models, Patterns, and Tools , Addison-Wesley, 1999.[Bir98] Biró, M., and T. Remzsö, “Business Motivations for Software Process Impro
 vement,” ERCIM News No. 32, January 1998, available at www.ercim.org/publication/Ercim_News/enw32/biro.html.[Boe81] Boehm, B., Software Engineering Economics , Prentice Hall, 1981. [Boe88] Boehm, B., “A Spiral Model for Software Development and Enhancement,” Computer, vol. 21, no. 5, May 1988, pp. 61–72.872 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 872[Boe89] Boehm, B. W., Software Risk Management, IEEE Computer Society Press, 1989.[Boe96] Boehm, B., “Anchoring the Software Process,” IEEE Software, vol. 13, no. 4, July 1996,pp. 73–82.[Boe98] Boehm, B., “Using the WINWIN Spiral Model: A Case Study,” Computer, vol. 31, no. 7, July 1998, pp. 33–44.[Boe00] Boehm, B., et al., Software Cost Estimation in COCOMO II, Prentice Hall, 2000.[Boe01a] Boehm, B., “The Spiral Model as a Tool for Evolutionary Software Acquisition,”CrossTalk, May 2001, available at www.stsc.hill.af.mil/crosstalk/2001/05/boehm.html.[Boe01b] Boehm, B., and V. Basili, “Software Defect Reduction Top 10 List,” IEEE Computer, vol. 34, no. 1, January 2001, pp. 135–137.[Boe08] Boehm, B., “Making a Difference in the Software Century,” IEEE Computer, vol. 41, no. 3, March 2008, pp. 32–38.[Boh66] Bohm, C., and G. Jacopini, “Flow Diagrams, Turing Machines and Languages with OnlyTwo Formation Rules,” CACM, vol. 9, no. 5, May 1966, pp. 366–371.[Boh00] Bohl, M., and M. Rynn, Tools for Structured Design: An Introduction to Programming Logic,5th ed., Prentice Hall, 2000.[Boi04] Boiko, B., Content Management Bible, 2d ed., Wiley, 2004.[Bol02] Boldyreff, C., et al., “Environments to Support Collaborative Software Engineering,”2002, downloadable from www.cs.put.poznan.pl/dweiss/site/publications/download/csmre-paper.pdf.[Boo94] Booch, G., Object-Oriented Analysis and Design, 2d ed., Benjamin Cummings, 1994.[Boo05] Booch, G., J. Rumbaugh, and I. Jacobsen, The Unified Modeling Language User Guide . 2d ed., Addison-Wesley, 2005.[Boo06] Bootstrap-institute.com, 2006, www.cse.dcu.ie/espinode/directory/directory.html.[Boo08] Booch, G., Handbook of Software Architecture , 2008, available at www.booch.com/ architecture/systems.jsp.[Bor01] Borchers, J., A Pattern Approach to Interaction Design, Wiley, 2001.[Bos00] Bosch, J., Design & Use of Software Architectures , Addison-Wesley, 2000. [Bra85] Bradley, J. H., “The Science and Art of Debugging,” Computerworld, August 19, 1985, pp. 35–38.[Bra94] Bradac, M., D. Perry, and L. Votta, “Prototyping a Process Monitoring Experiment,” IEEE Trans. Software Engineering, vol. 20, no. 10, October 1994, pp. 774–784.[Bre02] Breen, P., “Exposing the Fallacy of ’Good Enough’ Software,” informit.com, February 1,2002, available at www.informit.com/articles/article.asp?p=25141&rl=1.[Bro95] Brooks, F., The Mythical Man-Month, Silver Anniversary edition, Addison-Wesley,1995.[Bro96] Brown, A. W., and K. C. Wallnau, “Engineering of Component Based Systems,”Component-Based Software Engineering , IEEE Computer Society Press, 1996, pp. 7–15. [Bro01] Brown, B., Oracle9i Web Development , 2d ed., McGraw-Hill, 2001. [Bro03] Brooks, F, “Three Great Challenges for Half-Century-Old Computer Science,” JACM,vol. 50, no. 1, January 2003, pp. 25–26.[Bro06] Broy, M., “The ‘Grand Challenge’ in Informatics: Engineering Software IntensiveSystems,” IEEE Computer, vol. 39, no. 10, October 2006, pp. 72–80.[Buc99] Bucanac, C., “The V-Model,” University of Karlskrona/Ronneby, January 1999, down-loadable from www.bucanac.com/documents/The_V-Model.pdf.[Bud96] Budd, T., An Introduction to Object-Oriented Programming, 2d ed., Addison-Wesley, 1996.[Bus96] Buschmann, F., et al., Pattern-Oriented Software Architecture, Wiley, 1996.[Bus07] Buschmann, F., et al., Pattern-Oriented Software Architecture, A System of Patterns, Wiley,2007.[Cac02] Cachero, C., et al., “Conceptual Navigation Analysis: A Device and Platform Indepen-dent Navigation Specification,” Proc. 2nd Intl. Workshop on Web-Oriented Technology , June 2002, downloadable from www.dsic.upv.es/~west/iwwost02/papers/cachero.pdf.[Cai03] Caine, Frarber, and Gordon, Inc., PDL/81, 2003, available at www .cfg.com/pdl81/ lpd.html.[Car90] Card, D
. N., and R. L. Glass, Measuring Software Design Quality, Prentice Hall, 1990. [Cas89] Cashman, M., “Object Oriented Domain Analysis,” ACM Software Engineering Notes, vol. 14, no. 6, October 1989, p. 67.REFERENCES 873pre75977_Ref.qxd  11/27/08  6:40 PM  Page 873[Cav78] Cavano, J. P., and J. A. McCall, “A Framework for the Measurement of Software Quality,”Proc. ACM Software Quality Assurance Workshop, November 1978, pp. 133–139.[CCS02] CS3 Consulting Services, 2002, www.cs3inc.com/DSDM.htm.[Cec06] Cechich, A., et al., “Trends on COTS Component Identification,” Proc. Fifth Intl. Conf. onCOTS-Based Software Systems, IEEE, 2006.[Cha89] Charette, R. N., Software Engineering Risk Analysis and Management, McGraw-Hill/Intertext, 1989.[Cha92] Charette, R. N., “Building Bridges over Intelligent Rivers,” American Programmer, vol. 5,no. 7, September 1992, pp. 2–9.[Cha93] de Champeaux, D., D. Lea, and P. Faure, Object-Oriented System Development , Addison- Wesley, 1993.[Cha03] Chakravarti, A., “Online Software Design Pattern Links,” 2003, available at www.anupriyo.com/oopfm.shtml.[Che77] Chen, P., The Entity-Relationship Approach to Logical Database Design, QED InformationSystems, 1977.[Chi94] Chidamber, S. R., and C. F. Kemerer, “A Metrics Suite for Object-Oriented Design,” IEEE Trans. Software Engineering, vol. SE-20, no. 6, June 1994, pp. 476–493.[Cho89] Choi, S. C., and W. Scacchi, “Assuring the Correctness of a Configured SoftwareDescription,” Proc. 2nd Intl. Workshop on Software Configuration Management , ACM, Princeton, NJ, October 1989, pp. 66–75.[Chu95] Churcher, N. I., and M. J. Shepperd, “Towards a Conceptual Framework for Object-Oriented Metrics,” ACM Software Engineering Notes, vol. 20, no. 2, April 1995, pp. 69–76.[Cig07] Cigital, Inc., “Case Study: Finding Defects Earlier Yields Enormous Savings,” 2007, avail-able at www.cigital.com/solutions/roi-cs2.php.[Cla05] Clark, S., and E. Baniasaad, Aspect-Oriented Analysis and Design, Addison-Wesley, 2005. [Cle95] Clements, P., “From Subroutines to Subsystems: Component Based Software Develop-ment,” American Programmer, vol. 8, no. 11, November 1995.[Cle03] Clements, P., R. Kazman, and M. Klein, Evaluating Software Architectures: Methods and Case Studies, Addison-Wesley, 2003.[Cle06] Clemmons, R., “Project Estimation with Use Case Points,” CrossTalk, February 2006,p. 18–222, downloadable from www.stsc.hill.af.mil/crosstalk/2006/02/0602Clemmons.pdf.[CMM07] Capability Maturity Model Integration (CMMI), Software Engineering Institute, 2007,available at www.sei.cmu.edu/cmmi/.[CMM08] People Capability Maturity Model Integration (People CMM) , Software Engineering Institute, 2008, available at www.sei.cmu.edu/cmm-p/.[Coa91] Coad, P., and E. Yourdon, Object-Oriented Analysis, 2d ed., Prentice Hall, 1991.[Coa99] Coad, P., E. Lefebvre, and J. DeLuca, Java Modeling in Color with UML , Prentice Hall, 1999. [Coc01a] Cockburn, A., and J. Highsmith, “Agile Software Development: The People Factor,”IEEE Computer, vol. 34, no. 11, November 2001, pp. 131–133.[Coc01b] Cockburn, A., Writing Effective Use-Cases, Addison-Wesley, 2001.[Coc02] Cockburn, A., Agile Software Development, Addison-Wesley, 2002. [Coc04] Cockburn, A., “What the Agile Toolbox Contains,” CrossTalk, November 2004, available at www.stsc.hill.af.mil/crosstalk/2004/11/0411Cockburn.html.[Coc05] Cockburn, A., Crystal Clear, Addison-Wesley, 2005.[Con96] Conradi, R., “Software Process Improvement: Why We Need SPIQ,” NTNU, October1996, downloadable from www.idi.ntnu.no/grupper/su/publ/pdf/nik96-spiq.pdf.[Con02] Conradi, R., and A. Fuggetta, “Improving Software Process Improvement,” IEEE Software, July–August 2002, pp. 2–9, downloadable from http:/ /citeseer.ist.psu.edu/conradi02improving.html.[Con93] Constantine, L., “Work Organization: Paradigms for Project Management and Organi-zation, CACM, vol. 36, no. 10, October 1993, pp. 34–43.[Con95] Constantine, L, “What DO Users Want? Engineering Usability in Software,” WindowsTech Journal, December 1995, available from www.forUse.com.[Con03] Constantine, L., and L. Lockwood, Software for Use, Addison-Wesley
, 1999; see also www.foruse.com/.[Cop05] Coplien, J., “Software Patterns,” 2005, available at http:/ /hillside.net/patterns/definition.html.874 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 874[Cor98] Corfman, R., “An Overview of Patterns,” in The Patterns Handbook, SIGS Books, 1998. [Cou00] Coulouris, G., J. Dollimore, and T. Kindberg, Distributed Systems: Concepts and Design,3d ed., Addison-Wesley, 2000.[Cox86] Cox, Brad, Object-Oriented Programming, Addison-Wesley, 1986.[Cri92] Christel, M. G., and K. C. Kang, “Issues in Requirements Elicitation,” Software Engineer-ing Institute, CMU/SEI-92-TR-12 7, September 1992.[Cro79] Crosby, P., Quality Is Free, McGraw-Hill, 1979.[Cro07] Cross, M., and M. Fisher, Developer’s Guide to Web Application Security, SyngressPublishing, 2007.[Cur86] Curritt, P. A., M. Dyer, and H. D. Mills, “Certifying the Reliability of Software,” IEEE Trans, Software Engineering, vol. SE-12, no. 1, January 1994.[Cur88] Curtis, B., et al., “A Field Study of the Software Design Process for Large Systems,” IEEETrans. Software Engineering, vol. SE-31, no. 11, November 1988, pp. 1268–1287.[Cur01] Curtis, B., W. Hefley, and S. Miller, People Capability Maturity Model, Addison-Wesley,2001.[CVS07] Concurrent Versions System, Ximbiot, http:/ /ximbiot.com/cvs/wiki/index.php?title=Main_Page, 2007.[DAC03} “An Overview of Model-Based Testing for Software,” Data and Analysis Center forSoftware, CR/TA 12, June 2003, downloadable from www.goldpractices.com/dwnload/practice/pdf/Model_Based_Testing.pdf.[Dah72] Dahl, O., E. Dijkstra, and C. Hoare, Structured Programming, Academic Press, 1972. [Dar91] Dart, S., “Concepts in Configuration Management Systems,” Proc. Third International Workshop on Software Configuration Management , ACM SIGSOFT, 1991, downloadable from www.sei.cmu.edu/legacy/scm/abstracts/abscm_concepts.html.[Dar99] Dart, S., “Change Management: Containing the Web Crisis,” Proc. Software Configuration Management Symposium, Toulouse, France, 1999, available at www.perforce.com/perforce/conf99/dart.html.[Dar01] Dart, S., Spectrum of Functionality in Configuration Management Systems, SoftwareEngineering Institute, 2001, available at www.sei.cmu.edu/legacy/scm/tech_rep/TR11_90/TOC_TR11_90.html.[Das05] Dasari, R., “Lean Software Development,” a white paper, downloadable from www.projectperfect.com.au/downloads/Info/info_lean_development.pdf, 2005.[Dav90] Davenport, T. H., and J. E. Young, “The New Industrial Engineering: InformationTechnology and Business Process Redesign,” Sloan Management Review, Summer 1990, pp. 11–27.[Dav93] Davis, A., et al., “Identifying and Measuring Quality in a Software RequirementsSpecification,” Proc. First Intl. Software Metrics Symposium, IEEE, Baltimore, MD, May 1993,pp. 141–152.[Dav95a] Davis, M., “Process and Product: Dichotomy or Duality,” Software Engineering Notes,ACM Press, vol. 20, no. 2, April, 1995, pp. 17–18.[Dav95b] Davis, A., 201 Principles of Software Development , McGraw-Hill, 1995. [Day99] Dayani-Fard, H., et al., “Legacy Software Systems: Issues, Progress, and Challenges,”IBM Technical Report: TR-74.165-k, April 1999, available at www.cas.ibm.com/toronto/publications/TR-74.165/k/legacy.html.[Dem86] Deming, W. E., Out of the Crisis, MIT Press, 1986.[DeM79] DeMarco, T., Structured Analysis and System Specification, Prentice Hall, 1979.[DeM95] DeMarco, T., Why Does Software Cost So Much? Dorset House, 1995. [DeM95a] DeMarco, T., “Lean and Mean,” IEEE Software, November 1995, pp. 101–102. [DeM98] DeMarco, T., and T. Lister, Peopleware, 2d ed., Dorset House, 1998.[DeM02] DeMarco, T., and B. Boehm, “The Agile Methods Fray,” IEEE Computer, vol. 35, no. 6,June 2002, pp. 90–92.[Den73] Dennis, J., “Modularity,” in Advanced Course on Software Engineering (F. L. Bauer, ed.), Springer-Verlag, 1973, pp. 128–182.[Dev01] Devedzik, V., “Software Patterns,” in Handbook of Software Engineering and Knowledge Engineering, World Scientific Publishing Co., 2001.[Dha95] Dhama, H., “Quantitative Metrics for Cohesion and Coupling in Software,” Journal of Systems and Software, vol. 29, no. 4, April 1995.REFERENCES 875pre75977_Ref.qxd  11/27/08  6:40 PM  Page 875[Dij65] Dijkstra, E., “Programming Considered as a Human Activity,” in Proc. 1965 IFIP Congress, North-Holland Publishing Co., 1965.[Dij72] Dijkstra, E., “The Humble Programmer,” 1972 ACM Turing Award Lecture, CACM, vol. 15,no. 10, October 1972, pp. 859–866. [Dij76a] Dijkstra, E., “Structured Programming,” in Software Engineering, Concepts and Techniques, (J. Buxton et al., eds.), Van Nostrand-Reinhold, 1976.[Dij76b] Dijkstra, E., A Discipline of Programming, Prentice Hall, 1976.[Dij82] Dijksta, E., “On the Role of Scientific Thought,” Selected Writings on Computing: A Personal Perspective, Springer-Verlag, 1982.[Dix99] Dix, A., “Design of User Interfaces for the Web,” Proc. User Interfaces to Data SystemsConference, September 1999, downloadable from www.comp.lancs.ac.uk/computing/users/dixa/topics/webarch/.[Dob04] Dobb, F., ISO 9001:2000 Quality Registration Step-by-Step , 3d ed., Butterworth- Heinemann, 2004.[Don99] Donahue, G., S. Weinschenck, and J. Nowicki, “Usability Is Good Business,” CompuwareCorp., July 1999, available from www.compuware.com.[Dre99] Dreilinger, S., “CVS Version Control for Web Site Projects,” 1999, available at www.durak.org/cvswebsites/howto-cvs/howto-cvs.html.[Dru75] Drucker, P., Management, W. H. Heinemann, 1975.[Duc01] Ducatel, K., et al., Scenarios for Ambient Intelligence in 2010, ISTAG-EuropeanCommission, 2001, downloadable from ftp:/ /ftp.cordis.europa.eu/pub/ist/docs/istagscenarios2010.pdf.[Dun82] Dunn, R., and R. Ullman, Quality Assurance for Computer Software, McGraw-Hill, 1982. [Dun01] Dunaway, D., and S. Masters, CMM-Based Appraisal for Internal Process Improvement(CBA IPI Version 1,2 Method Description) , Software Engineering Institute, 2001, downloadable from www.sei.cmu.edu/publications/documents/01.reports/01tr033.html.[Dun02] Dunn, W., Practical Design of Safety-Critical Computer Systems, William Dunn, 2002.[Duy02] VanDuyne, D., J. Landay, and J. Hong, The Design of Sites, Addison-Wesley, 2002.[Dye92] Dyer, M., The Cleanroom Approach to Quality Software Development , Wiley, 1992. [Edg95] Edgemon, J., “Right Stuff: How to Recognize It When Selecting a Project Manager,”Application Development Trends, vol. 2, no. 5, May 1995, pp. 37–42. [Eji91] Ejiogu, L., Software Engineering with Formal Metrics, QED Publishing, 1991.[Elr01] Elrad, T., R. Filman, and A. Bader (eds.), “Aspect Oriented Programming,” Comm. ACM, vol. 44, no. 10, October 2001, special issue.[Eri05] Ericson, C., Hazard Analysis Techniques for System Safety, Wiley-Interscience, 2005.[Eri08] Erickson, T., The Interaction Design Patterns Page, May 2008, available at www.visi.com/~snowfall/InteractionPatterns.html.[Eva04] Evans, E., Domain Driven Design , Addison-Wesley, 2003. [Fag86] Fagan, M., “Advances in Software Inspections,” IEEE Trans. Software Engineering,vol. 12, no. 6, July 1986.[Fel89] Felican, L., and G. Zalateu, “Validating Halstead’s Theory for Pascal Programs,” IEEETrans. Software Engineering, vol. SE-15, no. 2, December 1989, pp. 1630–1632.[Fel07] Feller, J., et al. (eds.), Perspectives on Free and Open Source Software, The MIT Press, 2007.[Fen91] Fenton, N., Software Metrics, Chapman and Hall, 1991.[Fen94] Fenton, N., “Software Measurement: A Necessary Scientific Basis,” IEEE Trans. Software Engineering, vol. SE-20, no. 3, March 1994, pp. 199–206.[Fer97] Ferguson, P., et al., “Results of Applying the Personal Software Process,” IEEE Computer,vol. 30, no. 5, May 1997, pp. 24–31.[Fer98] Ferdinandi, P. L., “Facilitating Communication,” IEEE Software, September 1998, pp. 92–96.[Fer00] Fernandez, E. B., and X. Yuan, “Semantic Analysis Patterns,” Proceedings of the
 19th Int. Conf. on Conceptual Modeling, ER2000, Lecture Notes in Computer Science 1920, Springer,2000, pp. 183–195. Also available from www.cse.fau.edu/~ed/SAPpaper2.pdf.[Fir93] Firesmith, D. G., Object-Oriented Requirements Analysis and Logical Design, Wiley, 1993.[Fis06] Fisher, R., and D. Shapiro, Beyond Reason: Using Emotions as You Negotiate , Penguin, 2006.876 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 876[Fit54] Fitts, P., “The Information Capacity of the Human Motor System in Controlling theAmplitude of Movement,” Journal of Experimental Psychology, vol. 47, 1954, pp. 381–391.[Fle98] Fleming, Q. W., and J. M. Koppelman, “Earned Value Project Management,” CrossTalk,vol. 11, no. 7, July 1998, p. 19.[Fos06] Foster, E., “Quality Culprits,” InfoWorld Grip Line Weblog, May 2, 2006, available athttp:/ /weblog.infoworld.com/gripeline/2006/05/02_a395.html.[Fow97] Fowler, M., Analysis Patterns: Reusable Object Models , Addison-Wesley, 1997. [Fow00] Fowler, M., et al., Refactoring: Improving the Design of Existing Code, Addison-Wesley,2000.[Fow01] Fowler, M., and J. Highsmith, “The Agile Manifesto,” Software Development Magazine , August 2001, www.sdmagazine.com/documents/s=844/sdm0108a/0108a.htm.[Fow02] Fowler. M., “The New Methodology,” June 2002, www.martinfowler.com/articles/newMethodology.html#N8B.[Fow03] Fowler, M., et al., Patterns of Enterprise Application Architecture, Addison-Wesley, 2003.[Fow04] Fowler, M., UML Distilled, 3d ed., Addison-Wesley, 2004.[Fra93] Frankl, P. G., and S. Weiss, “An Experimental Comparison of the Effectiveness of BranchTesting and Data Flow,” IEEE Trans. Software Engineering, vol. SE-19, no. 8, August 1993,pp. 770–787.[Fra03] Francois, A., “Software Architecture for Immersipresence,” IMSC Technical Report IMSC-03-001, University of Southern California, December 2003, available at http:/ /iris.usc.edu/~afrancoi/pdf/sai-tr.pdf.[Fre80] Freeman, P., “The Context of Design,” in Software Design Techniques, 3d ed. (P. Freemanand A. Wasserman, eds.), IEEE Computer Society Press, 1980, pp. 2–4.[Fre90] Freedman, D. P., and G. M. Weinberg, Handbook of Walkthroughs, Inspections andTechnical Reviews, 3d ed., Dorset House, 1990.[Gag04] Gage, D., and J. McCormick, “We Did Nothing Wrong,” Baseline Magazine, March 4, 2004, available at www.baselinemag.com/article2/0,1397,1544403,00.asp.[Gai95] Gaines, B., “Modeling and Forecasting the Information Sciences,” Technical Report,University of Calgary, Calgary, Alberta, September 1995.[Gam95] Gamma, E., et al., Design Patterns: Elements of Reusable Object-Oriented Software , Addison-Wesley, 1995.[Gar84] Garvin, D., “What Does ‘Product Quality’ Really Mean?” Sloan Management Review, Fall 1984, pp. 25–45.[Gar87] Garvin D., “Competing on the Eight Dimensions of Quality,” Harvard Business Review , November 1987, pp. 101–109. A summary is available at www.acm.org/crossroads/xrds6-4/software.html.[Gar95] Garlan, D., and M. Shaw, “An Introduction to Software Architecture,” Advances inSoftware Engineering and Knowledge Engineering , vol. I (V. Ambriola and G. Tortora, eds.), World Scientific Publishing Company, 1995.[Gar08] GartnerGroup, “Understanding Hype Cycles,” 2008, available at www.gartner.com/pages/story.php.id.8795.s.8.jsp.[Gau89] Gause, D. C., and G. M. Weinberg, Exploring Requirements: Quality Before Design , Dorset House, 1989.[Gey01] Geyer-Schulz, A., and M. Hahsler, “Software Engineering with Analysis Patterns,”Technical Report 01/2001, Institut für Informationsverarbeitung und -wirtschaft, Wirschaft-suniversität Wien, November 2001, downloadable from wwwai.wu-wien.ac.at/~hahsler/research/virlib_working2001/virlib/.[Gil88] Gilb, T., Principles of Software Project Management , Addison-Wesley, 1988. [Gil95] Gilb, T., “What We Fail to Do in Our Current Testing Culture,” Testing Techniques Newslet-ter(online edition, ttn@soft.com), Software Research, January 1995.[Gil06] Gillis, D., “Pattern-Based Design,” tehan + lax blog, September 14, 2006, available atwww.teehanlax.com/blog/?p=96.[Gla98] Glass, R., “Defining Quality Intuitively,” IEEE Software, May 1998, pp. 103–104, 107. [Gla00] Gladwell, M., The Tipping Point, Back Bay Books, 2002. [Gli07] Glinz, M., and R. Wieringa, “Stakeholders in Requirements Engineering,” IEEE Software,vol. 24, no. 2, March–April 2007, pp. 18–20.REFERENCES 877pre75977_Ref.qxd  11/27/08  6:40 PM  Page 877[Glu94] Gluch, D., “A Construct for Describing Software Development Risks,” CMU/SEI-94-TR-14, Software Engineering Institute, 1994.[Gna99] Gnaho, C., and F. Larcher, “A User-Centered Methodology for Complex and Customiz-able Web Engineering,” Proc. 1st ICSE Workshop on Web Engineering, ACM, Los Angeles, May1999.[Gon04] Gonzales, R., “Requirements Engineering,” Sandia National Laboratories, a slide pres-entation, available at www.incose.org/enchantment/docs/04AprRequirementsEngineer-ing.pdf.[Gor02] Gordon, B., and M. Gordon, The Complete Guide to Digital Graphic Design , Watson- Guptill, 2002.[Gor06] Gorton, I., Essential Software Architecture, Springer, 2006.[Gra87] Grady, R. B., and D. L. Caswell, Software Metrics: Establishing a Company-Wide Program, Prentice Hall, 1987.[Gra92] Grady, R. B., Practical Software Metrics for Project Management and Process Improvement , Prentice Hall, 1992.[Gra99] Grable, R., et al., “Metrics for Small Projects: Experiences at SED,” IEEE Software, March 1999, pp. 21–29. [Gra03] Gradecki, J., and N. Lesiecki, Mastering AspectJ: Aspect-Oriented Programming in Java, Wiley, 2003.[Gru02] Grundy, J., “Aspect-Oriented Component Engineering,” 2002, www.cs.auckland.ac.nz/~john-g/aspects.html.[Gus89] Gustavsson, A., “Maintaining the Evolution of Software Objects in an Integrated Envi-ronment,” Proc. 2nd Intl. Workshop on Software Configuration Management , ACM, Princeton, NJ, October 1989, pp. 114–117.[Gut93] Guttag, J. V., and J. J. Horning, Larch: Languages and Tools for Formal Specification, Springer-Verlag, 1993.[Hac98] Hackos, J., and J. Redish, User and Task Analysis for Interface Design, Wiley, 1998.[Hai02] Hailpern, B., and P. Santhanam, “Software Debugging, Testing and Verification,” IBM Systems Journal, vol. 41, no. 1, 2002, available at www.research.ibm.com/journal/sj/411/hailpern.html.[Hal77] Halstead, M., Elements of Software Science, North-Holland, 1977. [Hal90] Hall, A., “Seven Myths of Formal Methods,” IEEE Software, September 1990, pp. 11–20. [Hal98] Hall, E. M., Managing Risk: Methods for Software Systems Development , Addison-Wesley, 1998.[Ham90] Hammer, M., “Reengineer Work: Don’t Automate, Obliterate,” Harvard Business Review,July–August 1990, pp. 104–112.[Han95] Hanna, M., “Farewell to Waterfalls,” Software Magazine, May 1995, pp. 38–46. [Har98a] Harmon, P., “Navigating the Distributed Components Landscape,” Cutter IT Journal., vol. 11, no. 2, December 1998, pp. 4–11.[Har98b] Harrison, R., S. J. Counsell, and R. V. Nithi, “An Evaluation of the MOOD Set of Object-Oriented Software Metrics,” IEEE Trans. Software Engineering, vol. SE-24, no. 6, June 1998,pp. 491–496.[Her00] Herrmann, D., Software Safety and Reliability , Wiley-IEEE Computer Society Press, 2000. [Het84] Hetzel, W., The Complete Guide to Software Testing , QED Information Sciences, 1984. [Het93] Hetzel, W., Making Software Measurement Work , QED Publishing, 1993. [Hev93] Hevner, A. R., and H. D. Mills, “Box Structure Methods for System Development withObjects,” IBM Systems Journal, vol. 31, no. 2, February 1993, pp. 232–251.[Hig95] Higuera, R. P., “Team Risk Management,” CrossTalk, U.S. Dept. of Defense, January 1995, pp. 2–4.[Hig00] Highsmith, J., Adaptive Software Development: An Evolutionary Approach to ManagingComplex Systems, Dorset House Publishing, 2000.[Hig01] Highsmith, J. (ed.), “The Great Methodologies Debate: Part 1,” Cutter IT Journal., vol. 14,no. 12, December 2001.[Hig02a] Highsmith, J. (ed.), “The Great Methodologies Debate: Part 2,” Cutter IT J
 ournal., vol. 15, no. 1, January 2002.[Hig02b] Highsmith, J., Agile Software Development Ecosystems , Addison-Wesley, 2002.878 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 878[Hil05] Hildreth, S., “Buggy Software: Up from a Low Quality Quagmire,” Computerworld, July 25, 2005, available at www.computerworld.com/developmenttopics/development/story/0,10801,103378,00.html.[Hil08] Hillside.net, Patterns Catalog, 2008, available at http:/ /hillside.net/patterns/onlinepatterncatalog.htm.[Hob06] Hoberman, S., Data Modeling Made Simple, Technics Publications, 2006. [Hof00] Hofmeister, C., R. Nord, and D. Soni, Applied Software Architecture, Addison-Wesley, 2000.[Hof01] Hofmann, C., et al., “Approaches to Software Architecture,” 2001, downloadable fromhttp:/ /citeseer.nj.nec.com/84015.html.[Hol06] Holzner, S., Design Patterns for Dummies , For Dummies Publishers, 2006. [Hoo96] Hooker, D., “Seven Principles of Software Development,” September 1996, available athttp:/ /c2.com/cgi/wikiSevenPrinciplesOfSoftwareDevelopment.[Hop90] Hopper, M. D., “Rattling SABRE, New Ways to Compete on Information,” Harvard Business Review, May–June 1990.[Hor03] Horch, J., Practical Guide to Software Quality Management, 2d ed., Artech House, 2003.[HPR02] Hypermedia Design Patterns Repository, 2002, available at www.designpattern.lu.unisi.ch/index.htm.[Hum95] Humphrey, W., A Discipline for Software Engineering, Addison-Wesley, 1995.[Hum96] Humphrey, W., “Using a Defined and Measured Personal Software Process,” IEEESoftware, vol. 13, no. 3, May–June 1996, pp. 77–88.[Hum97] Humphrey, W., Introduction to the Personal Software Process , Addison-Wesley, 1997. [Hum98] Humphrey, W., “The Three Dimensions of Process Improvement, Part III: The TeamProcess,” CrossTalk, April 1998, available at www.stsc.hill.af.mil/crosstalk/1998/apr/dimensions.asp.[Hum00] Humphrey, W., Introduction to the Team Software Process, Addison-Wesley, 2000.[Hun99] Hunt, A., D. Thomas, and W. Cunningham, The Pragmatic Programmer, Addison-Wesley, 1999.[Hur83] Hurley, R. B., Decision Tables in Software Engineering , Van Nostrand-Reinhold, 1983. [Hya96] Hyatt, L., and L. Rosenberg, “A Software Quality Model and Metrics for IdentifyingProject Risks and Assessing Software Quality,” NASA SATC, 1996, available at http:/ /satc.gsfc.nasa.gov/support/STC_APR96/qualtiy/stc_qual.html.[IBM81] “Implementing Software Inspections,” course notes, IBM Systems Sciences Institute,IBM Corporation, 1981.[IBM03] IBM, Web Services Globalization Model , 2003, available at www.ibm.com/ developerworks/webservices/library/ws-global/.[IEE93a] IEEE Standards Collection: Software Engineering , IEEE Standard 610.12-1990, IEEE, 1993. [IEE93b] IEEE Standard Glossary of Software Engineering Terminology , IEEE, 1993. [IEE00] IEEE Standard Association, IEEE-Std-1471-2000, Recommended Practice for Architectural Description of Software-Intensive Systems, 2000, available at http://standards.ieee.org/reading/ieee/std_public/description/se/1471-2000_desc.html.[IFP01] Function Point Counting Practices Manual, Release 4.1.1, International Function PointUsers Group, 2001, available from www.ifpug.org/publications/manual.htm.[IFP05] Function Point Bibliography/Reference Library, International Function Point UsersGroup, 2005, available from www.ifpug.org/about/bibliography.htm.[ISI08] iSixSigma, LLC, “New to Six Sigma: A Guide for Both Novice and ExperiencesQuality Practitioners,” 2008, available at www.isixsigma.com/library/content/six-sigma-newbie.asp.[ISO00] ISO 9001: 2000 Document Set, International Organization for Standards, 2000, www.iso.ch/iso/en/iso9000-14000/iso9000/iso9000index.html.[ISO02] Z Formal Specification Notation—Syntax, Type System and Semantics , ISO/IEC 13568:2002, Intl. Standards Organization, 2002.[ISO08] ISO SPICE, 2008, www.isospice.com/categories/SPICE-Project/.[Ivo01] Ivory, M., R. Sinha, and M. Hearst, “ Empirically Validated Web Page Design Metrics,”ACM SIGCHI’01, March 31–April 4, 2001, available at http:/ /webtango.berkeley.edu/papers/chi2001/.REFERENCES 879pre75977_Ref.qxd  11/27/08  6:40 PM  Page 879[Jac75] Jackson, M. A., Principles of Program Design, Academic Press, 1975.[Jac92] Jacobson, I., Object-Oriented Software Engineering , Addison-Wesley, 1992. [Jac98] Jackman, M., “Homeopathic Remedies for Team Toxicity,” IEEE Software, July 1998,pp. 43-45.[Jac99] Jacobson, I., G. Booch, and J. Rumbaugh, The Unified Software Development Process , Addison-Wesley, 1999.[Jac02a] Jacobson, I., “A Resounding ‘Yes’ to Agile Processes—But Also More,” Cutter IT Journal,vol. 15, no. 1, January 2002, pp. 18–24.[Jac02b] Jacyntho, D., D. Schwabe, and G. Rossi, “An Architecture for Structuring Complex WebApplications,” 2002, available at www2002.org/CDROM/alternate/478/.[Jac04] Jacobson, I., and P. Ng, Aspect-Oriented Software Development , Addison-Wesley, 2004. [Jal04] Jalote, P., et al., “Timeboxing: A Process Model for Iterative Software Development,”Journal of Systems and Software,vol. 70, issue 2, 2004, pp. 117–127. Available at www.cse.iitk.ac.in/users/jalote/papers/Timeboxing.pdf.[Jay94] Jaychandra, Y., Re-engineering the Networked Enterprise , McGraw-Hill, 1994. [Jec06] Jech, T., Set Theory, 3d ed., Springer, 2006.[Jon86] Jones, C., Programming Productivity, McGraw-Hill, 1986.[Jon91] Jones, C., Systematic Software Development Using VDM , 2d ed., Prentice Hall, 1991. [Jon96] Jones, C., “How Software Estimation Tools Work,” American Programmer, vol. 9, no. 7,July 1996, pp. 19–27.[Jon98] Jones, C., Estimating Software Costs, McGraw-Hill, 1998.[Jon04] Jones, C., “Software Project Management Practices: Failure Versus Success,” CrossTalk,October 2004. Available at www.stsc.hill.af.mil/crossTalk/2004/10/0410Jones.html.[Joy00] Joy, B., “The Future Doesn’t Need Us,” Wired, vol. 8, no. 4, April 2000.[Kai02] Kaiser, J., “Elements of Effective Web Design,” About, Inc., 2002, available at http:/ /webdesign.about.com/library/weekly/aa091998.htm.[Kal03] Kalman, S., Web Security Field Guide, Cisco Press, 2003.[Kan93] Kaner, C., J. Falk, and H. Q. Nguyen, Testing Computer Software, 2d ed., Van Nostrand-Reinhold, 1993.[Kan95] Kaner, C., “Lawyers, Lawsuits, and Quality Related Costs, 1995, available at www.badsoftware.com/plaintif.htm.[Kan01] Kaner, C., “Pattern: Scenario Testing” (draft), 2001, available at www.testing.com/test-patterns/patterns/pattern-scenario-testing-kaner.html.[Kar94] Karten, N., Managing Expectations, Dorset House, 1994.[Kau95] Kauffman, S., At Home in the Universe, Oxford, 1995. [Kaz98] Kazman, R., et al., The Architectural Tradeoff Analysis Method, Software EngineeringInstitute, CMU/SEI-98-TR-008, July 1998.[Kaz03] Kazman, R., and A. Eden, “Defining the Terms Architecture, Design, and Implementa-tion,” news@sei interactive, Software Engineering Institute, vol. 6, no. 1, 2003, available atwww.sei.cmu.edu/news-at-sei/columns/the_architect/2003/1q03/architect-1q03.htm.[Kei98] Keil, M., et al., “A Framework for Identifying Software Project Risks,” CACM, vol. 41,no. 11, November 1998, pp. 76–83.[Kel00] Kelly, D., and R. Oshana, “Improving Software Quality Using Statistical Techniques,Information and Software Technology,” Elsevier, vol. 42, August 2000, pp. 801–807, availableat www.eng.auburn.edu/~kchang/comp6710/readings/Improving_Quality_with_Statistical_Testing_InfoSoftTech_August2000.pdf.[Ker78] Kernighan, B., and P. Plauger, The Elements of Programming Style, 2d ed., McGraw-Hill, 1978.[Ker05] Kerievsky, J., Industrial XP: Making XP Work in Large Organizations, Cutter Consortium,Executive Report, vol. 6., no. 2, 2005, available at www.cutter.com/content-and-analysis/resource-centers/agile-project-management/sample-our-research/apmr0502.html.[Kim04] Kim, E., “A Manifesto for Collaborative Tools,” Dr. Dobb’s Journal , May 2004, available at www.blueoxen.com/papers/0000D/.[Kir94] Kirani, S., and W. T. Tsai, “Specification and Verification of Object-Oriented Programs,”Technical Report TR 94-64, Computer Science Department, University of Minnesota,December 1994.880 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 880[Kiz05] Kizza, J., Computer Network Security, Springer, 2005.[Knu98] Knuth, D., The Art of Computer Programming, three volumes, Addison-Wesley, 1998.[Kon02] Konrad, S., and B. Cheng, “Requirements Patterns for Embedded Systems,” Proceedingsof the 10th Anniversary IEEE Joint International Conference on Requirements Engineering , IEEE, September 2002, pp. 127–136, downloadable from http:/ /citeseer.ist.psu.edu/669258.html.[Kra88] Krasner, G., and S. Pope, “A Cookbook for Using the Model-View-Controller UserInterface Paradigm in Smalltalk-80,” Journal of Object-Oriented Programming, vol. 1, no. 3, August–September 1988, pp. 26–49.[Kra95] Kraul, R., and L. Streeter, “Coordination in Software Development,” CACM, vol. 38, no. 3,March 1995, pp. 69–81.[Kru05] Krutchen, P., “Software Design in a Postmodern Era,” IEEE Software, vol. 22, no. 2,March–April, 2005, pp. 16–18.[Kru06] Kruchten, P., H. Obbink, and J. Stafford (eds.), “Software Architectural” (special issue),IEEE Software, vol. 23, no. 2, March–April, 2006.[Kur05] Kurzweil, R., The Singularity Is Near, Penguin Books, 2005.[Kyb84] Kyburg, H. E., Theory and Measurement, Cambridge University Press, 1984.[Laa00] Laakso, S., et al., “Improved Scroll Bars,” CHI 2000 Conf. Proc., ACM, 2000, pp. 97–98,available at www.cs.helsinki.fi/u/salaakso/patterns/.[Lai02] Laitenberger, A., “A Survey of Software Inspection Technologies,” in Handbook on Soft-ware Engineering and Knowledge Engineering , World Scientific Publishing Company, 2002. [Lam01] Lam, W., “Testing E-Commerce Systems: A Practical Guide,” IEEE IT Pro , March–April 2001, pp. 19–28.[Lan01] Lange, M., “It’s Testing Time! Patterns for Testing Software, June 2001, downloadablefrom www.testing.com/test-patterns/patterns/index.html.[Lan02] Land, R., “A Brief Survey of Software Architecture,” Technical Report, Dept. of ComputerEngineering, Mälardalen University, Sweden, February 2002.[Leh97a] Lehman, M., and L. Belady, Program Evolution: Processes of Software Change, AcademicPress, 1997.[Leh97b] Lehman, M., et al., “Metrics and Laws of Software Evolution—The Nineties View,”Proceedings of the 4th International Software Metrics Symposium (METRICS ’97) , IEEE, 1997, downloadable from www.ece.utexas.edu/~perry/work/papers/feast1.pdf.[Let01] Lethbridge, T., and R. Laganiere, Object-Oriented Software Engineering: Practical SoftwareDevelopment Using UML and Java, McGraw-Hill, 2001. [Let03a] Lethbridge, T., Personal communication on domain analysis, May 2003.[Let03b] Lethbridge, T., Personal communication on software metrics, June 2003.[Lev95] Leveson, N. G., Safeware: System Safety and Computers , Addison-Wesley, 1995. [Lev01] Levinson, M., “Let’s Stop Wasting $78 billion a Year,” CIO Magazine, October 15, 2001,available at www.cio.com/archive/101501/wasting.html.[Lew06] Lewicki, R., B. Barry, and D. Saunders, Essentials of Negotiation, McGraw-Hill, 2006. [Lie03] Lieberherr, K., “Demeter: Aspect-Oriented Programming,” May 2003, available atwww.ccs.neu.edu/home/lieber/LoD.html.[Lin79] Linger, R., H. Mills, and B. Witt, Structured Programming, Addison-Wesley, 1979.[Lin88] Linger, R. M., and H. D. Mills, “A Case Study in Cleanroom Software Engineering: TheIBM COBOL Structuring Facility,” Proc. COMPSAC ’88, Chicago, October 1988. [Lin94] Linger, R., “Cleanroom Process Model,” IEEE Software, vol. 11, no. 2, March 1994, pp. 50–58.[Lis88] Liskov, B., “Data Abstraction and Hierarchy,” SIGPLAN Notices, vol. 23, no. 5, May 1988. [Liu98] Liu, K., et al., “Report on the First SEBPC Workshop on Legacy Systems,” Durham Uni-versity, February 1998, available at www.dur.ac.uk/CSM/SABA/legacy-wksp1/report.html.[Lon02] Longstreet, D., “Fundamental of Function Point Analysis,” Longstreet Consulting, Inc.,2002, available at www.ifpug.com/fpafund.htm.[Lor94] Lorenz, M., and J. Kidd, Object-Oriented Software Metrics, Prentice Hall, 1994. [Maa07] Maassen, O., and S. Stelting, “Creational Patterns: Creating Objects in an OO System,”2007, available at www.informit.com/articles/article.asp?p=26452&rl=1.[Man81] Mantai, M., “The Effect of Programming Team Structures on Programming Tasks,”CACM, vol. 24, no. 3, March 1981, pp. 106–113.[Man97] Mandel, T., The Elements of User Interface Design , Wiley, 1997.REFERENCES 881pre75977_Ref.qxd  11/27/08  6:40 PM  Page 881[Mar94] Marick, B., The Craft of Software Testing, Prentice Hall, 1994.[Mar00] Martin, R., “Design Principles and Design Patterns,” downloadable from www.objectmentor.com, 2000.[Mar01] Marciniak, J. J. (ed.), Encyclopedia of Software Engineering , 2d ed., Wiley, 2001. [Mar02] Marick, B., “Software Testing Patterns,” 2002, www.testing.com/test-patterns/index.html.[McC76] McCabe, T., “A Software Complexity Measure,” IEEE Trans. Software Engineering,vol. SE-2, December 1976, pp. 308–320.[McC77] McCall, J., P. Richards, and G. Walters, “Factors in Software Quality,” three volumes,NTIS AD-A049-014, 015, 055, November 1977.[McC94] McCabe, T. J., and A. H. Watson, “Software Complexity,” CrossTalk, vol. 7, no. 12,December 1994, pp. 5–9.[McC96] McConnell, S., “Best Practices: Daily Build and Smoke Test”, IEEE Software, vol. 13, no. 4, July 1996, pp. 143–144.[McC98] McConnell, S., Software Project Survival Guide , Microsoft Press, 1998. [McC99] McConnell, S., “Software Engineering Principles,” IEEE Software, vol. 16, no. 2,March–April 1999, available at www.stevemcconnell.com/ieeesoftware/eic04.htm.[McC04] McConnell, S., Code Complete, Microsoft Press, 2004.[McC05] McCrory, A., “Ten Technologies to Watch in 2006,” SeachCIO.com, October 27, 2005,available at http:/ /searchcio.techtarget.com/originalContent/0,289142,sid19_gci1137889,00.html.[McDE93] McDermid, J., and P. Rook, “Software Development Process Models,” in SoftwareEngineer’s Reference Book, CRC Press, 1993, pp. 15/26–15/28.[McG91] McGlaughlin, R., “Some Notes on Program Design,” Software Engineering Notes, vol. 16, no. 4, October 1991, pp. 53–54.[McG94] McGregor, J. D., and T. D. Korson, “Integrated Object-Oriented Testing and Develop-ment Processes,” Communications of the ACM, vol. 37, no. 9, September, 1994, pp. 59–77.[Men01] Mendes, E., N. Mosley, and S. Counsell, “Estimating Design and Authoring Effort,” IEEEMultimedia, vol. 8, no. 1, January–March 2001, pp. 50–57.[Mer93] Merlo, E., et al., “Reengineering User Interfaces,” IEEE Software, January 1993, pp. 64–73.[Mic08] Microsoft Accessibility Technology for Everyone, 2008, available at www.microsoft.com/enable/.[Mic04] Microsoft, “Prescriptive Architecture: Integration and Patterns,” MSDN, May 2004, avail-able at http:/ /msdn2.microsoft.com/en-us/library/ms978700.aspx.[Mic07] Microsoft, “Patterns and Practices,” MSDN, 2007, available at http://msdn2.microsoft .com/en-us/library/ms998478.aspx.[Mil72] Mills, H. D., “Mathematical Foundations for Structured Programming,” Technical ReportFSC 71-6012, IBM Corp., Federal Systems Division, Gaithersburg, MD, 1972.[Mil77] Miller, E., “The Philosophy of Testing,” in Program Testing Techniques, IEEE ComputerSociety Press, 1977, pp. 1–3.[Mil87] Mills, H. D., M. Dyer, and R. Linger, “Cleanroom Software Engineering,” IEEE Software,September 1987, pp. 19–25.[Mil88] Mills, H. D., “Stepwise Refinement and Verification in Box Structured Systems,”Computer, vol. 21, no. 6, June 1988, pp. 23–35.[Mil00a] Miller, E., “WebSite Testing,” 2000, available at www.soft.com/eValid/Technology/White.Papers/website.testing.html.[Mil00b] Mili, A., and R, Cowan, “Software Engineering Technology Watch,” April 6, 2000, avail-able at www.serc.net/projects/TechWatch/NSF%20TechWatch%20Proposal.htm.[Min95] Minoli, D., Analyzing Outsourcing, McGraw-Hill, 1995.[Mon84] Monk, A. (ed.), Fundamentals of Human-Computer Interaction , Academic Press, 1984. [Mor81] Moran, T. P., “The Command Language Grammar: A Representation for the UserInterface of Interactive Computer Systems,” Intl. Journal of Man-Machine Studies , vol. 15, pp. 3–50.[Mor05] Morales, A., “The Dream Team,” Dr. Dobbs Portal , March 3, 2005, available at www.ddj .com/dept/global/184415303.882 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 882[Mus87] Musa, J. D., A. Iannino, and K. Okumoto, Engineering and Managing Software withReliability Measures, McGraw-Hill, 1987.[Mus93] Musa, J., “Operational Profiles in Software Reliability Engineering,” IEEE Software,March 1993, pp. 14–32.[Mut03] Mutafelija, B., and H. Stromberg, Systematic Process Improvement Using ISO 9001:2000 and CMMI, Artech, 2003.[Mye78] Myers, G., Composite Structured Design , Van Nostrand, 1978. [Mye79] Myers, G., The Art of Software Testing, Wiley, 1979.[NAS07] NASA, Software Risk Checklist, Form LeR-F0510.051, March 2007, downloadable fromhttp:/ /osat-ext.grc.nasa.gov/rmo/spa/SoftwareRiskChecklist.doc.[Nau69] Naur, P., and B. Randall (eds.), Software Engineering: A Report on a Conference Sponsored by the NATO Science Committee, NATO, 1969. [Ngu00] Nguyen, H., “Testing Web-Based Applications,” Software Testing and Quality Engineer- ing, May–June 2000, available at www.stqemagazine.com.[Ngu01] Nguyen, H., Testing Applications on the Web, Wiley, 2001.[Ngu06] Nguyen, T., “Model-Based Version and Configuration Management for a Web Engi-neering Lifecycle,” Proc. 15th Intl. World Wide Web Conf., Edinburg, Scotland, 2006, downloadfrom www2006.org/programme/item.php?id=4552.[Nie92] Nierstrasz, O., S. Gibbs, and D. Tsichritzis, “Component-Oriented Software Develop-ment,” CACM, vol. 35, no. 9, September 1992, pp. 160–165.[Nie94] Nielsen, J., and J. Levy, “Measuring Usability: Preference vs. Performance,” CACM, vol. 37,no. 4, April 1994, pp. 65–75.[Nie96] Nielsen, J., and A. Wagner, “User Interface Design for the WWW,” Proc. CHI ’96 Conf. onHuman Factors in Computing Systems, ACM Press, 1996, pp. 330–331.[Nie00] Nielsen, J., Designing Web Usability, New Riders Publishing, 2000.[Nog00} Nogueira, J., C. Jones, and Luqi, “Surfing the Edge of Chaos: Applications to SoftwareEngineering,” Command and Control Research and Technology Symposium, Naval PostGraduate School, Monterey, CA, June 2000, downloadable from www.dodccrp.org/2000CCRTS/cd/html/pdf_papers/Track_4/075.pdf.[Nor70] Norden, P., “Useful Tools for Project Management” in Management of Production, M. K. Starr (ed.), Penguin Books, 1970.[Nor86] Norman, D. A., “Cognitive Engineering,” in User Centered Systems Design, LawrenceEarlbaum Associates, 1986.[Nor88] Norman, D., The Design of Everyday Things, Doubleday, 1988.[Nov04] Novotny, O., “Next Generation Tools for Object-Oriented Development,” The Architec-ture Journal, January 2005, available at http://msdn2.microsoft.com/en-us/library/aa480062.aspx.[Noy02] Noyes, B., “Rugby, Anyone?” Managing Development(an online publication of Fawcette Technical Publications), June 2002, www.fawcette.com/resources/managingdev/methodologies/scrum/.[Off02] Offutt, J., “Quality Attributes of Web Software Applications,” IEEE Software, March–April 2002, pp. 25–32.[Ols99] Olsina, L., et al., “Specifying Quality Characteristics and Attributes for Web Sites,” Proc. 1st ICSE Workshop on Web Engineering , ACM, Los Angeles, May 1999. [Ols06] Olsen, G., “From COM to Common,” Component Technologies , ACM, vol. 4, no. 5, June 2006, available at http:/ /acmqueue.com/modules.php?name=Content&pa=showpage&pid=394.[OMG03a] Object Management Group, OMG Unified Modeling Language Specification , version 1.5, March 2003, available from www.rational.com/uml/resources/documentation/.[OMG03b] “Object Constraint Language Specification,” in Unified Modeling Language, v2.0, Object Management Group, September 2003, downloadable from www.omg.org.[Orf99] Orfali, R., D. Harkey, and J. Edwards, Client/Server Survival Guide, 3d ed., Wiley, 1999. [Osb90] Osborne, W. M., and E. J. Chikofsky, “Fitting Pieces to the Maintenance Puzzle,” IEEESoftware, January 1990, pp. 10–11.[OSO08] OpenSource.org, 2008, available at www .opensource.org/. [Pag85] Page-Jones, M., Pr
actical Project Management, Dorset House, 1985, p. vii.REFERENCES 883pre75977_Ref.qxd  11/27/08  6:40 PM  Page 883[Pal02] Palmer, S., and J. Felsing, A Practical Guide to Feature Driven Development, Prentice Hall,2002.[Par72] Parnas, D. L., “On Criteria to Be Used in Decomposing Systems into Modules,” CACM,vol. 14, no. 1, April 1972, pp. 221–227.[Par96a] Pardee, W., To Satisfy and Delight Your Customer, Dorset House, 1996.[Par96b] Park, R. E., W. B. Goethert, and W. A. Florac, Goal Driven Software Measurement—A Guidebook, CMU/SEI-96-BH-002, Software Engineering Institute, Carnegie MellonUniversity, August 1996.[Pat07] Patton, J., “Understanding User Centricity,” IEEE Software, vol. 24, no. 6, November–- December, 2007, pp. 9–11.[Pau94] Paulish, D., and A. Carleton, “Case Studies of Software Process Improvement Measure-ment,” Computer, vol. 27, no. 9, September 1994, pp. 50–57.[PCM03] “Technologies to Watch,” PC Magazine, July 2003, available at www.pcmag.com/article2/0,4149,1130591,00.asp.[Per74] Persig, R., Zen and the Art of Motorcycle Maintenance, Bantam Books, 1974.[Pet06] Pethokoukis, J., “Small Biz Watch: Future Business Trends,” U.S. News & World Report,January 20, 2006, available at www.usnews.com/usnews/biztech/articles/060120/20sbw.htm.[Pha89] Phadke, M. S., Quality Engineering Using Robust Design, Prentice Hall, 1989.[Pha97] Phadke, M. S., “Planning Efficient Software Tests,” CrossTalk, vol. 10, no. 10, October1997, pp. 11–15.[Phi98] Phillips, D., The Software Project Manager’s Handbook , IEEE Computer Society Press, 1998.[Phi02] Phillips, M., “CMMI V1.1 Tutorial.,” April 2002, available at www.sei.cmu.edu/cmmi/.[Pol45] Polya, G., How to Solve It, Princeton University Press, 1945.[Poo88] Poore, J. H., and H. D. Mills, “Bringing Software Under Statistical Quality Control,”Quality Progress, November 1988, pp. 52–55.[Poo93] Poore, J. H., H. D. Mills, and D. Mutchler, “Planning and Certifying Software SystemReliability,” IEEE Software, vol. 10, no. 1, January 1993, pp. 88–99.[Pop03] Poppendieck, M., and T. Poppendieck, Lean Software Development, Addison-Wesley, 2003.[Pop06a] Poppendeick, LLC, Lean Software Development, available at www.poppendieck.com/.[Pop06b] Poppendieck, M., and T. Poppendieck, Implementing Lean Software Development , Addison-Wesley, 2006.[Pop08] Popcorn, F., Faith Popcorn’s Brain Reserve, 2008, available at www.faithpopcorn.com/.[Pot04] Potter, M., Set Theory and Its Philosophy: A Critical Introduction, Oxford University Press,2004.[Pow98] Powell, T., Web Site Engineering , Prentice Hall, 1998. [Pow02] Powell, T., Web Design, 2d ed., McGraw-Hill/Osborne, 2002.[Pre94] Premerlani, W., and M. Blaha, “An Approach for Reverse Engineering of Relational Data-bases,” CACM, vol. 37, no. 5, May 1994, pp. 42–49.[Pre88] Pressman, R., Making Software Engineering Happen , Prentice Hall, 1988. [Pre05] Pressman, R., Adaptable Process Model , revision 2.0, R. S. Pressman & Associates, 2005, available at www.rspa.com/apm/index.html.[Pre08] Pressman, R., and D. Lowe, Web Engineering: A Practitioner’s Approach, McGraw-Hill,2008.[Put78] Putnam, L., “A General Empirical Solution to the Macro Software Sizing and EstimationProblem,” IEEE Trans. Software Engineering , vol. SE-4, no. 4, July 1978, pp. 345–361. [Put92] Putnam, L., and W. Myers, Measures for Excellence, Yourdon Press, 1992. [Put97a] Putnam, L., and W
. Myers, “How Solved Is the Cost Estimation Problem?” IEEE Software, November 1997, pp. 105–107.[Put97b] Putnam, L., and W. Myers, Industrial Strength Software: Effective Management Using Measurement, IEEE Computer Society Press, 1997.[Pyz03] Pyzdek, T., The Six Sigma Handbook , McGraw-Hill, 2003. [QAI08] A Software Engineering Curriculum, QAI, 2008, information can be obtained at www.qaieschool.com/innerpages/offer.asp.884 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 884[QSM02] “QSM Function Point Language Gearing Factors,” Version 2.0, Quantitative SoftwareManagement, 2002, www.qsm.com/FPGearing.html.[Rad02] Radice, R., High-Quality Low Cost Software Inspections, Paradoxicon Publishing, 2002. [Rai06] Raiffa, H., The Art and Science of Negotiation, Belknap Press, 2005.[Ree99] Reel, J. S., “Critical Success Factors in Software Projects,” IEEE Software, May 1999, pp. 18–23.[Ric01] Ricadel, A., “The State of Software Quality,” InformationWeek, May 21, 2001, available at www.informationweek.com/838/quality.htm.[Ric04] Rico, D., ROI of Software Process Improvement , J. Ross Publishing, 2004. A summary article can be found at http://davidfrico.com/rico03a.pdf.[Roc94] Roche, J. M., “Software Metrics and Measurement Principles,” Software EngineeringNotes, ACM, vol. 19, no. 1, January 1994, pp. 76–85.[Roc06] Graphic Design That Works, Rockport Publishers, 2006.[Roe00] Roetzheim, W., “Estimating Internet Development,” Software Development , August 2000, available at www.sdmagazine.com/documents/s=741/sdm0008d/0008d.htm.[Roo96] Roos, J., “The Poised Organization: Navigating Effectively on Knowledge Landscapes,”1996, available at www.imd.ch/fac/roos/paper_po.html.[Ros75] Ross, D., J. Goodenough, and C. Irvine, “Software Engineering: Process, Principles andGoals,” IEEE Computer, vol. 8, no. 5, May 1975.[Ros04] Rosenhainer, L., “Identifying Crosscutting Concerns in Requirements Specifications,”2004, available at http:/ /trese.cs.utwente.nl/workshops/oopsla-early-aspects-2004/Papers/Rosenhainer.pdf.[Rou02] Rout, T (project manager), SPICE: Software Process Assessment—Part 1: Concepts andIntroductory Guide, 2002, downloadable from www.sqi.gu.edu.au/spice/suite/download.html.[Roy70] Royce, W. W., “Managing the Development of Large Software Systems: Concepts andTechniques,” Proc. WESCON, August 1970.[Roz05] Rozanski, N., and E. Woods, Software Systems Architecture, Addison-Wesley, 2005.[Rub88] Rubin, T., User Interface Design for Computer Systems , Halstead Press (Wiley), 1988. [Rum91] Rumbaugh, J., et al., Object-Oriented Modeling and Design , Prentice Hall, 1991. [Sar06] Sarwate, A., “Hot or Not: Web Application Vulnerabilities,” SC Magazine, December 27,2006, available at http:/ /scmagazine.com/us/news/article/623765/hot-not-web-application-vulnerabilities.[Sca00] Scacchi, W., “Understanding Software Process Redesign Using Modeling, Analysis,and Simulation,” Software Process Improvement and Practice, Wiley, 2000, pp. 185–195,downloadable at www.ics.uci.edu/~wscacchi/Papers/Software_Process_Redesign/SPIP-ProSim99.pdf.[Sce02] Sceppa, D., Microsoft ADO.NET, Microsoft Press, 2002.[Sch95] Schwabe, D., and G. Rossi, “The Object-Oriented Hypermedia Design Model,” CACM,vol. 38, no. 8, August 1995, pp. 45–46.[Sch96] Schorsch, T., “The Capability Im-Maturity Model,” CrossTalk, November 1996, available at www.stsc.hill.af.mil/crosstalk/1996/11/xt96d11h.asp.[Sch98a] Schneider, G., and J. Winters, Applying Use Cases, Addison-Wesley, 1998.[Sch98b] Schwabe, D., and G. Rossi, “Developing Hypermedia Applications Using OOHDM,”Proc. Workshop on Hypermedia Development Process, Methods and Models, Hypertext ‘98 , 1998, downloadable from http:/ /citeseer.nj.nec.com/schwabe98developing.html.[Sch98c] Schulmeyer, G. C., and J. I. McManus (eds.), Handbook of Software Quality Assurance,3d ed., Prentice Hall, 1998.[Sch99] Schneidewind, N., “Measuring and Evaluating Maintenance Process Using Reliability,Risk, and Test Metrics,” IEEE Trans. SE, vol. 25, no. 6, November–December 1999,pp. 768–781, downloadable from www.dacs.dtic.mil/topics/reliability/IEEETrans.pdf.[Sch01a] Schwabe, D., G. Rossi, and Barbosa, S., “Systematic Hypermedia Application DesignUsing OOHDM,” 2001, available at www-di.inf.puc-rio.br/~schwabe/HT96WWW/section1.html.[Sch01b] Schwaber, K., and M. Beedle, Agile Software Development with SCRUM, Prentice Hall,2001.REFERENCES 885pre75977_Ref.qxd  11/27/08  6:40 PM  Page 885[Sch02] Schwaber, K., “Agile Processes and Self-Organization,” Agile Alliance, 2002,www.aanpo.org/articles/index.[Sch03] Schlickman, J., ISO 9001: 2000 Quality Management System Design , Artech House Publishers, 2003.[Sch06] Schmidt, D., “Model-Driven Engineering,” IEEE Computer, vol. 39, no. 2, February 2006,pp. 25–31.[SDS08] Spice Document Suite, “The SPICE and ISO Document Suite,” ISO-Spice, 2008, avail-able at www.isospice.com/articles/9/1/SPICE-Project/Page1.html.[Sea93] Sears, A., “Layout Appropriateness: A Metric for Evaluating User Interface WidgetLayout, IEEE Trans. Software Engineering, vol. SE-19, no. 7, July 1993, pp. 707–719.[SEE03] The Software Engineering Ethics Research Institute, “UCITA Updates,” 2003, availableat http:/ /seeri.etsu.edu/default.htm.[SEI00] SCAMPI, V1.0 Standard CMMI ®Assessment Method for Process Improvement: MethodDescription, Software Engineering Institute, Technical Report CMU/SEI-2000-TR-009, down-loadable from www.sei.cmu.edu/publications/documents/00.reports/00tr009.html.[SEI02] “Maintainability Index Technique for Measuring Program Maintainability,” SEI, 2002,available at www.sei.cmu.edu/str/descriptions/mitmpm_body.html.[SEI08] “The Ideal Model,” Software Engineering Institute, 2008, available at www.sei.cmu.edu/ideal/.[Sha95a] Shaw, M., and D. Garlan, “Formulations and Formalisms in Software Architecture,”Volume 1000—Lecture Notes in Computer Science , Springer-Verlag, 1995. [Sha95b] Shaw, M., et al., “Abstractions for Software Architecture and Tools to Support Them,”IEEE Trans. Software Engineering, vol. SE-21, no. 4, April 1995, pp. 314–335. [Sha96] Shaw, M., and D. Garlan, Software Architecture, Prentice Hall, 1996.[Sha05] Shalloway, A., and J. Trott, Design Patterns Explained, 2d ed., Addison-Wesley, 2005. [Shn80] Shneiderman, B., Software Psychology, Winthrop Publishers, 1980, p. 28.[Shn04] Shneiderman, B., and C. Plaisant, Designing the User Interface, 4th ed., Addison-Wesley,2004.[Sho83] Shooman, M. L., Software Engineering, McGraw-Hill, 1983.[Sim05] Simsion, G., and G. Witt, Data Modeling Essentials, 3d ed., Morgan Kaufman, 2005.[Sin99] Singpurwalla, N., and S. Wilson, Statistical Methods in Software Engineering: Reliabilityand Risk, Springer-Verlag, 1999.[Smi99] Smith, J., “The Estimation of Effort Based on Use Cases,” Rational Software Corp., 1999,downloadable from www.rational.com/media/whitepapers/finalTP171.PDF.[Smi05] Smith, D, Reliability, Maintainability and Risk, 7th ed., Butterworth-Heinemann, 2005.[Sne95] Sneed, H., “Planning the Reengineering of Legacy Systems,” IEEE Software, January1995, pp. 24–25.[Sne03] Snee, R., and R. Hoerl, Leading Six Sigma, Prentice Hall, 2003.[Sol99] van Solingen, R., and E. Berghout, The Goal/Question/Metric Method, McGraw-Hill, 1999. [Som97] Somerville, I., and P. Sawyer, Requirements Engineering, Wiley, 1997.[Som05] Somerville, I., “Integrating Requirements Engineering: A Tutorial,” IEEE Software,vol. 22, no. 1, January–February 2005, pp. 16–23.[SPI99] “SPICE: Software Process Assessment, Part 1: Concepts and Introduction,” Version 1.0,ISO/IEC JTC1, 1999.[Spl01] Splaine, S., and S. Jaskiel, The Web Testing Handbook , STQE Publishing, 2001. [Spo02] Spolsky, J, “The Law of Leaky Abstractions,” November 2002, available at www.joelonsoftware.com/articles/LeakyAbstractions.html.[Sri01] Sridhar, M., and N. Mandyam, “Effective Use of Data Models in Building WebApplications,” 2001, available at www2002.org/CDROM/alternate/698/.[SSO08] Software-Supportability.org, www.software-supportability.org/, 2008.[Sta97] Stapleton, J., DSDM—Dynamic System Development Method: The Method in Practice , Addison-Wesley, 1997.[Sta97b] Statz, J., D. Oxley, and P. O’Toole, “Identifying and Managing Risks for Software ProcessImprovement,” CrossTalk, April 1997, available at www.stsc.hill.af.mil/crosstalk/1997/04/identifying.asp.[Ste74] Stevens, W., G. Myers, and L. Constantine, “Structured Design,” IBM Systems Journal,vol. 13, no. 2, 1974, pp. 115–139.886 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 886[Ste93] Stewart, T. A., “Reengineering: The Hot New Managing Tool,” Fortune, August 23, 1993,pp. 41–48.[Ste99] Stelzer, D., and W. Mellis, “Success Factors of Organizational Change in SoftwareProcess Improvement,” Software Process Improvement and Practice, vol. 4, no. 4, Wiley, 1999,downloadable from www.systementwicklung.uni-koeln.de/forschung/artikel/dokumente/successfactors.pdf.[Ste03] Stephens, M., and D. Rosenberg, Extreme Programming Refactored, Apress, 2003.[Sto05] Stone, D., et al., User Interface Design and Evaluation, Morgan Kaufman, 2005.[Tai89] Tai, K. C., “What to Do Beyond Branch Testing,” ACM Software Engineering Notes, vol. 14, no. 2, April 1989, pp. 58–61.[Tay90] Taylor, D., Object-Oriented Technology: A Manager’s Guide, Addison-Wesley, 1990.[Tha97] Thayer, R. H., and M. Dorfman, Software Requirements Engineering , 2d ed., IEEE Computer Society Press, 1997.[The01] Thelin, T., H. Petersson, and C. Wohlin, “Sample Driven Inspections,” Proc. of Workshop on Inspection in Software Engineering (WISE’01) , Paris, France, July 2001, pp. 81–91, down- loadable from http://www.cas.mcmaster.ca/wise/wise01/ThelinPeterssonWohlin.pdf.[Tho92] Thomsett, R., “The Indiana Jones School of Risk Management,” American Programmer,vol. 5, no. 7, September 1992, pp. 10–18.[Tic05] TickIT, 2005, www.tickit.org/.[Tid02] Tidwell, J., “IU Patterns and Techniques,” May 2002, available at http://time-tripper.com/uipatterns/index.html.[Til93] Tillmann, G., A Practical Guide to Logical Data Modeling, McGraw-Hill, 1993.[Til00] Tillman, H., “Evaluating Quality on the Net,” Babson College, May 30, 2000, available atwww.hopetillman.com/findqual.html#2.[Tog01] Tognozzi, B., “First Principles,” askTOG, 2001, available at www.asktog.com/basics/firstPrinciples.html.[Tra95] Tracz, W., “Third International Conference on Software Reuse—Summary,” ACM Software Engineering Notes, vol. 20, no. 2, April 1995, pp. 21–22.[Tre03] Trivedi, R, Professional Web Services Security, Wrox Press, 2003.[Tri05] Tricker, R., and B. Sherring-Lucas, ISO 9001: 2000 In Brief, 2d ed., Butterworth- Heinemann, 2005.[Tyr05] Tyree, J., and A. Akerman, “Architectural Decisions: Demystifying Architecture,” IEEE Software, vol. 22, no. 2, March–April, 2005.[Uem99] Uemura, T., S. Kusumoto, and K. Inoue: “A Function Point Measurement Tool for UMLDesign Specifications,’” Proc. of Sixth International Symposium on Software Metrics , IEEE, November 1999, pp. 62–69[Ull97] Ullman, E., Close to the Machine: Technophilia and Its Discontents, City Lights Books,2002.[UML03] The UML Café, “Customers Don’t Print Themselves,” May 2003, available atwww.theumlcafe.com/a0079.htm. [Uni03] Unicode, Inc., The Unicode Home Page , 2003, available at www.unicode.org/. [USA87] Management Quality Insight, AFCSP 800-14 (U.S. Air Force), January 20, 1987.[Vac06] Vacca, J., Practical Internet Security, Springer, 2006.[Van89] Van Vleck, T., “Three Questions About Each Bug You Find,” ACM Software EngineeringNotes, vol. 14, no. 5, July 1989, pp. 62–63.[Van02] Van Steen, M., and A. Tanenbaum, Distributed Systems: Principles and Paradigms,Prentice Hall, 2002.[Ven03] Venners, B., “Design by Contract: A Conversation with Bertrand Meyer,” ArtimaDeveloper, December 8, 2003, available at www.artima.com/intv/contracts.html.[Wal03] Wallace, D., I. Raggett, and J. Aufgang, Extreme Programming for Web Projects, Addison- Wesley, 2003.[War74] Warnier, J. D., Logical Construction of Programs, V an Nostrand-Reinhold, 1974. [W
ar07] Ward, M., “Using VoIP Software Building zBlocks—A Look at the Choices,” TMNNet,2007, available at www.tmcnet.com/voip/0605/featurearticle-using-voip-software-building-blocks.htm.[Web05] Weber, S., The Success of Open Source, Harvard University Press, 2005.[Wei86] Weinberg, G., On Becoming a Technical Leader, Dorset House, 1986.REFERENCES 887pre75977_Ref.qxd  11/27/08  6:40 PM  Page 887[Wel99] Wells, D., “XP—Unit Tests,” 1999, available at www.extremeprogramming.org/rules/unittests.html.[Wel01] vanWelie, M., “Interaction Design Patterns,” 2001, available at www.welie.com/patterns/.[Whi95] Whittle, B., “Models and Languages for Component Description and Reuse,” ACMSoftware Engineering Notes, vol. 20, no. 2, April 1995, pp. 76–89.[Whi97] Whitmire, S., Object-Oriented Design Measurement, Wiley, 1997.[Wie02] Wiegers, K., Peer Reviews in Software, Addison-Wesley, 2002.[Wie03] Wiegers, K., Software Requirements, 2d ed., Microsoft Press, 2003. [Wil93] Wilde, N., and R. Huitt, “Maintaining Object-Oriented Software,” IEEE Software , January 1993, pp. 75–80.[Wil97] Williams, R. C, J. A. Walker, and A. J. Dorofee, “Putting Risk Management into Practice,”IEEE Software, May 1997, pp. 75–81.[Wil99] Wilkens, T. T., “Earned Value, Clear and Simple,” Primavera Systems, April 1, 1999, p. 2.[Wil00] Williams, L., and R. Kessler, “All I Really Need to Know about Pair Programming ILearned in Kindergarten,” CACM, vol. 43, no. 5, May 2000, available at http:/ /collaboration.csc.ncsu.edu/laurie/Papers/Kindergarten.PDF.[Wil05] Willoughby, M., “Q&A: Quality Software Means More Secure Software,” Computerworld, March 21, 2005, available at www.computerworld.com/securitytopics/security/story/0,10801,91316,00.html.[Win90] Wing, J. M., “A Specifier’s Introduction to Formal Methods,” IEEE Computer, vol. 23,no. 9, September 1990, pp. 8–24.[Wir71] Wirth, N., “Program Development by Stepwise Refinement,” CACM, vol. 14, no. 4, 1971, pp. 221–227.[Wir90] Wirfs-Brock, R., B. Wilkerson, and L. Weiner, Designing Object-Oriented Software, Prentice Hall, 1990.[WMT02] Web Mapping Testbed Tutorial., 2002, available at www.webmapping.org/vcgdocuments/vcgTutorial/.[Woh94] Wohlin, C., and P. Runeson, “Certification of Software Components,” IEEE Trans.Software Engineering, vol. SE-20, no. 6, June 1994, pp. 494–499.[Wor04] World Bank, Digital Technology Risk Checklist , 2004, downloadable from www.moonv6.org/lists/att-0223/WWBANK_Technology_Risk_Checklist_Ver_6point1.pdf.[W3C03] World Wide Web Consortium, Web Content Accessibility Guidelines, 2003, available atwww.w3.org/TR/2003/WD-WCAG20-20030624/.[Yac03] Yacoub, S., et al., Pattern-Oriented Analysis and Design, Addison-Wesley, 2003.[You75] Yourdon, E., Techniques of Program Structure and Design, Prentice Hall, 1975.[You79] Yourdon, E., and L. Constantine, Structured Design, Prentice Hall, 1979. [You95] Yourdon, E., “When Good Enough Is Best,” IEEE Software, vol. 12, no. 3, May 1995,pp. 79–81.[You01] Young, R., Effective Requirements Practices, Addison-Wesley, 2001.[Zah90] Zahniser, R. A., “Building Software in Groups,” American Programmer, vol. 3, nos. 7–8,July–August 1990.[Zah94] Zahniser, R., “Timeboxing for Top Team Performance,” Software Development, March1994, pp. 35–38.[Zha98] Zhao, J, “On Assessing the Complexity of Software Architectures,” Proc. Intl. SoftwareArchitecture Workshop, ACM, Orlando, FL, 1998, pp. 163–167.[Zha02] Zhao, H., “Fitt’s Law: Modeling Movement Time in HCI,” Theories in Computer HumanInteraction, University of Maryland, October 2002, available at www.cs.umd.edu/class/fall2002/cmsc838s/tichi/fitts.html.[Zul92] Zultner, R., “Quality Function Deployment for Software: Satisfying Customers,” American Programmer, February 1992, pp. 28–41.[Zus90] Zuse, H., Software Complexity: Measures and Methods , DeGruyter, 1990. [Zus97] Zuse, H., A Framework of Software Measurement , DeGruyter, 1997.888 REFERENCESpre75977_Ref.qxd  11/27/08  6:40 PM  Page 888INDEX
Abstract interface design, 392Abstraction 99, 223, 284Access control, 597Accessibility, 334, 541ACS-DCV function, SafeHome,157Action, 14Activity, see also Frameworkactivity, 15Activity diagram, 162, 294, 853Actors, 134Adaptive Software Development(ASD), 81Aesthetic design, 380Aggregation, 845Agile manifesto, 65Agile modeling, 88Agility, 67cost of change, 67human factors, 71politics of, 70principles of, 69process, 68Alpha testing, 469Ambient intelligence, 815Analysis classes,Attributes, 171defining operations, 171identification of, 169selection criteria, 169state diagrams for, 196types of, 174Analysis model (see also,Requirementsmodel), 138class-based, 168elements of, 154flow oriented, 187scenario-based, 154Analysis patterns, 142, 199Anchor points, 46Application domains, 7Archetypes, 257Architectural alternatives, 255Architectural decisions, 246template for, 247Architectural description language(ADL), 224, 264Architectural design, see alsoDesign, architecturalcontext diagram, 256elements of, 234metrics, 624WebApps, 383Architectural mapping, 265Architectural patterns, 253Architectural structures, 250grid, 385hierarchical, 385linear, 384networked, 386Architecture,assessment of, 261complexity of, 263data centered, 250data flow, 251definition of, 223, 244genres, 247importance of, 245instantiations of, 260layered, 253MVC, 387object-oriented, 252patterns, 360refinement of, 258styles, 249types of, 250Architecture Trade-Off AnalysisMethod (ATAM), 262Aspect-oriented development, 52Aspects, 52, 228Associations, 180Attributes, 865specifying, 171Auditing, 609Availability, 375Baselines,definition of, 588project database, 588Basis path testing, 485Behavior models, 195testing of, 526Beta testing, 469Black-box testing, 495Bootstrap, 803Boundary value analysis, 498, 544Box structure specification,558, 561Bugs, characteristics of, 473Business process reengineering(BPR), 765Call and return architecture, 251Capability Maturity Model(CMM), 789Capability Maturity ModelIntegration (CMMI),797, 800Certification, 560, 567Change, 585Change control, 596process description, 597types of, 598Change control authority(CCA), 596Change management, 606Change request, 596Change set, 595Chaos, 38Check-in, 597, 606Checkout, 597, 606Chunking, 299CK metrics suite, 628Class diagrams, 842Class model, consistency, 514Class responsibility collaborator(CRC) model, 173, 514Class testing, 516Class-based modeling, 167Classes,basic concepts, 863design attributes, 868metrics for, 628testing methods, 522Classic life cycle, 39Cleanroom software engineering,51, 558design, 563process model, 559strategy, 558testing, 566Cluster testing, 467, 517COCOMO II, 709Code metrics, 638Code restructuring, 771Coding principles, 111Cohesion, 227, 286metrics for, 633types of, 287Collaboration, 126, 177Collaborative development, 822Common Closure Principle(CCP), 285Common Reuse Principle (CRP), 285Communication, 15, 101Communication diagram, 852Compatibility tests, 542Complexity,architectural, 263metrics defining, 634Component-based development,6, 50, 303Component-based softwareengineering (CBSE), 303889pre75977_Index.qxd  11/27/08  6:39 PM  Page 889Component-level design (seeDesign, component level)Components,adaptation, 305architectural design, 258class-based, 282classifying, 307composition, 305definition of, 277dependencies, 286design of, 237interfaces, 286metrics for, 632naming conventions, 286process-related view, 281object-oriented view 277qualification, 304retrieving, 308traditional, 298, 279wrapping, 305Composite aggregate class, 178Composite information, 164Composition, 845Concerns, 228Concretions, 284Concurrent engineering, 48Condition testing, 492Condition-transition-consequence (CTC), 754Configuration audit, 599Configuration objects, 589identification, 594WebApps, 603Configuration review, 468Configuration testing, 547Construction, 15, 111Content architecture, 384Content design, 297, 382Content management, 603Content object, 208, 382Content testing, 534Contingency planning, 757Control specification (CSPEC), 191Control structure testing, 492Correctness, 680verification, 559, 564Costs,change, 67defects, 417quality, 408Coupling, 227, 288categories, 289metrics 633CRC cards, 75Critical modules, 464Critical path, 724Cross cutting concerns, 52, 228Crystal, 85Customers, 103Cyclomatic complexity, 488Data abstraction, 223Data attibutes, 164Data design, 234Data flow architecture, 251Data flow diagram, 188context level, 188creation of, 189Data flow testing, 493Data invariant, 569Data modeling, 164Data objects, 164relationships, 165Data restructuring, 771Data tree, 208Database testing, 535Data-centered architecture, 250Debugging, 473automated, 476process, 473psychologicalconsiderations, 474strategies, 475tactics, 476tools, 477Decision tables, 300Decision trees, 716Defect amplification, 418Defect removal efficiency(DRE), 681Defects, 417Definition-use chain, 493Dependencies, 181, 844Dependency Inversion Principle(DIP), 284Dependency tracking, 592Deployment, 15diagrams, 846principles, 113testing, 472Design classes,characteristics of, 231types of, 230Design for reuse (DFR), 307Design model, 233dimensions of, 233metrics, 624Design patterns, 348description of, 348, 352goals, 349granularity, 369template, 353types of, 351Design process, 219Design quality, assessment of, 220Design recovery, 771Design verification, 564Design, 215architectural, 255component level, 237, 276design steps, 290graphical notation, 299guidelines, 285principles, 282tabular notation, 300WebApps, 296concepts, 222deployment level, 238description of, 243domain driven, 78evolution of, 221generic task set, 222granularity, 369object-oriented, 230pattern-based, 224, 347, 354postmodern, 825principles, 109reuse issues, 307user interface, 312, 319, 328,342, 331, 330user-centric, 318WebApps, see also WebApps,373, 377XP, 75Deterioration, 5Display content, 327Document restructuring, 770Domain analysis, 151Domain driven design, 78Domain engineering, 303Drivers, 458Dynamic Systems DevelopmentMethod (DSDM), 84Earned value analysis (EVA), 739Efficiency, 404Elaboration, 122, 228, 324Elicitation, 121, 128work products, 133End users, 103Engineering change order(ECO), 596Entity relationship (ER)diagrams, 166Equivalence partitioning, 497, 544Error density, 421Errorscorrection of, 409, 477definition of, 417estimation, 692handling, 333Estimation, 697agile, 713automated, 708decomposition techniques, 698empirical models, 708example of, 704FP-based, 702LOC-based, 700OO projects, 712problem-based, 699process-based, 703reconciling, 707use cases, 705WebApps, 714Ethics, 838Events, 195Evolutionary process model,42, 49890INDEXpre75977_Index.qxd  11/27/08  6:39 PM  Page 890INDEX 891Extreme Programming (XP), 72coding, 76debate about, 78design, 75Industrial XP, 77key elements, 72planning, 73process, 73testing, 76Factoring, 268Failure, 442Failure curve, 6Failures-in-time (FIT), 443Feature definition, 86Feature Driven Development(FDD), 86Fitt’s Law, 337Flow graph notation, 486Flow-oriented modeling, 187Formal design, 559Formal methods, 51, 558concepts, 568examples of, 568languages, 573mathematical notation, 571Formal technical reviews, seealso Reviews, 426Forward engineering, 771, 778client server, 779OO systems, 780Framework activity, 15, 32Framework models, 224Frameworks, 352, 787Function point (FP), 620, 674estimation of, 703Functional design, 297Functional independence, 227Functional model, WebApps, 210Functional specification, 560Functionality, 403Genres, 247Glass-box testing, 485Globalization, 813Golden rules, 313Good-enough software, 406Grammatical parse, 169, 189Granularity, 105Graph matrix, 491, 496Graphic design, WebApps, 380Guard, 197Hazard analysis, 444, 757Help facilities, 332Human factors, agility, 71Inception, 121Increment planning, 558Independent paths, 487Independent test group(ITG), 452Indicator, 614Information,representation, 835spectrum, 836Information flow continuity, 188Information hiding, 226Inheritance, 866Inspections (see Reviews)Integration testing, 459bottom-up, 461breadth-first, 460depth-first, 460OO context, 466, 516top-down, 459work products, 464Integrity, 680Interaction mechanisms, 313Interaction model, WebApps, 209Interfaceanalysis, 320design, 235, 320mechanisms, testing of, 538semantics, testing of, 540testing, 537Interface Segregation Principle(ISP), 284Internationalization, 334Inventory analysis, 770ISO 9001:2000, 38, 444ISO 9126 quality factors, 403Issues list, 427Lean Software development(LSD), 87Legacy software, 9Liability, 410Lines of code (LOC), 674Liskov Substitution Principle(LSP), 284Load testing, 551Loop testing, 493Maintainability, 404, 680, 762Maintenance, 6, 762metrics, 641Make/Buy decision, 715Mapping, architectural, 265Maturity model, 789Mean-time-between-failure(MTBF), 442Mean-time-to-repair (MTTR), 442Measure, 614Measurement, see also Metrics,614, 616, 671Mental model, 318Messages, 867Metaphors, 338Metrics,architectural design, 624arguments in favor, 683attributes of, 618baseline, 683class-oriented, 627components, 632cyclomatic complexity, 488definition of, 614design model, 624establishing a program, 686etiquette, 669function-oriented, 673maintenance, 641morphology, 625object-oriented, 627, 675process, 667product, 613project, 670public and private, 668reconciling LOC and FP, 673reliability, 442requirements, 619size-oriented, 672small organizations, 684software quality, 679specification quality, 623SPI, 667SQA, 438technical reviews, 420terminology, 614testing, 639use cases, 676user interface, 635WebApps, 636, 677Modeling, 15, 105Model-View-Controller(MVC), 387Modularity, 100, 225MOOD metrics suite, 631Multiplicity, 180, 844Myths, 22Navigation design, WebApps, 388Navigation modeling, 212Navigation semantic units(NSUs), 388, 546Navigation semantics, 388Navigation syntax, 389Navigation testing, 545Negligence, 410Negotiation, 122, 143Netsourcing, 9Object constraint language(OCL), 574example of, 576notation, 574, 859Object elaboration, 324Object points, 710Object-oriented,analysis, 153, 187architecture, 252design, 230models, 514OMG/CORBA, 306OOHDM, 390Open source software, 9, 818Open world computing, 8, 815Open-closed principle (OCP), 282pre75977_Index.qxd  11/27/08  6:39 PM  Page 891Operations, 171, 865Orthogonal array testing, 499Outsourcing, 717Packages, 182Pair programming, 76, 425Partition testing, 524Path testing, 544Pattern languages, 353Pattern organizing table, 358Patterns, 100analysis, 142, 199architecture, 253, 360component-level, 362creational, 350description of, 352design, 224, 348generative, 350repository, 353requirements modeling, 199testing, 507user interface, 330, 364WebApps, 368People, 647, 834effort, 725communication issues, 655People CMM, 801Performance testing, 471, 550Personal Software Process (PSP),56, 803Phase pattern, 35Planning, 15effort distribution, 727principles, 103XP, 73Polymorphism, 868Portability, 404Postcondition, 569Practice, 17description of, 97essence of, 17principles, 99Precondition, 569Priority points, 127Problem decomposition, 656Procedural abstraction, 223Process,adaptation, 16agile, 68business level, 765decomposition, 658duality of, 60elements of, 14management issues, 657metrics integration, 682patterns, 35, 37principles, 98trends, 819Process activation table, 193Process assessment, 37Process flow, 31Process framework, 15, 32Process improvement (seeSoftware ProcessImprovement)Process model,activities, 31agile, 80aspect-oriented, 52concurrent, 48evolutionary, 42generic, 31incremental, 41prescriptive, 38specialized, 50work flow, 39Process specification (PSPEC), 194Process technology, 59Producer, 426Product, 648, 656Program design language(PDL), 301Project, 648, 660Project management,concepts, 646critical practices, 662Project planning, 691estimation, 692resources, 695task set, 694Project tracking, 734Project velocity, 74Proof of correctness, 564Prototyping, 43, 319Putnam-Norden-Rayleigh (PNR)Curve, 726Quality, see also Software quality,guidelines, 219management, 397, 435measurement, 680metrics, 680views of, 399Quality function deployment(QFD), 131Questions, context free, 127Random testing, 522Readability, 339Recovery testing, 470Reengineering, see also Softwarereengineering, 764Refactoring, 75, 229, 292Refinement, 228Regression testing, 462Release Reuse EquivalencyPrinciple (REP), 285Reliability, 403definition of, 442metrics, 442Reporting, 609Repository, 308, 590design patterns, 361features, 591hypermedia, 370role of, 590Requirements,emergent, 816negotiating, 142tracing, 592validating, 144Requirements analysis, 149limits on, 205objectives, 150rules of thumb, 151Requirements engineering,120, 824Requirements gathering, 127, 558Requirements management, 124Requirements model, 138class-based, 168elements of, 139eliciting, 140metrics, 619scenario-based, 154Requirements modeling,approaches, 153input to, 206output from, 207patterns, 199principles, 107strategies, 186WebApps, 205Requirements specification,template, 123Requirements validationchecklist, 124Resources, 695Response time, 332Responsibilities, 175allocation guidelines, 175Restructuring, 776Reuse, 306Reuse library, 308Reverse engineering, 770, 772data, 773processing, 774user interface, 775Review leader, 426Review meeting, 426Reviews, 220, 416analyzing effectiveness, 421checklists, 425cost effectiveness, 421development effort , 422formality spectrum, 423guidelines, 427informal, 424inspection data, 422issues list, 427metrics for, 420record keeping, 427reference model, 423reporting, 427sample driven, 429summary report, 427walkthroughs, 426892INDEXpre75977_Index.qxd  11/27/08  6:39 PM  Page 892Risk exposure, 753Risk information sheet, 757Risk item checklist, 748Risk management, 744, 795Risk table, 751Risks, 409assessing, 748components and drivers, 749CTC format, 755exposure from, 753identification of, 747impact of, 752mitigation, 756projection, 749refinement, 755types of, 746RMMM plan, 757SafeHome,24, 45, 47ACS-DCV function, 157activity diagram, 211actors, 135agile development, 79archetypes, 258architecture assessment, 263architecture refinement,254, 272behavioral modeling, 141CK metrics, 630class diagram, 174class models, 173class testing, 523cohesion, 288content design, 382context diagram, 257coupling, 289CRC models, 179customer communication, 103cyclomatic complexity, 488data flow model, 189, 193, 622data tree, 208debugging, 475design class, 232design concepts, 229design vs. coding, 218domain analysis, 153estimation, 702function points, 622golden rules, 315grammatical parse, 169interface design review, 339interface representation, 236metrics approach, 682metrics debates, 619negotiation, 143NSUs, 388OCP in action, 283outsourcing, 717patterns, 364preliminary user scenario, 132product narrative, 129project initiation, 24project metrics, 670project tracking, 739PSPEC, 194requirements gathering, 131reviews, 430risk analysis, 755SCM issues, 598screen layout, 329state diagram, 192team structure, 655test case design, 484test preparations, 454UI design, 323use cases, 138, 155, 160, 161validation, 469WebApp, 206, 543Scalability, 375SCAMPI, 37Scenario-based modeling, 154Scheduling, 721concepts, 722principles, 725WebApps, 736Scope, 656Scrum, 82Security, 375, 410, 680Security testing, 470, 548Self-organization, 72Sensitivity testing, 471Separation of concerns, 99, 225Sequence diagram, 198, 202, 848Six Sigma, 441Smoke testing, 463Software,application domains, 7building blocks, 817characteristics, 4death of, 2definition of, 4economist’s view, 30importance of, 834myths, 20nature of, 3open source, 818open-world, 815questions about, 4Software architecture, see alsoArchitecture, 223Software configuration items(SCIs), 584, 589elements of, 587process, 593repository, 590scenario, 586standards, 609tasks, 593WebApps, 601Software design, see alsoDesign, 215Software engineering,core principles, 98definition of, 13environments, 828ethics, 838general principles, 19layers, 14model driven, 825practice, 17, 96realities, 12test driven, 826Software equation, 711Software evolution, 762Software increment, 16Software maintenance, see alsoMaintenance, 762Software maturity index, 641Software Metrics (see Metrics)Software process improvement(SPI), 667, 786approaches to, 37assessment, 791constituencies, 788critical success factors, 796definition of, 787education, 793elements of, 788framework, 787installation/migration, 794process, 791risk management, 795ROI, 804selection/justification, 793trends, 805Software process (see Process)Software quality, 220achieving, 412assessing, 404cost of, 407definition of, 400design guidelines, 219dilemma, 406dimensions of, 401elements of, 400impact of managementactions, 411McCall’s factors, 402quantitative view, 405relative costs, 409Software quality assurance(SQA), 413, 432attributes, 438elements of, 434formal approaches, 438goals, 437metrics, 438planning, 445statistical, 439tasks, 436Software quality control, 412Software reengineering,economics of, 780process model, 768Software reliability (see Reliability)Software repository (seeRepository)Software safety, 443, 757Software science, 638INDEX 893pre75977_Index.qxd  11/27/08  6:39 PM  Page 893Software scope, 694Software sizing, 698Software team, (see Team)Software testing (see Testing)Software tools (see Tools)Specification, 122SPICE, 38, 803Spike solution, 75Spiral model, 45, 319Stage pattern, 35Stakeholders, 15, 104, 649identifying, 125multiple viewpoints, 126Standards, component-based, 282State diagram, 141, 295, 856State representations, 196Statistical SPI, 669Statistical use testing, 566Status reporting, 600Stereotype, 181, 843Story-driven development, 78Stress testing, 471, 552Strong AI, 837Structure chart, 280Structured analysis, 153, 186Structured design, 265Structured programming, 298Stubs, 458Styles, 249Subclass, 865Superclass, 865Supportability, 764Swimlane diagram, 163Synchronization control, 597System of forces, 348System perception, 317System testing, 470Task, 14analysis, 322elaboration, 324network, 731pattern, 35Task set, 31, 33example, 729identifying, 34Team, 651agile, 654future trends, 817jelling of, 653leaders, 649self organizing, 72structures, 651Team Software Process (TSP),58, 803Technical reviews (see Reviews)Technology,evolution, 809grand challenge, 821hype cycle, 812innovation cycle, 810long view, 837managing complexity, 814trends, 808, 818Test cases, 489Testability, 482Testing,behavior models, 526black box, 495class hierarchy, 519client/server, 503completion criteria, 455component level, 543content, 534control structure, 492conventional software,456, 481data flow, 493database, 535deep structure, 522documentation, 505exhaustive, 485fault-based, 519fundamentals, 482graph-based, 495GUIs, 503, 537help facilities, 505loops, 493metrics, 639model-based, 502multiple classes, 524navigation paths, 545object-oriented software, 465,511, 516organization, 451patterns, 507performance, 550principles, 112real-time systems, 506scenario-based, 520security, 548specialized, 503state-based, 524statistical, 560, 566strategic approach, 450, 455surface structure, 522thread-based, 466, 517use-based, 466, 517WebApps, 467, 529, 547white-box, 485XP, 76TickIT, 803Time-line charts, 732Time-to-market, 376Tools,ADLs, 264agile development, 90analysis modeing withUML, 199architectural design, 260BPR, 767CBSE, 309change management, 605, 608CVS, 596data modeling, 167debugging, 477estimation, 714formal methods, 580process management, 53process modeling, 60product metrics, 641project and process, 679project management, 662requirements engineering, 125restructuring, 777reverse engineering, 776risk management, 758scheduling, 732SCM support, 600SQA, 446structured analysis, 194test case design, 501test management, 472trends, 827UI development, 335use case development, 138WebApp metrics, 638WebApp testing, 552Trends, 812Umbrella activities, 16UML, 841activity diagram, 162, 211,294, 854class diagram notation, 843communication diagramnotation, 852component diagram, 237deployment diagram notation,238, 846generalization, 843history of, 841OCL, 859realization, 843sequence diagram, 198, 850state diagram, 295, 857stereotype, 181, 843swimlane diagram, 163,326, 855use-case diagram, 847Unified Process, 53agile version, 89phases of, 54Unit testing, 456considerations, 457OO context, 466, 516Usability, 312, 317, 404design, 235tests, 540questions, 541Usage scenarios, 132Use cases, 132creating, 155diagram, 846exceptions, 159formal, 159894INDEXpre75977_Index.qxd  11/27/08  6:39 PM  Page 894interface design, 322isolating events, 195refining, 158supplementary UMLmodels, 161template, 136Use-based testing, 466, 517User analysis, 321User interface,analysis of, 317design model, 317patterns, 364testing of, 537User Interface Design (see alsoDesign, user interface),312User model, 318User stories, 74Users, types of, 318Validation, 112, 123, 451Validation testing, 468OO context, 517test criteria, 468Verification, 451Version control, 595, 608Versioning, 592Vital few, 439V-model, 40W
5HH principle, 661Walkthroughs (see Reviews)Waterfall model, 39Ways of navigating (WoN), 388Wear, 5Web applications (WebApps),8, 10aesthetic design, 380architectural design, 383characteristics of, 11component-level design,296, 390configurationmanagement, 601configuration model, 211configuration objects, 603content model, 207design patterns, 368design pyramid, 378design quality, 374errors, 531functional model, 210interaction model, 209interface design, 336, 340, 377managing changes, 606metrics, 636navigation design, 388navigation modeling, 211quality dimensions, 530requirements modeling, 205test planning, 532testing concepts, 530testing process, 533testing strategy, 532user interface design, 335White-box testing, 485Work breakdown structure(WBS), 732Work environment, 328Work flow, 39, 325XP (see Extreme Programming)Z specification language, 577INDEX 895pre75977_Index.qxd  11/27/08  6:39 PM  Page 895pre75977_Index.qxd  11/27/08  6:39 PM  Page 896pre75977_Index.qxd  11/27/08  6:39 PM  Page 897pre75977_Index.qxd  11/27/08  6:39 PM  Page 898pre75977_Index.qxd  11/27/08  6:39 PM  Page 899pre75977_Index.qxd  11/27/08  6:39 PM  Page 900Praise for earlier editions of
Software Engineering: A Practitioner’s Approach
“Roger Pressman has written a solid comprehensive guidebook for the /f#5fi  eld of software 
engineering for both students of the discipline and software developers and managers 
practicing it—or needing to practice it.” IEEE Software
“This is a classic modern textbook, clear and authoritative, with lots of pictures, examples, 
questions and references ... . I recommend it to anyone who asks, ‘What is software 
engineering and where is it now?’ ACM Computing Reviews
“An up-to-the minute, in-depth treatment of the software engineering process.”
Byte Book Club (main selection)
“... had the best explanations of what I want to cover ...”
“... The de/f#5fi  nitive book on the subject as far as I’m concerned ...”
“... A good textbook as well as reference ...” from comp.software-eng FAQ
“As a practicing Software Engineer, I /f#5fi  nd this book to be invaluable. It has served as 
a great reference for all the projects that I have worked on.”
“This book is a framework on how to develop high quality software.”
reviews from Amazon.com
For almost three decades, Software Engineering: A Practitioner’s Approach has been the best selling guide to software 
engineering for students and industry professionals alike.
In its seventh edition, the book has been restructured and redesigned, undergoing a substantial content update 
that addresses every important topic in what many have called “the engineering discipline of the 21st century.” 
Unique sidebars and marginal content have been expanded and enhanced, o/f#5ff  ering the reader an entertaining 
and informative complement to chapter topics. New chapters and a new organization make the book still easier 
to use in the classroom and as a self-study guide.
  Part 1, The Software Process, presents both prescriptive and agile process models.
  Part 2, Modeling, presents modern analysis and design methods with a new emphasis on UML-based modeling. 
   Part 3, Quality Management, is new for the seventh edition and address all aspects of software testing, quality 
assurance, formal veri/f#5fi  cation techniques, and change management.
   Part 4, Managing Software Projects, presents topics that are relevant to those who plan, manage, and control 
a software project. 
   Part 5, Advanced Topics, presents dedicated chapters that address software process improvement and 
future software engineering trends.
Roger Pressman, continuing in the tradition of his earlier editions, has written a book that will serve as an excellent 
guide to software engineering for everyone who must understand, build, or manage computer-based systems.
Visit the book’s On-Line Learning Center at www.mhhe.com/pressman.
The site, visited by thousands of readers each month, has been signi/f#5fi  cantly expanded and updated to provide 
comprehensive software engineering resources for students, instructors, and industry professionals.Software Engineering
A Practitioner’s Approach
Seventh Edition
Roger S. PressmanSeventh 
EditionSoftware EngineeringA Practitioner’s Approach
Pressman
Roger S. Pressman, Ph.D
MD DALIM #1001702 12/23/08 CYAN MAG YELO BLK